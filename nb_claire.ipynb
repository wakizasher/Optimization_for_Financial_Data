{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cbf4b9b-d353-4f33-a9b7-935886871687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (2.1.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from xgboost) (1.26.4)\nRequirement already satisfied: nvidia-nccl-cu12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from xgboost) (2.24.3)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%python \n",
    "%pip install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a278cc7-275a-4a37-b62c-d2f434d52da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO Load the trainers from the trainers folder\n",
    "# Note it might be necessary to change the import of each trainer to the appropriate path for the abstract class Trainer\n",
    "from abstract_classes.trainer import Trainer\n",
    "# Import the Trainer classes from the trainers folder\n",
    "from trainers.trainer_decision_tree import TrainerDecisionTree\n",
    "from trainers.trainer_average_last_year import TrainerAverageLastYear\n",
    "from trainers.trainer_gradient_boosting import TrainerGradientBoosting\n",
    "from trainers.trainer_knn import TrainerKNeighborsRegressor\n",
    "from trainers.trainer_random_forest import TrainerRandomForest\n",
    "from trainers.trainer_xgboost import TrainerXGBoost\n",
    "from trainers.trainer_moving_average import TrainerMovingAverage\n",
    "from trainers.trainer_value_last_years import TrainerValueLastYears\n",
    "from trainers.trainer_random_forest_pattern import TrainerRandomForestPattern\n",
    "from trainers.trainer_xgboost_pattern import TrainerXGBoostPattern\n",
    "from trainers.trainer_majority_selector import TrainerMajoritySelector\n",
    "from clairevoyance.helper_functions.dataframe_transformer import DataframeTransformer\n",
    "from clairevoyance.helper_functions.pattern_finder import PatternFinder\n",
    "from clairevoyance.helper_functions.trend_finder import TrendFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fda78783-a1b5-4865-89f9-fd0bde4dd790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (4.1.0)\nRequirement already satisfied: alembic>=1.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from optuna) (1.14.0)\nRequirement already satisfied: colorlog in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from optuna) (24.1)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from optuna) (2.0.37)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /databricks/python3/lib/python3.12/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\nRequirement already satisfied: typing-extensions>=4 in /databricks/python3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "%pip install optuna\n",
    "import time\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4872c8ed-d929-492a-b018-d82faf9da480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "file_path1 = \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/data/dagdata_new.csv\"\n",
    "file_path2 = \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/data/maanddata_new.csv\"\n",
    "file_path3 = \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/data/Madrid Daily Weather 1997-2015_claire_raw_new.csv\"\n",
    "file_path4 = \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/data/weekdata_new.csv\"\n",
    "\n",
    "day = pd.read_csv(file_path1)\n",
    "week = pd.read_csv(file_path4)\n",
    "month = pd.read_csv(file_path2)\n",
    "weather = pd.read_csv(file_path3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b006c2-2bae-428c-928c-492732aaf34c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Basic Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a15445e-c704-459a-b0f2-e3c9bc1df3df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "weather = weather.rename(columns={'CET': 'date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b4dbcb-7228-495b-b139-c33be444b1ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d91f8570-f281-4d15-a2b6-59e9b9cd367d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "day = day.rename(columns={'Datum':'date', 'Bedrag': 'value', 'Categorie': 'category'})\n",
    "order = ['category', 'date', 'value']\n",
    "day = day[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d08c87-77e6-4164-a2cf-68e46bb3946a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "week['date'] = pd.to_datetime(week['date']).dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0554c76-3767-438d-97d3-8b78e94a382f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# translate column names and reorder columns\n",
    "day = day.rename(columns={'Datum':'date', 'Bedrag': 'value', 'Categorie': 'category'})\n",
    "order = ['category', 'date', 'value']\n",
    "day = day[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4975a6e-1623-445d-91d4-b2b985e27b33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range in dataset\nStart date: 2020-01-01 00:00:00\nEnd date: 2023-12-28 00:00:00\nDate range in dataset\nStart date: 2022-01-03 00:00:00\nEnd date: 2023-01-01 00:00:00\nDate range in dataset\nStart date: 2020-01-01 00:00:00\nEnd date: 2023-12-31 00:00:00\nDate range in dataset\nStart date: 1997-01-01 00:00:00\nEnd date: 2015-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def process_dates(df): \n",
    "  '''\n",
    "  Convert date column to datetime format and set as index\n",
    "  Input: dataframe \n",
    "  Output: dataframe with datetime index\n",
    "  ''' \n",
    "  df['date'] = pd.to_datetime(df['date']) #Convert date column to datetime \n",
    "  df_indexed = df.set_index('date').sort_index() #Set date as index\n",
    "  df_indexed = df_indexed.sort_index() #Ensure the index is sorted\n",
    "  print(\"Date range in dataset\")\n",
    "  print(f\"Start date: {df_indexed.index.min()}\")\n",
    "  print(f\"End date: {df_indexed.index.max()}\")\n",
    "  return df_indexed\n",
    "day_processed = process_dates(day)\n",
    "week_processed = process_dates(week)\n",
    "month_processed = process_dates(month)\n",
    "weather_processed = process_dates(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9c43094-7b96-4739-9ec0-7f1c60685cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Handle outliers using Interquartile range (IQR)\n",
    "https://www.geeksforgeeks.org/interquartile-range-to-detect-outliers-in-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c004cf1-4134-4a14-ac54-8bd95e3f9110",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Removes outliers using the IQR method\n",
    "def handle_outliers_with_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    cleaned_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return cleaned_df, lower_bound, upper_bound\n",
    "day_cleaned, day_lower, day_upper = handle_outliers_with_iqr(day, 'value')\n",
    "week_cleaned, week_lower, week_upper = handle_outliers_with_iqr(week, 'value')\n",
    "month_cleaned, month_lower, month_upper = handle_outliers_with_iqr(month, 'value')\n",
    "weather_cleaned, weather_lower, weather_upper = handle_outliers_with_iqr(weather, 'Mean Temperature')\n",
    "\n",
    "# Plots box plots for before and after handling outliers\n",
    "def visualize_outliers_step(df_before, df_after, column, title):\n",
    "    plt.figure(figsize=(14, 3))\n",
    "    # Before handling outliers\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.boxplot(df_before[column], vert=False, patch_artist=True)\n",
    "    plt.title(f\"{title} - Before Handling Outliers\")\n",
    "    plt.xlabel(column)\n",
    "    # After handling outliers\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(df_after[column], vert=False, patch_artist=True)\n",
    "    plt.title(f\"{title} - After Handling Outliers\")\n",
    "    plt.xlabel(column)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#Visualize for each dataset\n",
    "visualize_outliers_step(day, day_cleaned, 'value', 'Day Data')\n",
    "visualize_outliers_step(week, week_cleaned, 'value', 'Week Data')\n",
    "visualize_outliers_step(month, month_cleaned, 'value', 'Month Data')\n",
    "visualize_outliers_step(weather, weather, 'Mean Temperature', 'Weather Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ba0af3-73e2-48d3-8592-0ed942ba1462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- For each dataset, outliers in the value column were identified using the interquiritle range. Rows containing outliers were removed rom the datasets. This step reduce noise in the data and made it less skewed.\n",
    "- For day_df outliers extended significanlty beyond the whiskers, with values reaching over 10,000. After handling outliers the extreme values were removed, and the range became more constrained. The data distribution now looks cleaner and easier to interpret. \n",
    "- For week_df significant negative and positive outliers distorted the data, with extreme values beyond 50,000. After handling, the outliers were removed, revealing tighter range for the value column. The boxplot now better represents typical weekly values. \n",
    "- For month_df, massive outliers exttended to +-100,000, making the dataset highly skewed. After hanling outliers the range reduced significantly, and the boxplot appears more representative of typical monthly data.\n",
    "\n",
    "- Overall, it is important to handle outliers since they can heavily influence machine learning models, leading to biased predictions. We can clearly see with the boxplots that by removing extreme values, patterns in the data become clearer. Last but not least, cleaner data improves model interpretability and ensures consistency. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d65a31b-47a6-48e4-8aaa-8e30f6ae9925",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from workalendar.europe import Netherlands\n",
    "\n",
    "# Initialize calendar for working day and holiday calculations\n",
    "calendar = Netherlands()\n",
    "def create_time_features(df):\n",
    "    \"\"\"\n",
    "    Adds required columns to the dataset for trainers.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Original DataFrame with 'category', 'value', and 'date'.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Enriched DataFrame with additional columns.\n",
    "    \"\"\"\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Convert 'date' column to datetime\n",
    "    \n",
    "    # Add time-based features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['month_number'] = df['date'].dt.month\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['day_of_week_number'] = df['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    \n",
    "    # Add flags for date characteristics\n",
    "    df['is_month_start'] = df['date'].dt.is_month_start\n",
    "    df['is_month_end'] = df['date'].dt.is_month_end\n",
    "    df['is_quarter_start'] = df['date'].dt.is_quarter_start\n",
    "    df['is_quarter_end'] = df['date'].dt.is_quarter_end\n",
    "    df['is_year_start'] = df['date'].dt.is_year_start\n",
    "    df['is_year_end'] = df['date'].dt.is_year_end\n",
    "    \n",
    "    # Calculate working days and holidays\n",
    "    df['is_holiday'] = df['date'].apply(lambda x: calendar.is_holiday(x) if pd.notnull(x) else False)\n",
    "    df['is_working_day'] = ~df['is_holiday'] & (df['day_of_week_number'] < 5)  # Exclude weekends\n",
    "    df['first_workday_of_month'] = df['date'].apply(\n",
    "        lambda x: calendar.add_working_days(x.replace(day=1), 0) == x if pd.notnull(x) else False\n",
    "    )\n",
    "\n",
    "    # Add month start flags\n",
    "    month_starts = [\n",
    "        'january_start', 'february_start', 'march_start', 'april_start', 'may_start',\n",
    "        'june_start', 'july_start', 'august_start', 'september_start',\n",
    "        'october_start', 'november_start', 'december_start'\n",
    "    ]\n",
    "    for i, month in enumerate(month_starts, start=1):\n",
    "        df[month] = df['date'].dt.month == i\n",
    "    \n",
    "    # Add quarter-specific start flags\n",
    "    df['is_quarter_start_february'] = (df['date'].dt.month == 2) & (df['date'].dt.is_quarter_start)\n",
    "    df['is_quarter_start_march'] = (df['date'].dt.month == 3) & (df['date'].dt.is_quarter_start)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42cd27b1-3c4f-4487-a4b2-9762f4366a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "day_cleaned = create_time_features(day_cleaned)\n",
    "week_cleaned = create_time_features(week_cleaned)\n",
    "month_cleaned = create_time_features(month_cleaned)\n",
    "weather_cleaned = create_time_features(weather_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "416829d5-f44e-4e71-95b0-a239614f44b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>A</td>\n",
       "      <td>110.1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>A</td>\n",
       "      <td>1470.6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>A</td>\n",
       "      <td>930.9496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>A</td>\n",
       "      <td>1152.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>A</td>\n",
       "      <td>692.6490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category      value\n",
       "date                          \n",
       "2020-01-01        A   110.1472\n",
       "2020-01-02        A  1470.6150\n",
       "2020-01-03        A   930.9496\n",
       "2020-01-04        A  1152.1100\n",
       "2020-01-05        A   692.6490"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba57307-56c1-4f71-9533-d50274ad33f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "day_cleaned_outliers = create_time_features(day)\n",
    "week_cleaned_outliers = create_time_features(week)\n",
    "month_cleaned_outliers = create_time_features(month)\n",
    "weather_cleaned_outliers = create_time_features(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04362ae0-4bcd-4254-a67d-73d27dcd7489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Split dataset without handiling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d717a6-2f7e-46f5-a669-1a8f8cec3762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New datasets created:\nweek_data_cleaned_algemene_kosten\nweek_data_cleaned_autokosten\nweek_data_cleaned_exploitatie-_en_machinekosten\nweek_data_cleaned_huisvestingskosten\nweek_data_cleaned_kantoorkosten\nweek_data_cleaned_lonen_en_salarissen\nweek_data_cleaned_overige_bedrijfsopbrengsten\nweek_data_cleaned_overige_personeelskosten\nweek_data_cleaned_overige_rentelasten\nweek_data_cleaned_sociale_lasten\nweek_data_cleaned_verkoopkosten\nmonth_data_cleaned_afschrijvingen_mva\nmonth_data_cleaned_afschrijvingen_iva\nmonth_data_cleaned_omzet\nmonth_data_cleaned_algemene_kosten\nmonth_data_cleaned_autokosten\nmonth_data_cleaned_overige_rentelasten\nmonth_data_cleaned_pensioenlasten\nmonth_data_cleaned_lonen_en_salarissen\nmonth_data_cleaned_overige_personeelskosten\nmonth_data_cleaned_sociale_lasten\nmonth_data_cleaned_exploitatie-_en_machinekosten\nmonth_data_cleaned_kostprijs_van_de_omzet\nmonth_data_cleaned_kantoorkosten\nmonth_data_cleaned_verkoopkosten\nmonth_data_cleaned_huisvestingskosten\nday_data\nweather_data\n\nTotal datasets created: 30\nDatasets retained after filtering: 28\nSkipped datasets due to insufficient rows: 2\n"
     ]
    }
   ],
   "source": [
    "# Function to split dataset by category\n",
    "def split_dataset(df, name_prefix):\n",
    "    split_dfs = {}\n",
    "    unique_categories = df['category'].unique()\n",
    "    \n",
    "    for category in unique_categories:\n",
    "        filtered_df = df[df['category'] == category].copy()\n",
    "        filtered_df.reset_index(drop=True, inplace=True)\n",
    "        split_dfs[f\"{name_prefix}_{category.replace(' ', '_').lower()}\"] = filtered_df\n",
    "    \n",
    "    return split_dfs\n",
    "\n",
    "\n",
    "# Split dataset\n",
    "week_split = split_dataset(week_cleaned, 'week_data_cleaned') \n",
    "month_split = split_dataset(month_cleaned, 'month_data_cleaned') \n",
    "\n",
    "#dictionary\n",
    "all_split_data = {**week_split, **month_split}\n",
    "\n",
    "MIN_ROWS = 3\n",
    "all_split_data = {name: df for name, df in all_split_data.items() if len(df) >= MIN_ROWS}\n",
    "\n",
    "all_split_data['day_data'] = day_cleaned\n",
    "all_split_data['weather_data'] = weather_cleaned\n",
    "\n",
    "print(\"New datasets created:\")\n",
    "for name in all_split_data.keys():\n",
    "    print(name)\n",
    "\n",
    "print(f\"\\nTotal datasets created: {len(week_split) + len(month_split)}\")\n",
    "print(f\"Datasets retained after filtering: {len(all_split_data)}\")\n",
    "print(f\"Skipped datasets due to insufficient rows: {len(week_split) + len(month_split) - len(all_split_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afcd4982-f780-4c14-8b6f-69fbc5dec553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-665646844167802>, line 15\u001B[0m\n",
       "\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m split_dfs\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Split dataset\u001B[39;00m\n",
       "\u001B[0;32m---> 15\u001B[0m week_split \u001B[38;5;241m=\u001B[39m split_dataset(week_cleaned, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek_data_cleaned\u001B[39m\u001B[38;5;124m'\u001B[39m) \n",
       "\u001B[1;32m     16\u001B[0m month_split \u001B[38;5;241m=\u001B[39m split_dataset(month_cleaned, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth_data_cleaned\u001B[39m\u001B[38;5;124m'\u001B[39m) \n",
       "\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#dictionary\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'week_cleaned' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'week_cleaned' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'week_cleaned' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-665646844167802>, line 15\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m split_dfs\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Split dataset\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m week_split \u001B[38;5;241m=\u001B[39m split_dataset(week_cleaned, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek_data_cleaned\u001B[39m\u001B[38;5;124m'\u001B[39m) \n\u001B[1;32m     16\u001B[0m month_split \u001B[38;5;241m=\u001B[39m split_dataset(month_cleaned, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth_data_cleaned\u001B[39m\u001B[38;5;124m'\u001B[39m) \n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#dictionary\u001B[39;00m\n",
        "\u001B[0;31mNameError\u001B[0m: name 'week_cleaned' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to split dataset by category\n",
    "def split_dataset(df, name_prefix):\n",
    "    split_dfs = {}\n",
    "    unique_categories = df['category'].unique()\n",
    "    \n",
    "    for category in unique_categories:\n",
    "        filtered_df = df[df['category'] == category].copy()\n",
    "        filtered_df.reset_index(drop=True, inplace=True)\n",
    "        split_dfs[f\"{name_prefix}_{category.replace(' ', '_').lower()}\"] = filtered_df\n",
    "    \n",
    "    return split_dfs\n",
    "\n",
    "\n",
    "# Split dataset\n",
    "week_split = split_dataset(week_cleaned, 'week_data_cleaned') \n",
    "month_split = split_dataset(month_cleaned, 'month_data_cleaned') \n",
    "\n",
    "#dictionary\n",
    "all_split_data = {**week_split, **month_split, weather_cleaned_outliers, day_cleaned_outliers}\n",
    "\n",
    "MIN_ROWS = 3\n",
    "all_split_data = {name: df for name, df in all_split_data.items() if len(df) >= MIN_ROWS}\n",
    "\n",
    "print(\"New datasets created:\")\n",
    "for name in all_split_data.keys():\n",
    "    print(name)\n",
    "\n",
    "print(f\"\\nTotal datasets created: {len(week_split) + len(month_split)}\")\n",
    "print(f\"Datasets retained after filtering: {len(all_split_data)}\")\n",
    "print(f\"Skipped datasets due to insufficient rows: {len(week_split) + len(month_split) - len(all_split_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13019fd1-da16-4bfa-a4ef-b7295018af66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following variables have been created:\nweek_data_cleaned_algemene_kosten\nweek_data_cleaned_autokosten\nweek_data_cleaned_exploitatie-_en_machinekosten\nweek_data_cleaned_huisvestingskosten\nweek_data_cleaned_kantoorkosten\nweek_data_cleaned_lonen_en_salarissen\nweek_data_cleaned_overige_bedrijfsopbrengsten\nweek_data_cleaned_overige_personeelskosten\nweek_data_cleaned_overige_rentelasten\nweek_data_cleaned_sociale_lasten\nweek_data_cleaned_verkoopkosten\nmonth_data_cleaned_afschrijvingen_mva\nmonth_data_cleaned_afschrijvingen_iva\nmonth_data_cleaned_omzet\nmonth_data_cleaned_algemene_kosten\nmonth_data_cleaned_autokosten\nmonth_data_cleaned_overige_rentelasten\nmonth_data_cleaned_pensioenlasten\nmonth_data_cleaned_lonen_en_salarissen\nmonth_data_cleaned_overige_personeelskosten\nmonth_data_cleaned_sociale_lasten\nmonth_data_cleaned_exploitatie-_en_machinekosten\nmonth_data_cleaned_kostprijs_van_de_omzet\nmonth_data_cleaned_kantoorkosten\nmonth_data_cleaned_verkoopkosten\nmonth_data_cleaned_huisvestingskosten\nday_data\nweather_data\n"
     ]
    }
   ],
   "source": [
    "# Dynamically create variables for each category and type (week or month)\n",
    "globals().update({\n",
    "    name: df for name, df in all_split_data.items()\n",
    "})\n",
    "\n",
    "# Print confirmation of created variables\n",
    "print(\"The following variables have been created:\")\n",
    "for name in all_split_data.keys():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3528fde1-b351-40b0-9985-e80ae1c7b997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPrepared week_data_cleaned_afschrijvingen_mva:\nShape: (53, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_algemene_kosten:\nShape: (356, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_autokosten:\nShape: (11, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_exploitatie-_en_machinekosten:\nShape: (101, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_huisvestingskosten:\nShape: (314, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_kantoorkosten:\nShape: (156, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_kostprijs_van_de_omzet:\nShape: (364, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_lonen_en_salarissen:\nShape: (108, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_omzet:\nShape: (364, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_overige_bedrijfsopbrengsten:\nShape: (105, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_overige_personeelskosten:\nShape: (361, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_overige_rentelasten:\nShape: (300, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_pensioenlasten:\nShape: (14, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_sociale_lasten:\nShape: (54, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared week_data_cleaned_verkoopkosten:\nShape: (364, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_4, value_lag_12\n\nPrepared month_data_cleaned_afschrijvingen_mva:\nShape: (194, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_algemene_kosten:\nShape: (315, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_afschrijvingen_iva:\nShape: (49, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_omzet:\nShape: (602, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_exploitatie-_en_machinekosten:\nShape: (131, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_kostprijs_van_de_omzet:\nShape: (318, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_autokosten:\nShape: (313, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_overige_rentelasten:\nShape: (180, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_pensioenlasten:\nShape: (49, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_lonen_en_salarissen:\nShape: (152, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_overige_personeelskosten:\nShape: (293, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_sociale_lasten:\nShape: (103, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_kantoorkosten:\nShape: (208, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_verkoopkosten:\nShape: (127, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared month_data_cleaned_huisvestingskosten:\nShape: (101, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n\nPrepared day_data:\nShape: (1456, 35)\nFeatures: category, date, value, year, quarter, month_number, week_of_year, day_of_year, day_of_week_number, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end, is_holiday, is_working_day, first_workday_of_month, january_start, february_start, march_start, april_start, may_start, june_start, july_start, august_start, september_start, october_start, november_start, december_start, is_quarter_start_february, is_quarter_start_march, value_lag_1, value_lag_3, value_lag_12\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n",
       "\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n",
       "\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
       "\n",
       "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
       "\n",
       "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
       "\n",
       "\u001B[0;31mKeyError\u001B[0m: 'value'\n",
       "\n",
       "The above exception was the direct cause of the following exception:\n",
       "\n",
       "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-534193673359337>, line 90\u001B[0m\n",
       "\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prepared_datasets\n",
       "\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# Example usage:\u001B[39;00m\n",
       "\u001B[0;32m---> 90\u001B[0m prepared_data \u001B[38;5;241m=\u001B[39m prepare_all_categories(all_split_data)\n",
       "\n",
       "File \u001B[0;32m<command-534193673359337>, line 80\u001B[0m, in \u001B[0;36mprepare_all_categories\u001B[0;34m(all_split_data)\u001B[0m\n",
       "\u001B[1;32m     77\u001B[0m frequency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m name \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[1;32m     79\u001B[0m \u001B[38;5;66;03m# Prepare dataset\u001B[39;00m\n",
       "\u001B[0;32m---> 80\u001B[0m prepared_df \u001B[38;5;241m=\u001B[39m prepare_category_dataset(df, frequency)\n",
       "\u001B[1;32m     81\u001B[0m prepared_datasets[name] \u001B[38;5;241m=\u001B[39m prepared_df\n",
       "\u001B[1;32m     83\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mPrepared \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m<command-534193673359337>, line 55\u001B[0m, in \u001B[0;36mprepare_category_dataset\u001B[0;34m(df, frequency)\u001B[0m\n",
       "\u001B[1;32m     52\u001B[0m     lags \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m12\u001B[39m]  \u001B[38;5;66;03m# Previous month, quarter, year\u001B[39;00m\n",
       "\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m lag \u001B[38;5;129;01min\u001B[39;00m lags:\n",
       "\u001B[0;32m---> 55\u001B[0m     prepared_df[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue_lag_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlag\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m prepared_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshift(lag)\n",
       "\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Drop the helper column 'first_working_day' (optional)\u001B[39;00m\n",
       "\u001B[1;32m     58\u001B[0m prepared_df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_working_day\u001B[39m\u001B[38;5;124m'\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n",
       "\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
       "\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n",
       "\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n",
       "\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n",
       "\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n",
       "\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n",
       "\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
       "\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n",
       "\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
       "\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n",
       "\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n",
       "\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n",
       "\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
       "\n",
       "\u001B[0;31mKeyError\u001B[0m: 'value'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "KeyError",
        "evalue": "'value'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>KeyError</span>: 'value'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
        "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
        "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
        "\u001B[0;31mKeyError\u001B[0m: 'value'",
        "\nThe above exception was the direct cause of the following exception:\n",
        "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
        "File \u001B[0;32m<command-534193673359337>, line 90\u001B[0m\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prepared_datasets\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# Example usage:\u001B[39;00m\n\u001B[0;32m---> 90\u001B[0m prepared_data \u001B[38;5;241m=\u001B[39m prepare_all_categories(all_split_data)\n",
        "File \u001B[0;32m<command-534193673359337>, line 80\u001B[0m, in \u001B[0;36mprepare_all_categories\u001B[0;34m(all_split_data)\u001B[0m\n\u001B[1;32m     77\u001B[0m frequency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweek\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m name \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;66;03m# Prepare dataset\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m prepared_df \u001B[38;5;241m=\u001B[39m prepare_category_dataset(df, frequency)\n\u001B[1;32m     81\u001B[0m prepared_datasets[name] \u001B[38;5;241m=\u001B[39m prepared_df\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mPrepared \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m<command-534193673359337>, line 55\u001B[0m, in \u001B[0;36mprepare_category_dataset\u001B[0;34m(df, frequency)\u001B[0m\n\u001B[1;32m     52\u001B[0m     lags \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m12\u001B[39m]  \u001B[38;5;66;03m# Previous month, quarter, year\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m lag \u001B[38;5;129;01min\u001B[39;00m lags:\n\u001B[0;32m---> 55\u001B[0m     prepared_df[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue_lag_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlag\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m prepared_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshift(lag)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Drop the helper column 'first_working_day' (optional)\u001B[39;00m\n\u001B[1;32m     58\u001B[0m prepared_df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_working_day\u001B[39m\u001B[38;5;124m'\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
        "\u001B[0;31mKeyError\u001B[0m: 'value'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def prepare_category_dataset(df: pd.DataFrame, frequency: str = 'week') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform a category dataset into the format required by trainers.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame for a specific category\n",
    "        frequency: Data frequency ('week' or 'month')\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all required features for trainers\n",
    "    \"\"\"\n",
    "    # Create copy to avoid modifying original\n",
    "    prepared_df = df.copy()\n",
    "    \n",
    "    # Ensure date is datetime\n",
    "    prepared_df['date'] = pd.to_datetime(prepared_df['date'])\n",
    "    \n",
    "    # Extract time components required by trainers\n",
    "    prepared_df['year'] = prepared_df['date'].dt.year\n",
    "    prepared_df['quarter'] = prepared_df['date'].dt.quarter\n",
    "    prepared_df['month_number'] = prepared_df['date'].dt.month\n",
    "    prepared_df['week_of_year'] = prepared_df['date'].dt.isocalendar().week\n",
    "    prepared_df['day_of_year'] = prepared_df['date'].dt.dayofyear\n",
    "    prepared_df['day_of_week_number'] = prepared_df['date'].dt.dayofweek\n",
    "    \n",
    "    # Create boolean flags\n",
    "    prepared_df['is_month_start'] = prepared_df['date'].dt.is_month_start\n",
    "    prepared_df['is_month_end'] = prepared_df['date'].dt.is_month_end\n",
    "    prepared_df['is_quarter_start'] = prepared_df['date'].dt.is_quarter_start\n",
    "    prepared_df['is_quarter_end'] = prepared_df['date'].dt.is_quarter_end\n",
    "    prepared_df['is_year_start'] = prepared_df['date'].dt.is_year_start\n",
    "    prepared_df['is_year_end'] = prepared_df['date'].dt.is_year_end\n",
    "    \n",
    "    # Create is_working_day column\n",
    "    prepared_df['is_working_day'] = prepared_df['day_of_week_number'].apply(lambda x: x < 5)  # Monday to Friday\n",
    "\n",
    "    # Create first_workday_of_month column\n",
    "    # First, find the first working day for each month\n",
    "    prepared_df['first_working_day'] = (\n",
    "        prepared_df[prepared_df['is_working_day']]\n",
    "        .groupby(['year', 'month_number'])['date']\n",
    "        .transform('min')\n",
    "    )\n",
    "\n",
    "    # Compare 'date' with 'first_working_day' to create the boolean flag\n",
    "    prepared_df['first_workday_of_month'] = prepared_df['date'] == prepared_df['first_working_day']\n",
    "\n",
    "    # Add lag features appropriate for the frequency\n",
    "    if frequency == 'week':\n",
    "        lags = [1, 4, 12]  # Previous week, month, quarter\n",
    "    else:  # month\n",
    "        lags = [1, 3, 12]  # Previous month, quarter, year\n",
    "        \n",
    "    for lag in lags:\n",
    "        prepared_df[f'value_lag_{lag}'] = prepared_df['value'].shift(lag)\n",
    "    \n",
    "    # Drop the helper column 'first_working_day' (optional)\n",
    "    prepared_df.drop(columns=['first_working_day'], inplace=True)\n",
    "    \n",
    "    return prepared_df\n",
    "\n",
    "# Process all split datasets\n",
    "def prepare_all_categories(all_split_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Prepare all category datasets for trainers.\n",
    "    \n",
    "    Args:\n",
    "        all_split_data: Dictionary of split datasets\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of prepared datasets\n",
    "    \"\"\"\n",
    "    prepared_datasets = {}\n",
    "    \n",
    "    for name, df in all_split_data.items():\n",
    "        # Determine frequency from name\n",
    "        frequency = 'week' if 'week' in name else 'month'\n",
    "        \n",
    "        # Prepare dataset\n",
    "        prepared_df = prepare_category_dataset(df, frequency)\n",
    "        prepared_datasets[name] = prepared_df\n",
    "        \n",
    "        print(f\"\\nPrepared {name}:\")\n",
    "        print(f\"Shape: {prepared_df.shape}\")\n",
    "        print(f\"Features: {', '.join(prepared_df.columns)}\")\n",
    "    \n",
    "    return prepared_datasets\n",
    "\n",
    "# Example usage:\n",
    "prepared_data = prepare_all_categories(all_split_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba17703-5cc2-4a94-982e-7e59c8a9700c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "132d5cc4-fce6-4f7e-8596-205ab6f684cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== Dataset Split Summary ===\nTotal datasets: 28\nSuccessfully split: 28\nSkipped: 0\n\nweek_data_cleaned_algemene_kosten: Train size = 240, Test size = 103\nweek_data_cleaned_autokosten: Train size = 7, Test size = 3\nweek_data_cleaned_exploitatie-_en_machinekosten: Train size = 64, Test size = 28\nweek_data_cleaned_huisvestingskosten: Train size = 181, Test size = 78\nweek_data_cleaned_kantoorkosten: Train size = 108, Test size = 47\nweek_data_cleaned_lonen_en_salarissen: Train size = 37, Test size = 17\nweek_data_cleaned_overige_bedrijfsopbrengsten: Train size = 67, Test size = 29\nweek_data_cleaned_overige_personeelskosten: Train size = 244, Test size = 105\nweek_data_cleaned_overige_rentelasten: Train size = 208, Test size = 90\nweek_data_cleaned_sociale_lasten: Train size = 28, Test size = 12\nweek_data_cleaned_verkoopkosten: Train size = 217, Test size = 93\nmonth_data_cleaned_afschrijvingen_mva: Train size = 102, Test size = 45\nmonth_data_cleaned_afschrijvingen_iva: Train size = 34, Test size = 15\nmonth_data_cleaned_omzet: Train size = 126, Test size = 54\nmonth_data_cleaned_algemene_kosten: Train size = 181, Test size = 78\nmonth_data_cleaned_autokosten: Train size = 212, Test size = 92\nmonth_data_cleaned_overige_rentelasten: Train size = 120, Test size = 52\nmonth_data_cleaned_pensioenlasten: Train size = 32, Test size = 15\nmonth_data_cleaned_lonen_en_salarissen: Train size = 72, Test size = 31\nmonth_data_cleaned_overige_personeelskosten: Train size = 151, Test size = 66\nmonth_data_cleaned_sociale_lasten: Train size = 69, Test size = 30\nmonth_data_cleaned_exploitatie-_en_machinekosten: Train size = 85, Test size = 37\nmonth_data_cleaned_kostprijs_van_de_omzet: Train size = 110, Test size = 48\nmonth_data_cleaned_kantoorkosten: Train size = 144, Test size = 63\nmonth_data_cleaned_verkoopkosten: Train size = 88, Test size = 39\nmonth_data_cleaned_huisvestingskosten: Train size = 69, Test size = 30\nday_data: Train size = 977, Test size = 419\nweather_data: Train size = 4766, Test size = 2043\n\nNo datasets were skipped.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dictionary to store train/test splits for each dataset\n",
    "data_splits = {}\n",
    "\n",
    "# Initialize counters\n",
    "total_datasets = len(all_split_data)\n",
    "skipped_datasets = []\n",
    "processed_datasets = []\n",
    "\n",
    "# Loop through all datasets in globals\n",
    "for dataset_name in all_split_data.keys():\n",
    "    dataset = globals()[dataset_name]  # Access dataset dynamically\n",
    "    if len(dataset) > 1:  # Only split if dataset has more than one row\n",
    "        train, test = train_test_split(dataset, test_size=0.3, shuffle=False)  # No shuffle for time series\n",
    "        data_splits[dataset_name] = {'train': train, 'test': test}\n",
    "        processed_datasets.append(dataset_name)\n",
    "    else:\n",
    "        skipped_datasets.append(dataset_name)\n",
    "        print(f\"Skipping dataset '{dataset_name}' due to insufficient data (only {len(dataset)} row(s)).\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n=== Dataset Split Summary ===\")\n",
    "print(f\"Total datasets: {total_datasets}\")\n",
    "print(f\"Successfully split: {len(processed_datasets)}\")\n",
    "print(f\"Skipped: {len(skipped_datasets)}\\n\")\n",
    "\n",
    "# Print details of processed datasets\n",
    "for dataset_name, splits in data_splits.items():\n",
    "    print(f\"{dataset_name}: Train size = {len(splits['train'])}, Test size = {len(splits['test'])}\")\n",
    "\n",
    "# Print skipped datasets\n",
    "if skipped_datasets:\n",
    "    print(\"\\nSkipped datasets:\")\n",
    "    for dataset_name in skipped_datasets:\n",
    "        print(f\"{dataset_name} (only {len(globals()[dataset_name])} row(s))\")\n",
    "else:\n",
    "    print(\"\\nNo datasets were skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4157365d-00cd-445c-bbb2-bda7de6074f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected dataset: month_data_cleaned_exploitatie-_en_machinekosten\nNumber of columns: 32\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month_number</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week_number</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_working_day</th>\n",
       "      <th>first_workday_of_month</th>\n",
       "      <th>january_start</th>\n",
       "      <th>february_start</th>\n",
       "      <th>march_start</th>\n",
       "      <th>april_start</th>\n",
       "      <th>may_start</th>\n",
       "      <th>june_start</th>\n",
       "      <th>july_start</th>\n",
       "      <th>august_start</th>\n",
       "      <th>september_start</th>\n",
       "      <th>october_start</th>\n",
       "      <th>november_start</th>\n",
       "      <th>december_start</th>\n",
       "      <th>is_quarter_start_february</th>\n",
       "      <th>is_quarter_start_march</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exploitatie- en machinekosten</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>54</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exploitatie- en machinekosten</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>478</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exploitatie- en machinekosten</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>117</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exploitatie- en machinekosten</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>3678</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exploitatie- en machinekosten</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>677</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        category  ... is_quarter_start_march\n",
       "0  Exploitatie- en machinekosten  ...                  False\n",
       "1  Exploitatie- en machinekosten  ...                  False\n",
       "2  Exploitatie- en machinekosten  ...                  False\n",
       "3  Exploitatie- en machinekosten  ...                  False\n",
       "4  Exploitatie- en machinekosten  ...                  False\n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def show_random_df_info(dataset_dict, num_rows=5):\n",
    "    \"\"\"\n",
    "    Displays the head and column count of a random DataFrame from the provided dictionary.\n",
    "    \n",
    "    Args:\n",
    "        dataset_dict (dict): Dictionary of DataFrames.\n",
    "        num_rows (int): Number of rows to display from the head. Default is 5.\n",
    "    \"\"\"\n",
    "    # Randomly select a dataset\n",
    "    dataset_name = random.choice(list(dataset_dict.keys()))\n",
    "    dataset = dataset_dict[dataset_name]\n",
    "    \n",
    "    # Display dataset name, head, and column count\n",
    "    print(f\"Randomly selected dataset: {dataset_name}\")\n",
    "    print(f\"Number of columns: {len(dataset.columns)}\")\n",
    "    return dataset.head(num_rows)\n",
    "\n",
    "# Example usage\n",
    "show_random_df_info(all_split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f80e141-61a7-4661-be9b-17630e8c7aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4cd23c-9889-4eb1-859f-afe395157425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of trainer instances\n",
    "trainers = [\n",
    "    TrainerAverageLastYear(),\n",
    "    TrainerDecisionTree(),\n",
    "    TrainerGradientBoosting(),\n",
    "    TrainerKNeighborsRegressor(),\n",
    "    TrainerMajoritySelector(),\n",
    "    TrainerMovingAverage(),\n",
    "    TrainerRandomForest(),\n",
    "    TrainerRandomForestPattern(),\n",
    "    TrainerValueLastYears(),\n",
    "    TrainerXGBoost(),\n",
    "    TrainerXGBoostPattern(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca0a5aa9-8eaa-4421-a166-20a7171094fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average last year on dataset week_data_cleaned_algemene_kosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_algemene_kosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_algemene_kosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_algemene_kosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_algemene_kosten...\nTraining Majority selector on dataset week_data_cleaned_algemene_kosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_algemene_kosten...\nTraining Random Forest on dataset week_data_cleaned_algemene_kosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_algemene_kosten...\nTraining Value last year on dataset week_data_cleaned_algemene_kosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_algemene_kosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_algemene_kosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\nTraining XGBoost Pattern on dataset week_data_cleaned_algemene_kosten...\nTraining Average last year on dataset week_data_cleaned_autokosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_autokosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_autokosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_autokosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_autokosten...\nTraining Majority selector on dataset week_data_cleaned_autokosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_autokosten...\nTraining Random Forest on dataset week_data_cleaned_autokosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_autokosten...\nTraining Value last year on dataset week_data_cleaned_autokosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_autokosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_autokosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_autokosten...\nTraining Average last year on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_exploitatie-_en_machinekosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Majority selector on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Random Forest on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Value last year on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_exploitatie-_en_machinekosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_exploitatie-_en_machinekosten...\nTraining Average last year on dataset week_data_cleaned_huisvestingskosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_huisvestingskosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_huisvestingskosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_huisvestingskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_huisvestingskosten...\nTraining Majority selector on dataset week_data_cleaned_huisvestingskosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_huisvestingskosten...\nTraining Random Forest on dataset week_data_cleaned_huisvestingskosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_huisvestingskosten...\nTraining Value last year on dataset week_data_cleaned_huisvestingskosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_huisvestingskosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_huisvestingskosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_huisvestingskosten...\nTraining Average last year on dataset week_data_cleaned_kantoorkosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_kantoorkosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_kantoorkosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_kantoorkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_kantoorkosten...\nTraining Majority selector on dataset week_data_cleaned_kantoorkosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_kantoorkosten...\nTraining Random Forest on dataset week_data_cleaned_kantoorkosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_kantoorkosten...\nTraining Value last year on dataset week_data_cleaned_kantoorkosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_kantoorkosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_kantoorkosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_kantoorkosten...\nTraining Average last year on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Decision Tree Regressor on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_lonen_en_salarissen...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_lonen_en_salarissen: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Majority selector on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Moving Average Pattern on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Random Forest on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Random Forest Pattern on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Value last year on dataset week_data_cleaned_lonen_en_salarissen...\nTraining XGBoost Thomas on dataset week_data_cleaned_lonen_en_salarissen...\nError for model XGBoost Thomas on dataset week_data_cleaned_lonen_en_salarissen: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_lonen_en_salarissen...\nTraining Average last year on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_overige_bedrijfsopbrengsten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Majority selector on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Moving Average Pattern on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Random Forest on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Random Forest Pattern on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Value last year on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining XGBoost Thomas on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nError for model XGBoost Thomas on dataset week_data_cleaned_overige_bedrijfsopbrengsten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_overige_bedrijfsopbrengsten...\nTraining Average last year on dataset week_data_cleaned_overige_personeelskosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_overige_personeelskosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_overige_personeelskosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_overige_personeelskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_overige_personeelskosten...\nTraining Majority selector on dataset week_data_cleaned_overige_personeelskosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_overige_personeelskosten...\nTraining Random Forest on dataset week_data_cleaned_overige_personeelskosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_overige_personeelskosten...\nTraining Value last year on dataset week_data_cleaned_overige_personeelskosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_overige_personeelskosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_overige_personeelskosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_overige_personeelskosten...\nTraining Average last year on dataset week_data_cleaned_overige_rentelasten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_overige_rentelasten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_overige_rentelasten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_overige_rentelasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_overige_rentelasten...\nTraining Majority selector on dataset week_data_cleaned_overige_rentelasten...\nTraining Moving Average Pattern on dataset week_data_cleaned_overige_rentelasten...\nTraining Random Forest on dataset week_data_cleaned_overige_rentelasten...\nTraining Random Forest Pattern on dataset week_data_cleaned_overige_rentelasten...\nTraining Value last year on dataset week_data_cleaned_overige_rentelasten...\nTraining XGBoost Thomas on dataset week_data_cleaned_overige_rentelasten...\nError for model XGBoost Thomas on dataset week_data_cleaned_overige_rentelasten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_overige_rentelasten...\nTraining Average last year on dataset week_data_cleaned_sociale_lasten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_sociale_lasten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_sociale_lasten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_sociale_lasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_sociale_lasten...\nTraining Majority selector on dataset week_data_cleaned_sociale_lasten...\nTraining Moving Average Pattern on dataset week_data_cleaned_sociale_lasten...\nTraining Random Forest on dataset week_data_cleaned_sociale_lasten...\nTraining Random Forest Pattern on dataset week_data_cleaned_sociale_lasten...\nTraining Value last year on dataset week_data_cleaned_sociale_lasten...\nTraining XGBoost Thomas on dataset week_data_cleaned_sociale_lasten...\nError for model XGBoost Thomas on dataset week_data_cleaned_sociale_lasten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_sociale_lasten...\nTraining Average last year on dataset week_data_cleaned_verkoopkosten...\nTraining Decision Tree Regressor on dataset week_data_cleaned_verkoopkosten...\nTraining Gradient Boosting Regressor on dataset week_data_cleaned_verkoopkosten...\nError for model Gradient Boosting Regressor on dataset week_data_cleaned_verkoopkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset week_data_cleaned_verkoopkosten...\nTraining Majority selector on dataset week_data_cleaned_verkoopkosten...\nTraining Moving Average Pattern on dataset week_data_cleaned_verkoopkosten...\nTraining Random Forest on dataset week_data_cleaned_verkoopkosten...\nTraining Random Forest Pattern on dataset week_data_cleaned_verkoopkosten...\nTraining Value last year on dataset week_data_cleaned_verkoopkosten...\nTraining XGBoost Thomas on dataset week_data_cleaned_verkoopkosten...\nError for model XGBoost Thomas on dataset week_data_cleaned_verkoopkosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset week_data_cleaned_verkoopkosten...\nTraining Average last year on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Decision Tree Regressor on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_afschrijvingen_mva...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_afschrijvingen_mva: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Majority selector on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Moving Average Pattern on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Random Forest on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Random Forest Pattern on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Value last year on dataset month_data_cleaned_afschrijvingen_mva...\nError for model Value last year on dataset month_data_cleaned_afschrijvingen_mva: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_afschrijvingen_mva...\nError for model XGBoost Thomas on dataset month_data_cleaned_afschrijvingen_mva: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_afschrijvingen_mva...\nTraining Average last year on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Decision Tree Regressor on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_afschrijvingen_iva...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_afschrijvingen_iva: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Majority selector on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Moving Average Pattern on dataset month_data_cleaned_afschrijvingen_iva...\nError for model Moving Average Pattern on dataset month_data_cleaned_afschrijvingen_iva: Input contains NaN.\nTraining Random Forest on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Random Forest Pattern on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Value last year on dataset month_data_cleaned_afschrijvingen_iva...\nError for model Value last year on dataset month_data_cleaned_afschrijvingen_iva: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_afschrijvingen_iva...\nError for model XGBoost Thomas on dataset month_data_cleaned_afschrijvingen_iva: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_afschrijvingen_iva...\nTraining Average last year on dataset month_data_cleaned_omzet...\nTraining Decision Tree Regressor on dataset month_data_cleaned_omzet...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_omzet...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_omzet: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_omzet...\nTraining Majority selector on dataset month_data_cleaned_omzet...\nTraining Moving Average Pattern on dataset month_data_cleaned_omzet...\nTraining Random Forest on dataset month_data_cleaned_omzet...\nTraining Random Forest Pattern on dataset month_data_cleaned_omzet...\nTraining Value last year on dataset month_data_cleaned_omzet...\nError for model Value last year on dataset month_data_cleaned_omzet: don't know how to coerce float64 and int64\nTraining XGBoost Thomas on dataset month_data_cleaned_omzet...\nError for model XGBoost Thomas on dataset month_data_cleaned_omzet: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_omzet...\nTraining Average last year on dataset month_data_cleaned_algemene_kosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_algemene_kosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_algemene_kosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_algemene_kosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_algemene_kosten...\nTraining Majority selector on dataset month_data_cleaned_algemene_kosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_algemene_kosten...\nError for model Moving Average Pattern on dataset month_data_cleaned_algemene_kosten: Input contains NaN.\nTraining Random Forest on dataset month_data_cleaned_algemene_kosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_algemene_kosten...\nTraining Value last year on dataset month_data_cleaned_algemene_kosten...\nError for model Value last year on dataset month_data_cleaned_algemene_kosten: don't know how to coerce float64 and int64\nTraining XGBoost Thomas on dataset month_data_cleaned_algemene_kosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_algemene_kosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_algemene_kosten...\nTraining Average last year on dataset month_data_cleaned_autokosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_autokosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_autokosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_autokosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_autokosten...\nTraining Majority selector on dataset month_data_cleaned_autokosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_autokosten...\nError for model Moving Average Pattern on dataset month_data_cleaned_autokosten: Input contains NaN.\nTraining Random Forest on dataset month_data_cleaned_autokosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_autokosten...\nTraining Value last year on dataset month_data_cleaned_autokosten...\nError for model Value last year on dataset month_data_cleaned_autokosten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_autokosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_autokosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_autokosten...\nTraining Average last year on dataset month_data_cleaned_overige_rentelasten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_overige_rentelasten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_overige_rentelasten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_overige_rentelasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_overige_rentelasten...\nTraining Majority selector on dataset month_data_cleaned_overige_rentelasten...\nTraining Moving Average Pattern on dataset month_data_cleaned_overige_rentelasten...\nTraining Random Forest on dataset month_data_cleaned_overige_rentelasten...\nTraining Random Forest Pattern on dataset month_data_cleaned_overige_rentelasten...\nTraining Value last year on dataset month_data_cleaned_overige_rentelasten...\nError for model Value last year on dataset month_data_cleaned_overige_rentelasten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_overige_rentelasten...\nError for model XGBoost Thomas on dataset month_data_cleaned_overige_rentelasten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_overige_rentelasten...\nTraining Average last year on dataset month_data_cleaned_pensioenlasten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_pensioenlasten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_pensioenlasten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_pensioenlasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_pensioenlasten...\nTraining Majority selector on dataset month_data_cleaned_pensioenlasten...\nTraining Moving Average Pattern on dataset month_data_cleaned_pensioenlasten...\nTraining Random Forest on dataset month_data_cleaned_pensioenlasten...\nTraining Random Forest Pattern on dataset month_data_cleaned_pensioenlasten...\nTraining Value last year on dataset month_data_cleaned_pensioenlasten...\nError for model Value last year on dataset month_data_cleaned_pensioenlasten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_pensioenlasten...\nError for model XGBoost Thomas on dataset month_data_cleaned_pensioenlasten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_pensioenlasten...\nTraining Average last year on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Decision Tree Regressor on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_lonen_en_salarissen...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_lonen_en_salarissen: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Majority selector on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Moving Average Pattern on dataset month_data_cleaned_lonen_en_salarissen...\nError for model Moving Average Pattern on dataset month_data_cleaned_lonen_en_salarissen: Input contains NaN.\nTraining Random Forest on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Random Forest Pattern on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Value last year on dataset month_data_cleaned_lonen_en_salarissen...\nError for model Value last year on dataset month_data_cleaned_lonen_en_salarissen: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_lonen_en_salarissen...\nError for model XGBoost Thomas on dataset month_data_cleaned_lonen_en_salarissen: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_lonen_en_salarissen...\nTraining Average last year on dataset month_data_cleaned_overige_personeelskosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_overige_personeelskosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_overige_personeelskosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_overige_personeelskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_overige_personeelskosten...\nTraining Majority selector on dataset month_data_cleaned_overige_personeelskosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_overige_personeelskosten...\nError for model Moving Average Pattern on dataset month_data_cleaned_overige_personeelskosten: Input contains NaN.\nTraining Random Forest on dataset month_data_cleaned_overige_personeelskosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_overige_personeelskosten...\nTraining Value last year on dataset month_data_cleaned_overige_personeelskosten...\nError for model Value last year on dataset month_data_cleaned_overige_personeelskosten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_overige_personeelskosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_overige_personeelskosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_overige_personeelskosten...\nTraining Average last year on dataset month_data_cleaned_sociale_lasten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_sociale_lasten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_sociale_lasten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_sociale_lasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_sociale_lasten...\nTraining Majority selector on dataset month_data_cleaned_sociale_lasten...\nTraining Moving Average Pattern on dataset month_data_cleaned_sociale_lasten...\nTraining Random Forest on dataset month_data_cleaned_sociale_lasten...\nTraining Random Forest Pattern on dataset month_data_cleaned_sociale_lasten...\nTraining Value last year on dataset month_data_cleaned_sociale_lasten...\nError for model Value last year on dataset month_data_cleaned_sociale_lasten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_sociale_lasten...\nError for model XGBoost Thomas on dataset month_data_cleaned_sociale_lasten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_sociale_lasten...\nTraining Average last year on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_exploitatie-_en_machinekosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Majority selector on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Random Forest on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Value last year on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nError for model Value last year on dataset month_data_cleaned_exploitatie-_en_machinekosten: don't know how to coerce float64 and int64\nTraining XGBoost Thomas on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_exploitatie-_en_machinekosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_exploitatie-_en_machinekosten...\nTraining Average last year on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Decision Tree Regressor on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_kostprijs_van_de_omzet...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_kostprijs_van_de_omzet: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Majority selector on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Moving Average Pattern on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Random Forest on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Random Forest Pattern on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Value last year on dataset month_data_cleaned_kostprijs_van_de_omzet...\nError for model Value last year on dataset month_data_cleaned_kostprijs_van_de_omzet: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_kostprijs_van_de_omzet...\nError for model XGBoost Thomas on dataset month_data_cleaned_kostprijs_van_de_omzet: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_kostprijs_van_de_omzet...\nTraining Average last year on dataset month_data_cleaned_kantoorkosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_kantoorkosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_kantoorkosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_kantoorkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_kantoorkosten...\nTraining Majority selector on dataset month_data_cleaned_kantoorkosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_kantoorkosten...\nTraining Random Forest on dataset month_data_cleaned_kantoorkosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_kantoorkosten...\nTraining Value last year on dataset month_data_cleaned_kantoorkosten...\nError for model Value last year on dataset month_data_cleaned_kantoorkosten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_kantoorkosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_kantoorkosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_kantoorkosten...\nTraining Average last year on dataset month_data_cleaned_verkoopkosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_verkoopkosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_verkoopkosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_verkoopkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_verkoopkosten...\nTraining Majority selector on dataset month_data_cleaned_verkoopkosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_verkoopkosten...\nTraining Random Forest on dataset month_data_cleaned_verkoopkosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_verkoopkosten...\nTraining Value last year on dataset month_data_cleaned_verkoopkosten...\nError for model Value last year on dataset month_data_cleaned_verkoopkosten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_verkoopkosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_verkoopkosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_verkoopkosten...\nTraining Average last year on dataset month_data_cleaned_huisvestingskosten...\nTraining Decision Tree Regressor on dataset month_data_cleaned_huisvestingskosten...\nTraining Gradient Boosting Regressor on dataset month_data_cleaned_huisvestingskosten...\nError for model Gradient Boosting Regressor on dataset month_data_cleaned_huisvestingskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset month_data_cleaned_huisvestingskosten...\nTraining Majority selector on dataset month_data_cleaned_huisvestingskosten...\nTraining Moving Average Pattern on dataset month_data_cleaned_huisvestingskosten...\nTraining Random Forest on dataset month_data_cleaned_huisvestingskosten...\nTraining Random Forest Pattern on dataset month_data_cleaned_huisvestingskosten...\nTraining Value last year on dataset month_data_cleaned_huisvestingskosten...\nError for model Value last year on dataset month_data_cleaned_huisvestingskosten: list index out of range\nTraining XGBoost Thomas on dataset month_data_cleaned_huisvestingskosten...\nError for model XGBoost Thomas on dataset month_data_cleaned_huisvestingskosten: 'outlier_removal'\nTraining XGBoost Pattern on dataset month_data_cleaned_huisvestingskosten...\nTraining Average last year on dataset day_data...\nTraining Decision Tree Regressor on dataset day_data...\nTraining Gradient Boosting Regressor on dataset day_data...\nError for model Gradient Boosting Regressor on dataset day_data: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\nTraining KNeighbors Ivo on dataset day_data...\nTraining Majority selector on dataset day_data...\nTraining Moving Average Pattern on dataset day_data...\nTraining Random Forest on dataset day_data...\nTraining Random Forest Pattern on dataset day_data...\nTraining Value last year on dataset day_data...\nTraining XGBoost Thomas on dataset day_data...\nError for model XGBoost Thomas on dataset day_data: 'outlier_removal'\nTraining XGBoost Pattern on dataset day_data...\nTraining Average last year on dataset weather_data...\nError for model Average last year on dataset weather_data: \"['category', 'value'] not in index\"\nTraining Decision Tree Regressor on dataset weather_data...\nError for model Decision Tree Regressor on dataset weather_data: \"['category', 'value'] not in index\"\nTraining Gradient Boosting Regressor on dataset weather_data...\nError for model Gradient Boosting Regressor on dataset weather_data: \"['category', 'value'] not in index\"\nTraining KNeighbors Ivo on dataset weather_data...\nError for model KNeighbors Ivo on dataset weather_data: \"['category', 'value'] not in index\"\nTraining Majority selector on dataset weather_data...\nError for model Majority selector on dataset weather_data: 'value'\nTraining Moving Average Pattern on dataset weather_data...\nError for model Moving Average Pattern on dataset weather_data: \"['category', 'value'] not in index\"\nTraining Random Forest on dataset weather_data...\nError for model Random Forest on dataset weather_data: \"['category', 'value'] not in index\"\nTraining Random Forest Pattern on dataset weather_data...\nError for model Random Forest Pattern on dataset weather_data: \"['category', 'value'] not in index\"\nTraining Value last year on dataset weather_data...\nError for model Value last year on dataset weather_data: \"['category', 'value'] not in index\"\nTraining XGBoost Thomas on dataset weather_data...\nError for model XGBoost Thomas on dataset weather_data: \"['category', 'value'] not in index\"\nTraining XGBoost Pattern on dataset weather_data...\nError for model XGBoost Pattern on dataset weather_data: \"['category', 'value'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results for each model and dataset\n",
    "evaluation_results = []\n",
    "\n",
    "# Loop through datasets and trainers\n",
    "for dataset_name, splits in data_splits.items():\n",
    "    train_data = splits['train']\n",
    "    test_data = splits['test']\n",
    "    for trainer in trainers:\n",
    "        try:\n",
    "            print(f\"Training {trainer.name} on dataset {dataset_name}...\")\n",
    "            \n",
    "            # Fit the trainer on the training data\n",
    "            trainer.fit(train_data)\n",
    "            \n",
    "            # Predict on the test data\n",
    "            predictions = trainer.predict(test_data)\n",
    "            \n",
    "            # Validate predictions length\n",
    "            if len(predictions) != len(test_data):\n",
    "                raise ValueError(\n",
    "                    f\"Prediction length mismatch for model {trainer.name} on dataset {dataset_name}. \"\n",
    "                    f\"Expected {len(test_data)}, got {len(predictions)}.\"\n",
    "                )\n",
    "            \n",
    "            # Store the true values\n",
    "            actuals = test_data['value']\n",
    "            \n",
    "            # Calculate sMAPE and RMSE\n",
    "            smape_score = smape(actuals, predictions)\n",
    "            rmse_score = rmse(actuals, predictions)\n",
    "            mae_score = mae(actuals, predictions)\n",
    "            r_squared_score = r_squared(actuals, predictions)\n",
    "            \n",
    "            # Append results to the list\n",
    "            evaluation_results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': trainer.name,\n",
    "                'sMAPE': smape_score,\n",
    "                'RMSE': rmse_score,\n",
    "                'MAE': mae_score,\n",
    "                'R-squared': r_squared_score\n",
    "            })\n",
    "        except Exception as e:\n",
    "            # Log the error for the current trainer and dataset\n",
    "            print(f\"Error for model {trainer.name} on dataset {dataset_name}: {e}\")\n",
    "            evaluation_results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': trainer.name,\n",
    "                'Error': str(e)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f800129d-8a02-4c32-896b-356ab26e0113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered datasets: 27 remaining out of 28\nweek_data_cleaned_algemene_kosten: Train size = 240, Test size = 103\nweek_data_cleaned_exploitatie-_en_machinekosten: Train size = 64, Test size = 28\nweek_data_cleaned_huisvestingskosten: Train size = 181, Test size = 78\nweek_data_cleaned_kantoorkosten: Train size = 108, Test size = 47\nweek_data_cleaned_lonen_en_salarissen: Train size = 37, Test size = 17\nweek_data_cleaned_overige_bedrijfsopbrengsten: Train size = 67, Test size = 29\nweek_data_cleaned_overige_personeelskosten: Train size = 244, Test size = 105\nweek_data_cleaned_overige_rentelasten: Train size = 208, Test size = 90\nweek_data_cleaned_sociale_lasten: Train size = 28, Test size = 12\nweek_data_cleaned_verkoopkosten: Train size = 217, Test size = 93\nmonth_data_cleaned_afschrijvingen_mva: Train size = 102, Test size = 45\nmonth_data_cleaned_afschrijvingen_iva: Train size = 34, Test size = 15\nmonth_data_cleaned_omzet: Train size = 126, Test size = 54\nmonth_data_cleaned_algemene_kosten: Train size = 181, Test size = 78\nmonth_data_cleaned_autokosten: Train size = 212, Test size = 92\nmonth_data_cleaned_overige_rentelasten: Train size = 120, Test size = 52\nmonth_data_cleaned_pensioenlasten: Train size = 32, Test size = 15\nmonth_data_cleaned_lonen_en_salarissen: Train size = 72, Test size = 31\nmonth_data_cleaned_overige_personeelskosten: Train size = 151, Test size = 66\nmonth_data_cleaned_sociale_lasten: Train size = 69, Test size = 30\nmonth_data_cleaned_exploitatie-_en_machinekosten: Train size = 85, Test size = 37\nmonth_data_cleaned_kostprijs_van_de_omzet: Train size = 110, Test size = 48\nmonth_data_cleaned_kantoorkosten: Train size = 144, Test size = 63\nmonth_data_cleaned_verkoopkosten: Train size = 88, Test size = 39\nmonth_data_cleaned_huisvestingskosten: Train size = 69, Test size = 30\nday_data: Train size = 977, Test size = 419\nweather_data: Train size = 4766, Test size = 2043\n"
     ]
    }
   ],
   "source": [
    "# Filter out datasets with small train/test sizes\n",
    "filtered_data_splits = {\n",
    "    name: splits\n",
    "    for name, splits in data_splits.items()\n",
    "    if len(splits['train']) >= 20 and len(splits['test']) >= 10\n",
    "}\n",
    "\n",
    "print(f\"Filtered datasets: {len(filtered_data_splits)} remaining out of {len(data_splits)}\")\n",
    "for dataset_name, splits in filtered_data_splits.items():\n",
    "    print(f\"{dataset_name}: Train size = {len(splits['train'])}, Test size = {len(splits['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85203572-12ce-40fd-9ea3-e2d228349692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== Debugging data_splits ===\n{'week_data_cleaned_algemene_kosten': {'train':             category  ... is_quarter_start_march\n0    Algemene kosten  ...                  False\n1    Algemene kosten  ...                  False\n2    Algemene kosten  ...                  False\n3    Algemene kosten  ...                  False\n4    Algemene kosten  ...                  False\n..               ...  ...                    ...\n235  Algemene kosten  ...                  False\n236  Algemene kosten  ...                  False\n237  Algemene kosten  ...                  False\n238  Algemene kosten  ...                  False\n239  Algemene kosten  ...                  False\n\n[240 rows x 32 columns], 'test':             category       date  ...  is_quarter_start_march  predictions\n240  Algemene kosten 2022-09-16  ...                   False           -2\n241  Algemene kosten 2022-09-17  ...                   False           -2\n242  Algemene kosten 2022-09-19  ...                   False           -2\n243  Algemene kosten 2022-09-20  ...                   False           -2\n244  Algemene kosten 2022-09-21  ...                   False           -2\n..               ...        ...  ...                     ...          ...\n338  Algemene kosten 2022-12-28  ...                   False           -2\n339  Algemene kosten 2022-12-29  ...                   False           -2\n340  Algemene kosten 2022-12-30  ...                   False           -2\n341  Algemene kosten 2022-12-31  ...                   False           -2\n342  Algemene kosten 2023-01-01  ...                   False           -2\n\n[103 rows x 33 columns]}, 'week_data_cleaned_autokosten': {'train':      category       date  ...  is_quarter_start_february  is_quarter_start_march\n0  Autokosten 2022-02-06  ...                      False                   False\n1  Autokosten 2022-02-16  ...                      False                   False\n2  Autokosten 2022-03-06  ...                      False                   False\n3  Autokosten 2022-04-12  ...                      False                   False\n4  Autokosten 2022-05-01  ...                      False                   False\n5  Autokosten 2022-06-26  ...                      False                   False\n6  Autokosten 2022-07-24  ...                      False                   False\n\n[7 rows x 32 columns], 'test':      category       date  ...  is_quarter_start_march  predictions\n7  Autokosten 2022-09-18  ...                   False          -13\n8  Autokosten 2022-10-16  ...                   False          -13\n9  Autokosten 2023-01-01  ...                   False          -13\n\n[3 rows x 33 columns]}, 'week_data_cleaned_exploitatie-_en_machinekosten': {'train':                          category  ... is_quarter_start_march\n0   Exploitatie- en machinekosten  ...                  False\n1   Exploitatie- en machinekosten  ...                  False\n2   Exploitatie- en machinekosten  ...                  False\n3   Exploitatie- en machinekosten  ...                  False\n4   Exploitatie- en machinekosten  ...                  False\n..                            ...  ...                    ...\n59  Exploitatie- en machinekosten  ...                  False\n60  Exploitatie- en machinekosten  ...                  False\n61  Exploitatie- en machinekosten  ...                  False\n62  Exploitatie- en machinekosten  ...                  False\n63  Exploitatie- en machinekosten  ...                  False\n\n[64 rows x 32 columns], 'test':                          category  ... predictions\n64  Exploitatie- en machinekosten  ...         383\n65  Exploitatie- en machinekosten  ...         383\n66  Exploitatie- en machinekosten  ...         383\n67  Exploitatie- en machinekosten  ...         383\n68  Exploitatie- en machinekosten  ...         383\n69  Exploitatie- en machinekosten  ...         383\n70  Exploitatie- en machinekosten  ...         383\n71  Exploitatie- en machinekosten  ...         383\n72  Exploitatie- en machinekosten  ...         383\n73  Exploitatie- en machinekosten  ...         383\n74  Exploitatie- en machinekosten  ...         383\n75  Exploitatie- en machinekosten  ...         383\n76  Exploitatie- en machinekosten  ...         383\n77  Exploitatie- en machinekosten  ...         383\n78  Exploitatie- en machinekosten  ...         383\n79  Exploitatie- en machinekosten  ...         383\n80  Exploitatie- en machinekosten  ...         383\n81  Exploitatie- en machinekosten  ...         383\n82  Exploitatie- en machinekosten  ...         383\n83  Exploitatie- en machinekosten  ...         383\n84  Exploitatie- en machinekosten  ...         383\n85  Exploitatie- en machinekosten  ...         383\n86  Exploitatie- en machinekosten  ...         383\n87  Exploitatie- en machinekosten  ...         383\n88  Exploitatie- en machinekosten  ...         383\n89  Exploitatie- en machinekosten  ...         383\n90  Exploitatie- en machinekosten  ...         383\n91  Exploitatie- en machinekosten  ...         383\n\n[28 rows x 33 columns]}, 'week_data_cleaned_huisvestingskosten': {'train':                category  ... is_quarter_start_march\n0    Huisvestingskosten  ...                  False\n1    Huisvestingskosten  ...                  False\n2    Huisvestingskosten  ...                  False\n3    Huisvestingskosten  ...                  False\n4    Huisvestingskosten  ...                  False\n..                  ...  ...                    ...\n176  Huisvestingskosten  ...                  False\n177  Huisvestingskosten  ...                  False\n178  Huisvestingskosten  ...                  False\n179  Huisvestingskosten  ...                  False\n180  Huisvestingskosten  ...                  False\n\n[181 rows x 32 columns], 'test':                category       date  ...  is_quarter_start_march  predictions\n181  Huisvestingskosten 2022-09-09  ...                   False            2\n182  Huisvestingskosten 2022-09-10  ...                   False            2\n183  Huisvestingskosten 2022-09-12  ...                   False            2\n184  Huisvestingskosten 2022-09-13  ...                   False            2\n185  Huisvestingskosten 2022-09-15  ...                   False            2\n..                  ...        ...  ...                     ...          ...\n254  Huisvestingskosten 2022-12-24  ...                   False            2\n255  Huisvestingskosten 2022-12-27  ...                   False            2\n256  Huisvestingskosten 2022-12-28  ...                   False            2\n257  Huisvestingskosten 2022-12-29  ...                   False            2\n258  Huisvestingskosten 2022-12-30  ...                   False            2\n\n[78 rows x 33 columns]}, 'week_data_cleaned_kantoorkosten': {'train':           category  ... is_quarter_start_march\n0    Kantoorkosten  ...                  False\n1    Kantoorkosten  ...                  False\n2    Kantoorkosten  ...                  False\n3    Kantoorkosten  ...                  False\n4    Kantoorkosten  ...                  False\n..             ...  ...                    ...\n103  Kantoorkosten  ...                  False\n104  Kantoorkosten  ...                  False\n105  Kantoorkosten  ...                  False\n106  Kantoorkosten  ...                  False\n107  Kantoorkosten  ...                  False\n\n[108 rows x 32 columns], 'test':           category       date  ...  is_quarter_start_march  predictions\n108  Kantoorkosten 2022-09-15  ...                   False          -50\n109  Kantoorkosten 2022-09-18  ...                   False          -50\n110  Kantoorkosten 2022-09-19  ...                   False          -50\n111  Kantoorkosten 2022-09-23  ...                   False          -50\n112  Kantoorkosten 2022-09-25  ...                   False          -50\n113  Kantoorkosten 2022-09-26  ...                   False          -50\n114  Kantoorkosten 2022-09-27  ...                   False          -50\n115  Kantoorkosten 2022-09-29  ...                   False          -50\n116  Kantoorkosten 2022-10-02  ...                   False          -50\n117  Kantoorkosten 2022-10-03  ...                   False          -50\n118  Kantoorkosten 2022-10-05  ...                   False          -50\n119  Kantoorkosten 2022-10-06  ...                   False          -50\n120  Kantoorkosten 2022-10-09  ...                   False          -50\n121  Kantoorkosten 2022-10-10  ...                   False          -50\n122  Kantoorkosten 2022-10-12  ...                   False          -50\n123  Kantoorkosten 2022-10-16  ...                   False          -50\n124  Kantoorkosten 2022-10-17  ...                   False          -50\n125  Kantoorkosten 2022-10-23  ...                   False          -50\n126  Kantoorkosten 2022-10-24  ...                   False          -50\n127  Kantoorkosten 2022-10-26  ...                   False          -50\n128  Kantoorkosten 2022-10-30  ...                   False          -50\n129  Kantoorkosten 2022-11-01  ...                   False          -50\n130  Kantoorkosten 2022-11-06  ...                   False          -50\n131  Kantoorkosten 2022-11-07  ...                   False          -50\n132  Kantoorkosten 2022-11-10  ...                   False          -50\n133  Kantoorkosten 2022-11-11  ...                   False          -50\n134  Kantoorkosten 2022-11-13  ...                   False          -50\n135  Kantoorkosten 2022-11-14  ...                   False          -50\n136  Kantoorkosten 2022-11-20  ...                   False          -50\n137  Kantoorkosten 2022-11-21  ...                   False          -50\n138  Kantoorkosten 2022-11-22  ...                   False          -50\n139  Kantoorkosten 2022-11-24  ...                   False          -50\n140  Kantoorkosten 2022-11-27  ...                   False          -50\n141  Kantoorkosten 2022-11-28  ...                   False          -50\n142  Kantoorkosten 2022-12-04  ...                   False          -50\n143  Kantoorkosten 2022-12-05  ...                   False          -50\n144  Kantoorkosten 2022-12-07  ...                   False          -50\n145  Kantoorkosten 2022-12-10  ...                   False          -50\n146  Kantoorkosten 2022-12-11  ...                   False          -50\n147  Kantoorkosten 2022-12-12  ...                   False          -50\n148  Kantoorkosten 2022-12-15  ...                   False          -50\n149  Kantoorkosten 2022-12-18  ...                   False          -50\n150  Kantoorkosten 2022-12-19  ...                   False          -50\n151  Kantoorkosten 2022-12-21  ...                   False          -50\n152  Kantoorkosten 2022-12-25  ...                   False          -50\n153  Kantoorkosten 2022-12-27  ...                   False          -50\n154  Kantoorkosten 2023-01-01  ...                   False          -50\n\n[47 rows x 33 columns]}, 'week_data_cleaned_lonen_en_salarissen': {'train':                category  ... is_quarter_start_march\n0   Lonen en salarissen  ...                  False\n1   Lonen en salarissen  ...                  False\n2   Lonen en salarissen  ...                  False\n3   Lonen en salarissen  ...                  False\n4   Lonen en salarissen  ...                  False\n5   Lonen en salarissen  ...                  False\n6   Lonen en salarissen  ...                  False\n7   Lonen en salarissen  ...                  False\n8   Lonen en salarissen  ...                  False\n9   Lonen en salarissen  ...                  False\n10  Lonen en salarissen  ...                  False\n11  Lonen en salarissen  ...                  False\n12  Lonen en salarissen  ...                  False\n13  Lonen en salarissen  ...                  False\n14  Lonen en salarissen  ...                  False\n15  Lonen en salarissen  ...                  False\n16  Lonen en salarissen  ...                  False\n17  Lonen en salarissen  ...                  False\n18  Lonen en salarissen  ...                  False\n19  Lonen en salarissen  ...                  False\n20  Lonen en salarissen  ...                  False\n21  Lonen en salarissen  ...                  False\n22  Lonen en salarissen  ...                  False\n23  Lonen en salarissen  ...                  False\n24  Lonen en salarissen  ...                  False\n25  Lonen en salarissen  ...                  False\n26  Lonen en salarissen  ...                  False\n27  Lonen en salarissen  ...                  False\n28  Lonen en salarissen  ...                  False\n29  Lonen en salarissen  ...                  False\n30  Lonen en salarissen  ...                  False\n31  Lonen en salarissen  ...                  False\n32  Lonen en salarissen  ...                  False\n33  Lonen en salarissen  ...                  False\n34  Lonen en salarissen  ...                  False\n35  Lonen en salarissen  ...                  False\n36  Lonen en salarissen  ...                  False\n\n[37 rows x 32 columns], 'test':                category       date  ...  is_quarter_start_march  predictions\n37  Lonen en salarissen 2022-09-01  ...                   False         -549\n38  Lonen en salarissen 2022-09-05  ...                   False         -549\n39  Lonen en salarissen 2022-09-14  ...                   False         -549\n40  Lonen en salarissen 2022-09-16  ...                   False         -549\n41  Lonen en salarissen 2022-09-18  ...                   False         -549\n42  Lonen en salarissen 2022-09-27  ...                   False         -549\n43  Lonen en salarissen 2022-10-02  ...                   False         -549\n44  Lonen en salarissen 2022-10-06  ...                   False         -549\n45  Lonen en salarissen 2022-10-13  ...                   False         -549\n46  Lonen en salarissen 2022-10-16  ...                   False         -549\n47  Lonen en salarissen 2022-10-17  ...                   False         -549\n48  Lonen en salarissen 2022-10-28  ...                   False         -549\n49  Lonen en salarissen 2022-10-30  ...                   False         -549\n50  Lonen en salarissen 2022-11-03  ...                   False         -549\n51  Lonen en salarissen 2022-11-13  ...                   False         -549\n52  Lonen en salarissen 2022-12-01  ...                   False         -549\n53  Lonen en salarissen 2022-12-27  ...                   False         -549\n\n[17 rows x 33 columns]}, 'week_data_cleaned_overige_bedrijfsopbrengsten': {'train':                        category  ... is_quarter_start_march\n0   Overige bedrijfsopbrengsten  ...                  False\n1   Overige bedrijfsopbrengsten  ...                  False\n2   Overige bedrijfsopbrengsten  ...                  False\n3   Overige bedrijfsopbrengsten  ...                  False\n4   Overige bedrijfsopbrengsten  ...                  False\n..                          ...  ...                    ...\n62  Overige bedrijfsopbrengsten  ...                  False\n63  Overige bedrijfsopbrengsten  ...                  False\n64  Overige bedrijfsopbrengsten  ...                  False\n65  Overige bedrijfsopbrengsten  ...                  False\n66  Overige bedrijfsopbrengsten  ...                  False\n\n[67 rows x 32 columns], 'test':                        category       date  ...  is_quarter_start_march  predictions\n67  Overige bedrijfsopbrengsten 2022-12-01  ...                   False           -1\n68  Overige bedrijfsopbrengsten 2022-12-02  ...                   False           -1\n69  Overige bedrijfsopbrengsten 2022-12-03  ...                   False           -1\n70  Overige bedrijfsopbrengsten 2022-12-04  ...                   False           -1\n71  Overige bedrijfsopbrengsten 2022-12-05  ...                   False           -1\n72  Overige bedrijfsopbrengsten 2022-12-06  ...                   False           -1\n73  Overige bedrijfsopbrengsten 2022-12-07  ...                   False           -1\n74  Overige bedrijfsopbrengsten 2022-12-08  ...                   False           -1\n75  Overige bedrijfsopbrengsten 2022-12-09  ...                   False           -1\n76  Overige bedrijfsopbrengsten 2022-12-10  ...                   False           -1\n77  Overige bedrijfsopbrengsten 2022-12-11  ...                   False           -1\n78  Overige bedrijfsopbrengsten 2022-12-12  ...                   False           -1\n79  Overige bedrijfsopbrengsten 2022-12-13  ...                   False           -1\n80  Overige bedrijfsopbrengsten 2022-12-14  ...                   False           -1\n81  Overige bedrijfsopbrengsten 2022-12-15  ...                   False           -1\n82  Overige bedrijfsopbrengsten 2022-12-16  ...                   False           -1\n83  Overige bedrijfsopbrengsten 2022-12-17  ...                   False           -1\n84  Overige bedrijfsopbrengsten 2022-12-19  ...                   False           -1\n85  Overige bedrijfsopbrengsten 2022-12-20  ...                   False           -1\n86  Overige bedrijfsopbrengsten 2022-12-21  ...                   False           -1\n87  Overige bedrijfsopbrengsten 2022-12-22  ...                   False           -1\n88  Overige bedrijfsopbrengsten 2022-12-23  ...                   False           -1\n89  Overige bedrijfsopbrengsten 2022-12-24  ...                   False           -1\n90  Overige bedrijfsopbrengsten 2022-12-25  ...                   False           -1\n91  Overige bedrijfsopbrengsten 2022-12-26  ...                   False           -1\n92  Overige bedrijfsopbrengsten 2022-12-27  ...                   False           -1\n93  Overige bedrijfsopbrengsten 2022-12-28  ...                   False           -1\n94  Overige bedrijfsopbrengsten 2022-12-29  ...                   False           -1\n95  Overige bedrijfsopbrengsten 2022-12-30  ...                   False           -1\n\n[29 rows x 33 columns]}, 'week_data_cleaned_overige_personeelskosten': {'train':                      category  ... is_quarter_start_march\n0    Overige personeelskosten  ...                  False\n1    Overige personeelskosten  ...                  False\n2    Overige personeelskosten  ...                  False\n3    Overige personeelskosten  ...                  False\n4    Overige personeelskosten  ...                  False\n..                        ...  ...                    ...\n239  Overige personeelskosten  ...                  False\n240  Overige personeelskosten  ...                  False\n241  Overige personeelskosten  ...                  False\n242  Overige personeelskosten  ...                  False\n243  Overige personeelskosten  ...                  False\n\n[244 rows x 32 columns], 'test':                      category       date  ...  is_quarter_start_march  predictions\n244  Overige personeelskosten 2022-09-13  ...                   False           15\n245  Overige personeelskosten 2022-09-14  ...                   False           15\n246  Overige personeelskosten 2022-09-15  ...                   False           15\n247  Overige personeelskosten 2022-09-16  ...                   False           15\n248  Overige personeelskosten 2022-09-17  ...                   False           15\n..                        ...        ...  ...                     ...          ...\n344  Overige personeelskosten 2022-12-28  ...                   False           15\n345  Overige personeelskosten 2022-12-29  ...                   False           15\n346  Overige personeelskosten 2022-12-30  ...                   False           15\n347  Overige personeelskosten 2022-12-31  ...                   False           15\n348  Overige personeelskosten 2023-01-01  ...                   False           15\n\n[105 rows x 33 columns]}, 'week_data_cleaned_overige_rentelasten': {'train':                 category  ... is_quarter_start_march\n0    Overige rentelasten  ...                  False\n1    Overige rentelasten  ...                  False\n2    Overige rentelasten  ...                  False\n3    Overige rentelasten  ...                  False\n4    Overige rentelasten  ...                  False\n..                   ...  ...                    ...\n203  Overige rentelasten  ...                  False\n204  Overige rentelasten  ...                  False\n205  Overige rentelasten  ...                  False\n206  Overige rentelasten  ...                  False\n207  Overige rentelasten  ...                  False\n\n[208 rows x 32 columns], 'test':                 category       date  ...  is_quarter_start_march  predictions\n208  Overige rentelasten 2022-09-14  ...                   False            4\n209  Overige rentelasten 2022-09-15  ...                   False            4\n210  Overige rentelasten 2022-09-16  ...                   False            4\n211  Overige rentelasten 2022-09-18  ...                   False            4\n212  Overige rentelasten 2022-09-19  ...                   False            4\n..                   ...        ...  ...                     ...          ...\n293  Overige rentelasten 2022-12-27  ...                   False            4\n294  Overige rentelasten 2022-12-28  ...                   False            4\n295  Overige rentelasten 2022-12-29  ...                   False            4\n296  Overige rentelasten 2022-12-30  ...                   False            4\n297  Overige rentelasten 2023-01-01  ...                   False            4\n\n[90 rows x 33 columns]}, 'week_data_cleaned_sociale_lasten': {'train':           category  ... is_quarter_start_march\n0   Sociale lasten  ...                  False\n1   Sociale lasten  ...                  False\n2   Sociale lasten  ...                  False\n3   Sociale lasten  ...                  False\n4   Sociale lasten  ...                  False\n5   Sociale lasten  ...                  False\n6   Sociale lasten  ...                  False\n7   Sociale lasten  ...                  False\n8   Sociale lasten  ...                  False\n9   Sociale lasten  ...                  False\n10  Sociale lasten  ...                  False\n11  Sociale lasten  ...                  False\n12  Sociale lasten  ...                  False\n13  Sociale lasten  ...                  False\n14  Sociale lasten  ...                  False\n15  Sociale lasten  ...                  False\n16  Sociale lasten  ...                  False\n17  Sociale lasten  ...                  False\n18  Sociale lasten  ...                  False\n19  Sociale lasten  ...                  False\n20  Sociale lasten  ...                  False\n21  Sociale lasten  ...                  False\n22  Sociale lasten  ...                  False\n23  Sociale lasten  ...                  False\n24  Sociale lasten  ...                  False\n25  Sociale lasten  ...                  False\n26  Sociale lasten  ...                  False\n27  Sociale lasten  ...                  False\n\n[28 rows x 32 columns], 'test':           category       date  ...  is_quarter_start_march  predictions\n28  Sociale lasten 2022-09-18  ...                   False           46\n29  Sociale lasten 2022-09-25  ...                   False           46\n30  Sociale lasten 2022-10-02  ...                   False           46\n31  Sociale lasten 2022-10-16  ...                   False           46\n32  Sociale lasten 2022-10-23  ...                   False           46\n33  Sociale lasten 2022-10-30  ...                   False           46\n34  Sociale lasten 2022-11-13  ...                   False           46\n35  Sociale lasten 2022-11-20  ...                   False           46\n36  Sociale lasten 2022-11-27  ...                   False           46\n37  Sociale lasten 2022-12-11  ...                   False           46\n38  Sociale lasten 2022-12-18  ...                   False           46\n39  Sociale lasten 2022-12-25  ...                   False           46\n\n[12 rows x 33 columns]}, 'week_data_cleaned_verkoopkosten': {'train':           category  ... is_quarter_start_march\n0    Verkoopkosten  ...                  False\n1    Verkoopkosten  ...                  False\n2    Verkoopkosten  ...                  False\n3    Verkoopkosten  ...                  False\n4    Verkoopkosten  ...                  False\n..             ...  ...                    ...\n212  Verkoopkosten  ...                  False\n213  Verkoopkosten  ...                  False\n214  Verkoopkosten  ...                  False\n215  Verkoopkosten  ...                  False\n216  Verkoopkosten  ...                  False\n\n[217 rows x 32 columns], 'test':           category       date  ...  is_quarter_start_march  predictions\n217  Verkoopkosten 2022-09-13  ...                   False           74\n218  Verkoopkosten 2022-09-14  ...                   False           74\n219  Verkoopkosten 2022-09-15  ...                   False           74\n220  Verkoopkosten 2022-09-16  ...                   False           74\n221  Verkoopkosten 2022-09-17  ...                   False           74\n..             ...        ...  ...                     ...          ...\n305  Verkoopkosten 2022-12-26  ...                   False           74\n306  Verkoopkosten 2022-12-27  ...                   False           74\n307  Verkoopkosten 2022-12-28  ...                   False           74\n308  Verkoopkosten 2022-12-29  ...                   False           74\n309  Verkoopkosten 2022-12-30  ...                  \n\n*** WARNING: max output size exceeded, skipping output. ***\n\nelskosten 2023-12-31  ...                   False           25\n\n[66 rows x 33 columns]}, 'month_data_cleaned_sociale_lasten': {'train':           category  ... is_quarter_start_march\n0   Sociale lasten  ...                  False\n1   Sociale lasten  ...                  False\n2   Sociale lasten  ...                  False\n3   Sociale lasten  ...                  False\n4   Sociale lasten  ...                  False\n..             ...  ...                    ...\n64  Sociale lasten  ...                  False\n65  Sociale lasten  ...                  False\n66  Sociale lasten  ...                  False\n67  Sociale lasten  ...                  False\n68  Sociale lasten  ...                  False\n\n[69 rows x 32 columns], 'test':           category       date  ...  is_quarter_start_march  predictions\n69  Sociale lasten 2020-10-01  ...                   False         1448\n70  Sociale lasten 2021-10-01  ...                   False         1448\n71  Sociale lasten 2021-10-01  ...                   False         1448\n72  Sociale lasten 2022-10-01  ...                   False         1448\n73  Sociale lasten 2022-10-01  ...                   False         1448\n74  Sociale lasten 2023-06-01  ...                   False         1448\n75  Sociale lasten 2023-06-01  ...                   False         1448\n76  Sociale lasten 2020-06-01  ...                   False         1448\n77  Sociale lasten 2020-06-01  ...                   False         1448\n78  Sociale lasten 2021-06-01  ...                   False         1448\n79  Sociale lasten 2021-06-01  ...                   False         1448\n80  Sociale lasten 2022-06-01  ...                   False         1448\n81  Sociale lasten 2022-06-01  ...                   False         1448\n82  Sociale lasten 2023-03-01  ...                   False         1448\n83  Sociale lasten 2023-03-01  ...                   False         1448\n84  Sociale lasten 2021-05-01  ...                   False         1448\n85  Sociale lasten 2021-05-01  ...                   False         1448\n86  Sociale lasten 2020-05-01  ...                   False         1448\n87  Sociale lasten 2020-05-01  ...                   False         1448\n88  Sociale lasten 2022-05-01  ...                   False         1448\n89  Sociale lasten 2022-05-01  ...                   False         1448\n90  Sociale lasten 2021-11-01  ...                   False         1448\n91  Sociale lasten 2021-11-01  ...                   False         1448\n92  Sociale lasten 2020-11-01  ...                   False         1448\n93  Sociale lasten 2020-11-01  ...                   False         1448\n94  Sociale lasten 2022-11-01  ...                   False         1448\n95  Sociale lasten 2022-11-01  ...                   False         1448\n96  Sociale lasten 2023-12-01  ...                   False         1448\n97  Sociale lasten 2023-12-01  ...                   False         1448\n98  Sociale lasten 2023-12-31  ...                   False         1448\n\n[30 rows x 33 columns]}, 'month_data_cleaned_exploitatie-_en_machinekosten': {'train':                          category  ... is_quarter_start_march\n0   Exploitatie- en machinekosten  ...                  False\n1   Exploitatie- en machinekosten  ...                  False\n2   Exploitatie- en machinekosten  ...                  False\n3   Exploitatie- en machinekosten  ...                  False\n4   Exploitatie- en machinekosten  ...                  False\n..                            ...  ...                    ...\n80  Exploitatie- en machinekosten  ...                  False\n81  Exploitatie- en machinekosten  ...                  False\n82  Exploitatie- en machinekosten  ...                  False\n83  Exploitatie- en machinekosten  ...                  False\n84  Exploitatie- en machinekosten  ...                  False\n\n[85 rows x 32 columns], 'test':                           category  ... predictions\n85   Exploitatie- en machinekosten  ...        3703\n86   Exploitatie- en machinekosten  ...        3703\n87   Exploitatie- en machinekosten  ...        3703\n88   Exploitatie- en machinekosten  ...        3703\n89   Exploitatie- en machinekosten  ...        3703\n90   Exploitatie- en machinekosten  ...        3703\n91   Exploitatie- en machinekosten  ...        3703\n92   Exploitatie- en machinekosten  ...        3703\n93   Exploitatie- en machinekosten  ...        3703\n94   Exploitatie- en machinekosten  ...        3703\n95   Exploitatie- en machinekosten  ...        3703\n96   Exploitatie- en machinekosten  ...        3703\n97   Exploitatie- en machinekosten  ...        3703\n98   Exploitatie- en machinekosten  ...        3703\n99   Exploitatie- en machinekosten  ...        3703\n100  Exploitatie- en machinekosten  ...        3703\n101  Exploitatie- en machinekosten  ...        3703\n102  Exploitatie- en machinekosten  ...        3703\n103  Exploitatie- en machinekosten  ...        3703\n104  Exploitatie- en machinekosten  ...        3703\n105  Exploitatie- en machinekosten  ...        3703\n106  Exploitatie- en machinekosten  ...        3703\n107  Exploitatie- en machinekosten  ...        3703\n108  Exploitatie- en machinekosten  ...        3703\n109  Exploitatie- en machinekosten  ...        3703\n110  Exploitatie- en machinekosten  ...        3703\n111  Exploitatie- en machinekosten  ...        3703\n112  Exploitatie- en machinekosten  ...        3703\n113  Exploitatie- en machinekosten  ...        3703\n114  Exploitatie- en machinekosten  ...        3703\n115  Exploitatie- en machinekosten  ...        3703\n116  Exploitatie- en machinekosten  ...        3703\n117  Exploitatie- en machinekosten  ...        3703\n118  Exploitatie- en machinekosten  ...        3703\n119  Exploitatie- en machinekosten  ...        3703\n120  Exploitatie- en machinekosten  ...        3703\n121  Exploitatie- en machinekosten  ...        3703\n\n[37 rows x 33 columns]}, 'month_data_cleaned_kostprijs_van_de_omzet': {'train':                    category  ... is_quarter_start_march\n0    Kostprijs van de omzet  ...                  False\n1    Kostprijs van de omzet  ...                  False\n2    Kostprijs van de omzet  ...                  False\n3    Kostprijs van de omzet  ...                  False\n4    Kostprijs van de omzet  ...                  False\n..                      ...  ...                    ...\n105  Kostprijs van de omzet  ...                  False\n106  Kostprijs van de omzet  ...                  False\n107  Kostprijs van de omzet  ...                  False\n108  Kostprijs van de omzet  ...                  False\n109  Kostprijs van de omzet  ...                  False\n\n[110 rows x 32 columns], 'test':                    category       date  ...  is_quarter_start_march  predictions\n110  Kostprijs van de omzet 2020-10-01  ...                   False         1862\n111  Kostprijs van de omzet 2020-10-01  ...                   False         1862\n112  Kostprijs van de omzet 2021-10-01  ...                   False         1862\n113  Kostprijs van de omzet 2021-10-01  ...                   False         1862\n114  Kostprijs van de omzet 2020-10-01  ...                   False         1862\n115  Kostprijs van de omzet 2020-10-01  ...                   False         1862\n116  Kostprijs van de omzet 2021-10-01  ...                   False         1862\n117  Kostprijs van de omzet 2022-10-01  ...                   False         1862\n118  Kostprijs van de omzet 2022-10-01  ...                   False         1862\n119  Kostprijs van de omzet 2023-06-01  ...                   False         1862\n120  Kostprijs van de omzet 2023-06-01  ...                   False         1862\n121  Kostprijs van de omzet 2023-06-01  ...                   False         1862\n122  Kostprijs van de omzet 2023-06-01  ...                   False         1862\n123  Kostprijs van de omzet 2023-06-01  ...                   False         1862\n124  Kostprijs van de omzet 2020-06-01  ...                   False         1862\n125  Kostprijs van de omzet 2020-06-01  ...                   False         1862\n126  Kostprijs van de omzet 2021-06-01  ...                   False         1862\n127  Kostprijs van de omzet 2020-06-01  ...                   False         1862\n128  Kostprijs van de omzet 2020-06-01  ...                   False         1862\n129  Kostprijs van de omzet 2021-06-01  ...                   False         1862\n130  Kostprijs van de omzet 2022-06-01  ...                   False         1862\n131  Kostprijs van de omzet 2022-06-01  ...                   False         1862\n132  Kostprijs van de omzet 2022-06-01  ...                   False         1862\n133  Kostprijs van de omzet 2023-03-01  ...                   False         1862\n134  Kostprijs van de omzet 2023-03-01  ...                   False         1862\n135  Kostprijs van de omzet 2023-03-01  ...                   False         1862\n136  Kostprijs van de omzet 2023-03-01  ...                   False         1862\n137  Kostprijs van de omzet 2020-05-01  ...                   False         1862\n138  Kostprijs van de omzet 2020-05-01  ...                   False         1862\n139  Kostprijs van de omzet 2020-05-01  ...                   False         1862\n140  Kostprijs van de omzet 2021-05-01  ...                   False         1862\n141  Kostprijs van de omzet 2020-05-01  ...                   False         1862\n142  Kostprijs van de omzet 2020-05-01  ...                   False         1862\n143  Kostprijs van de omzet 2021-05-01  ...                   False         1862\n144  Kostprijs van de omzet 2022-05-01  ...                   False         1862\n145  Kostprijs van de omzet 2022-05-01  ...                   False         1862\n146  Kostprijs van de omzet 2022-05-01  ...                   False         1862\n147  Kostprijs van de omzet 2022-05-01  ...                   False         1862\n148  Kostprijs van de omzet 2020-11-01  ...                   False         1862\n149  Kostprijs van de omzet 2020-11-01  ...                   False         1862\n150  Kostprijs van de omzet 2021-11-01  ...                   False         1862\n151  Kostprijs van de omzet 2020-11-01  ...                   False         1862\n152  Kostprijs van de omzet 2022-11-01  ...                   False         1862\n153  Kostprijs van de omzet 2022-11-01  ...                   False         1862\n154  Kostprijs van de omzet 2023-12-01  ...                   False         1862\n155  Kostprijs van de omzet 2023-12-01  ...                   False         1862\n156  Kostprijs van de omzet 2023-12-01  ...                   False         1862\n157  Kostprijs van de omzet 2023-12-31  ...                   False         1862\n\n[48 rows x 33 columns]}, 'month_data_cleaned_kantoorkosten': {'train':           category  ... is_quarter_start_march\n0    Kantoorkosten  ...                  False\n1    Kantoorkosten  ...                  False\n2    Kantoorkosten  ...                  False\n3    Kantoorkosten  ...                  False\n4    Kantoorkosten  ...                  False\n..             ...  ...                    ...\n139  Kantoorkosten  ...                  False\n140  Kantoorkosten  ...                  False\n141  Kantoorkosten  ...                  False\n142  Kantoorkosten  ...                  False\n143  Kantoorkosten  ...                  False\n\n[144 rows x 32 columns], 'test':           category       date  ...  is_quarter_start_march  predictions\n144  Kantoorkosten 2020-10-01  ...                   False          318\n145  Kantoorkosten 2020-10-01  ...                   False          318\n146  Kantoorkosten 2021-10-01  ...                   False          318\n147  Kantoorkosten 2021-10-01  ...                   False          318\n148  Kantoorkosten 2022-10-01  ...                   False          318\n..             ...        ...  ...                     ...          ...\n202  Kantoorkosten 2023-12-01  ...                   False          318\n203  Kantoorkosten 2023-12-01  ...                   False          318\n204  Kantoorkosten 2023-12-01  ...                   False          318\n205  Kantoorkosten 2023-12-01  ...                   False          318\n206  Kantoorkosten 2023-12-31  ...                   False          318\n\n[63 rows x 33 columns]}, 'month_data_cleaned_verkoopkosten': {'train':          category       date  ...  is_quarter_start_february  is_quarter_start_march\n0   Verkoopkosten 2021-01-01  ...                      False                   False\n1   Verkoopkosten 2021-01-01  ...                      False                   False\n2   Verkoopkosten 2020-01-01  ...                      False                   False\n3   Verkoopkosten 2020-01-01  ...                      False                   False\n4   Verkoopkosten 2020-01-01  ...                      False                   False\n..            ...        ...  ...                        ...                     ...\n83  Verkoopkosten 2020-10-01  ...                      False                   False\n84  Verkoopkosten 2020-10-01  ...                      False                   False\n85  Verkoopkosten 2021-10-01  ...                      False                   False\n86  Verkoopkosten 2022-10-01  ...                      False                   False\n87  Verkoopkosten 2022-10-01  ...                      False                   False\n\n[88 rows x 32 columns], 'test':           category       date  ...  is_quarter_start_march  predictions\n88   Verkoopkosten 2022-10-01  ...                   False          100\n89   Verkoopkosten 2022-10-01  ...                   False          100\n90   Verkoopkosten 2022-10-01  ...                   False          100\n91   Verkoopkosten 2023-06-01  ...                   False          100\n92   Verkoopkosten 2023-06-01  ...                   False          100\n93   Verkoopkosten 2023-06-01  ...                   False          100\n94   Verkoopkosten 2021-06-01  ...                   False          100\n95   Verkoopkosten 2020-06-01  ...                   False          100\n96   Verkoopkosten 2021-06-01  ...                   False          100\n97   Verkoopkosten 2020-06-01  ...                   False          100\n98   Verkoopkosten 2021-06-01  ...                   False          100\n99   Verkoopkosten 2022-06-01  ...                   False          100\n100  Verkoopkosten 2022-06-01  ...                   False          100\n101  Verkoopkosten 2022-06-01  ...                   False          100\n102  Verkoopkosten 2022-06-01  ...                   False          100\n103  Verkoopkosten 2023-03-01  ...                   False          100\n104  Verkoopkosten 2023-03-01  ...                   False          100\n105  Verkoopkosten 2023-03-01  ...                   False          100\n106  Verkoopkosten 2023-03-01  ...                   False          100\n107  Verkoopkosten 2021-05-01  ...                   False          100\n108  Verkoopkosten 2020-05-01  ...                   False          100\n109  Verkoopkosten 2021-05-01  ...                   False          100\n110  Verkoopkosten 2020-05-01  ...                   False          100\n111  Verkoopkosten 2021-05-01  ...                   False          100\n112  Verkoopkosten 2020-05-01  ...                   False          100\n113  Verkoopkosten 2022-05-01  ...                   False          100\n114  Verkoopkosten 2022-05-01  ...                   False          100\n115  Verkoopkosten 2022-05-01  ...                   False          100\n116  Verkoopkosten 2020-11-01  ...                   False          100\n117  Verkoopkosten 2021-11-01  ...                   False          100\n118  Verkoopkosten 2021-11-01  ...                   False          100\n119  Verkoopkosten 2021-11-01  ...                   False          100\n120  Verkoopkosten 2022-11-01  ...                   False          100\n121  Verkoopkosten 2022-11-01  ...                   False          100\n122  Verkoopkosten 2022-11-01  ...                   False          100\n123  Verkoopkosten 2023-12-01  ...                   False          100\n124  Verkoopkosten 2023-12-01  ...                   False          100\n125  Verkoopkosten 2023-12-01  ...                   False          100\n126  Verkoopkosten 2023-12-31  ...                   False          100\n\n[39 rows x 33 columns]}, 'month_data_cleaned_huisvestingskosten': {'train':               category  ... is_quarter_start_march\n0   Huisvestingskosten  ...                  False\n1   Huisvestingskosten  ...                  False\n2   Huisvestingskosten  ...                  False\n3   Huisvestingskosten  ...                  False\n4   Huisvestingskosten  ...                  False\n..                 ...  ...                    ...\n64  Huisvestingskosten  ...                  False\n65  Huisvestingskosten  ...                  False\n66  Huisvestingskosten  ...                  False\n67  Huisvestingskosten  ...                  False\n68  Huisvestingskosten  ...                  False\n\n[69 rows x 32 columns], 'test':               category       date  ...  is_quarter_start_march  predictions\n69  Huisvestingskosten 2022-07-01  ...                   False         1950\n70  Huisvestingskosten 2022-07-01  ...                   False         1950\n71  Huisvestingskosten 2020-10-01  ...                   False         1950\n72  Huisvestingskosten 2020-10-01  ...                   False         1950\n73  Huisvestingskosten 2022-10-01  ...                   False         1950\n74  Huisvestingskosten 2022-10-01  ...                   False         1950\n75  Huisvestingskosten 2023-06-01  ...                   False         1950\n76  Huisvestingskosten 2023-06-01  ...                   False         1950\n77  Huisvestingskosten 2020-06-01  ...                   False         1950\n78  Huisvestingskosten 2020-06-01  ...                   False         1950\n79  Huisvestingskosten 2021-06-01  ...                   False         1950\n80  Huisvestingskosten 2022-06-01  ...                   False         1950\n81  Huisvestingskosten 2022-06-01  ...                   False         1950\n82  Huisvestingskosten 2023-03-01  ...                   False         1950\n83  Huisvestingskosten 2023-03-01  ...                   False         1950\n84  Huisvestingskosten 2020-05-01  ...                   False         1950\n85  Huisvestingskosten 2020-05-01  ...                   False         1950\n86  Huisvestingskosten 2021-05-01  ...                   False         1950\n87  Huisvestingskosten 2021-05-01  ...                   False         1950\n88  Huisvestingskosten 2020-05-01  ...                   False         1950\n89  Huisvestingskosten 2021-05-01  ...                   False         1950\n90  Huisvestingskosten 2022-05-01  ...                   False         1950\n91  Huisvestingskosten 2022-05-01  ...                   False         1950\n92  Huisvestingskosten 2022-05-01  ...                   False         1950\n93  Huisvestingskosten 2020-11-01  ...                   False         1950\n94  Huisvestingskosten 2021-11-01  ...                   False         1950\n95  Huisvestingskosten 2022-11-01  ...                   False         1950\n96  Huisvestingskosten 2023-12-01  ...                   False         1950\n97  Huisvestingskosten 2023-12-01  ...                   False         1950\n98  Huisvestingskosten 2023-12-31  ...                   False         1950\n\n[30 rows x 33 columns]}, 'day_data': {'train':      category       date  ...  is_quarter_start_february  is_quarter_start_march\n0           A 2020-01-01  ...                      False                   False\n1           A 2020-01-02  ...                      False                   False\n2           A 2020-01-03  ...                      False                   False\n3           A 2020-01-04  ...                      False                   False\n4           A 2020-01-05  ...                      False                   False\n...       ...        ...  ...                        ...                     ...\n1011        A 2022-10-08  ...                      False                   False\n1012        A 2022-10-09  ...                      False                   False\n1013        A 2022-10-10  ...                      False                   False\n1014        A 2022-10-11  ...                      False                   False\n1015        A 2022-10-12  ...                      False                   False\n\n[977 rows x 32 columns], 'test':      category       date  ...  is_quarter_start_march  predictions\n1016        A 2022-10-13  ...                   False        891.9\n1017        A 2022-10-14  ...                   False        891.9\n1018        A 2022-10-15  ...                   False        891.9\n1019        A 2022-10-16  ...                   False        891.9\n1020        A 2022-10-17  ...                   False        891.9\n...       ...        ...  ...                     ...          ...\n1451        A 2023-12-23  ...                   False        891.9\n1452        A 2023-12-24  ...                   False        891.9\n1453        A 2023-12-25  ...                   False        891.9\n1454        A 2023-12-27  ...                   False        891.9\n1455        A 2023-12-28  ...                   False        891.9\n\n[419 rows x 33 columns]}, 'weather_data': {'train':         City       date  ...  is_quarter_start_february  is_quarter_start_march\n0     Madrid 1997-01-01  ...                      False                   False\n1     Madrid 1997-01-02  ...                      False                   False\n2     Madrid 1997-01-03  ...                      False                   False\n3     Madrid 1997-01-04  ...                      False                   False\n4     Madrid 1997-01-05  ...                      False                   False\n...      ...        ...  ...                        ...                     ...\n4764  Madrid 2010-05-24  ...                      False                   False\n4765  Madrid 2010-05-25  ...                      False                   False\n4766  Madrid 2010-05-26  ...                      False                   False\n4767  Madrid 2010-05-27  ...                      False                   False\n4768  Madrid 2010-05-28  ...                      False                   False\n\n[4766 rows x 32 columns], 'test':         City       date  ...  is_quarter_start_february  is_quarter_start_march\n4769  Madrid 2010-05-29  ...                      False                   False\n4770  Madrid 2010-05-30  ...                      False                   False\n4771  Madrid 2010-05-31  ...                      False                   False\n4772  Madrid 2010-06-01  ...                      False                   False\n4773  Madrid 2010-06-02  ...                      False                   False\n...      ...        ...  ...                        ...                     ...\n6807  Madrid 2015-12-27  ...                      False                   False\n6808  Madrid 2015-12-28  ...                      False                   False\n6809  Madrid 2015-12-29  ...                      False                   False\n6810  Madrid 2015-12-30  ...                      False                   False\n6811  Madrid 2015-12-31  ...                      False                   False\n\n[2043 rows x 32 columns]}}\nweek_data_cleaned_algemene_kosten: Train size = 240, Test size = 103\nweek_data_cleaned_autokosten: Train size = 7, Test size = 3\nweek_data_cleaned_exploitatie-_en_machinekosten: Train size = 64, Test size = 28\nweek_data_cleaned_huisvestingskosten: Train size = 181, Test size = 78\nweek_data_cleaned_kantoorkosten: Train size = 108, Test size = 47\nweek_data_cleaned_lonen_en_salarissen: Train size = 37, Test size = 17\nweek_data_cleaned_overige_bedrijfsopbrengsten: Train size = 67, Test size = 29\nweek_data_cleaned_overige_personeelskosten: Train size = 244, Test size = 105\nweek_data_cleaned_overige_rentelasten: Train size = 208, Test size = 90\nweek_data_cleaned_sociale_lasten: Train size = 28, Test size = 12\nweek_data_cleaned_verkoopkosten: Train size = 217, Test size = 93\nmonth_data_cleaned_afschrijvingen_mva: Train size = 102, Test size = 45\nmonth_data_cleaned_afschrijvingen_iva: Train size = 34, Test size = 15\nmonth_data_cleaned_omzet: Train size = 126, Test size = 54\nmonth_data_cleaned_algemene_kosten: Train size = 181, Test size = 78\nmonth_data_cleaned_autokosten: Train size = 212, Test size = 92\nmonth_data_cleaned_overige_rentelasten: Train size = 120, Test size = 52\nmonth_data_cleaned_pensioenlasten: Train size = 32, Test size = 15\nmonth_data_cleaned_lonen_en_salarissen: Train size = 72, Test size = 31\nmonth_data_cleaned_overige_personeelskosten: Train size = 151, Test size = 66\nmonth_data_cleaned_sociale_lasten: Train size = 69, Test size = 30\nmonth_data_cleaned_exploitatie-_en_machinekosten: Train size = 85, Test size = 37\nmonth_data_cleaned_kostprijs_van_de_omzet: Train size = 110, Test size = 48\nmonth_data_cleaned_kantoorkosten: Train size = 144, Test size = 63\nmonth_data_cleaned_verkoopkosten: Train size = 88, Test size = 39\nmonth_data_cleaned_huisvestingskosten: Train size = 69, Test size = 30\nday_data: Train size = 977, Test size = 419\nweather_data: Train size = 4766, Test size = 2043\n"
     ]
    }
   ],
   "source": [
    "# Debugging the data_splits dictionary\n",
    "print(\"\\n=== Debugging data_splits ===\")\n",
    "print(data_splits)\n",
    "\n",
    "# Check if data_splits is empty\n",
    "if not data_splits:\n",
    "    print(\"The data_splits dictionary is empty.\")\n",
    "else:\n",
    "    for dataset_name, splits in data_splits.items():\n",
    "        print(f\"{dataset_name}: Train size = {len(splits['train'])}, Test size = {len(splits['test'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3cf91b1-c172-4ba9-bb84-0105fa6e96dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Optuna results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b600bdc-894c-481c-b00e-1d9d66dfc3a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:20,589] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_algemene_kosten\n[I 2025-01-19 13:15:20,616] Trial 0 finished with value: 296.17201771549907 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 296.17201771549907.\n[I 2025-01-19 13:15:20,644] Trial 1 finished with value: 296.17201771549907 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 296.17201771549907.\n[I 2025-01-19 13:15:20,669] Trial 2 finished with value: 296.17201771549907 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 296.17201771549907.\n[I 2025-01-19 13:15:20,694] Trial 3 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,720] Trial 4 finished with value: 296.17201771549907 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,748] Trial 5 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,773] Trial 6 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,798] Trial 7 finished with value: 296.17201771549907 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 3 with value: 295.3088804318189.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nProcessing Trainer: TrainerAverageLastYear\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 0 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343 in 0.03 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 1 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343 in 0.02 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 2 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343 in 0.02 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 3 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.02 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 4 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343 in 0.03 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 5 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.03 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.02 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 7 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343 in 0.02 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:20,824] Trial 8 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,848] Trial 9 finished with value: 296.17201771549907 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,885] Trial 10 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,916] Trial 11 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,947] Trial 12 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:20,978] Trial 13 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 295.3088804318189.\n[I 2025-01-19 13:15:21,011] Trial 14 finished with value: 295.3088804318189 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 3 with value: 295.3088804318189.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.02 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 9 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343 in 0.02 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 10 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.04 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 11 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.03 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 12 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.03 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 13 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.03 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:21,038] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_autokosten\n[I 2025-01-19 13:15:21,049] Trial 0 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,060] Trial 1 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,071] Trial 2 finished with value: 92.63188795801727 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,082] Trial 3 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,093] Trial 4 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,105] Trial 5 finished with value: 92.63188795801727 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,115] Trial 6 finished with value: 92.63188795801727 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,128] Trial 7 finished with value: 92.63188795801727 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,139] Trial 8 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,150] Trial 9 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,169] Trial 10 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,187] Trial 11 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,205] Trial 12 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 37.21514581711727.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerAverageLastYear_week_data_cleaned_algemene_kosten: 0.42 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_algemene_kosten: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 0 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.01 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 1 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.01 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 2 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921 in 0.01 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 3 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.01 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 4 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.01 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921 in 0.01 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 6 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921 in 0.01 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921 in 0.01 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 8 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.01 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 9 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.01 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.02 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 11 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.02 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 12 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.02 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:21,225] Trial 13 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,249] Trial 14 finished with value: 37.21514581711727 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 37.21514581711727.\n[I 2025-01-19 13:15:21,295] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:15:21,324] Trial 0 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,339] Trial 1 finished with value: 397.4713376908004 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,356] Trial 2 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,375] Trial 3 finished with value: 397.4713376908004 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,391] Trial 4 finished with value: 397.4713376908004 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,406] Trial 5 finished with value: 397.4713376908004 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,422] Trial 6 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.02 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914 in 0.02 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_autokosten: 0.24 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_autokosten: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 0 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.02 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 1 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630 in 0.01 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 2 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.01 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630 in 0.02 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 4 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630 in 0.01 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630 in 0.01 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 6 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.01 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:21,438] Trial 7 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,453] Trial 8 finished with value: 397.4713376908004 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,469] Trial 9 finished with value: 397.4713376908004 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,498] Trial 10 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,522] Trial 11 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,545] Trial 12 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,568] Trial 13 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,589] Trial 14 finished with value: 395.344124713736 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 395.344124713736.\n[I 2025-01-19 13:15:21,606] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:15:21,623] Trial 0 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,638] Trial 1 finished with value: 147.5745315041416 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.01 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 8 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630 in 0.01 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630 in 0.01 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.03 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 11 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.02 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 12 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.02 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.02 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346 in 0.02 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_exploitatie-_en_machinekosten: 0.30 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_exploitatie-_en_machinekosten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 0 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.01 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014 in 0.01 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:21,653] Trial 2 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,669] Trial 3 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,683] Trial 4 finished with value: 147.5745315041416 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,697] Trial 5 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,712] Trial 6 finished with value: 147.5745315041416 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,727] Trial 7 finished with value: 147.5745315041416 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,752] Trial 8 finished with value: 147.5745315041416 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,766] Trial 9 finished with value: 147.5745315041416 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,788] Trial 10 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,810] Trial 11 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,831] Trial 12 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,852] Trial 13 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.01 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 3 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.01 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 4 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014 in 0.01 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.01 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014 in 0.01 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 7 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014 in 0.01 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 8 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014 in 0.02 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 9 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014 in 0.01 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 10 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.02 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 11 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.02 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.02 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 13 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.02 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:21,873] Trial 14 finished with value: 147.54825373242198 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 147.54825373242198.\n[I 2025-01-19 13:15:21,888] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_kantoorkosten\n[I 2025-01-19 13:15:21,904] Trial 0 finished with value: 360.45042743531025 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 360.45042743531025.\n[I 2025-01-19 13:15:21,920] Trial 1 finished with value: 360.45042743531025 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 360.45042743531025.\n[I 2025-01-19 13:15:21,936] Trial 2 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:21,951] Trial 3 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:21,967] Trial 4 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:21,986] Trial 5 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,002] Trial 6 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,018] Trial 7 finished with value: 360.45042743531025 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,034] Trial 8 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,054] Trial 9 finished with value: 360.45042743531025 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerAverageLastYear_week_data_cleaned_huisvestingskosten: 0.27 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_huisvestingskosten: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 0 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239 in 0.01 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239 in 0.01 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 2 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.01 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 3 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.01 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 4 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.01 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.02 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 6 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.01 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 7 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239 in 0.01 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.01 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239 in 0.02 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:22,078] Trial 10 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,103] Trial 11 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,129] Trial 12 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,152] Trial 13 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,178] Trial 14 finished with value: 359.5246930770254 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 359.5246930770254.\n[I 2025-01-19 13:15:22,194] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:15:22,209] Trial 0 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 525.6161347527756.\n[I 2025-01-19 13:15:22,223] Trial 1 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 525.6161347527756.\n[I 2025-01-19 13:15:22,237] Trial 2 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 525.6161347527756.\n[I 2025-01-19 13:15:22,254] Trial 3 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,270] Trial 4 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 519.7038183653546.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.02 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 11 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.02 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.02 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 13 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.02 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104 in 0.02 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_kantoorkosten: 0.29 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_kantoorkosten: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 0 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 1 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 2 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 3 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.02 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 4 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 5 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:22,285] Trial 5 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,300] Trial 6 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,315] Trial 7 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,329] Trial 8 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,344] Trial 9 finished with value: 525.6161347527756 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,366] Trial 10 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,387] Trial 11 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,408] Trial 12 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,430] Trial 13 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,451] Trial 14 finished with value: 519.7038183653546 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 3 with value: 519.7038183653546.\n[I 2025-01-19 13:15:22,468] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_overige_bedrijfsopbrengsten\n[I 2025-01-19 13:15:22,559] Trial 0 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.01 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 9 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200 in 0.01 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 10 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.02 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 11 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.02 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 12 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.02 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 13 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.02 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028 in 0.02 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_lonen_en_salarissen: 0.26 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_lonen_en_salarissen: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 0 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.09 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:22,651] Trial 1 finished with value: 86.95380950372511 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:22,742] Trial 2 finished with value: 86.95380950372511 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 1 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798 in 0.09 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 2 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798 in 0.09 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:22,831] Trial 3 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:22,921] Trial 4 finished with value: 86.95380950372511 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,009] Trial 5 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.09 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 4 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798 in 0.09 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.09 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:23,098] Trial 6 finished with value: 86.95380950372511 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,181] Trial 7 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,274] Trial 8 finished with value: 86.95380950372511 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798 in 0.09 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 7 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.08 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 8 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798 in 0.09 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.08 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:23,359] Trial 9 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,457] Trial 10 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,557] Trial 11 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.10 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.10 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:23,655] Trial 12 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,750] Trial 13 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n[I 2025-01-19 13:15:23,851] Trial 14 finished with value: 62.7592553965631 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 62.7592553965631.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.10 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.09 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918 in 0.09 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_overige_bedrijfsopbrengsten: 1.38 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_overige_bedrijfsopbrengsten: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:23,950] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:15:23,975] Trial 0 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,000] Trial 1 finished with value: 202.02937669462588 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,023] Trial 2 finished with value: 202.02937669462588 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,047] Trial 3 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,076] Trial 4 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,100] Trial 5 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,126] Trial 6 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,150] Trial 7 finished with value: 202.02937669462588 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 0 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.02 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094 in 0.02 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 2 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094 in 0.02 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.02 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 4 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.03 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 5 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.02 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.02 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 7 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:24,176] Trial 8 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,201] Trial 9 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,234] Trial 10 finished with value: 202.02937669462588 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,267] Trial 11 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,300] Trial 12 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,333] Trial 13 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,365] Trial 14 finished with value: 200.77836340135713 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 200.77836340135713.\n[I 2025-01-19 13:15:24,391] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_overige_rentelasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 8 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.02 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.02 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094 in 0.03 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.03 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 12 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.03 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.03 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 14 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957 in 0.03 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_overige_personeelskosten: 0.42 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_overige_personeelskosten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:24,413] Trial 0 finished with value: 215.54453007312537 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 215.54453007312537.\n[I 2025-01-19 13:15:24,435] Trial 1 finished with value: 215.54453007312537 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 215.54453007312537.\n[I 2025-01-19 13:15:24,455] Trial 2 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,477] Trial 3 finished with value: 215.54453007312537 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,498] Trial 4 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,519] Trial 5 finished with value: 215.54453007312537 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,540] Trial 6 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,561] Trial 7 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,582] Trial 8 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,608] Trial 9 finished with value: 215.54453007312537 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096 in 0.02 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 1 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096 in 0.02 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 2 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.02 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096 in 0.02 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 4 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.02 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 5 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096 in 0.02 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.02 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 7 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.02 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.02 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 9 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096 in 0.02 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:24,639] Trial 10 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,674] Trial 11 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,703] Trial 12 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,731] Trial 13 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,762] Trial 14 finished with value: 214.75505922039076 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 214.75505922039076.\n[I 2025-01-19 13:15:24,783] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:15:24,792] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:15:24,793] Trial 0 failed with value None.\n[I 2025-01-19 13:15:24,794] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_verkoopkosten\n[I 2025-01-19 13:15:24,815] Trial 0 finished with value: 343.3029164937552 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 343.3029164937552.\n[I 2025-01-19 13:15:24,836] Trial 1 finished with value: 343.3029164937552 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 343.3029164937552.\n[I 2025-01-19 13:15:24,860] Trial 2 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.03 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.03 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 12 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.03 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.03 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008 in 0.03 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_overige_rentelasten: 0.37 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_overige_rentelasten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Error with trainer TrainerAverageLastYear on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 0 completed with RMSE: 343.3029, MAE: 256.6559, R²: -1.2785 in 0.02 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 1 completed with RMSE: 343.3029, MAE: 256.6559, R²: -1.2785 in 0.02 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:24,882] Trial 3 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:24,907] Trial 4 finished with value: 343.3029164937552 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:24,928] Trial 5 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:24,949] Trial 6 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:24,971] Trial 7 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 3 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.02 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 4 completed with RMSE: 343.3029, MAE: 256.6559, R²: -1.2785 in 0.02 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.02 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.02 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 7 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.02 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 8 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:24,996] Trial 8 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:25,018] Trial 9 finished with value: 343.3029164937552 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:25,053] Trial 10 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:25,082] Trial 11 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 343.3029, MAE: 256.6559, R²: -1.2785 in 0.02 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 10 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.03 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 11 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:25,110] Trial 12 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:25,138] Trial 13 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:25,165] Trial 14 finished with value: 343.141546353643 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 2 with value: 343.141546353643.\n[I 2025-01-19 13:15:25,187] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_afschrijvingen_mva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 12 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.03 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 13 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.03 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 14 completed with RMSE: 343.1415, MAE: 257.0760, R²: -1.2764 in 0.03 seconds\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_verkoopkosten: 0.37 seconds\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_verkoopkosten: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 0 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.13 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:25,319] Trial 0 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 495.2963649169409.\n[I 2025-01-19 13:15:25,447] Trial 1 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 495.2963649169409.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 1 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.13 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.12 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:25,570] Trial 2 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 495.2963649169409.\n[I 2025-01-19 13:15:25,689] Trial 3 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 3 with value: 491.024959763871.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 3 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.12 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:25,817] Trial 4 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:25,940] Trial 5 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.13 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 5 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.12 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 6 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.12 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:26,062] Trial 6 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:26,180] Trial 7 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:26,302] Trial 8 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 7 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.12 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.12 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:26,440] Trial 9 finished with value: 495.2963649169409 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:26,567] Trial 10 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 3 with value: 491.024959763871.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 9 completed with RMSE: 495.2964, MAE: 364.3300, R²: 0.0243 in 0.14 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 10 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.13 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 11 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.13 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:26,695] Trial 11 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:26,822] Trial 12 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 3 with value: 491.024959763871.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.13 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 13 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.13 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:26,953] Trial 13 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:27,079] Trial 14 finished with value: 491.024959763871 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 3 with value: 491.024959763871.\n[I 2025-01-19 13:15:27,199] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_afschrijvingen_iva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 491.0250, MAE: 364.4000, R²: 0.0410 in 0.12 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_mva: 1.89 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_mva: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Added results for TrainerAverageLastYear on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:27,242] Trial 0 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,286] Trial 1 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,331] Trial 2 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,374] Trial 3 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,419] Trial 4 finished with value: 0.0 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 0 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 1 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 2 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 3 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 4 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:27,465] Trial 5 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,509] Trial 6 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,553] Trial 7 finished with value: 0.0 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,598] Trial 8 finished with value: 0.0 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,641] Trial 9 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 6 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 7 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 8 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.04 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 10 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:27,693] Trial 10 finished with value: 0.0 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,745] Trial 11 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,794] Trial 12 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,847] Trial 13 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n[I 2025-01-19 13:15:27,896] Trial 14 finished with value: 0.0 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 11 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.05 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 12 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.05 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 13 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.05 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 14 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.05 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_iva: 0.70 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_iva: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Added results for TrainerAverageLastYear on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:27,944] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_omzet\n[I 2025-01-19 13:15:28,088] Trial 0 finished with value: 851.2408018755784 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 851.2408018755784.\n[I 2025-01-19 13:15:28,240] Trial 1 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 0 completed with RMSE: 851.2408, MAE: 667.8426, R²: -0.0246 in 0.14 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 1 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:28,384] Trial 2 finished with value: 851.2408018755784 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n[I 2025-01-19 13:15:28,541] Trial 3 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 2 completed with RMSE: 851.2408, MAE: 667.8426, R²: -0.0246 in 0.14 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 3 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:28,686] Trial 4 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 4 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.14 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 5 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:28,838] Trial 5 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n[I 2025-01-19 13:15:28,990] Trial 6 finished with value: 851.2408018755784 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 851.2408, MAE: 667.8426, R²: -0.0246 in 0.15 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 7 completed with RMSE: 851.2408, MAE: 667.8426, R²: -0.0246 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:29,134] Trial 7 finished with value: 851.2408018755784 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 832.0836507536724.\n[I 2025-01-19 13:15:29,278] Trial 8 finished with value: 851.2408018755784 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 8 completed with RMSE: 851.2408, MAE: 667.8426, R²: -0.0246 in 0.14 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 9 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:29,425] Trial 9 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 1 with value: 832.0836507536724.\n[I 2025-01-19 13:15:29,580] Trial 10 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:29,736] Trial 11 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n[I 2025-01-19 13:15:29,890] Trial 12 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 12 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 13 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:30,046] Trial 13 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n[I 2025-01-19 13:15:30,195] Trial 14 finished with value: 832.0836507536724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 1 with value: 832.0836507536724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 14 completed with RMSE: 832.0837, MAE: 662.7670, R²: 0.0210 in 0.15 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_omzet: 2.25 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_omzet: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:30,345] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_algemene_kosten\n[I 2025-01-19 13:15:30,555] Trial 0 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 0 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:30,765] Trial 1 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 1 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:30,981] Trial 2 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:31,199] Trial 3 finished with value: 1247.3781246668693 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1247.3781, MAE: 905.4872, R²: -0.2473 in 0.22 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 4 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:31,409] Trial 4 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n[I 2025-01-19 13:15:31,627] Trial 5 finished with value: 1247.3781246668693 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 5 completed with RMSE: 1247.3781, MAE: 905.4872, R²: -0.2473 in 0.22 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.20 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:31,833] Trial 6 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1121.0507904219921.\n[I 2025-01-19 13:15:32,049] Trial 7 finished with value: 1247.3781246668693 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 7 completed with RMSE: 1247.3781, MAE: 905.4872, R²: -0.2473 in 0.21 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 8 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:32,258] Trial 8 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1121.0507904219921.\n[I 2025-01-19 13:15:32,456] Trial 9 finished with value: 1247.3781246668693 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 9 completed with RMSE: 1247.3781, MAE: 905.4872, R²: -0.2473 in 0.20 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:32,700] Trial 10 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.24 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:32,912] Trial 11 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n[I 2025-01-19 13:15:33,139] Trial 12 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 12 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.22 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.22 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:33,359] Trial 13 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:33,572] Trial 14 finished with value: 1121.0507904219921 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 1121.0507904219921.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1121.0508, MAE: 903.6408, R²: -0.0075 in 0.21 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_algemene_kosten: 3.23 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_algemene_kosten: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Added results for TrainerAverageLastYear on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:33,782] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_autokosten\n[I 2025-01-19 13:15:34,021] Trial 0 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1520.7091809558717.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 0 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.24 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:34,259] Trial 1 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1520.7091809558717.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.24 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:34,497] Trial 2 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1520.7091809558717.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.24 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.24 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:34,740] Trial 3 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1520.7091809558717.\n[I 2025-01-19 13:15:35,005] Trial 4 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 4 with value: 1351.9611806413977.\n[I 2025-01-19 13:15:35,266] Trial 5 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 4 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.26 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.26 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 6 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.26 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:35,529] Trial 6 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 4 with value: 1351.9611806413977.\n[I 2025-01-19 13:15:35,779] Trial 7 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 7 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.25 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:36,040] Trial 8 finished with value: 1520.7091809558717 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 8 completed with RMSE: 1520.7092, MAE: 1023.6304, R²: -0.2463 in 0.26 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:36,338] Trial 9 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.30 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:36,609] Trial 10 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.27 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:36,864] Trial 11 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.25 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:37,132] Trial 12 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.27 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.25 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:37,385] Trial 13 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 4 with value: 1351.9611806413977.\n[I 2025-01-19 13:15:37,641] Trial 14 finished with value: 1351.9611806413977 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 4 with value: 1351.9611806413977.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 1351.9612, MAE: 1143.7006, R²: 0.0150 in 0.25 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:37,901] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_overige_rentelasten\n[I 2025-01-19 13:15:38,055] Trial 0 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerAverageLastYear_month_data_cleaned_autokosten: 3.86 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_autokosten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 0 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.15 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:38,205] Trial 1 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:38,357] Trial 2 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:38,496] Trial 3 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.15 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 3 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:38,634] Trial 4 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:38,776] Trial 5 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 4 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.14 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 5 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:38,922] Trial 6 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:39,060] Trial 7 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 6 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.14 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 7 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:39,207] Trial 8 finished with value: 881.8884009997572 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 8 completed with RMSE: 881.8884, MAE: 603.4435, R²: -0.1663 in 0.14 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:39,357] Trial 9 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:39,504] Trial 10 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 10 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 11 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:39,657] Trial 11 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:39,809] Trial 12 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 821.2668118811828.\n[I 2025-01-19 13:15:39,963] Trial 13 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 12 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:40,118] Trial 14 finished with value: 821.2668118811828 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 821.2668118811828.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 821.2668, MAE: 577.4654, R²: -0.0114 in 0.15 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_overige_rentelasten: 2.22 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_overige_rentelasten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Added results for TrainerAverageLastYear on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:40,273] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_pensioenlasten\n[I 2025-01-19 13:15:40,322] Trial 0 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 460.64666502646037.\n[I 2025-01-19 13:15:40,368] Trial 1 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 460.64666502646037.\n[I 2025-01-19 13:15:40,411] Trial 2 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 460.64666502646037.\n[I 2025-01-19 13:15:40,454] Trial 3 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 460.64666502646037.\n[I 2025-01-19 13:15:40,503] Trial 4 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 4 with value: 433.478201814724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 0 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.05 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 1 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.04 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 2 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.04 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 3 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.04 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 4 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:40,549] Trial 5 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,593] Trial 6 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,641] Trial 7 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,683] Trial 8 finished with value: 460.64666502646037 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,728] Trial 9 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.04 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.04 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.05 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 8 completed with RMSE: 460.6467, MAE: 297.3667, R²: 0.0648 in 0.04 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 9 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.04 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:40,781] Trial 10 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,831] Trial 11 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,884] Trial 12 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:40,936] Trial 13 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.05 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 11 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.05 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.05 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 13 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.05 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 433.4782, MAE: 389.1784, R²: 0.1719 in 0.05 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:40,988] Trial 14 finished with value: 433.478201814724 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 4 with value: 433.478201814724.\n[I 2025-01-19 13:15:41,042] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:15:41,129] Trial 0 finished with value: 1100.372875203784 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1100.372875203784.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_pensioenlasten: 0.72 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_pensioenlasten: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 0 completed with RMSE: 1100.3729, MAE: 810.4741, R²: -0.0081 in 0.09 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 1 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:41,215] Trial 1 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:41,301] Trial 2 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:41,385] Trial 3 finished with value: 1100.372875203784 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:41,470] Trial 4 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1093.8553304121015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 2 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 3 completed with RMSE: 1100.3729, MAE: 810.4741, R²: -0.0081 in 0.08 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 4 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:41,554] Trial 5 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:41,639] Trial 6 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:41,722] Trial 7 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1093.8553304121015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 5 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 6 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:41,806] Trial 8 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:41,891] Trial 9 finished with value: 1100.372875203784 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.08 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 1100.3729, MAE: 810.4741, R²: -0.0081 in 0.08 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:41,986] Trial 10 finished with value: 1100.372875203784 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:42,081] Trial 11 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:42,172] Trial 12 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1100.3729, MAE: 810.4741, R²: -0.0081 in 0.09 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 11 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.09 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 12 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.09 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 13 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.09 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:42,264] Trial 13 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:42,354] Trial 14 finished with value: 1093.8553304121015 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 1 with value: 1093.8553304121015.\n[I 2025-01-19 13:15:42,439] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_overige_personeelskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 14 completed with RMSE: 1093.8553, MAE: 804.9677, R²: 0.0038 in 0.09 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_lonen_en_salarissen: 1.31 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_lonen_en_salarissen: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:42,620] Trial 0 finished with value: 909.1485443851163 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 909.1485443851163.\n[I 2025-01-19 13:15:42,804] Trial 1 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 909.1485, MAE: 401.0152, R²: -0.0639 in 0.18 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 1 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.18 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:42,988] Trial 2 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 874.1253483191928.\n[I 2025-01-19 13:15:43,167] Trial 3 finished with value: 909.1485443851163 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.18 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 3 completed with RMSE: 909.1485, MAE: 401.0152, R²: -0.0639 in 0.18 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:43,366] Trial 4 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n[I 2025-01-19 13:15:43,545] Trial 5 finished with value: 909.1485443851163 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.20 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 5 completed with RMSE: 909.1485, MAE: 401.0152, R²: -0.0639 in 0.18 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.20 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:43,750] Trial 6 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n[I 2025-01-19 13:15:43,927] Trial 7 finished with value: 909.1485443851163 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 7 completed with RMSE: 909.1485, MAE: 401.0152, R²: -0.0639 in 0.18 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:44,123] Trial 8 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n[I 2025-01-19 13:15:44,295] Trial 9 finished with value: 909.1485443851163 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.19 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 909.1485, MAE: 401.0152, R²: -0.0639 in 0.17 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:44,485] Trial 10 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n[I 2025-01-19 13:15:44,676] Trial 11 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.19 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 11 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.19 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:44,941] Trial 12 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.26 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.20 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:45,149] Trial 13 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 874.1253, MAE: 481.0741, R²: 0.0165 in 0.24 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:45,395] Trial 14 finished with value: 874.1253483191928 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 1 with value: 874.1253483191928.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerAverageLastYear_month_data_cleaned_overige_personeelskosten: 3.00 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_overige_personeelskosten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Added results for TrainerAverageLastYear on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:45,711] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_sociale_lasten\n[I 2025-01-19 13:15:45,814] Trial 0 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:45,897] Trial 1 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:45,985] Trial 2 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 0 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.08 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 1 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.08 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 2 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.09 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:46,069] Trial 3 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:46,151] Trial 4 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 3 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.08 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 4 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.08 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:46,233] Trial 5 finished with value: 743.5845950529099 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:46,346] Trial 6 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:46,450] Trial 7 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 743.5846, MAE: 530.4000, R²: -0.0598 in 0.08 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.11 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 7 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:46,530] Trial 8 finished with value: 743.5845950529099 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:46,613] Trial 9 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:46,702] Trial 10 finished with value: 743.5845950529099 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 8 completed with RMSE: 743.5846, MAE: 530.4000, R²: -0.0598 in 0.08 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 9 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.08 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 743.5846, MAE: 530.4000, R²: -0.0598 in 0.09 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:46,793] Trial 11 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:46,882] Trial 12 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 708.2698013537029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 11 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.09 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.09 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:46,977] Trial 13 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:47,074] Trial 14 finished with value: 708.2698013537029 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 708.2698013537029.\n[I 2025-01-19 13:15:47,164] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_exploitatie-_en_machinekosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.09 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 708.2698, MAE: 501.3493, R²: 0.0385 in 0.10 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_sociale_lasten: 1.36 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_sociale_lasten: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:47,287] Trial 0 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:47,398] Trial 1 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.12 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 1 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.11 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 2 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.11 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:47,512] Trial 2 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:47,618] Trial 3 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:47,719] Trial 4 finished with value: 1367.0604029340732 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 3 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 4 completed with RMSE: 1367.0604, MAE: 997.5676, R²: -0.0774 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:47,823] Trial 5 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:47,925] Trial 6 finished with value: 1367.0604029340732 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 5 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 6 completed with RMSE: 1367.0604, MAE: 997.5676, R²: -0.0774 in 0.10 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 7 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:48,023] Trial 7 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:48,127] Trial 8 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:48,226] Trial 9 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 8 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 10 completed with RMSE: 1367.0604, MAE: 997.5676, R²: -0.0774 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:48,328] Trial 10 finished with value: 1367.0604029340732 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:48,436] Trial 11 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:48,541] Trial 12 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 11 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.11 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 12 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:48,652] Trial 13 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 1194.7978837047015.\n[I 2025-01-19 13:15:48,757] Trial 14 finished with value: 1194.7978837047015 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 1194.7978837047015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.11 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 14 completed with RMSE: 1194.7979, MAE: 937.8255, R²: 0.1770 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:48,858] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_kostprijs_van_de_omzet\n[I 2025-01-19 13:15:49,002] Trial 0 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerAverageLastYear_month_data_cleaned_exploitatie-_en_machinekosten: 1.59 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_exploitatie-_en_machinekosten: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 0 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:49,141] Trial 1 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:49,269] Trial 2 finished with value: 1371.1733574942605 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 1 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.13 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 1371.1734, MAE: 984.2656, R²: -0.1530 in 0.13 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 3 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.14 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:49,408] Trial 3 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:49,545] Trial 4 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 4 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.14 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.14 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:49,688] Trial 5 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:49,819] Trial 6 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:49,952] Trial 7 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.13 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 7 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.13 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 1371.1734, MAE: 984.2656, R²: -0.1530 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:50,089] Trial 8 finished with value: 1371.1733574942605 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:50,222] Trial 9 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.13 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:50,357] Trial 10 finished with value: 1371.1733574942605 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1371.1734, MAE: 984.2656, R²: -0.1530 in 0.13 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 11 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.14 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:50,498] Trial 11 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:50,635] Trial 12 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.14 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 13 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.13 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:50,771] Trial 13 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:50,906] Trial 14 finished with value: 1284.8064530123156 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 1284.8064530123156.\n[I 2025-01-19 13:15:51,039] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_kantoorkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 14 completed with RMSE: 1284.8065, MAE: 984.0263, R²: -0.0124 in 0.13 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_kostprijs_van_de_omzet: 2.05 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_kostprijs_van_de_omzet: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Added results for TrainerAverageLastYear on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:51,209] Trial 0 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 0 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.17 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:51,380] Trial 1 finished with value: 570.065743911132 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:51,545] Trial 2 finished with value: 570.065743911132 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 570.0657, MAE: 365.4603, R²: -0.0897 in 0.17 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 570.0657, MAE: 365.4603, R²: -0.0897 in 0.16 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:51,729] Trial 3 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:51,902] Trial 4 finished with value: 570.065743911132 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.18 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 4 completed with RMSE: 570.0657, MAE: 365.4603, R²: -0.0897 in 0.17 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:52,073] Trial 5 finished with value: 570.065743911132 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:52,242] Trial 6 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 570.0657, MAE: 365.4603, R²: -0.0897 in 0.17 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.17 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:52,417] Trial 7 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:52,597] Trial 8 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.17 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 8 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.18 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:52,774] Trial 9 finished with value: 570.065743911132 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:52,951] Trial 10 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 570.0657, MAE: 365.4603, R²: -0.0897 in 0.18 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 10 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.18 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:53,133] Trial 11 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:53,305] Trial 12 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.18 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.17 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 13 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.18 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:53,484] Trial 13 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 552.8550348997708.\n[I 2025-01-19 13:15:53,659] Trial 14 finished with value: 552.8550348997708 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 552.8550348997708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 552.8550, MAE: 375.7226, R²: -0.0249 in 0.17 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_kantoorkosten: 2.62 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_kantoorkosten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:53,839] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_verkoopkosten\n[I 2025-01-19 13:15:53,950] Trial 0 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 0 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 348.4839, MAE: 195.2179, R²: -0.2245 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:54,052] Trial 1 finished with value: 348.4839461110302 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:54,156] Trial 2 finished with value: 348.4839461110302 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:54,261] Trial 3 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 2 completed with RMSE: 348.4839, MAE: 195.2179, R²: -0.2245 in 0.10 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:54,369] Trial 4 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:54,470] Trial 5 finished with value: 348.4839461110302 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 4 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 348.4839, MAE: 195.2179, R²: -0.2245 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:54,577] Trial 6 finished with value: 348.4839461110302 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:54,688] Trial 7 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:54,794] Trial 8 finished with value: 348.4839461110302 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 6 completed with RMSE: 348.4839, MAE: 195.2179, R²: -0.2245 in 0.11 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 8 completed with RMSE: 348.4839, MAE: 195.2179, R²: -0.2245 in 0.11 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:54,908] Trial 9 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:55,019] Trial 10 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 10 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,130] Trial 11 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n[I 2025-01-19 13:15:55,240] Trial 12 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 12 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,350] Trial 13 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 13 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.11 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,477] Trial 14 finished with value: 319.4535478518266 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 319.4535478518266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 14 completed with RMSE: 319.4535, MAE: 193.3625, R²: -0.0290 in 0.12 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,584] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_huisvestingskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerAverageLastYear_month_data_cleaned_verkoopkosten: 1.64 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_verkoopkosten: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Added results for TrainerAverageLastYear on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,665] Trial 0 finished with value: 1232.191665285884 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 1232.191665285884.\n[I 2025-01-19 13:15:55,754] Trial 1 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 0 completed with RMSE: 1232.1917, MAE: 953.4333, R²: -0.0466 in 0.08 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 1 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.09 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,840] Trial 2 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.08 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:55,931] Trial 3 finished with value: 1232.191665285884 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n[I 2025-01-19 13:15:56,019] Trial 4 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1232.1917, MAE: 953.4333, R²: -0.0466 in 0.09 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 4 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.09 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 5 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:56,105] Trial 5 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 1213.8206632211966.\n[I 2025-01-19 13:15:56,190] Trial 6 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 6 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.08 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:56,274] Trial 7 finished with value: 1232.191665285884 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n[I 2025-01-19 13:15:56,360] Trial 8 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1232.1917, MAE: 953.4333, R²: -0.0466 in 0.08 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.08 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 1232.1917, MAE: 953.4333, R²: -0.0466 in 0.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:56,441] Trial 9 finished with value: 1232.191665285884 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:56,537] Trial 10 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1213.8206632211966.\n[I 2025-01-19 13:15:56,628] Trial 11 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.09 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 11 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.09 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 12 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.09 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:56,719] Trial 12 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 13 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.10 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:56,817] Trial 13 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n[I 2025-01-19 13:15:56,905] Trial 14 finished with value: 1213.8206632211966 and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}. Best is trial 1 with value: 1213.8206632211966.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 1213.8207, MAE: 955.5428, R²: -0.0157 in 0.09 seconds\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_huisvestingskosten: 1.32 seconds\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_huisvestingskosten: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:57,005] A new study created in memory with name: TrainerAverageLastYear_day_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:58,280] Trial 0 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.27 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:15:59,419] Trial 1 finished with value: 695.3738748006145 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 695.3739, MAE: 559.4041, R²: -0.0397 in 1.14 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:00,687] Trial 2 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.27 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:01,955] Trial 3 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.27 seconds\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:03,091] Trial 4 finished with value: 695.3738748006145 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 695.3739, MAE: 559.4041, R²: -0.0397 in 1.13 seconds\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:04,224] Trial 5 finished with value: 695.3738748006145 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 695.3739, MAE: 559.4041, R²: -0.0397 in 1.13 seconds\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:05,480] Trial 6 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.26 seconds\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:06,619] Trial 7 finished with value: 695.3738748006145 and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 695.3739, MAE: 559.4041, R²: -0.0397 in 1.14 seconds\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:07,748] Trial 8 finished with value: 695.3738748006145 and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 695.3739, MAE: 559.4041, R²: -0.0397 in 1.13 seconds\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:08,883] Trial 9 finished with value: 695.3738748006145 and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 695.3739, MAE: 559.4041, R²: -0.0397 in 1.13 seconds\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:10,203] Trial 10 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.32 seconds\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:11,476] Trial 11 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.27 seconds\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:12,817] Trial 12 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.34 seconds\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:14,088] Trial 13 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.27 seconds\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:15,360] Trial 14 finished with value: 689.4241188933919 and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}. Best is trial 0 with value: 689.4241188933919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 689.4241, MAE: 558.2878, R²: -0.0220 in 1.27 seconds\nTotal optimization time for TrainerAverageLastYear_day_data: 18.36 seconds\nBest hyperparameters for TrainerAverageLastYear_day_data: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:16,642] A new study created in memory with name: TrainerAverageLastYear_weather_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:16,645] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_average_last_year.py\", line 32, in fit\n    trainset = pdf_train[[\n               ^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:16:16,863] Trial 0 failed with value None.\n[I 2025-01-19 13:16:16,864] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_algemene_kosten\n[I 2025-01-19 13:16:16,910] Trial 0 finished with value: 214.46401920597447 and parameters: {'max_depth': 23, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 214.46401920597447.\n[I 2025-01-19 13:16:16,944] Trial 1 finished with value: 172.4564502505189 and parameters: {'max_depth': 40, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:16,981] Trial 2 finished with value: 175.3725853413822 and parameters: {'max_depth': 29, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,015] Trial 3 finished with value: 179.85970382009535 and parameters: {'max_depth': 54, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,049] Trial 4 finished with value: 208.31760199505675 and parameters: {'max_depth': 92, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerAverageLastYear on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerDecisionTree\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'max_depth': 23, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 214.4640, MAE: 114.3107, R²: 0.4052 in 0.05 seconds\n  Trial 1: Hyperparameters {'max_depth': 40, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 172.4565, MAE: 112.9311, R²: 0.6154 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 29, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 175.3726, MAE: 68.9029, R²: 0.6023 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 54, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 179.8597, MAE: 117.7117, R²: 0.5817 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 92, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 208.3176, MAE: 111.6990, R²: 0.4388 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 12, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:17,084] Trial 5 finished with value: 172.53284744245641 and parameters: {'max_depth': 12, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,119] Trial 6 finished with value: 214.4636796823943 and parameters: {'max_depth': 52, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,154] Trial 7 finished with value: 185.19318501688724 and parameters: {'max_depth': 92, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,188] Trial 8 finished with value: 183.3364683609564 and parameters: {'max_depth': 66, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,222] Trial 9 finished with value: 183.3364683609564 and parameters: {'max_depth': 40, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,269] Trial 10 finished with value: 183.3364683609564 and parameters: {'max_depth': 72, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 172.5328, MAE: 113.2408, R²: 0.6151 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 52, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 214.4637, MAE: 114.5146, R²: 0.4052 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 92, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 185.1932, MAE: 120.0243, R²: 0.5565 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 66, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 183.3365, MAE: 118.8087, R²: 0.5653 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 40, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 183.3365, MAE: 118.8087, R²: 0.5653 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 72, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 183.3365, MAE: 118.8087, R²: 0.5653 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 5, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:17,319] Trial 11 finished with value: 172.49102537509438 and parameters: {'max_depth': 5, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,367] Trial 12 finished with value: 172.49102537509438 and parameters: {'max_depth': 9, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,412] Trial 13 finished with value: 183.3364683609564 and parameters: {'max_depth': 27, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,458] Trial 14 finished with value: 183.3364683609564 and parameters: {'max_depth': 38, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.4564502505189.\n[I 2025-01-19 13:16:17,492] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_autokosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 172.4910, MAE: 113.1000, R²: 0.6153 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 9, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 172.4910, MAE: 113.1000, R²: 0.6153 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 27, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 183.3365, MAE: 118.8087, R²: 0.5653 in 0.04 seconds\n  Trial 14: Hyperparameters {'max_depth': 38, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 183.3365, MAE: 118.8087, R²: 0.5653 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_algemene_kosten: 0.60 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_algemene_kosten: {'max_depth': 40, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'max_depth': 8, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:17,527] Trial 0 finished with value: 99.09423124817441 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 99.09423124817441.\n[I 2025-01-19 13:16:17,562] Trial 1 finished with value: 96.41873953404148 and parameters: {'max_depth': 36, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,597] Trial 2 finished with value: 96.41873953404148 and parameters: {'max_depth': 57, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,631] Trial 3 finished with value: 117.20368978833388 and parameters: {'max_depth': 20, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,665] Trial 4 finished with value: 96.41873953404148 and parameters: {'max_depth': 84, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,700] Trial 5 finished with value: 96.41873953404148 and parameters: {'max_depth': 5, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 99.0942, MAE: 63.6667, R²: -0.4787 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 36, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 96.4187, MAE: 62.0667, R²: -0.3999 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 57, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 96.4187, MAE: 62.0667, R²: -0.3999 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 20, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 117.2037, MAE: 104.5233, R²: -1.0685 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 84, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 96.4187, MAE: 62.0667, R²: -0.3999 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 5, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 96.4187, MAE: 62.0667, R²: -0.3999 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 45, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:17,736] Trial 6 finished with value: 96.41873953404148 and parameters: {'max_depth': 45, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,770] Trial 7 finished with value: 99.09423124817441 and parameters: {'max_depth': 70, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,803] Trial 8 finished with value: 96.41873953404148 and parameters: {'max_depth': 37, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,837] Trial 9 finished with value: 117.20368978833388 and parameters: {'max_depth': 24, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,882] Trial 10 finished with value: 99.09423124817441 and parameters: {'max_depth': 99, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n[I 2025-01-19 13:16:17,929] Trial 11 finished with value: 101.39526616169022 and parameters: {'max_depth': 60, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 96.41873953404148.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 96.4187, MAE: 62.0667, R²: -0.3999 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 70, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 99.0942, MAE: 63.6667, R²: -0.4787 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 37, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 96.4187, MAE: 62.0667, R²: -0.3999 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 24, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 117.2037, MAE: 104.5233, R²: -1.0685 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 99, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 99.0942, MAE: 63.6667, R²: -0.4787 in 0.04 seconds\n  Trial 11: Hyperparameters {'max_depth': 60, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 101.3953, MAE: 65.0000, R²: -0.5481 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 57, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:17,978] Trial 12 finished with value: 95.06839643120105 and parameters: {'max_depth': 57, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 12 with value: 95.06839643120105.\n[I 2025-01-19 13:16:18,022] Trial 13 finished with value: 101.39526616169022 and parameters: {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 12 with value: 95.06839643120105.\n[I 2025-01-19 13:16:18,068] Trial 14 finished with value: 117.20368978833388 and parameters: {'max_depth': 68, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 12 with value: 95.06839643120105.\n[I 2025-01-19 13:16:18,100] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:16:18,134] Trial 0 finished with value: 136.37012379654757 and parameters: {'max_depth': 16, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,167] Trial 1 finished with value: 310.69248692005965 and parameters: {'max_depth': 77, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 95.0684, MAE: 61.3333, R²: -0.3610 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 101.3953, MAE: 65.0000, R²: -0.5481 in 0.04 seconds\n  Trial 14: Hyperparameters {'max_depth': 68, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 117.2037, MAE: 104.5233, R²: -1.0685 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_autokosten: 0.58 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_autokosten: {'max_depth': 57, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'max_depth': 16, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 136.3701, MAE: 100.1214, R²: 0.6865 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 77, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 310.6925, MAE: 244.2500, R²: -0.6272 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 37, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:18,201] Trial 2 finished with value: 310.69248692005965 and parameters: {'max_depth': 37, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,235] Trial 3 finished with value: 138.3869061079944 and parameters: {'max_depth': 28, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,267] Trial 4 finished with value: 307.55031579634016 and parameters: {'max_depth': 6, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,301] Trial 5 finished with value: 311.033702813239 and parameters: {'max_depth': 18, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,335] Trial 6 finished with value: 138.3869061079944 and parameters: {'max_depth': 46, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,368] Trial 7 finished with value: 311.033702813239 and parameters: {'max_depth': 40, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 310.6925, MAE: 244.2500, R²: -0.6272 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 28, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 138.3869, MAE: 105.0896, R²: 0.6772 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 6, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 307.5503, MAE: 244.7025, R²: -0.5944 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 18, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 311.0337, MAE: 250.3929, R²: -0.6307 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 46, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 138.3869, MAE: 105.0896, R²: 0.6772 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 40, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 311.0337, MAE: 250.3929, R²: -0.6307 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 33, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 311.0337, MAE: 250.3929, R²: -0.6307 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:18,405] Trial 8 finished with value: 311.033702813239 and parameters: {'max_depth': 33, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,444] Trial 9 finished with value: 310.3198654441667 and parameters: {'max_depth': 15, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,492] Trial 10 finished with value: 325.0669161880366 and parameters: {'max_depth': 66, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 136.37012379654757.\n[I 2025-01-19 13:16:18,540] Trial 11 finished with value: 132.5329887235627 and parameters: {'max_depth': 25, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 11 with value: 132.5329887235627.\n[I 2025-01-19 13:16:18,588] Trial 12 finished with value: 141.66499742854114 and parameters: {'max_depth': 98, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 11 with value: 132.5329887235627.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: Hyperparameters {'max_depth': 15, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 310.3199, MAE: 249.5296, R²: -0.6233 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 66, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 325.0669, MAE: 253.0714, R²: -0.7812 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 25, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 132.5330, MAE: 99.0693, R²: 0.7039 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 98, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 141.6650, MAE: 106.9825, R²: 0.6617 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 61, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:18,637] Trial 13 finished with value: 132.5329887235627 and parameters: {'max_depth': 61, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 11 with value: 132.5329887235627.\n[I 2025-01-19 13:16:18,686] Trial 14 finished with value: 140.0907780690792 and parameters: {'max_depth': 64, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 11 with value: 132.5329887235627.\n[I 2025-01-19 13:16:18,729] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:16:18,764] Trial 0 finished with value: 139.2382830268185 and parameters: {'max_depth': 9, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 139.2382830268185.\n[I 2025-01-19 13:16:18,799] Trial 1 finished with value: 139.2382830268185 and parameters: {'max_depth': 58, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 139.2382830268185.\n[I 2025-01-19 13:16:18,835] Trial 2 finished with value: 139.16693535978976 and parameters: {'max_depth': 77, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 139.16693535978976.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 132.5330, MAE: 99.0693, R²: 0.7039 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 64, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 140.0908, MAE: 106.1193, R²: 0.6692 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_exploitatie-_en_machinekosten: 0.59 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_exploitatie-_en_machinekosten: {'max_depth': 25, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'max_depth': 9, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 139.2383, MAE: 53.9040, R²: -0.0695 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 58, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 139.2383, MAE: 53.9040, R²: -0.0695 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 77, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 139.1669, MAE: 55.0513, R²: -0.0684 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 13, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:18,870] Trial 3 finished with value: 139.10879343253757 and parameters: {'max_depth': 13, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:18,902] Trial 4 finished with value: 139.4869355338176 and parameters: {'max_depth': 93, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:18,937] Trial 5 finished with value: 139.69199511324172 and parameters: {'max_depth': 32, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:18,974] Trial 6 finished with value: 142.5258291930957 and parameters: {'max_depth': 49, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,008] Trial 7 finished with value: 139.65298395280738 and parameters: {'max_depth': 55, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,049] Trial 8 finished with value: 139.4869355338176 and parameters: {'max_depth': 41, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 139.1088, MAE: 54.9231, R²: -0.0676 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 93, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 139.4869, MAE: 53.3428, R²: -0.0734 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 32, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 139.6920, MAE: 54.4404, R²: -0.0765 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 49, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 142.5258, MAE: 54.9985, R²: -0.1206 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 55, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 139.6530, MAE: 53.0160, R²: -0.0759 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 41, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 139.4869, MAE: 53.3428, R²: -0.0734 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 80, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:19,086] Trial 9 finished with value: 139.2382830268185 and parameters: {'max_depth': 80, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,130] Trial 10 finished with value: 140.01123830350923 and parameters: {'max_depth': 6, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,175] Trial 11 finished with value: 139.16693535978976 and parameters: {'max_depth': 73, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,221] Trial 12 finished with value: 142.5258291930957 and parameters: {'max_depth': 23, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,266] Trial 13 finished with value: 139.39094855284378 and parameters: {'max_depth': 73, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 139.2383, MAE: 53.9040, R²: -0.0695 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 6, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 140.0112, MAE: 53.8108, R²: -0.0815 in 0.04 seconds\n  Trial 11: Hyperparameters {'max_depth': 73, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 139.1669, MAE: 55.0513, R²: -0.0684 in 0.04 seconds\n  Trial 12: Hyperparameters {'max_depth': 23, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 142.5258, MAE: 54.9985, R²: -0.1206 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 73, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 139.3909, MAE: 54.9679, R²: -0.0719 in 0.04 seconds\n  Trial 14: Hyperparameters {'max_depth': 100, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:19,312] Trial 14 finished with value: 140.05179252141522 and parameters: {'max_depth': 100, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 139.10879343253757.\n[I 2025-01-19 13:16:19,344] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_kantoorkosten\n[I 2025-01-19 13:16:19,378] Trial 0 finished with value: 187.0551652389027 and parameters: {'max_depth': 18, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 187.0551652389027.\n[I 2025-01-19 13:16:19,414] Trial 1 finished with value: 172.07728038742334 and parameters: {'max_depth': 68, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.07728038742334.\n[I 2025-01-19 13:16:19,447] Trial 2 finished with value: 181.59546205901054 and parameters: {'max_depth': 36, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.07728038742334.\n[I 2025-01-19 13:16:19,481] Trial 3 finished with value: 181.59546205901054 and parameters: {'max_depth': 85, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 172.07728038742334.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 140.0518, MAE: 53.9686, R²: -0.0821 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_huisvestingskosten: 0.58 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_huisvestingskosten: {'max_depth': 13, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'max_depth': 18, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 187.0552, MAE: 113.6562, R²: 0.2934 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 68, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 172.0773, MAE: 86.1383, R²: 0.4020 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 36, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 181.5955, MAE: 109.2343, R²: 0.3340 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 85, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 181.5955, MAE: 109.2343, R²: 0.3340 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 37, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 181.5955, MAE: 109.2343, R²: 0.3340 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:19,517] Trial 4 finished with value: 181.59546205901054 and parameters: {'max_depth': 37, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 172.07728038742334.\n[I 2025-01-19 13:16:19,552] Trial 5 finished with value: 171.98835474556148 and parameters: {'max_depth': 95, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n[I 2025-01-19 13:16:19,589] Trial 6 finished with value: 187.0551652389027 and parameters: {'max_depth': 87, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n[I 2025-01-19 13:16:19,623] Trial 7 finished with value: 180.75024425986263 and parameters: {'max_depth': 29, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n[I 2025-01-19 13:16:19,656] Trial 8 finished with value: 172.73029113793487 and parameters: {'max_depth': 99, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n[I 2025-01-19 13:16:19,690] Trial 9 finished with value: 205.95934064761423 and parameters: {'max_depth': 68, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'max_depth': 95, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 171.9884, MAE: 86.1436, R²: 0.4026 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 87, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 187.0552, MAE: 113.6562, R²: 0.2934 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 29, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 180.7502, MAE: 107.2413, R²: 0.3402 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 99, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 172.7303, MAE: 86.8723, R²: 0.3975 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 68, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 205.9593, MAE: 102.3723, R²: 0.1433 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 58, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:19,739] Trial 10 finished with value: 179.5117639717668 and parameters: {'max_depth': 58, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n[I 2025-01-19 13:16:19,788] Trial 11 finished with value: 172.81923898021924 and parameters: {'max_depth': 71, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 171.98835474556148.\n[I 2025-01-19 13:16:19,836] Trial 12 finished with value: 169.54344199468247 and parameters: {'max_depth': 99, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 12 with value: 169.54344199468247.\n[I 2025-01-19 13:16:19,884] Trial 13 finished with value: 169.538673175555 and parameters: {'max_depth': 100, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 13 with value: 169.538673175555.\n[I 2025-01-19 13:16:19,930] Trial 14 finished with value: 173.9673483670782 and parameters: {'max_depth': 81, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 13 with value: 169.538673175555.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 179.5118, MAE: 90.1596, R²: 0.3492 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 71, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 172.8192, MAE: 86.8723, R²: 0.3968 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 99, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 169.5434, MAE: 85.7447, R²: 0.4195 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 100, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 169.5387, MAE: 85.7021, R²: 0.4195 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 81, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 173.9673, MAE: 91.0213, R²: 0.3888 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_kantoorkosten: 0.59 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_kantoorkosten: {'max_depth': 100, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:19,964] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:16:19,999] Trial 0 finished with value: 461.31865437091125 and parameters: {'max_depth': 60, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 461.31865437091125.\n[I 2025-01-19 13:16:20,034] Trial 1 finished with value: 470.3718311894013 and parameters: {'max_depth': 79, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 461.31865437091125.\n[I 2025-01-19 13:16:20,067] Trial 2 finished with value: 632.77553868093 and parameters: {'max_depth': 68, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 461.31865437091125.\n[I 2025-01-19 13:16:20,102] Trial 3 finished with value: 634.1424292139833 and parameters: {'max_depth': 6, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 461.31865437091125.\n[I 2025-01-19 13:16:20,134] Trial 4 finished with value: 461.31865437091125 and parameters: {'max_depth': 51, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 461.31865437091125.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'max_depth': 60, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 461.3187, MAE: 369.5659, R²: 0.2143 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 79, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 470.3718, MAE: 393.2624, R²: 0.1832 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 68, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 632.7755, MAE: 424.8824, R²: -0.4783 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 6, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 634.1424, MAE: 433.3918, R²: -0.4847 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 51, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 461.3187, MAE: 369.5659, R²: 0.2143 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 63, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 635.6117, MAE: 447.3129, R²: -0.4915 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:20,167] Trial 5 finished with value: 635.6116718470762 and parameters: {'max_depth': 63, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 461.31865437091125.\n[I 2025-01-19 13:16:20,201] Trial 6 finished with value: 423.08439956224004 and parameters: {'max_depth': 93, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,232] Trial 7 finished with value: 483.0728756068372 and parameters: {'max_depth': 46, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,265] Trial 8 finished with value: 635.6116718470762 and parameters: {'max_depth': 53, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,298] Trial 9 finished with value: 461.31865437091125 and parameters: {'max_depth': 88, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,343] Trial 10 finished with value: 423.08439956224004 and parameters: {'max_depth': 99, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: Hyperparameters {'max_depth': 93, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 423.0844, MAE: 337.9482, R²: 0.3391 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 46, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 483.0729, MAE: 337.5676, R²: 0.1385 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 53, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 635.6117, MAE: 447.3129, R²: -0.4915 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 88, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 461.3187, MAE: 369.5659, R²: 0.2143 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 99, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 423.0844, MAE: 337.9482, R²: 0.3391 in 0.04 seconds\n  Trial 11: Hyperparameters {'max_depth': 97, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 423.0844, MAE: 337.9482, R²: 0.3391 in 0.04 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:20,388] Trial 11 finished with value: 423.08439956224004 and parameters: {'max_depth': 97, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,432] Trial 12 finished with value: 423.08439956224004 and parameters: {'max_depth': 98, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,477] Trial 13 finished with value: 470.3718311894013 and parameters: {'max_depth': 32, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,521] Trial 14 finished with value: 423.08439956224004 and parameters: {'max_depth': 78, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 423.08439956224004.\n[I 2025-01-19 13:16:20,554] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_overige_bedrijfsopbrengsten\n[I 2025-01-19 13:16:20,587] Trial 0 finished with value: 56.11566060840095 and parameters: {'max_depth': 30, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 56.11566060840095.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 12: Hyperparameters {'max_depth': 98, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 423.0844, MAE: 337.9482, R²: 0.3391 in 0.04 seconds\n  Trial 13: Hyperparameters {'max_depth': 32, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 470.3718, MAE: 393.2624, R²: 0.1832 in 0.04 seconds\n  Trial 14: Hyperparameters {'max_depth': 78, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 423.0844, MAE: 337.9482, R²: 0.3391 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_lonen_en_salarissen: 0.56 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_lonen_en_salarissen: {'max_depth': 93, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'max_depth': 30, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 56.1157, MAE: 10.9897, R²: -0.0328 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 100, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:20,621] Trial 1 finished with value: 56.083297040175445 and parameters: {'max_depth': 100, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 56.083297040175445.\n[I 2025-01-19 13:16:20,653] Trial 2 finished with value: 56.083705913264296 and parameters: {'max_depth': 75, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 56.083297040175445.\n[I 2025-01-19 13:16:20,686] Trial 3 finished with value: 56.082451616440096 and parameters: {'max_depth': 20, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 56.082451616440096.\n[I 2025-01-19 13:16:20,719] Trial 4 finished with value: 56.081836754809515 and parameters: {'max_depth': 76, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:20,752] Trial 5 finished with value: 56.11568518817116 and parameters: {'max_depth': 99, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:20,783] Trial 6 finished with value: 56.11566060840095 and parameters: {'max_depth': 98, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:20,815] Trial 7 finished with value: 56.11566060840095 and parameters: {'max_depth': 36, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 56.0833, MAE: 10.8448, R²: -0.0316 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 75, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 56.0837, MAE: 10.8414, R²: -0.0316 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 20, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 56.0825, MAE: 10.6897, R²: -0.0316 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 76, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 56.0818, MAE: 10.7241, R²: -0.0315 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 99, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 56.1157, MAE: 10.9952, R²: -0.0328 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 98, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 56.1157, MAE: 10.9897, R²: -0.0328 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 36, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 56.1157, MAE: 10.9897, R²: -0.0328 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 57, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:20,855] Trial 8 finished with value: 56.11566060840095 and parameters: {'max_depth': 57, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:20,887] Trial 9 finished with value: 56.083304910241985 and parameters: {'max_depth': 89, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:20,930] Trial 10 finished with value: 56.082451616440096 and parameters: {'max_depth': 61, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:20,983] Trial 11 finished with value: 56.081836754809515 and parameters: {'max_depth': 20, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:21,030] Trial 12 finished with value: 56.08216878092727 and parameters: {'max_depth': 6, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 56.1157, MAE: 10.9897, R²: -0.0328 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 89, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 56.0833, MAE: 10.8848, R²: -0.0316 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 61, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 56.0825, MAE: 10.6897, R²: -0.0316 in 0.04 seconds\n  Trial 11: Hyperparameters {'max_depth': 20, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 56.0818, MAE: 10.6207, R²: -0.0315 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 6, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 56.0822, MAE: 10.7034, R²: -0.0315 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 70, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:21,080] Trial 13 finished with value: 56.08337389624671 and parameters: {'max_depth': 70, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 56.081836754809515.\n[I 2025-01-19 13:16:21,127] Trial 14 finished with value: 56.08175989663171 and parameters: {'max_depth': 39, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 14 with value: 56.08175989663171.\n[I 2025-01-19 13:16:21,159] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:16:21,192] Trial 0 finished with value: 615.7107468686281 and parameters: {'max_depth': 41, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 615.7107468686281.\n[I 2025-01-19 13:16:21,226] Trial 1 finished with value: 617.8655732978385 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 615.7107468686281.\n[I 2025-01-19 13:16:21,260] Trial 2 finished with value: 194.81759478572576 and parameters: {'max_depth': 48, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 56.0834, MAE: 10.8621, R²: -0.0316 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 39, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 56.0818, MAE: 10.6724, R²: -0.0315 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_overige_bedrijfsopbrengsten: 0.57 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_overige_bedrijfsopbrengsten: {'max_depth': 39, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'max_depth': 41, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 615.7107, MAE: 606.0476, R²: -9.3044 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 9, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 617.8656, MAE: 607.1429, R²: -9.3767 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 48, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 194.8176, MAE: 56.7143, R²: -0.0316 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 48, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:21,295] Trial 3 finished with value: 616.5230877382336 and parameters: {'max_depth': 48, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,329] Trial 4 finished with value: 615.7107468686281 and parameters: {'max_depth': 13, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,361] Trial 5 finished with value: 617.5540076632589 and parameters: {'max_depth': 98, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,395] Trial 6 finished with value: 605.2874248377102 and parameters: {'max_depth': 17, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,430] Trial 7 finished with value: 617.9833870474729 and parameters: {'max_depth': 26, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,464] Trial 8 finished with value: 615.7107468686281 and parameters: {'max_depth': 21, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 616.5231, MAE: 606.4724, R²: -9.3316 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 13, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 615.7107, MAE: 606.0476, R²: -9.3044 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 98, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 617.5540, MAE: 606.9905, R²: -9.3662 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 17, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 605.2874, MAE: 595.0762, R²: -8.9585 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 26, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 617.9834, MAE: 607.2000, R²: -9.3806 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 21, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 615.7107, MAE: 606.0476, R²: -9.3044 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 57, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 618.0885, MAE: 607.2508, R²: -9.3842 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:21,497] Trial 9 finished with value: 618.0884913443875 and parameters: {'max_depth': 57, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,546] Trial 10 finished with value: 617.9898822480449 and parameters: {'max_depth': 82, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,592] Trial 11 finished with value: 194.81759478572576 and parameters: {'max_depth': 66, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,638] Trial 12 finished with value: 636.0011006279785 and parameters: {'max_depth': 68, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n[I 2025-01-19 13:16:21,688] Trial 13 finished with value: 605.2874248377102 and parameters: {'max_depth': 69, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 194.81759478572576.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'max_depth': 82, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 617.9899, MAE: 607.2031, R²: -9.3809 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 66, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 194.8176, MAE: 56.7143, R²: -0.0316 in 0.04 seconds\n  Trial 12: Hyperparameters {'max_depth': 68, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 636.0011, MAE: 344.3333, R²: -9.9948 in 0.04 seconds\n  Trial 13: Hyperparameters {'max_depth': 69, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 605.2874, MAE: 595.0762, R²: -8.9585 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 41, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:21,738] Trial 14 finished with value: 178.29360483149563 and parameters: {'max_depth': 41, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 14 with value: 178.29360483149563.\n[I 2025-01-19 13:16:21,773] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_overige_rentelasten\n[I 2025-01-19 13:16:21,808] Trial 0 finished with value: 85.31108652064708 and parameters: {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:21,842] Trial 1 finished with value: 85.3219238140663 and parameters: {'max_depth': 6, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:21,875] Trial 2 finished with value: 85.31937510189452 and parameters: {'max_depth': 61, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:21,909] Trial 3 finished with value: 85.31108652064708 and parameters: {'max_depth': 79, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 178.2936, MAE: 53.7714, R²: 0.1359 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_overige_personeelskosten: 0.58 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_overige_personeelskosten: {'max_depth': 41, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 85.3111, MAE: 29.8921, R²: 0.8105 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 6, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 85.3219, MAE: 30.0914, R²: 0.8105 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 61, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 85.3194, MAE: 30.0430, R²: 0.8105 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 79, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 85.3111, MAE: 29.8921, R²: 0.8105 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 67, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 85.3194, MAE: 30.0430, R²: 0.8105 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:21,943] Trial 4 finished with value: 85.31937510189452 and parameters: {'max_depth': 67, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:21,976] Trial 5 finished with value: 85.31108652064708 and parameters: {'max_depth': 83, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,009] Trial 6 finished with value: 85.31937510189452 and parameters: {'max_depth': 22, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,042] Trial 7 finished with value: 87.62229548845811 and parameters: {'max_depth': 31, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,077] Trial 8 finished with value: 85.31108652064708 and parameters: {'max_depth': 94, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,111] Trial 9 finished with value: 85.31108652064708 and parameters: {'max_depth': 70, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'max_depth': 83, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 85.3111, MAE: 29.8921, R²: 0.8105 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 22, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 85.3194, MAE: 30.0430, R²: 0.8105 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 31, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 87.6223, MAE: 31.9333, R²: 0.8001 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 94, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 85.3111, MAE: 29.8921, R²: 0.8105 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 70, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 85.3111, MAE: 29.8921, R²: 0.8105 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 43, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,161] Trial 10 finished with value: 85.3141308798125 and parameters: {'max_depth': 43, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,210] Trial 11 finished with value: 85.31597046665217 and parameters: {'max_depth': 47, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,256] Trial 12 finished with value: 94.73110092959615 and parameters: {'max_depth': 81, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,303] Trial 13 finished with value: 85.31215557521033 and parameters: {'max_depth': 55, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n[I 2025-01-19 13:16:22,350] Trial 14 finished with value: 85.31937510189452 and parameters: {'max_depth': 100, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 85.31108652064708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 85.3141, MAE: 29.9310, R²: 0.8105 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 47, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 85.3160, MAE: 30.0032, R²: 0.8105 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 81, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 94.7311, MAE: 33.8921, R²: 0.7663 in 0.04 seconds\n  Trial 13: Hyperparameters {'max_depth': 55, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 85.3122, MAE: 29.8944, R²: 0.8105 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 100, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 85.3194, MAE: 30.0430, R²: 0.8105 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_overige_rentelasten: 0.58 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_overige_rentelasten: {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,383] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:22,415] Trial 0 failed with parameters: {'max_depth': 33, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:16:22,416] Trial 0 failed with value None.\n[I 2025-01-19 13:16:22,417] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_verkoopkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'max_depth': 33, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerDecisionTree on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'max_depth': 86, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,453] Trial 0 finished with value: 231.98585833336193 and parameters: {'max_depth': 86, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,487] Trial 1 finished with value: 231.98585833336193 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,519] Trial 2 finished with value: 234.36955011584882 and parameters: {'max_depth': 65, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,552] Trial 3 finished with value: 234.36955011584882 and parameters: {'max_depth': 30, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 231.9859, MAE: 153.1692, R²: -0.0405 in 0.03 seconds\n  Trial 1: Hyperparameters {'max_depth': 8, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 231.9859, MAE: 153.1692, R²: -0.0405 in 0.03 seconds\n  Trial 2: Hyperparameters {'max_depth': 65, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 234.3696, MAE: 151.5054, R²: -0.0619 in 0.03 seconds\n  Trial 3: Hyperparameters {'max_depth': 30, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 234.3696, MAE: 151.5054, R²: -0.0619 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 231.9859, MAE: 153.1692, R²: -0.0405 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,584] Trial 4 finished with value: 231.98585833336193 and parameters: {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,617] Trial 5 finished with value: 231.98585833336193 and parameters: {'max_depth': 59, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,649] Trial 6 finished with value: 231.98585833336193 and parameters: {'max_depth': 32, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: Hyperparameters {'max_depth': 59, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 231.9859, MAE: 153.1692, R²: -0.0405 in 0.03 seconds\n  Trial 6: Hyperparameters {'max_depth': 32, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 231.9859, MAE: 153.1692, R²: -0.0405 in 0.03 seconds\n  Trial 7: Hyperparameters {'max_depth': 12, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,684] Trial 7 finished with value: 263.4229192925364 and parameters: {'max_depth': 12, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,718] Trial 8 finished with value: 234.36955011584882 and parameters: {'max_depth': 20, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,751] Trial 9 finished with value: 234.36955011584882 and parameters: {'max_depth': 30, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,798] Trial 10 finished with value: 252.000609668148 and parameters: {'max_depth': 91, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 263.4229, MAE: 162.1720, R²: -0.3415 in 0.03 seconds\n  Trial 8: Hyperparameters {'max_depth': 20, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 234.3696, MAE: 151.5054, R²: -0.0619 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 30, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 234.3696, MAE: 151.5054, R²: -0.0619 in 0.03 seconds\n  Trial 10: Hyperparameters {'max_depth': 91, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 252.0006, MAE: 155.0996, R²: -0.2277 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,844] Trial 11 finished with value: 251.39648361968807 and parameters: {'max_depth': 97, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'max_depth': 97, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 251.3965, MAE: 155.5269, R²: -0.2218 in 0.04 seconds\n  Trial 12: Hyperparameters {'max_depth': 78, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:22,889] Trial 12 finished with value: 252.000609668148 and parameters: {'max_depth': 78, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,934] Trial 13 finished with value: 251.39648361968807 and parameters: {'max_depth': 77, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:22,978] Trial 14 finished with value: 231.98585833336193 and parameters: {'max_depth': 41, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 231.98585833336193.\n[I 2025-01-19 13:16:23,012] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_afschrijvingen_mva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 252.0006, MAE: 155.0996, R²: -0.2277 in 0.04 seconds\n  Trial 13: Hyperparameters {'max_depth': 77, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 251.3965, MAE: 155.5269, R²: -0.2218 in 0.04 seconds\n  Trial 14: Hyperparameters {'max_depth': 41, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 231.9859, MAE: 153.1692, R²: -0.0405 in 0.04 seconds\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_verkoopkosten: 0.56 seconds\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_verkoopkosten: {'max_depth': 86, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'max_depth': 85, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,059] Trial 0 finished with value: 555.7228320768126 and parameters: {'max_depth': 85, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 555.7228320768126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 555.7228, MAE: 420.4162, R²: -0.2283 in 0.05 seconds\n  Trial 1: Hyperparameters {'max_depth': 16, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,097] Trial 1 finished with value: 523.1380340067471 and parameters: {'max_depth': 16, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 523.1380340067471.\n[I 2025-01-19 13:16:23,135] Trial 2 finished with value: 528.9570943469802 and parameters: {'max_depth': 67, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 523.1380340067471.\n[I 2025-01-19 13:16:23,175] Trial 3 finished with value: 519.6111290571056 and parameters: {'max_depth': 79, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 519.6111290571056.\n[I 2025-01-19 13:16:23,216] Trial 4 finished with value: 528.9570943469802 and parameters: {'max_depth': 82, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 519.6111290571056.\n[I 2025-01-19 13:16:23,256] Trial 5 finished with value: 523.5173633563223 and parameters: {'max_depth': 60, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 519.6111290571056.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 523.1380, MAE: 392.1922, R²: -0.0885 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 67, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 528.9571, MAE: 398.5109, R²: -0.1129 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 79, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 519.6111, MAE: 387.7111, R²: -0.0739 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 82, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 528.9571, MAE: 398.5109, R²: -0.1129 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 60, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 523.5174, MAE: 392.1922, R²: -0.0901 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 17, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,295] Trial 6 finished with value: 574.1028150651629 and parameters: {'max_depth': 17, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 519.6111290571056.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 574.1028, MAE: 439.8586, R²: -0.3109 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 82, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,335] Trial 7 finished with value: 521.2422994858853 and parameters: {'max_depth': 82, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 519.6111290571056.\n[I 2025-01-19 13:16:23,372] Trial 8 finished with value: 516.0457106346728 and parameters: {'max_depth': 69, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n[I 2025-01-19 13:16:23,410] Trial 9 finished with value: 523.1380340067471 and parameters: {'max_depth': 71, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n[I 2025-01-19 13:16:23,458] Trial 10 finished with value: 556.3394035007856 and parameters: {'max_depth': 35, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 521.2423, MAE: 389.0960, R²: -0.0806 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 69, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 516.0457, MAE: 382.9629, R²: -0.0592 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 71, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 523.1380, MAE: 392.1922, R²: -0.0885 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 35, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 556.3394, MAE: 422.7702, R²: -0.2311 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,507] Trial 11 finished with value: 519.6111290571056 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 519.6111, MAE: 387.7111, R²: -0.0739 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 43, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,556] Trial 12 finished with value: 525.4550957831168 and parameters: {'max_depth': 43, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n[I 2025-01-19 13:16:23,606] Trial 13 finished with value: 528.9570943469802 and parameters: {'max_depth': 100, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n[I 2025-01-19 13:16:23,654] Trial 14 finished with value: 525.4550957831168 and parameters: {'max_depth': 50, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 516.0457106346728.\n[I 2025-01-19 13:16:23,691] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_afschrijvingen_iva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 525.4551, MAE: 393.7627, R²: -0.0982 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 100, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 528.9571, MAE: 398.5109, R²: -0.1129 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 50, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 525.4551, MAE: 393.7627, R²: -0.0982 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_afschrijvingen_mva: 0.64 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_afschrijvingen_mva: {'max_depth': 69, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'max_depth': 53, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,729] Trial 0 finished with value: 161.3743060919757 and parameters: {'max_depth': 53, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 100, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,768] Trial 1 finished with value: 161.3743060919757 and parameters: {'max_depth': 100, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:23,809] Trial 2 finished with value: 161.3743060919757 and parameters: {'max_depth': 69, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:23,844] Trial 3 finished with value: 161.3743060919757 and parameters: {'max_depth': 38, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:23,881] Trial 4 finished with value: 161.3743060919757 and parameters: {'max_depth': 37, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:23,919] Trial 5 finished with value: 161.3743060919757 and parameters: {'max_depth': 75, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'max_depth': 69, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 38, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 37, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 75, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 72, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,957] Trial 6 finished with value: 161.3743060919757 and parameters: {'max_depth': 72, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 89, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:23,996] Trial 7 finished with value: 161.3743060919757 and parameters: {'max_depth': 89, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:24,034] Trial 8 finished with value: 161.3743060919757 and parameters: {'max_depth': 66, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:24,071] Trial 9 finished with value: 161.3743060919757 and parameters: {'max_depth': 61, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:24,121] Trial 10 finished with value: 161.3743060919757 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 66, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 61, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 8, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 100, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,171] Trial 11 finished with value: 161.3743060919757 and parameters: {'max_depth': 100, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 43, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,218] Trial 12 finished with value: 161.3743060919757 and parameters: {'max_depth': 43, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:24,269] Trial 13 finished with value: 161.3743060919757 and parameters: {'max_depth': 16, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:24,320] Trial 14 finished with value: 161.3743060919757 and parameters: {'max_depth': 87, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:24,357] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_omzet\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 16, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 87, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_afschrijvingen_iva: 0.63 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_afschrijvingen_iva: {'max_depth': 53, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'max_depth': 11, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,394] Trial 0 finished with value: 997.3739874299168 and parameters: {'max_depth': 11, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 997.3739874299168.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 997.3740, MAE: 755.6602, R²: -0.4066 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 63, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1080.9535, MAE: 811.5331, R²: -0.6522 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,432] Trial 1 finished with value: 1080.9535055809652 and parameters: {'max_depth': 63, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 997.3739874299168.\n[I 2025-01-19 13:16:24,469] Trial 2 finished with value: 1040.2215197851244 and parameters: {'max_depth': 58, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 997.3739874299168.\n[I 2025-01-19 13:16:24,507] Trial 3 finished with value: 930.9974043055437 and parameters: {'max_depth': 62, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 930.9974043055437.\n[I 2025-01-19 13:16:24,545] Trial 4 finished with value: 1006.7485537932572 and parameters: {'max_depth': 56, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 930.9974043055437.\n[I 2025-01-19 13:16:24,582] Trial 5 finished with value: 930.7480975186126 and parameters: {'max_depth': 95, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: Hyperparameters {'max_depth': 58, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1040.2215, MAE: 786.1528, R²: -0.5300 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 62, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 930.9974, MAE: 701.2168, R²: -0.2256 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 56, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 1006.7486, MAE: 760.4869, R²: -0.4331 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 95, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 930.7481, MAE: 707.4647, R²: -0.2249 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 77, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,620] Trial 6 finished with value: 939.2690534910416 and parameters: {'max_depth': 77, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 939.2691, MAE: 700.2737, R²: -0.2475 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 8, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1041.1204, MAE: 788.2483, R²: -0.5327 in 0.04 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,658] Trial 7 finished with value: 1041.120387505513 and parameters: {'max_depth': 8, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n[I 2025-01-19 13:16:24,695] Trial 8 finished with value: 941.1491655940466 and parameters: {'max_depth': 36, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n[I 2025-01-19 13:16:24,732] Trial 9 finished with value: 1006.7485537932572 and parameters: {'max_depth': 87, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n[I 2025-01-19 13:16:24,780] Trial 10 finished with value: 938.5722445820538 and parameters: {'max_depth': 92, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 8: Hyperparameters {'max_depth': 36, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 941.1492, MAE: 711.0223, R²: -0.2525 in 0.03 seconds\n  Trial 9: Hyperparameters {'max_depth': 87, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1006.7486, MAE: 760.4869, R²: -0.4331 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 92, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 938.5722, MAE: 700.1605, R²: -0.2456 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,829] Trial 11 finished with value: 941.1903364979233 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 941.1903, MAE: 710.1341, R²: -0.2526 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 35, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:24,878] Trial 12 finished with value: 941.1903364979233 and parameters: {'max_depth': 35, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 930.7480975186126.\n[I 2025-01-19 13:16:24,927] Trial 13 finished with value: 930.0618191662295 and parameters: {'max_depth': 76, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 13 with value: 930.0618191662295.\n[I 2025-01-19 13:16:24,976] Trial 14 finished with value: 929.9888785896393 and parameters: {'max_depth': 79, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 14 with value: 929.9888785896393.\n[I 2025-01-19 13:16:25,028] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 941.1903, MAE: 710.1341, R²: -0.2526 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 76, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 930.0618, MAE: 701.2168, R²: -0.2231 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 79, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 929.9889, MAE: 701.1036, R²: -0.2229 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_omzet: 0.62 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_omzet: {'max_depth': 79, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'max_depth': 54, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:25,068] Trial 0 finished with value: 1386.0737686635948 and parameters: {'max_depth': 54, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1386.0737686635948.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1386.0738, MAE: 1162.1479, R²: -0.5401 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 38, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:25,108] Trial 1 finished with value: 1164.5423732797801 and parameters: {'max_depth': 38, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1164.5423732797801.\n[I 2025-01-19 13:16:25,148] Trial 2 finished with value: 1164.3008959358071 and parameters: {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,187] Trial 3 finished with value: 1361.0052672453255 and parameters: {'max_depth': 82, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,224] Trial 4 finished with value: 1357.50101466939 and parameters: {'max_depth': 37, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,264] Trial 5 finished with value: 1380.9803534535622 and parameters: {'max_depth': 67, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1164.5424, MAE: 972.8846, R²: -0.0872 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1164.3009, MAE: 968.2997, R²: -0.0867 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 82, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1361.0053, MAE: 1132.8252, R²: -0.4849 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 37, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 1357.5010, MAE: 1125.0187, R²: -0.4773 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 67, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1380.9804, MAE: 1160.0126, R²: -0.5288 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 87, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:25,309] Trial 6 finished with value: 1369.4017875696097 and parameters: {'max_depth': 87, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1369.4018, MAE: 1142.9424, R²: -0.5033 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:25,350] Trial 7 finished with value: 1173.1955504846253 and parameters: {'max_depth': 26, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,401] Trial 8 finished with value: 1398.145623726322 and parameters: {'max_depth': 28, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,441] Trial 9 finished with value: 1361.3133732961712 and parameters: {'max_depth': 95, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,490] Trial 10 finished with value: 1179.6600440489797 and parameters: {'max_depth': 10, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: Hyperparameters {'max_depth': 26, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1173.1956, MAE: 984.3205, R²: -0.1034 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 28, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1398.1456, MAE: 1168.9499, R²: -0.5671 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 95, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1361.3134, MAE: 1132.8252, R²: -0.4856 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 10, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1179.6600, MAE: 989.5133, R²: -0.1156 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 6, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:25,542] Trial 11 finished with value: 1165.15976064031 and parameters: {'max_depth': 6, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,595] Trial 12 finished with value: 1177.4955668390608 and parameters: {'max_depth': 43, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,648] Trial 13 finished with value: 1183.5391147989044 and parameters: {'max_depth': 21, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,701] Trial 14 finished with value: 1169.2122392975011 and parameters: {'max_depth': 55, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1164.3008959358071.\n[I 2025-01-19 13:16:25,738] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_autokosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1165.1598, MAE: 977.4244, R²: -0.0883 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 43, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1177.4956, MAE: 988.7510, R²: -0.1115 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 21, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1183.5391, MAE: 994.0854, R²: -0.1229 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 55, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 1169.2122, MAE: 978.9656, R²: -0.0959 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_algemene_kosten: 0.67 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_algemene_kosten: {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'max_depth': 8, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:25,779] Trial 0 finished with value: 1426.4254753632304 and parameters: {'max_depth': 8, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:25,817] Trial 1 finished with value: 1519.6497628743384 and parameters: {'max_depth': 89, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:25,855] Trial 2 finished with value: 1447.0400744465744 and parameters: {'max_depth': 97, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:25,891] Trial 3 finished with value: 1433.5304725025828 and parameters: {'max_depth': 35, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:25,930] Trial 4 finished with value: 1519.2368915927266 and parameters: {'max_depth': 39, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:25,967] Trial 5 finished with value: 1433.1670568034008 and parameters: {'max_depth': 50, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1426.4255, MAE: 1230.3185, R²: -0.0965 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 89, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1519.6498, MAE: 1357.6006, R²: -0.2446 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 97, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1447.0401, MAE: 1242.4811, R²: -0.1285 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 35, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1433.5305, MAE: 1239.4596, R²: -0.1075 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 39, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 1519.2369, MAE: 1357.6006, R²: -0.2439 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 50, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1433.1671, MAE: 1248.8463, R²: -0.1069 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 80, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:26,005] Trial 6 finished with value: 1503.447384813095 and parameters: {'max_depth': 80, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:26,042] Trial 7 finished with value: 1523.471690021971 and parameters: {'max_depth': 35, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:26,080] Trial 8 finished with value: 1432.1740355897364 and parameters: {'max_depth': 38, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:26,116] Trial 9 finished with value: 1433.5304725025828 and parameters: {'max_depth': 28, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1426.4254753632304.\n[I 2025-01-19 13:16:26,165] Trial 10 finished with value: 1411.8729294185791 and parameters: {'max_depth': 5, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 1411.8729294185791.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1503.4474, MAE: 1332.1675, R²: -0.2182 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 35, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1523.4717, MAE: 1335.7542, R²: -0.2508 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 38, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1432.1740, MAE: 1241.0996, R²: -0.1054 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 28, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1433.5305, MAE: 1239.4596, R²: -0.1075 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 5, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1411.8729, MAE: 1233.6114, R²: -0.0743 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 8, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:26,216] Trial 11 finished with value: 1433.1579399392342 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 1411.8729294185791.\n[I 2025-01-19 13:16:26,266] Trial 12 finished with value: 1434.01790548331 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 1411.8729294185791.\n[I 2025-01-19 13:16:26,318] Trial 13 finished with value: 1447.1156657468678 and parameters: {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 1411.8729294185791.\n[I 2025-01-19 13:16:26,369] Trial 14 finished with value: 1447.1156657468678 and parameters: {'max_depth': 66, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 1411.8729294185791.\n[I 2025-01-19 13:16:26,409] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_overige_rentelasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1433.1579, MAE: 1239.4596, R²: -0.1069 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1434.0179, MAE: 1242.9860, R²: -0.1083 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1447.1157, MAE: 1233.7737, R²: -0.1286 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 66, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 1447.1157, MAE: 1233.7737, R²: -0.1286 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_autokosten: 0.63 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_autokosten: {'max_depth': 5, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'max_depth': 58, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:26,450] Trial 0 finished with value: 1229.2522095623815 and parameters: {'max_depth': 58, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1229.2522095623815.\n[I 2025-01-19 13:16:26,488] Trial 1 finished with value: 988.402508671481 and parameters: {'max_depth': 69, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 988.402508671481.\n[I 2025-01-19 13:16:26,528] Trial 2 finished with value: 1224.5854737014763 and parameters: {'max_depth': 70, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 988.402508671481.\n[I 2025-01-19 13:16:26,565] Trial 3 finished with value: 1230.6413229628827 and parameters: {'max_depth': 31, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 988.402508671481.\n[I 2025-01-19 13:16:26,603] Trial 4 finished with value: 893.6130145219893 and parameters: {'max_depth': 38, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1229.2522, MAE: 984.8349, R²: -1.2660 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 69, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 988.4025, MAE: 734.8563, R²: -0.4650 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 70, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1224.5855, MAE: 978.4358, R²: -1.2488 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 31, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1230.6413, MAE: 991.4969, R²: -1.2711 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 38, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 893.6130, MAE: 643.3550, R²: -0.1975 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 99, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 987.1820, MAE: 737.1467, R²: -0.4614 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:26,653] Trial 5 finished with value: 987.1820022738774 and parameters: {'max_depth': 99, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:26,698] Trial 6 finished with value: 979.8957529365442 and parameters: {'max_depth': 20, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:26,736] Trial 7 finished with value: 1228.523880208815 and parameters: {'max_depth': 25, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:26,779] Trial 8 finished with value: 1228.6032143136742 and parameters: {'max_depth': 57, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:26,817] Trial 9 finished with value: 989.9317550846624 and parameters: {'max_depth': 45, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: Hyperparameters {'max_depth': 20, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 979.8958, MAE: 731.9304, R²: -0.4399 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 25, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1228.5239, MAE: 991.7209, R²: -1.2633 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 57, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1228.6032, MAE: 989.1948, R²: -1.2636 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 45, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 989.9318, MAE: 736.5390, R²: -0.4695 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 10, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:26,868] Trial 10 finished with value: 979.2426177752415 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:26,919] Trial 11 finished with value: 973.8416585221013 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:26,974] Trial 12 finished with value: 978.1737672600759 and parameters: {'max_depth': 11, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:27,035] Trial 13 finished with value: 902.970011521807 and parameters: {'max_depth': 37, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 979.2426, MAE: 732.4229, R²: -0.4380 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 7, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 973.8417, MAE: 731.4731, R²: -0.4222 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 11, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 978.1738, MAE: 723.4102, R²: -0.4348 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 37, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 902.9700, MAE: 644.2100, R²: -0.2227 in 0.06 seconds\n  Trial 14: Hyperparameters {'max_depth': 40, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:27,090] Trial 14 finished with value: 981.4019594349159 and parameters: {'max_depth': 40, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 893.6130145219893.\n[I 2025-01-19 13:16:27,127] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_pensioenlasten\n[I 2025-01-19 13:16:27,166] Trial 0 finished with value: 1020081.2354479133 and parameters: {'max_depth': 65, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1020081.2354479133.\n[I 2025-01-19 13:16:27,205] Trial 1 finished with value: 547.0933497432895 and parameters: {'max_depth': 45, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,245] Trial 2 finished with value: 641834.4284329144 and parameters: {'max_depth': 18, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,283] Trial 3 finished with value: 578.0427149556798 and parameters: {'max_depth': 22, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 981.4020, MAE: 728.7425, R²: -0.4443 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_overige_rentelasten: 0.68 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_overige_rentelasten: {'max_depth': 38, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'max_depth': 65, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1020081.2354, MAE: 474039.4151, R²: -4585946.7349 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 45, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 547.0933, MAE: 322.7333, R²: -0.3191 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 18, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 641834.4284, MAE: 309637.3774, R²: -1815538.0809 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 22, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 578.0427, MAE: 438.5687, R²: -0.4726 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 67, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:27,327] Trial 4 finished with value: 633105.170727581 and parameters: {'max_depth': 67, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,365] Trial 5 finished with value: 744.803865161829 and parameters: {'max_depth': 20, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,404] Trial 6 finished with value: 558.2473344077277 and parameters: {'max_depth': 22, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,446] Trial 7 finished with value: 646890.8726874747 and parameters: {'max_depth': 53, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,485] Trial 8 finished with value: 1045054.3292717588 and parameters: {'max_depth': 37, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,528] Trial 9 finished with value: 648430.493248677 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 633105.1707, MAE: 320887.5827, R²: -1766489.4930 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 20, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 744.8039, MAE: 515.6560, R²: -1.4448 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 22, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 558.2473, MAE: 338.7560, R²: -0.3735 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 53, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 646890.8727, MAE: 306856.1878, R²: -1844256.8064 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 37, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1045054.3293, MAE: 485309.1511, R²: -4813236.8236 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 648430.4932, MAE: 308741.7746, R²: -1853046.0361 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:27,580] Trial 10 finished with value: 631.305578411385 and parameters: {'max_depth': 98, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,631] Trial 11 finished with value: 621.4133805178858 and parameters: {'max_depth': 38, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,682] Trial 12 finished with value: 620.6249990829137 and parameters: {'max_depth': 39, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 547.0933497432895.\n[I 2025-01-19 13:16:27,739] Trial 13 finished with value: 546.9919560651692 and parameters: {'max_depth': 84, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 13 with value: 546.9919560651692.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'max_depth': 98, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 631.3056, MAE: 411.6667, R²: -0.7565 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 38, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 621.4134, MAE: 404.0007, R²: -0.7018 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 39, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 620.6250, MAE: 399.2007, R²: -0.6975 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 84, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 546.9920, MAE: 320.6000, R²: -0.3186 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 94, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:27,790] Trial 14 finished with value: 689.4470731438829 and parameters: {'max_depth': 94, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 13 with value: 546.9919560651692.\n[I 2025-01-19 13:16:27,829] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:16:27,867] Trial 0 finished with value: 1134.1974592621755 and parameters: {'max_depth': 74, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1134.1974592621755.\n[I 2025-01-19 13:16:27,906] Trial 1 finished with value: 1132.2758454546313 and parameters: {'max_depth': 46, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1132.2758454546313.\n[I 2025-01-19 13:16:27,943] Trial 2 finished with value: 1132.2758454546313 and parameters: {'max_depth': 19, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1132.2758454546313.\n[I 2025-01-19 13:16:27,979] Trial 3 finished with value: 1133.3883962118819 and parameters: {'max_depth': 80, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1132.2758454546313.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 689.4471, MAE: 442.7333, R²: -1.0949 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_pensioenlasten: 0.66 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_pensioenlasten: {'max_depth': 84, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'max_depth': 74, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1134.1975, MAE: 968.1558, R²: -0.0710 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 46, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1132.2758, MAE: 969.1800, R²: -0.0674 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 19, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1132.2758, MAE: 969.1800, R²: -0.0674 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 80, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1133.3884, MAE: 968.1558, R²: -0.0695 in 0.03 seconds\n  Trial 4: Hyperparameters {'max_depth': 92, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:28,035] Trial 4 finished with value: 1130.4145616585438 and parameters: {'max_depth': 92, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,074] Trial 5 finished with value: 1135.8858969104247 and parameters: {'max_depth': 31, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,112] Trial 6 finished with value: 1135.2573935370979 and parameters: {'max_depth': 100, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,149] Trial 7 finished with value: 1132.2758454546313 and parameters: {'max_depth': 78, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,186] Trial 8 finished with value: 1134.5489298253037 and parameters: {'max_depth': 29, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,223] Trial 9 finished with value: 1163.7394071349358 and parameters: {'max_depth': 32, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1130.4146, MAE: 966.1190, R²: -0.0639 in 0.05 seconds\n  Trial 5: Hyperparameters {'max_depth': 31, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1135.8859, MAE: 969.1800, R²: -0.0742 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 100, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1135.2574, MAE: 969.1800, R²: -0.0730 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 78, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1132.2758, MAE: 969.1800, R²: -0.0674 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 29, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1134.5489, MAE: 969.1800, R²: -0.0717 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 32, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1163.7394, MAE: 994.6264, R²: -0.1275 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 59, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:28,273] Trial 10 finished with value: 1158.8430675171992 and parameters: {'max_depth': 59, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,322] Trial 11 finished with value: 1160.3312574943354 and parameters: {'max_depth': 50, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,378] Trial 12 finished with value: 1141.0112312585113 and parameters: {'max_depth': 50, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,427] Trial 13 finished with value: 1130.4145616585438 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1158.8431, MAE: 991.3166, R²: -0.1180 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 50, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 1160.3313, MAE: 994.5124, R²: -0.1209 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 50, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1141.0112, MAE: 977.7258, R²: -0.0839 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1130.4146, MAE: 966.1190, R²: -0.0639 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 1130.4146, MAE: 966.1190, R²: -0.0639 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:28,477] Trial 14 finished with value: 1130.4145616585438 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1130.4145616585438.\n[I 2025-01-19 13:16:28,520] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:16:28,559] Trial 0 finished with value: 960.2949080841908 and parameters: {'max_depth': 76, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 960.2949080841908.\n[I 2025-01-19 13:16:28,597] Trial 1 finished with value: 991.6692146723059 and parameters: {'max_depth': 70, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 960.2949080841908.\n[I 2025-01-19 13:16:28,635] Trial 2 finished with value: 959.9978161165186 and parameters: {'max_depth': 79, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n[I 2025-01-19 13:16:28,676] Trial 3 finished with value: 1227.6268213841604 and parameters: {'max_depth': 100, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerDecisionTree_month_data_cleaned_lonen_en_salarissen: 0.65 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_lonen_en_salarissen: {'max_depth': 92, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'max_depth': 76, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 960.2949, MAE: 520.7750, R²: -0.1870 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 70, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 991.6692, MAE: 576.9820, R²: -0.2658 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 79, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 959.9978, MAE: 546.4964, R²: -0.1862 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 100, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1227.6268, MAE: 808.5489, R²: -0.9398 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 74, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:28,714] Trial 4 finished with value: 997.266094110354 and parameters: {'max_depth': 74, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n[I 2025-01-19 13:16:28,752] Trial 5 finished with value: 1258.0501073279654 and parameters: {'max_depth': 53, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n[I 2025-01-19 13:16:28,789] Trial 6 finished with value: 974.804491452548 and parameters: {'max_depth': 36, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n[I 2025-01-19 13:16:28,826] Trial 7 finished with value: 1232.0472776581234 and parameters: {'max_depth': 72, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n[I 2025-01-19 13:16:28,863] Trial 8 finished with value: 1261.098423780084 and parameters: {'max_depth': 43, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 959.9978161165186.\n[I 2025-01-19 13:16:28,901] Trial 9 finished with value: 955.7075331333739 and parameters: {'max_depth': 80, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 9 with value: 955.7075331333739.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 997.2661, MAE: 584.7462, R²: -0.2801 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 53, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1258.0501, MAE: 849.4138, R²: -1.0371 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 36, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 974.8045, MAE: 574.6420, R²: -0.2231 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 72, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1232.0473, MAE: 810.9024, R²: -0.9538 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 43, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1261.0984, MAE: 842.6695, R²: -1.0470 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 80, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 955.7075, MAE: 516.9488, R²: -0.1756 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 97, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:28,951] Trial 10 finished with value: 975.4984081576873 and parameters: {'max_depth': 97, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 9 with value: 955.7075331333739.\n[I 2025-01-19 13:16:28,998] Trial 11 finished with value: 954.1026203263654 and parameters: {'max_depth': 13, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 954.1026203263654.\n[I 2025-01-19 13:16:29,047] Trial 12 finished with value: 949.841035147461 and parameters: {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 949.841035147461.\n[I 2025-01-19 13:16:29,096] Trial 13 finished with value: 961.7057323767825 and parameters: {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 949.841035147461.\n[I 2025-01-19 13:16:29,145] Trial 14 finished with value: 967.2511276887465 and parameters: {'max_depth': 11, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 949.841035147461.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 975.4984, MAE: 576.4061, R²: -0.2248 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 13, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 954.1026, MAE: 535.4386, R²: -0.1717 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 949.8410, MAE: 542.1571, R²: -0.1613 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 961.7057, MAE: 552.9326, R²: -0.1904 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 11, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 967.2511, MAE: 547.0485, R²: -0.2042 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_overige_personeelskosten: 0.63 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_overige_personeelskosten: {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:29,183] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_sociale_lasten\n[I 2025-01-19 13:16:29,223] Trial 0 finished with value: 1819.8861969553623 and parameters: {'max_depth': 46, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1819.8861969553623.\n[I 2025-01-19 13:16:29,263] Trial 1 finished with value: 1795.1334509219532 and parameters: {'max_depth': 52, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1795.1334509219532.\n[I 2025-01-19 13:16:29,305] Trial 2 finished with value: 912.0753259206903 and parameters: {'max_depth': 26, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 912.0753259206903.\n[I 2025-01-19 13:16:29,342] Trial 3 finished with value: 1686.456962729749 and parameters: {'max_depth': 67, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 912.0753259206903.\n[I 2025-01-19 13:16:29,382] Trial 4 finished with value: 856.265287890772 and parameters: {'max_depth': 37, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 856.265287890772.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'max_depth': 46, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1819.8862, MAE: 1214.5314, R²: -5.3482 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 52, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1795.1335, MAE: 1210.6648, R²: -5.1767 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 26, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 912.0753, MAE: 693.5053, R²: -0.5945 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 67, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1686.4570, MAE: 1139.2109, R²: -4.4515 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 37, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 856.2653, MAE: 645.5947, R²: -0.4053 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 98, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:29,423] Trial 5 finished with value: 1696.4408262215031 and parameters: {'max_depth': 98, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 856.265287890772.\n[I 2025-01-19 13:16:29,465] Trial 6 finished with value: 1704.64306992234 and parameters: {'max_depth': 73, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 856.265287890772.\n[I 2025-01-19 13:16:29,503] Trial 7 finished with value: 855.3401130661416 and parameters: {'max_depth': 8, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n[I 2025-01-19 13:16:29,542] Trial 8 finished with value: 1749.1601277052707 and parameters: {'max_depth': 24, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n[I 2025-01-19 13:16:29,582] Trial 9 finished with value: 926.313901180372 and parameters: {'max_depth': 50, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1696.4408, MAE: 1155.5176, R²: -4.5162 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 73, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1704.6431, MAE: 1166.1918, R²: -4.5697 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 8, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 855.3401, MAE: 663.1833, R²: -0.4023 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 24, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1749.1601, MAE: 1168.0222, R²: -4.8644 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 50, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 926.3139, MAE: 719.8940, R²: -0.6447 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 5, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:29,638] Trial 10 finished with value: 873.3460233721797 and parameters: {'max_depth': 5, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n[I 2025-01-19 13:16:29,687] Trial 11 finished with value: 912.7954817811052 and parameters: {'max_depth': 5, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n[I 2025-01-19 13:16:29,737] Trial 12 finished with value: 911.4434700919928 and parameters: {'max_depth': 29, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n[I 2025-01-19 13:16:29,787] Trial 13 finished with value: 880.5019713322622 and parameters: {'max_depth': 18, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n[I 2025-01-19 13:16:29,835] Trial 14 finished with value: 865.3861400207425 and parameters: {'max_depth': 37, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 855.3401130661416.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 873.3460, MAE: 672.2227, R²: -0.4620 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 5, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 912.7955, MAE: 694.8667, R²: -0.5970 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 29, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 911.4435, MAE: 693.5053, R²: -0.5923 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 18, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 880.5020, MAE: 671.0500, R²: -0.4860 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 37, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 865.3861, MAE: 667.1060, R²: -0.4354 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_sociale_lasten: 0.65 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_sociale_lasten: {'max_depth': 8, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:29,872] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:16:29,910] Trial 0 finished with value: 1665.8668282779258 and parameters: {'max_depth': 80, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1665.8668282779258.\n[I 2025-01-19 13:16:29,948] Trial 1 finished with value: 13747.124348108031 and parameters: {'max_depth': 9, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1665.8668282779258.\n[I 2025-01-19 13:16:29,984] Trial 2 finished with value: 1457.5947545500744 and parameters: {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,022] Trial 3 finished with value: 13711.099867667628 and parameters: {'max_depth': 99, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,058] Trial 4 finished with value: 1665.8668282779258 and parameters: {'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'max_depth': 80, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1665.8668, MAE: 1248.1881, R²: -0.5999 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 9, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 13747.1243, MAE: 9312.5062, R²: -107.9536 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1457.5948, MAE: 1132.5995, R²: -0.2249 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 99, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 13711.0999, MAE: 9151.4619, R²: -107.3833 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 1665.8668, MAE: 1248.1881, R²: -0.5999 in 0.03 seconds\n  Trial 5: Hyperparameters {'max_depth': 8, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:30,096] Trial 5 finished with value: 13394.710610822833 and parameters: {'max_depth': 8, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,133] Trial 6 finished with value: 1666.3523152942435 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,170] Trial 7 finished with value: 13335.229996677937 and parameters: {'max_depth': 13, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,212] Trial 8 finished with value: 1457.5947545500744 and parameters: {'max_depth': 20, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,254] Trial 9 finished with value: 12854.548436104655 and parameters: {'max_depth': 50, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 13394.7106, MAE: 8956.4860, R²: -102.4390 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 9, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1666.3523, MAE: 1256.1249, R²: -0.6009 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 13, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 13335.2300, MAE: 8931.4331, R²: -101.5224 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 20, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1457.5948, MAE: 1132.5995, R²: -0.2249 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 50, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 12854.5484, MAE: 8532.2786, R²: -94.2646 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 40, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1457.5948, MAE: 1132.5995, R²: -0.2249 in 0.05 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:30,307] Trial 10 finished with value: 1457.5947545500744 and parameters: {'max_depth': 40, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,358] Trial 11 finished with value: 1457.5947545500744 and parameters: {'max_depth': 36, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1457.5947545500744.\n[I 2025-01-19 13:16:30,409] Trial 12 finished with value: 1440.7579946971607 and parameters: {'max_depth': 29, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 1440.7579946971607.\n[I 2025-01-19 13:16:30,460] Trial 13 finished with value: 1462.5122179558946 and parameters: {'max_depth': 65, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 1440.7579946971607.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 11: Hyperparameters {'max_depth': 36, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 1457.5948, MAE: 1132.5995, R²: -0.2249 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 29, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1440.7580, MAE: 1125.1392, R²: -0.1967 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 65, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1462.5122, MAE: 1136.1730, R²: -0.2332 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 33, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 1458.8798, MAE: 1127.4357, R²: -0.2270 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:30,512] Trial 14 finished with value: 1458.8798266052195 and parameters: {'max_depth': 33, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 1440.7579946971607.\n[I 2025-01-19 13:16:30,550] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_kostprijs_van_de_omzet\n[I 2025-01-19 13:16:30,589] Trial 0 finished with value: 1463.0313670894072 and parameters: {'max_depth': 96, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1463.0313670894072.\n[I 2025-01-19 13:16:30,630] Trial 1 finished with value: 1477.9916666791178 and parameters: {'max_depth': 40, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1463.0313670894072.\n[I 2025-01-19 13:16:30,671] Trial 2 finished with value: 1520.0898385916482 and parameters: {'max_depth': 63, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 1463.0313670894072.\n[I 2025-01-19 13:16:30,710] Trial 3 finished with value: 1452.6830510171515 and parameters: {'max_depth': 12, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimization time for TrainerDecisionTree_month_data_cleaned_exploitatie-_en_machinekosten: 0.64 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_exploitatie-_en_machinekosten: {'max_depth': 29, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'max_depth': 96, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1463.0314, MAE: 1176.9554, R²: -0.3127 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 40, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1477.9917, MAE: 1214.9477, R²: -0.3397 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 63, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1520.0898, MAE: 1246.8056, R²: -0.4171 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 12, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1452.6831, MAE: 1176.9554, R²: -0.2942 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 43, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:30,749] Trial 4 finished with value: 1656.476175955813 and parameters: {'max_depth': 43, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:30,789] Trial 5 finished with value: 1613.937407123593 and parameters: {'max_depth': 94, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:30,828] Trial 6 finished with value: 1608.0719191250853 and parameters: {'max_depth': 57, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:30,866] Trial 7 finished with value: 1471.4728346392433 and parameters: {'max_depth': 36, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:30,905] Trial 8 finished with value: 2100.0078576379397 and parameters: {'max_depth': 58, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:30,943] Trial 9 finished with value: 1486.7538286621852 and parameters: {'max_depth': 25, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1656.4762, MAE: 1343.5597, R²: -0.6828 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 94, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1613.9374, MAE: 1310.2095, R²: -0.5975 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 57, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1608.0719, MAE: 1309.5362, R²: -0.5859 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 36, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1471.4728, MAE: 1192.9719, R²: -0.3279 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 58, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 2100.0079, MAE: 1645.3121, R²: -1.7046 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 25, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1486.7538, MAE: 1202.7912, R²: -0.3556 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 5, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:30,993] Trial 10 finished with value: 1474.6765681589584 and parameters: {'max_depth': 5, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:31,045] Trial 11 finished with value: 1458.0002438121367 and parameters: {'max_depth': 99, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:31,095] Trial 12 finished with value: 1458.0002438121367 and parameters: {'max_depth': 78, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n[I 2025-01-19 13:16:31,147] Trial 13 finished with value: 1609.1946606681609 and parameters: {'max_depth': 10, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1452.6830510171515.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 10 completed with RMSE: 1474.6766, MAE: 1195.9465, R²: -0.3337 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 99, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 1458.0002, MAE: 1173.0598, R²: -0.3037 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 78, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1458.0002, MAE: 1173.0598, R²: -0.3037 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 10, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1609.1947, MAE: 1304.9477, R²: -0.5881 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 75, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:31,202] Trial 14 finished with value: 1447.348183207252 and parameters: {'max_depth': 75, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 14 with value: 1447.348183207252.\n[I 2025-01-19 13:16:31,238] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_kantoorkosten\n[I 2025-01-19 13:16:31,285] Trial 0 finished with value: 607.9543422353829 and parameters: {'max_depth': 79, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 607.9543422353829.\n[I 2025-01-19 13:16:31,324] Trial 1 finished with value: 646.9512040218682 and parameters: {'max_depth': 24, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 607.9543422353829.\n[I 2025-01-19 13:16:31,362] Trial 2 finished with value: 606.0743682928583 and parameters: {'max_depth': 76, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 606.0743682928583.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1447.3482, MAE: 1169.1642, R²: -0.2847 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_kostprijs_van_de_omzet: 0.65 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_kostprijs_van_de_omzet: {'max_depth': 75, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'max_depth': 79, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 607.9543, MAE: 447.4176, R²: -0.2394 in 0.05 seconds\n  Trial 1: Hyperparameters {'max_depth': 24, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 646.9512, MAE: 488.6036, R²: -0.4035 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 76, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 606.0744, MAE: 453.4994, R²: -0.2318 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 24, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 615.7088, MAE: 451.3714, R²: -0.2712 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:31,406] Trial 3 finished with value: 615.7087975039901 and parameters: {'max_depth': 24, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 606.0743682928583.\n[I 2025-01-19 13:16:31,445] Trial 4 finished with value: 639.8954607456749 and parameters: {'max_depth': 59, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 606.0743682928583.\n[I 2025-01-19 13:16:31,484] Trial 5 finished with value: 647.6120605516518 and parameters: {'max_depth': 50, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 606.0743682928583.\n[I 2025-01-19 13:16:31,523] Trial 6 finished with value: 605.887918564073 and parameters: {'max_depth': 14, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,560] Trial 7 finished with value: 605.9852366555182 and parameters: {'max_depth': 56, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,599] Trial 8 finished with value: 614.9893736260943 and parameters: {'max_depth': 83, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: Hyperparameters {'max_depth': 59, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 639.8955, MAE: 485.8013, R²: -0.3731 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 50, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 647.6121, MAE: 488.9828, R²: -0.4064 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 14, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 605.8879, MAE: 447.0176, R²: -0.2310 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 56, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 605.9852, MAE: 447.4152, R²: -0.2314 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 83, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 614.9894, MAE: 450.1238, R²: -0.2683 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 19, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 639.8955, MAE: 485.8013, R²: -0.3731 in 0.04 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:31,638] Trial 9 finished with value: 639.8954607456749 and parameters: {'max_depth': 19, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,689] Trial 10 finished with value: 607.4786629514405 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,742] Trial 11 finished with value: 611.2398512651176 and parameters: {'max_depth': 48, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,801] Trial 12 finished with value: 611.2398512651176 and parameters: {'max_depth': 41, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,852] Trial 13 finished with value: 613.288242309891 and parameters: {'max_depth': 66, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'max_depth': 7, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 607.4787, MAE: 453.5792, R²: -0.2375 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 48, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 611.2399, MAE: 447.9025, R²: -0.2529 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 41, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 611.2399, MAE: 447.9025, R²: -0.2529 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 66, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 613.2882, MAE: 448.3025, R²: -0.2613 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:31,904] Trial 14 finished with value: 618.4181276655761 and parameters: {'max_depth': 100, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 605.887918564073.\n[I 2025-01-19 13:16:31,941] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_verkoopkosten\n[I 2025-01-19 13:16:31,978] Trial 0 finished with value: 372.3172449121506 and parameters: {'max_depth': 87, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 372.3172449121506.\n[I 2025-01-19 13:16:32,018] Trial 1 finished with value: 378.51172361540284 and parameters: {'max_depth': 87, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 372.3172449121506.\n[I 2025-01-19 13:16:32,056] Trial 2 finished with value: 381.3700477796016 and parameters: {'max_depth': 12, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 372.3172449121506.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'max_depth': 100, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 618.4181, MAE: 452.4873, R²: -0.2825 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_kantoorkosten: 0.67 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_kantoorkosten: {'max_depth': 14, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'max_depth': 87, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 372.3172, MAE: 267.2972, R²: -0.3978 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 87, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 378.5117, MAE: 278.8976, R²: -0.4446 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 12, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 381.3700, MAE: 278.1394, R²: -0.4666 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 11, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:32,095] Trial 3 finished with value: 383.25532829474224 and parameters: {'max_depth': 11, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 372.3172449121506.\n[I 2025-01-19 13:16:32,134] Trial 4 finished with value: 370.76928428502646 and parameters: {'max_depth': 84, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 370.76928428502646.\n[I 2025-01-19 13:16:32,171] Trial 5 finished with value: 383.069330119513 and parameters: {'max_depth': 80, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 370.76928428502646.\n[I 2025-01-19 13:16:32,210] Trial 6 finished with value: 381.556874307768 and parameters: {'max_depth': 20, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 370.76928428502646.\n[I 2025-01-19 13:16:32,248] Trial 7 finished with value: 381.3700477796016 and parameters: {'max_depth': 31, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 370.76928428502646.\n[I 2025-01-19 13:16:32,287] Trial 8 finished with value: 368.9415039486577 and parameters: {'max_depth': 45, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 368.9415039486577.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 383.2553, MAE: 277.5077, R²: -0.4811 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 84, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 370.7693, MAE: 269.1231, R²: -0.3862 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 80, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 383.0693, MAE: 277.4259, R²: -0.4796 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 20, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 381.5569, MAE: 278.2212, R²: -0.4680 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 31, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 381.3700, MAE: 278.1394, R²: -0.4666 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 45, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 368.9415, MAE: 268.7644, R²: -0.3725 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 15, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:32,325] Trial 9 finished with value: 381.0197484300413 and parameters: {'max_depth': 15, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 8 with value: 368.9415039486577.\n[I 2025-01-19 13:16:32,375] Trial 10 finished with value: 366.3968121257299 and parameters: {'max_depth': 56, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 366.3968121257299.\n[I 2025-01-19 13:16:32,426] Trial 11 finished with value: 366.93335290534566 and parameters: {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 366.3968121257299.\n[I 2025-01-19 13:16:32,475] Trial 12 finished with value: 366.93335290534566 and parameters: {'max_depth': 62, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 366.3968121257299.\n[I 2025-01-19 13:16:32,524] Trial 13 finished with value: 367.5596788626862 and parameters: {'max_depth': 60, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 366.3968121257299.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 381.0197, MAE: 279.9759, R²: -0.4639 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 56, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 366.3968, MAE: 262.8249, R²: -0.3537 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 366.9334, MAE: 264.6710, R²: -0.3576 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 62, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 366.9334, MAE: 264.6710, R²: -0.3576 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 60, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 367.5597, MAE: 264.5300, R²: -0.3623 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:32,577] Trial 14 finished with value: 367.5596788626862 and parameters: {'max_depth': 45, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 366.3968121257299.\n[I 2025-01-19 13:16:32,613] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:16:32,653] Trial 0 finished with value: 1793.5110084508324 and parameters: {'max_depth': 54, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1793.5110084508324.\n[I 2025-01-19 13:16:32,690] Trial 1 finished with value: 1392.023083753762 and parameters: {'max_depth': 57, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1392.023083753762.\n[I 2025-01-19 13:16:32,728] Trial 2 finished with value: 1409.8436932428597 and parameters: {'max_depth': 33, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1392.023083753762.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'max_depth': 45, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 367.5597, MAE: 264.5300, R²: -0.3623 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_verkoopkosten: 0.64 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_verkoopkosten: {'max_depth': 56, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'max_depth': 54, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1793.5110, MAE: 1297.9886, R²: -1.2174 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 57, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1392.0231, MAE: 1159.1543, R²: -0.3358 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 33, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1409.8437, MAE: 1193.3543, R²: -0.3702 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 31, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:32,782] Trial 3 finished with value: 1952.6904750437216 and parameters: {'max_depth': 31, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1392.023083753762.\n[I 2025-01-19 13:16:32,819] Trial 4 finished with value: 1620.6174117441485 and parameters: {'max_depth': 77, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1392.023083753762.\n[I 2025-01-19 13:16:32,857] Trial 5 finished with value: 1395.640466128962 and parameters: {'max_depth': 37, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1392.023083753762.\n[I 2025-01-19 13:16:32,895] Trial 6 finished with value: 1390.493670535756 and parameters: {'max_depth': 17, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 1390.493670535756.\n[I 2025-01-19 13:16:32,934] Trial 7 finished with value: 1403.072360894714 and parameters: {'max_depth': 50, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 1390.493670535756.\n[I 2025-01-19 13:16:32,973] Trial 8 finished with value: 1813.8901917035462 and parameters: {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 1390.493670535756.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1952.6905, MAE: 1443.5277, R²: -1.6285 in 0.05 seconds\n  Trial 4: Hyperparameters {'max_depth': 77, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 1620.6174, MAE: 1234.7430, R²: -0.8105 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 37, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1395.6405, MAE: 1176.1163, R²: -0.3427 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 17, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1390.4937, MAE: 1183.3713, R²: -0.3328 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 50, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1403.0724, MAE: 1178.8413, R²: -0.3571 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1813.8902, MAE: 1351.4993, R²: -1.2681 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 69, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:33,011] Trial 9 finished with value: 1400.9022838680314 and parameters: {'max_depth': 69, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 1390.493670535756.\n[I 2025-01-19 13:16:33,060] Trial 10 finished with value: 1394.6860898053965 and parameters: {'max_depth': 94, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 1390.493670535756.\n[I 2025-01-19 13:16:33,110] Trial 11 finished with value: 1380.1006186289462 and parameters: {'max_depth': 19, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1380.1006186289462.\n[I 2025-01-19 13:16:33,159] Trial 12 finished with value: 1392.6686455638564 and parameters: {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1380.1006186289462.\n[I 2025-01-19 13:16:33,208] Trial 13 finished with value: 1372.7112549282413 and parameters: {'max_depth': 6, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 13 with value: 1372.7112549282413.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1400.9023, MAE: 1178.8413, R²: -0.3529 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 94, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1394.6861, MAE: 1184.6770, R²: -0.3409 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 19, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 1380.1006, MAE: 1146.6260, R²: -0.3130 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 5, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1392.6686, MAE: 1173.7570, R²: -0.3370 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 6, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1372.7113, MAE: 1141.1900, R²: -0.2990 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:33,258] Trial 14 finished with value: 1371.3570380028682 and parameters: {'max_depth': 7, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 14 with value: 1371.3570380028682.\n[I 2025-01-19 13:16:33,296] A new study created in memory with name: TrainerDecisionTree_day_data\n[I 2025-01-19 13:16:33,336] Trial 0 finished with value: 768.4240096039229 and parameters: {'max_depth': 21, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 768.4240096039229.\n[I 2025-01-19 13:16:33,379] Trial 1 finished with value: 727.3968258814965 and parameters: {'max_depth': 74, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,419] Trial 2 finished with value: 736.3373719974438 and parameters: {'max_depth': 21, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'max_depth': 7, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 1371.3570, MAE: 1139.5167, R²: -0.2964 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_huisvestingskosten: 0.65 seconds\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_huisvestingskosten: {'max_depth': 7, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'max_depth': 21, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 768.4240, MAE: 614.0966, R²: -0.2696 in 0.04 seconds\n  Trial 1: Hyperparameters {'max_depth': 74, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 727.3968, MAE: 575.9011, R²: -0.1377 in 0.04 seconds\n  Trial 2: Hyperparameters {'max_depth': 21, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 736.3374, MAE: 580.6640, R²: -0.1658 in 0.04 seconds\n  Trial 3: Hyperparameters {'max_depth': 88, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:33,464] Trial 3 finished with value: 780.0622824165533 and parameters: {'max_depth': 88, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,504] Trial 4 finished with value: 737.5309590298809 and parameters: {'max_depth': 76, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,544] Trial 5 finished with value: 743.8871713476615 and parameters: {'max_depth': 31, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,583] Trial 6 finished with value: 727.3968258814965 and parameters: {'max_depth': 35, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,624] Trial 7 finished with value: 765.5814351806134 and parameters: {'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,663] Trial 8 finished with value: 784.8853828075042 and parameters: {'max_depth': 89, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 780.0623, MAE: 611.9740, R²: -0.3084 in 0.04 seconds\n  Trial 4: Hyperparameters {'max_depth': 76, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 737.5310, MAE: 582.5993, R²: -0.1696 in 0.04 seconds\n  Trial 5: Hyperparameters {'max_depth': 31, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 743.8872, MAE: 590.0686, R²: -0.1898 in 0.04 seconds\n  Trial 6: Hyperparameters {'max_depth': 35, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 727.3968, MAE: 575.9011, R²: -0.1377 in 0.04 seconds\n  Trial 7: Hyperparameters {'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 765.5814, MAE: 611.3776, R²: -0.2602 in 0.04 seconds\n  Trial 8: Hyperparameters {'max_depth': 89, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 784.8854, MAE: 621.1781, R²: -0.3246 in 0.04 seconds\n  Trial 9: Hyperparameters {'max_depth': 56, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:33,705] Trial 9 finished with value: 743.7181191945157 and parameters: {'max_depth': 56, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 727.3968258814965.\n[I 2025-01-19 13:16:33,761] Trial 10 finished with value: 725.8987116659594 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 725.8987116659594.\n[I 2025-01-19 13:16:33,815] Trial 11 finished with value: 725.8987116659594 and parameters: {'max_depth': 100, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 725.8987116659594.\n[I 2025-01-19 13:16:33,866] Trial 12 finished with value: 725.8987116659594 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 725.8987116659594.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 743.7181, MAE: 589.8361, R²: -0.1893 in 0.04 seconds\n  Trial 10: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 725.8987, MAE: 574.4304, R²: -0.1330 in 0.05 seconds\n  Trial 11: Hyperparameters {'max_depth': 100, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 725.8987, MAE: 574.4304, R²: -0.1330 in 0.05 seconds\n  Trial 12: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 725.8987, MAE: 574.4304, R²: -0.1330 in 0.05 seconds\n  Trial 13: Hyperparameters {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:33,921] Trial 13 finished with value: 725.8987116659594 and parameters: {'max_depth': 99, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 725.8987116659594.\n[I 2025-01-19 13:16:33,970] Trial 14 finished with value: 636.5860679666233 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 14 with value: 636.5860679666233.\n[I 2025-01-19 13:16:34,009] A new study created in memory with name: TrainerDecisionTree_weather_data\n[W 2025-01-19 13:16:34,012] Trial 0 failed with parameters: {'max_depth': 42, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_decision_tree.py\", line 45, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:16:34,085] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,087] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 725.8987, MAE: 574.4304, R²: -0.1330 in 0.05 seconds\n  Trial 14: Hyperparameters {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 636.5861, MAE: 499.2468, R²: 0.1287 in 0.05 seconds\nTotal optimization time for TrainerDecisionTree_day_data: 0.68 seconds\nBest hyperparameters for TrainerDecisionTree_day_data: {'max_depth': 6, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerDecisionTree on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'max_depth': 42, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerDecisionTree on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerGradientBoosting\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'learning_rate': 0.09584603736193427, 'n_estimators': 122, 'subsample': 0.9622444355681719, 'min_samples_split': 9, 'max_depth': 19, 'prediction_mode': 'AverageTrend'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:34,098] Trial 0 failed with parameters: {'learning_rate': 0.09584603736193427, 'n_estimators': 122, 'subsample': 0.9622444355681719, 'min_samples_split': 9, 'max_depth': 19, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,292] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,294] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_autokosten\n[W 2025-01-19 13:16:34,306] Trial 0 failed with parameters: {'learning_rate': 0.02102522683688826, 'n_estimators': 60, 'subsample': 0.8023899616713931, 'min_samples_split': 2, 'max_depth': 12, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,310] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,311] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:16:34,321] Trial 0 failed with parameters: {'learning_rate': 0.19367407713079274, 'n_estimators': 133, 'subsample': 0.6774001827048846, 'min_samples_split': 7, 'max_depth': 30, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,325] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,326] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:16:34,337] Trial 0 failed with parameters: {'learning_rate': 0.1465287959649593, 'n_estimators': 105, 'subsample': 0.5635090090425552, 'min_samples_split': 8, 'max_depth': 3, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,341] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,341] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_kantoorkosten\n[W 2025-01-19 13:16:34,351] Trial 0 failed with parameters: {'learning_rate': 0.16065971546408372, 'n_estimators': 96, 'subsample': 0.5989015400875848, 'min_samples_split': 3, 'max_depth': 30, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,354] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,355] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:34,365] Trial 0 failed with parameters: {'learning_rate': 0.01839674637500957, 'n_estimators': 244, 'subsample': 0.8329472571737525, 'min_samples_split': 7, 'max_depth': 27, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,368] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,368] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_overige_bedrijfsopbrengsten\n[W 2025-01-19 13:16:34,379] Trial 0 failed with parameters: {'learning_rate': 0.0732316336382413, 'n_estimators': 72, 'subsample': 0.5728956066299334, 'min_samples_split': 6, 'max_depth': 14, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,382] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,383] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:16:34,394] Trial 0 failed with parameters: {'learning_rate': 0.10334896786682636, 'n_estimators': 232, 'subsample': 0.6408980070591899, 'min_samples_split': 5, 'max_depth': 23, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,397] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,398] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:34,408] Trial 0 failed with parameters: {'learning_rate': 0.09673722537774243, 'n_estimators': 106, 'subsample': 0.8221948002566271, 'min_samples_split': 2, 'max_depth': 5, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,412] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,413] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:34,423] Trial 0 failed with parameters: {'learning_rate': 0.12111829452214296, 'n_estimators': 92, 'subsample': 0.7662969621568934, 'min_samples_split': 7, 'max_depth': 26, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,427] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,427] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_verkoopkosten\n[W 2025-01-19 13:16:34,438] Trial 0 failed with parameters: {'learning_rate': 0.001210872961858043, 'n_estimators': 193, 'subsample': 0.5654221927088688, 'min_samples_split': 2, 'max_depth': 5, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,442] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,442] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_afschrijvingen_mva\n[W 2025-01-19 13:16:34,453] Trial 0 failed with parameters: {'learning_rate': 0.004129365998900099, 'n_estimators': 103, 'subsample': 0.8229279236025652, 'min_samples_split': 6, 'max_depth': 28, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,456] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,456] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_afschrijvingen_iva\n[W 2025-01-19 13:16:34,467] Trial 0 failed with parameters: {'learning_rate': 0.19943718330733018, 'n_estimators': 216, 'subsample': 0.71903670182156, 'min_samples_split': 3, 'max_depth': 20, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,472] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,473] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_omzet\n[W 2025-01-19 13:16:34,484] Trial 0 failed with parameters: {'learning_rate': 0.06052965486005755, 'n_estimators': 146, 'subsample': 0.6561472049814571, 'min_samples_split': 6, 'max_depth': 18, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,487] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,488] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_algemene_kosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'learning_rate': 0.02102522683688826, 'n_estimators': 60, 'subsample': 0.8023899616713931, 'min_samples_split': 2, 'max_depth': 12, 'prediction_mode': 'Zero'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_autokosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'learning_rate': 0.19367407713079274, 'n_estimators': 133, 'subsample': 0.6774001827048846, 'min_samples_split': 7, 'max_depth': 30, 'prediction_mode': 'Zero'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_exploitatie-_en_machinekosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'learning_rate': 0.1465287959649593, 'n_estimators': 105, 'subsample': 0.5635090090425552, 'min_samples_split': 8, 'max_depth': 3, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_huisvestingskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'learning_rate': 0.16065971546408372, 'n_estimators': 96, 'subsample': 0.5989015400875848, 'min_samples_split': 3, 'max_depth': 30, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_kantoorkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'learning_rate': 0.01839674637500957, 'n_estimators': 244, 'subsample': 0.8329472571737525, 'min_samples_split': 7, 'max_depth': 27, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_lonen_en_salarissen: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'learning_rate': 0.0732316336382413, 'n_estimators': 72, 'subsample': 0.5728956066299334, 'min_samples_split': 6, 'max_depth': 14, 'prediction_mode': 'Zero'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_overige_bedrijfsopbrengsten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'learning_rate': 0.10334896786682636, 'n_estimators': 232, 'subsample': 0.6408980070591899, 'min_samples_split': 5, 'max_depth': 23, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_overige_personeelskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'learning_rate': 0.09673722537774243, 'n_estimators': 106, 'subsample': 0.8221948002566271, 'min_samples_split': 2, 'max_depth': 5, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_overige_rentelasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'learning_rate': 0.12111829452214296, 'n_estimators': 92, 'subsample': 0.7662969621568934, 'min_samples_split': 7, 'max_depth': 26, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_sociale_lasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'learning_rate': 0.001210872961858043, 'n_estimators': 193, 'subsample': 0.5654221927088688, 'min_samples_split': 2, 'max_depth': 5, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_verkoopkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'learning_rate': 0.004129365998900099, 'n_estimators': 103, 'subsample': 0.8229279236025652, 'min_samples_split': 6, 'max_depth': 28, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_afschrijvingen_mva: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'learning_rate': 0.19943718330733018, 'n_estimators': 216, 'subsample': 0.71903670182156, 'min_samples_split': 3, 'max_depth': 20, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_afschrijvingen_iva: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'learning_rate': 0.06052965486005755, 'n_estimators': 146, 'subsample': 0.6561472049814571, 'min_samples_split': 6, 'max_depth': 18, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_omzet: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'learning_rate': 0.013171041822201152, 'n_estimators': 215, 'subsample': 0.8431431901905382, 'min_samples_split': 3, 'max_depth': 29, 'prediction_mode': 'AverageTrend'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:34,498] Trial 0 failed with parameters: {'learning_rate': 0.013171041822201152, 'n_estimators': 215, 'subsample': 0.8431431901905382, 'min_samples_split': 3, 'max_depth': 29, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,503] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,504] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_autokosten\n[W 2025-01-19 13:16:34,515] Trial 0 failed with parameters: {'learning_rate': 0.18810220003820674, 'n_estimators': 204, 'subsample': 0.710057899148899, 'min_samples_split': 7, 'max_depth': 26, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,518] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,519] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:34,529] Trial 0 failed with parameters: {'learning_rate': 0.004152419439976443, 'n_estimators': 250, 'subsample': 0.8314564336737821, 'min_samples_split': 10, 'max_depth': 22, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,533] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,534] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_pensioenlasten\n[W 2025-01-19 13:16:34,544] Trial 0 failed with parameters: {'learning_rate': 0.1291016767828668, 'n_estimators': 293, 'subsample': 0.5658870257900714, 'min_samples_split': 7, 'max_depth': 29, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,548] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,548] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:34,560] Trial 0 failed with parameters: {'learning_rate': 0.17414047544128552, 'n_estimators': 258, 'subsample': 0.798639323489805, 'min_samples_split': 9, 'max_depth': 6, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,564] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,564] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:16:34,575] Trial 0 failed with parameters: {'learning_rate': 0.16534617498604998, 'n_estimators': 128, 'subsample': 0.720613496393177, 'min_samples_split': 5, 'max_depth': 17, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,579] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,580] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:34,591] Trial 0 failed with parameters: {'learning_rate': 0.0594348260939621, 'n_estimators': 185, 'subsample': 0.9668243537009281, 'min_samples_split': 6, 'max_depth': 24, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,594] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,595] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:16:34,606] Trial 0 failed with parameters: {'learning_rate': 0.05519938354120202, 'n_estimators': 127, 'subsample': 0.5082143071628452, 'min_samples_split': 4, 'max_depth': 28, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,609] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,610] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_kostprijs_van_de_omzet\n[W 2025-01-19 13:16:34,620] Trial 0 failed with parameters: {'learning_rate': 0.12142887740019555, 'n_estimators': 237, 'subsample': 0.9330084335497603, 'min_samples_split': 2, 'max_depth': 30, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,629] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,630] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_kantoorkosten\n[W 2025-01-19 13:16:34,641] Trial 0 failed with parameters: {'learning_rate': 0.02632683256187617, 'n_estimators': 253, 'subsample': 0.6492886086798169, 'min_samples_split': 6, 'max_depth': 5, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,645] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,646] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_verkoopkosten\n[W 2025-01-19 13:16:34,656] Trial 0 failed with parameters: {'learning_rate': 0.003943666349914683, 'n_estimators': 126, 'subsample': 0.9918276774571539, 'min_samples_split': 5, 'max_depth': 10, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,660] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,661] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:16:34,671] Trial 0 failed with parameters: {'learning_rate': 0.16764775929567685, 'n_estimators': 283, 'subsample': 0.5548060508853598, 'min_samples_split': 6, 'max_depth': 25, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,674] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,675] A new study created in memory with name: TrainerGradientBoosting_day_data\n[W 2025-01-19 13:16:34,686] Trial 0 failed with parameters: {'learning_rate': 0.10578881406734783, 'n_estimators': 159, 'subsample': 0.5520526642124037, 'min_samples_split': 5, 'max_depth': 17, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:16:34,689] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,690] A new study created in memory with name: TrainerGradientBoosting_weather_data\n[W 2025-01-19 13:16:34,693] Trial 0 failed with parameters: {'learning_rate': 0.04655065593207405, 'n_estimators': 245, 'subsample': 0.7036955937639444, 'min_samples_split': 10, 'max_depth': 4, 'prediction_mode': 'AverageTrend'} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 47, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:16:34,695] Trial 0 failed with value None.\n[I 2025-01-19 13:16:34,696] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_algemene_kosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'learning_rate': 0.18810220003820674, 'n_estimators': 204, 'subsample': 0.710057899148899, 'min_samples_split': 7, 'max_depth': 26, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_autokosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'learning_rate': 0.004152419439976443, 'n_estimators': 250, 'subsample': 0.8314564336737821, 'min_samples_split': 10, 'max_depth': 22, 'prediction_mode': 'Zero'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_overige_rentelasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'learning_rate': 0.1291016767828668, 'n_estimators': 293, 'subsample': 0.5658870257900714, 'min_samples_split': 7, 'max_depth': 29, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_pensioenlasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'learning_rate': 0.17414047544128552, 'n_estimators': 258, 'subsample': 0.798639323489805, 'min_samples_split': 9, 'max_depth': 6, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_lonen_en_salarissen: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'learning_rate': 0.16534617498604998, 'n_estimators': 128, 'subsample': 0.720613496393177, 'min_samples_split': 5, 'max_depth': 17, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_overige_personeelskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'learning_rate': 0.0594348260939621, 'n_estimators': 185, 'subsample': 0.9668243537009281, 'min_samples_split': 6, 'max_depth': 24, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_sociale_lasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'learning_rate': 0.05519938354120202, 'n_estimators': 127, 'subsample': 0.5082143071628452, 'min_samples_split': 4, 'max_depth': 28, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_exploitatie-_en_machinekosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'learning_rate': 0.12142887740019555, 'n_estimators': 237, 'subsample': 0.9330084335497603, 'min_samples_split': 2, 'max_depth': 30, 'prediction_mode': 'Zero'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_kostprijs_van_de_omzet: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'learning_rate': 0.02632683256187617, 'n_estimators': 253, 'subsample': 0.6492886086798169, 'min_samples_split': 6, 'max_depth': 5, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_kantoorkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'learning_rate': 0.003943666349914683, 'n_estimators': 126, 'subsample': 0.9918276774571539, 'min_samples_split': 5, 'max_depth': 10, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_verkoopkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'learning_rate': 0.16764775929567685, 'n_estimators': 283, 'subsample': 0.5548060508853598, 'min_samples_split': 6, 'max_depth': 25, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_huisvestingskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'learning_rate': 0.10578881406734783, 'n_estimators': 159, 'subsample': 0.5520526642124037, 'min_samples_split': 5, 'max_depth': 17, 'prediction_mode': 'Zero'}\n  Error with trainer TrainerGradientBoosting on dataset day_data: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'learning_rate': 0.04655065593207405, 'n_estimators': 245, 'subsample': 0.7036955937639444, 'min_samples_split': 10, 'max_depth': 4, 'prediction_mode': 'AverageTrend'}\n  Error with trainer TrainerGradientBoosting on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerKNeighborsRegressor\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:34,728] Trial 0 finished with value: 296.85772537783964 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 296.85772537783964.\n[I 2025-01-19 13:16:34,758] Trial 1 finished with value: 281.94644408131325 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 281.94644408131325.\n[I 2025-01-19 13:16:34,789] Trial 2 finished with value: 322.9996843907202 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 281.94644408131325.\n[I 2025-01-19 13:16:34,819] Trial 3 finished with value: 228.57211594032395 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:34,848] Trial 4 finished with value: 296.8250604394015 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 24, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:34,879] Trial 5 finished with value: 280.45881946816314 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:34,913] Trial 6 finished with value: 281.94644408131325 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}. Best is trial 3 with value: 228.57211594032395.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 296.8577, MAE: 122.2984, R²: -0.1396 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 281.9464, MAE: 166.7087, R²: -0.0280 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 322.9997, MAE: 170.0583, R²: -0.3491 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 228.5721, MAE: 112.6426, R²: 0.3244 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 24, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 296.8251, MAE: 122.2427, R²: -0.1393 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 280.4588, MAE: 177.5563, R²: -0.0171 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 281.9464, MAE: 166.7087, R²: -0.0280 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:34,944] Trial 7 finished with value: 283.1326866171901 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:34,979] Trial 8 finished with value: 280.67840050267114 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:35,015] Trial 9 finished with value: 269.5331848185796 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 283.1327, MAE: 202.9513, R²: -0.0366 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 280.6784, MAE: 184.1000, R²: -0.0187 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 269.5332, MAE: 157.3860, R²: 0.0606 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:35,078] Trial 10 finished with value: 272.49910032451464 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 272.4991, MAE: 169.6812, R²: 0.0398 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:35,154] Trial 11 finished with value: 264.08916907425436 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:35,208] Trial 12 finished with value: 245.9787442904741 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 264.0892, MAE: 155.4253, R²: 0.0981 in 0.08 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 245.9787, MAE: 114.5406, R²: 0.2176 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:35,264] Trial 13 finished with value: 228.57211594032395 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:35,317] Trial 14 finished with value: 322.9996843907202 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 228.57211594032395.\n[I 2025-01-19 13:16:35,352] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_autokosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 228.5721, MAE: 112.6426, R²: 0.3244 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 322.9997, MAE: 170.0583, R²: -0.3491 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_algemene_kosten: 0.62 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_algemene_kosten: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 48, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:35,396] Trial 0 failed with parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 48, 'p': 2, 'outlier_removal': 0} because of the following error: ValueError('Expected n_neighbors <= n_samples_fit, but n_neighbors = 10, n_samples_fit = 7, n_samples = 3').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_knn.py\", line 119, in predict\n    df['predictions'] = self.model.predict(df).round(2)\n                        ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/neighbors/_regression.py\", line 242, in predict\n    neigh_ind = self.kneighbors(X, return_distance=False)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/neighbors/_base.py\", line 835, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 10, n_samples_fit = 7, n_samples = 3\n[W 2025-01-19 13:16:35,504] Trial 0 failed with value None.\n[I 2025-01-19 13:16:35,505] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:16:35,538] Trial 0 finished with value: 266.7520095586375 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 266.7520095586375.\n[I 2025-01-19 13:16:35,570] Trial 1 finished with value: 246.0050649594725 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,601] Trial 2 finished with value: 592.0880122800277 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,633] Trial 3 finished with value: 254.74432090263142 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,664] Trial 4 finished with value: 331.2879526074819 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,694] Trial 5 finished with value: 246.0050649594725 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 246.0050649594725.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerKNeighborsRegressor on dataset week_data_cleaned_autokosten: Expected n_neighbors <= n_samples_fit, but n_neighbors = 10, n_samples_fit = 7, n_samples = 3\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 266.7520, MAE: 218.2618, R²: -0.1994 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 246.0051, MAE: 205.2814, R²: -0.0201 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 592.0880, MAE: 541.1429, R²: -4.9093 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 254.7443, MAE: 207.0889, R²: -0.0939 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 331.2880, MAE: 266.0707, R²: -0.8500 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 246.0051, MAE: 205.2814, R²: -0.0201 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 38, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:35,726] Trial 6 finished with value: 249.78202061283068 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 38, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,759] Trial 7 finished with value: 249.90886846865942 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,791] Trial 8 finished with value: 394.8686832715041 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,826] Trial 9 finished with value: 250.89816828033756 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 246.0050649594725.\n[I 2025-01-19 13:16:35,891] Trial 10 finished with value: 251.72611882758608 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 246.0050649594725.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 249.7820, MAE: 203.8843, R²: -0.0517 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 249.9089, MAE: 203.4254, R²: -0.0528 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 394.8687, MAE: 337.2607, R²: -1.6283 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 250.8982, MAE: 204.2289, R²: -0.0611 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 251.7261, MAE: 199.4471, R²: -0.0681 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:35,949] Trial 11 finished with value: 235.7161484028134 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}. Best is trial 11 with value: 235.7161484028134.\n[I 2025-01-19 13:16:36,004] Trial 12 finished with value: 251.72611882758608 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 48, 'p': 2, 'outlier_removal': 1}. Best is trial 11 with value: 235.7161484028134.\n[I 2025-01-19 13:16:36,057] Trial 13 finished with value: 235.7161484028134 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}. Best is trial 11 with value: 235.7161484028134.\n[I 2025-01-19 13:16:36,109] Trial 14 finished with value: 235.7161484028134 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}. Best is trial 11 with value: 235.7161484028134.\n[I 2025-01-19 13:16:36,138] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_huisvestingskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 235.7161, MAE: 187.1646, R²: 0.0634 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 48, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 251.7261, MAE: 199.4471, R²: -0.0681 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 235.7161, MAE: 187.1646, R²: 0.0634 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 235.7161, MAE: 187.1646, R²: 0.0634 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_exploitatie-_en_machinekosten: 0.61 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_exploitatie-_en_machinekosten: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:36,169] Trial 0 finished with value: 138.14772838411895 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 138.14772838411895.\n[I 2025-01-19 13:16:36,198] Trial 1 finished with value: 139.7554755589846 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 138.14772838411895.\n[I 2025-01-19 13:16:36,228] Trial 2 finished with value: 138.9536447331101 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 138.14772838411895.\n[I 2025-01-19 13:16:36,258] Trial 3 finished with value: 137.92432935564753 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 137.92432935564753.\n[I 2025-01-19 13:16:36,288] Trial 4 finished with value: 139.66165100534383 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}. Best is trial 3 with value: 137.92432935564753.\n[I 2025-01-19 13:16:36,318] Trial 5 finished with value: 140.64927195888396 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 137.92432935564753.\n[I 2025-01-19 13:16:36,349] Trial 6 finished with value: 141.01044510320904 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 137.92432935564753.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 138.1477, MAE: 55.2378, R²: -0.0529 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 139.7555, MAE: 54.8782, R²: -0.0775 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 138.9536, MAE: 55.1923, R²: -0.0652 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 137.9243, MAE: 55.9436, R²: -0.0495 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 139.6617, MAE: 54.7641, R²: -0.0761 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 140.6493, MAE: 54.5651, R²: -0.0913 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 141.0104, MAE: 54.3105, R²: -0.0969 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:36,381] Trial 7 finished with value: 139.84159180099425 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 137.92432935564753.\n[I 2025-01-19 13:16:36,411] Trial 8 finished with value: 140.68520541192262 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}. Best is trial 3 with value: 137.92432935564753.\n[I 2025-01-19 13:16:36,441] Trial 9 finished with value: 140.65133907864293 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 137.92432935564753.\n[I 2025-01-19 13:16:36,494] Trial 10 finished with value: 136.89360548643944 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}. Best is trial 10 with value: 136.89360548643944.\n[I 2025-01-19 13:16:36,547] Trial 11 finished with value: 146.74454517446821 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 10 with value: 136.89360548643944.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 139.8416, MAE: 54.6244, R²: -0.0788 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 140.6852, MAE: 54.1481, R²: -0.0919 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 140.6513, MAE: 54.5579, R²: -0.0914 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 136.8936, MAE: 57.2574, R²: -0.0338 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:36,602] Trial 12 finished with value: 146.74454517446821 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 10 with value: 136.89360548643944.\n[I 2025-01-19 13:16:36,655] Trial 13 finished with value: 137.92432935564753 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}. Best is trial 10 with value: 136.89360548643944.\n[I 2025-01-19 13:16:36,710] Trial 14 finished with value: 136.89360548643944 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}. Best is trial 10 with value: 136.89360548643944.\n[I 2025-01-19 13:16:36,739] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_kantoorkosten\n[I 2025-01-19 13:16:36,771] Trial 0 finished with value: 217.20752127861502 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:36,802] Trial 1 finished with value: 225.03836365611372 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 217.20752127861502.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 137.9243, MAE: 55.9436, R²: -0.0495 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 136.8936, MAE: 57.2574, R²: -0.0338 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_huisvestingskosten: 0.57 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_huisvestingskosten: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 217.2075, MAE: 192.3985, R²: 0.0472 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 225.0384, MAE: 201.8594, R²: -0.0227 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:36,835] Trial 2 finished with value: 225.98953042968557 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:36,873] Trial 3 finished with value: 232.66241836892482 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:36,906] Trial 4 finished with value: 241.14339992997367 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:36,938] Trial 5 finished with value: 225.98953042968557 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:36,967] Trial 6 finished with value: 227.20201726423156 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:36,997] Trial 7 finished with value: 387.4458369833707 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 217.20752127861502.\n[I 2025-01-19 13:16:37,029] Trial 8 finished with value: 209.54203265947345 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}. Best is trial 8 with value: 209.54203265947345.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 225.9895, MAE: 207.0591, R²: -0.0314 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 2, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 232.6624, MAE: 213.3564, R²: -0.0932 in 0.04 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 241.1434, MAE: 214.5572, R²: -0.1744 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 225.9895, MAE: 207.0591, R²: -0.0314 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 227.2020, MAE: 210.8670, R²: -0.0425 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 387.4458, MAE: 317.5532, R²: -2.0316 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 209.5420, MAE: 186.9664, R²: 0.1133 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:37,061] Trial 9 finished with value: 226.48447816337472 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}. Best is trial 8 with value: 209.54203265947345.\n[I 2025-01-19 13:16:37,115] Trial 10 finished with value: 228.25688962126526 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}. Best is trial 8 with value: 209.54203265947345.\n[I 2025-01-19 13:16:37,173] Trial 11 finished with value: 221.3813682602173 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 209.54203265947345.\n[I 2025-01-19 13:16:37,229] Trial 12 finished with value: 228.22762968841323 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 50, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 209.54203265947345.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 226.4845, MAE: 209.4249, R²: -0.0359 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 228.2569, MAE: 207.9702, R²: -0.0522 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 221.3814, MAE: 202.1830, R²: 0.0102 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 50, 'p': 1, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 228.2276, MAE: 209.6157, R²: -0.0519 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:37,289] Trial 13 finished with value: 209.54203265947345 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 209.54203265947345.\n[I 2025-01-19 13:16:37,346] Trial 14 finished with value: 228.25688962126526 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}. Best is trial 8 with value: 209.54203265947345.\n[I 2025-01-19 13:16:37,375] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:16:37,407] Trial 0 finished with value: 557.0524176043252 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 557.0524176043252.\n[I 2025-01-19 13:16:37,436] Trial 1 finished with value: 527.7724180709623 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 527.7724180709623.\n[I 2025-01-19 13:16:37,466] Trial 2 finished with value: 522.9791498487015 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 522.9791498487015.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 209.5420, MAE: 186.9664, R²: 0.1133 in 0.06 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 228.2569, MAE: 207.9702, R²: -0.0522 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_kantoorkosten: 0.61 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_kantoorkosten: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 557.0524, MAE: 415.7853, R²: -0.1456 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 527.7724, MAE: 384.7135, R²: -0.0284 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 522.9791, MAE: 379.0882, R²: -0.0098 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:37,514] Trial 3 finished with value: 594.3997407172263 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 522.9791498487015.\n[I 2025-01-19 13:16:37,550] Trial 4 finished with value: 522.853750449228 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}. Best is trial 4 with value: 522.853750449228.\n[I 2025-01-19 13:16:37,580] Trial 5 finished with value: 573.0054917301763 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}. Best is trial 4 with value: 522.853750449228.\n[I 2025-01-19 13:16:37,614] Trial 6 finished with value: 517.5652519418658 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}. Best is trial 6 with value: 517.5652519418658.\n[I 2025-01-19 13:16:37,646] Trial 7 finished with value: 522.6721501319248 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}. Best is trial 6 with value: 517.5652519418658.\n[I 2025-01-19 13:16:37,681] Trial 8 finished with value: 492.99098388724883 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 492.99098388724883.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 594.3997, MAE: 441.8235, R²: -0.3044 in 0.05 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 522.8538, MAE: 406.0465, R²: -0.0093 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 573.0055, MAE: 425.6412, R²: -0.2122 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 517.5653, MAE: 379.2147, R²: 0.0110 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 522.6722, MAE: 380.0335, R²: -0.0086 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 492.9910, MAE: 381.6465, R²: 0.1027 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 520.5931, MAE: 380.6071, R²: -0.0006 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:37,715] Trial 9 finished with value: 520.5931397256516 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}. Best is trial 8 with value: 492.99098388724883.\n[I 2025-01-19 13:16:37,772] Trial 10 finished with value: 528.8974122755421 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 492.99098388724883.\n[I 2025-01-19 13:16:37,827] Trial 11 finished with value: 526.531197679123 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}. Best is trial 8 with value: 492.99098388724883.\n[I 2025-01-19 13:16:37,883] Trial 12 finished with value: 529.8492307861793 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}. Best is trial 8 with value: 492.99098388724883.\n[I 2025-01-19 13:16:37,942] Trial 13 finished with value: 492.99098388724883 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}. Best is trial 8 with value: 492.99098388724883.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 528.8974, MAE: 388.9924, R²: -0.0328 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 526.5312, MAE: 403.2129, R²: -0.0235 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 529.8492, MAE: 389.4306, R²: -0.0365 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 492.9910, MAE: 381.6465, R²: 0.1027 in 0.06 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:37,997] Trial 14 finished with value: 535.3105905865469 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}. Best is trial 8 with value: 492.99098388724883.\n[I 2025-01-19 13:16:38,026] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_overige_bedrijfsopbrengsten\n[I 2025-01-19 13:16:38,055] Trial 0 finished with value: 56.144597216043195 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 56.144597216043195.\n[I 2025-01-19 13:16:38,086] Trial 1 finished with value: 56.15357021842745 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 56.144597216043195.\n[I 2025-01-19 13:16:38,116] Trial 2 finished with value: 56.08460357906339 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,146] Trial 3 finished with value: 56.15364003922784 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 17, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,176] Trial 4 finished with value: 56.15714997311961 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 56.08460357906339.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 535.3106, MAE: 396.5582, R²: -0.0580 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_lonen_en_salarissen: 0.62 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_lonen_en_salarissen: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 56.1446, MAE: 10.9659, R²: -0.0338 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 56.1536, MAE: 10.9545, R²: -0.0342 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 56.0846, MAE: 10.9310, R²: -0.0316 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 17, 'p': 2, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 56.1536, MAE: 10.9579, R²: -0.0342 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 56.1571, MAE: 10.9452, R²: -0.0343 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:38,210] Trial 5 finished with value: 56.14805852264234 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,240] Trial 6 finished with value: 56.1536630978812 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,270] Trial 7 finished with value: 56.12526798952992 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,301] Trial 8 finished with value: 56.15148752904181 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,343] Trial 9 finished with value: 56.17552541073749 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,408] Trial 10 finished with value: 56.08583323491925 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 56.1481, MAE: 10.9552, R²: -0.0340 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 56.1537, MAE: 10.9603, R²: -0.0342 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 56.1253, MAE: 10.8976, R²: -0.0331 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 56.1515, MAE: 10.9276, R²: -0.0341 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 56.1755, MAE: 10.9310, R²: -0.0350 in 0.04 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.06 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:38,488] Trial 11 finished with value: 56.08583323491925 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,541] Trial 12 finished with value: 56.08583323491925 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,595] Trial 13 finished with value: 56.144597216043195 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n[I 2025-01-19 13:16:38,649] Trial 14 finished with value: 56.08583323491925 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 56.08460357906339.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.08 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 56.1446, MAE: 10.9659, R²: -0.0338 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_overige_bedrijfsopbrengsten: 0.62 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_overige_bedrijfsopbrengsten: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:38,678] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:16:38,709] Trial 0 finished with value: 262.3039411591428 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 262.3039411591428.\n[I 2025-01-19 13:16:38,739] Trial 1 finished with value: 238.600342699231 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 238.600342699231.\n[I 2025-01-19 13:16:38,770] Trial 2 finished with value: 273.5414683370695 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 238.600342699231.\n[I 2025-01-19 13:16:38,799] Trial 3 finished with value: 273.5414683370695 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 238.600342699231.\n[I 2025-01-19 13:16:38,829] Trial 4 finished with value: 602.9102609778515 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 238.600342699231.\n[I 2025-01-19 13:16:38,860] Trial 5 finished with value: 217.2939520798409 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}. Best is trial 5 with value: 217.2939520798409.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 262.3039, MAE: 224.7123, R²: -0.8702 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 238.6003, MAE: 191.7799, R²: -0.5474 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 273.5415, MAE: 149.7325, R²: -1.0338 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 273.5415, MAE: 149.7325, R²: -1.0338 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 602.9103, MAE: 586.2994, R²: -8.8804 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 217.2940, MAE: 154.4365, R²: -0.2834 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:38,896] Trial 6 finished with value: 257.5637912458822 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:38,934] Trial 7 finished with value: 225.9411267227857 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 1, 'outlier_removal': 1}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:38,965] Trial 8 finished with value: 225.80431351272364 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:38,996] Trial 9 finished with value: 336.36087902727337 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:39,048] Trial 10 finished with value: 217.2939520798409 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}. Best is trial 5 with value: 217.2939520798409.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 257.5638, MAE: 218.7508, R²: -0.8032 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 1, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 225.9411, MAE: 171.6516, R²: -0.3876 in 0.04 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 225.8043, MAE: 171.1290, R²: -0.3859 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 336.3609, MAE: 312.2435, R²: -2.0753 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 217.2940, MAE: 154.4365, R²: -0.2834 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:39,101] Trial 11 finished with value: 217.2939520798409 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:39,173] Trial 12 finished with value: 217.2939520798409 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:39,228] Trial 13 finished with value: 223.26253812389533 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}. Best is trial 5 with value: 217.2939520798409.\n[I 2025-01-19 13:16:39,281] Trial 14 finished with value: 217.2939520798409 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}. Best is trial 5 with value: 217.2939520798409.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 217.2940, MAE: 154.4365, R²: -0.2834 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 217.2940, MAE: 154.4365, R²: -0.2834 in 0.07 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 223.2625, MAE: 165.9099, R²: -0.3549 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 217.2940, MAE: 154.4365, R²: -0.2834 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_overige_personeelskosten: 0.60 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_overige_personeelskosten: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:39,321] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_overige_rentelasten\n[I 2025-01-19 13:16:39,363] Trial 0 finished with value: 198.26834730569914 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 198.26834730569914.\n[I 2025-01-19 13:16:39,396] Trial 1 finished with value: 181.39975150050356 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 181.39975150050356.\n[I 2025-01-19 13:16:39,427] Trial 2 finished with value: 85.47007273504178 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,465] Trial 3 finished with value: 182.5555207753399 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,501] Trial 4 finished with value: 164.74464964841127 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 85.47007273504178.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 198.2683, MAE: 125.0019, R²: -0.0235 in 0.04 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 181.3998, MAE: 105.7327, R²: 0.1432 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 85.4701, MAE: 31.4000, R²: 0.8098 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 182.5555, MAE: 101.5734, R²: 0.1323 in 0.04 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 164.7446, MAE: 66.2077, R²: 0.2933 in 0.04 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:39,533] Trial 5 finished with value: 141.34114561741902 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,563] Trial 6 finished with value: 197.53586903536166 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,592] Trial 7 finished with value: 198.72508122753123 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,622] Trial 8 finished with value: 194.150906084245 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,653] Trial 9 finished with value: 85.47007273504178 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,709] Trial 10 finished with value: 196.80226101061157 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 141.3411, MAE: 56.6389, R²: 0.4799 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 197.5359, MAE: 132.6533, R²: -0.0160 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 198.7251, MAE: 119.1744, R²: -0.0282 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 194.1509, MAE: 125.7767, R²: 0.0186 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 85.4701, MAE: 31.4000, R²: 0.8098 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 196.8023, MAE: 143.7363, R²: -0.0084 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:39,764] Trial 11 finished with value: 85.47007273504178 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,816] Trial 12 finished with value: 85.47007273504178 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 43, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,868] Trial 13 finished with value: 164.74518501141222 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n[I 2025-01-19 13:16:39,920] Trial 14 finished with value: 85.47007273504178 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 85.47007273504178.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 85.4701, MAE: 31.4000, R²: 0.8098 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 43, 'p': 1, 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 85.4701, MAE: 31.4000, R²: 0.8098 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 1, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 164.7452, MAE: 66.1144, R²: 0.2933 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 85.4701, MAE: 31.4000, R²: 0.8098 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_overige_rentelasten: 0.60 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_overige_rentelasten: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:39,951] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:39,994] Trial 0 failed with parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:16:39,995] Trial 0 failed with value None.\n[I 2025-01-19 13:16:39,996] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_verkoopkosten\n[I 2025-01-19 13:16:40,027] Trial 0 finished with value: 251.73682109849204 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 251.73682109849204.\n[I 2025-01-19 13:16:40,057] Trial 1 finished with value: 254.41637481114105 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 251.73682109849204.\n[I 2025-01-19 13:16:40,089] Trial 2 finished with value: 234.04167666951875 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,121] Trial 3 finished with value: 251.9918399301808 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,152] Trial 4 finished with value: 277.0153134232253 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,182] Trial 5 finished with value: 254.95808020607151 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 234.04167666951875.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Error with trainer TrainerKNeighborsRegressor on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 251.7368, MAE: 156.0129, R²: -0.2252 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 254.4164, MAE: 157.5961, R²: -0.2514 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 234.0417, MAE: 152.5620, R²: -0.0590 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 251.9918, MAE: 156.2308, R²: -0.2276 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 277.0153, MAE: 172.0215, R²: -0.4836 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 254.9581, MAE: 157.9170, R²: -0.2567 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:40,214] Trial 6 finished with value: 277.0153134232253 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,245] Trial 7 finished with value: 254.62631308248268 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,276] Trial 8 finished with value: 264.1344965317187 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,308] Trial 9 finished with value: 255.1876304578842 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 234.04167666951875.\n[I 2025-01-19 13:16:40,364] Trial 10 finished with value: 233.48044770893685 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 40, 'p': 1, 'outlier_removal': 1}. Best is trial 10 with value: 233.48044770893685.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 277.0153, MAE: 172.0215, R²: -0.4836 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 254.6263, MAE: 154.3931, R²: -0.2534 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 264.1345, MAE: 169.2473, R²: -0.3488 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 255.1876, MAE: 157.0354, R²: -0.2590 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 40, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 233.4804, MAE: 151.7108, R²: -0.0539 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 40, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:40,418] Trial 11 finished with value: 233.48044770893685 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 40, 'p': 1, 'outlier_removal': 1}. Best is trial 10 with value: 233.48044770893685.\n[I 2025-01-19 13:16:40,472] Trial 12 finished with value: 233.48044770893685 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 39, 'p': 1, 'outlier_removal': 1}. Best is trial 10 with value: 233.48044770893685.\n[I 2025-01-19 13:16:40,527] Trial 13 finished with value: 233.48044770893685 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}. Best is trial 10 with value: 233.48044770893685.\n[I 2025-01-19 13:16:40,580] Trial 14 finished with value: 236.4723880173405 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}. Best is trial 10 with value: 233.48044770893685.\n[I 2025-01-19 13:16:40,615] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_mva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 233.4804, MAE: 151.7108, R²: -0.0539 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 39, 'p': 1, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 233.4804, MAE: 151.7108, R²: -0.0539 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 233.4804, MAE: 151.7108, R²: -0.0539 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 236.4724, MAE: 153.7813, R²: -0.0811 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_verkoopkosten: 0.58 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_verkoopkosten: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 40, 'p': 1, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:40,647] Trial 0 finished with value: 516.1786905369539 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 516.1786905369539.\n[I 2025-01-19 13:16:40,678] Trial 1 finished with value: 569.8630829711058 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 516.1786905369539.\n[I 2025-01-19 13:16:40,710] Trial 2 finished with value: 510.11876754775886 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 510.11876754775886.\n[I 2025-01-19 13:16:40,741] Trial 3 finished with value: 523.1234096399561 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 37, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 510.11876754775886.\n[I 2025-01-19 13:16:40,770] Trial 4 finished with value: 515.2566089931415 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 35, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 510.11876754775886.\n[I 2025-01-19 13:16:40,800] Trial 5 finished with value: 523.217145847581 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 510.11876754775886.\n[I 2025-01-19 13:16:40,830] Trial 6 finished with value: 614.4960717711889 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 510.11876754775886.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 516.1787, MAE: 413.7853, R²: -0.0597 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 569.8631, MAE: 465.8889, R²: -0.2916 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 510.1188, MAE: 411.6667, R²: -0.0350 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 37, 'p': 2, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 523.1234, MAE: 424.6531, R²: -0.0885 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 35, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 515.2566, MAE: 407.4156, R²: -0.0560 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 2, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 523.2171, MAE: 423.4167, R²: -0.0888 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 614.4961, MAE: 452.8000, R²: -0.5019 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:40,880] Trial 7 finished with value: 504.6294864551615 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:40,910] Trial 8 finished with value: 515.9820814869015 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:40,941] Trial 9 finished with value: 523.329075383952 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:40,991] Trial 10 finished with value: 527.5651249951148 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:41,046] Trial 11 finished with value: 514.8445271255305 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 504.6295, MAE: 402.6076, R²: -0.0129 in 0.05 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 515.9821, MAE: 413.7402, R²: -0.0589 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 523.3291, MAE: 420.4889, R²: -0.0893 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 527.5651, MAE: 418.9444, R²: -0.1070 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 514.8445, MAE: 415.1822, R²: -0.0543 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:41,102] Trial 12 finished with value: 522.8728721230641 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:41,155] Trial 13 finished with value: 521.0219884995258 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 23, 'p': 1, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:41,208] Trial 14 finished with value: 504.6294864551615 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}. Best is trial 7 with value: 504.6294864551615.\n[I 2025-01-19 13:16:41,236] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_iva\n[I 2025-01-19 13:16:41,266] Trial 0 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,295] Trial 1 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 522.8729, MAE: 420.3669, R²: -0.0874 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 23, 'p': 1, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 521.0220, MAE: 424.4056, R²: -0.0797 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 504.6295, MAE: 402.6076, R²: -0.0129 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_mva: 0.59 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_mva: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:41,324] Trial 2 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,353] Trial 3 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,382] Trial 4 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 15, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,411] Trial 5 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,441] Trial 6 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,473] Trial 7 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,502] Trial 8 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 15, 'p': 2, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 37, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:41,532] Trial 9 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 37, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,583] Trial 10 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,636] Trial 11 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,686] Trial 12 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:41,738] Trial 13 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,793] Trial 14 finished with value: 161.3743060919757 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:41,821] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_omzet\n[I 2025-01-19 13:16:41,857] Trial 0 finished with value: 1044.317692700376 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1044.317692700376.\n[I 2025-01-19 13:16:41,890] Trial 1 finished with value: 1144.4155091541675 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 1044.317692700376.\n[I 2025-01-19 13:16:41,922] Trial 2 finished with value: 976.2071889859128 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 976.2071889859128.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_iva: 0.56 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_iva: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 1044.3177, MAE: 767.6898, R²: -0.5421 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1144.4155, MAE: 878.3607, R²: -0.8519 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 976.2072, MAE: 732.3561, R²: -0.3475 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 43, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:41,954] Trial 3 finished with value: 1191.4685176464347 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 43, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 976.2071889859128.\n[I 2025-01-19 13:16:41,986] Trial 4 finished with value: 946.8799607130779 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,020] Trial 5 finished with value: 1070.5151148447699 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,055] Trial 6 finished with value: 2572.5810716808073 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,090] Trial 7 finished with value: 1107.8293024106329 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,124] Trial 8 finished with value: 1357.0290851000236 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 30, 'p': 2, 'outlier_removal': 1}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,153] Trial 9 finished with value: 1214.3671131033798 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 36, 'p': 1, 'outlier_removal': 0}. Best is trial 4 with value: 946.8799607130779.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1191.4685, MAE: 892.7661, R²: -1.0073 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 946.8800, MAE: 750.0259, R²: -0.2678 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1070.5151, MAE: 839.8704, R²: -0.6204 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 2572.5811, MAE: 2153.2593, R²: -8.3580 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 1107.8293, MAE: 831.9661, R²: -0.7354 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 30, 'p': 2, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1357.0291, MAE: 1078.6141, R²: -1.6039 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 36, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 1214.3671, MAE: 944.7687, R²: -1.0852 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:42,206] Trial 10 finished with value: 1077.7796521802143 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,259] Trial 11 finished with value: 978.6441703817698 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 4 with value: 946.8799607130779.\n[I 2025-01-19 13:16:42,310] Trial 12 finished with value: 920.3609187382636 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}. Best is trial 12 with value: 920.3609187382636.\n[I 2025-01-19 13:16:42,363] Trial 13 finished with value: 970.9494340697513 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}. Best is trial 12 with value: 920.3609187382636.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 1077.7797, MAE: 804.0050, R²: -0.6425 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 978.6442, MAE: 739.4259, R²: -0.3542 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 920.3609, MAE: 701.5667, R²: -0.1977 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 970.9494, MAE: 728.4917, R²: -0.3330 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:42,418] Trial 14 finished with value: 1166.6929771636421 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}. Best is trial 12 with value: 920.3609187382636.\n[I 2025-01-19 13:16:42,448] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_algemene_kosten\n[I 2025-01-19 13:16:42,484] Trial 0 finished with value: 1198.1232091729858 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 1198.1232091729858.\n[I 2025-01-19 13:16:42,521] Trial 1 finished with value: 1171.3789314143987 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 1171.3789314143987.\n[I 2025-01-19 13:16:42,552] Trial 2 finished with value: 1141.1746343806656 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1141.1746343806656.\n[I 2025-01-19 13:16:42,587] Trial 3 finished with value: 1132.408409989693 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 1132.408409989693.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 1166.6930, MAE: 896.4852, R²: -0.9247 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_omzet: 0.60 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_omzet: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1198.1232, MAE: 1055.2564, R²: -0.1508 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 1171.3789, MAE: 938.8590, R²: -0.1000 in 0.04 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1141.1746, MAE: 928.0128, R²: -0.0440 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 2, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 1132.4084, MAE: 914.4159, R²: -0.0280 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:42,624] Trial 4 finished with value: 1127.6384433754488 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}. Best is trial 4 with value: 1127.6384433754488.\n[I 2025-01-19 13:16:42,665] Trial 5 finished with value: 1189.0456962812118 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}. Best is trial 4 with value: 1127.6384433754488.\n[I 2025-01-19 13:16:42,704] Trial 6 finished with value: 1547.1213042706784 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}. Best is trial 4 with value: 1127.6384433754488.\n[I 2025-01-19 13:16:42,737] Trial 7 finished with value: 1161.0917841681685 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}. Best is trial 4 with value: 1127.6384433754488.\n[I 2025-01-19 13:16:42,769] Trial 8 finished with value: 1134.0948254744612 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}. Best is trial 4 with value: 1127.6384433754488.\n[I 2025-01-19 13:16:42,802] Trial 9 finished with value: 1120.9530099400197 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}. Best is trial 9 with value: 1120.9530099400197.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1127.6384, MAE: 931.9504, R²: -0.0194 in 0.04 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 1189.0457, MAE: 969.4781, R²: -0.1334 in 0.04 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1547.1213, MAE: 1302.3782, R²: -0.9188 in 0.04 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1161.0918, MAE: 983.8896, R²: -0.0807 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1134.0948, MAE: 936.2729, R²: -0.0311 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1120.9530, MAE: 928.3101, R²: -0.0073 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:42,861] Trial 10 finished with value: 1138.661640219645 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}. Best is trial 9 with value: 1120.9530099400197.\n[I 2025-01-19 13:16:42,919] Trial 11 finished with value: 1130.2879548978567 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 23, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 1120.9530099400197.\n[I 2025-01-19 13:16:42,982] Trial 12 finished with value: 1134.2892769579526 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 1120.9530099400197.\n[I 2025-01-19 13:16:43,037] Trial 13 finished with value: 1138.661640219645 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 10, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 1120.9530099400197.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1138.6616, MAE: 950.4895, R²: -0.0394 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 23, 'p': 2, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 1130.2880, MAE: 928.9572, R²: -0.0241 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 1134.2893, MAE: 939.5586, R²: -0.0314 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 10, 'p': 2, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 1138.6616, MAE: 950.4895, R²: -0.0394 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:43,103] Trial 14 finished with value: 1142.4207418505043 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}. Best is trial 9 with value: 1120.9530099400197.\n[I 2025-01-19 13:16:43,136] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_autokosten\n[I 2025-01-19 13:16:43,168] Trial 0 finished with value: 1410.290185214361 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 1410.290185214361.\n[I 2025-01-19 13:16:43,199] Trial 1 finished with value: 1430.1814430009738 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 1410.290185214361.\n[I 2025-01-19 13:16:43,230] Trial 2 finished with value: 1440.8583567911119 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1410.290185214361.\n[I 2025-01-19 13:16:43,260] Trial 3 finished with value: 1419.703720860065 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 1410.290185214361.\n[I 2025-01-19 13:16:43,291] Trial 4 finished with value: 1496.1601406528182 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1410.290185214361.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1142.4207, MAE: 924.9346, R²: -0.0463 in 0.07 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_algemene_kosten: 0.66 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_algemene_kosten: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1410.2902, MAE: 1179.0953, R²: -0.0719 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1430.1814, MAE: 1244.6170, R²: -0.1023 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 1440.8584, MAE: 1264.2620, R²: -0.1188 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 1419.7037, MAE: 1248.6215, R²: -0.0862 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 1496.1601, MAE: 1239.4750, R²: -0.2064 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:43,322] Trial 5 finished with value: 1614.3950188602084 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1410.290185214361.\n[I 2025-01-19 13:16:43,352] Trial 6 finished with value: 1408.7714346542614 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}. Best is trial 6 with value: 1408.7714346542614.\n[I 2025-01-19 13:16:43,383] Trial 7 finished with value: 1584.9888427590436 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}. Best is trial 6 with value: 1408.7714346542614.\n[I 2025-01-19 13:16:43,414] Trial 8 finished with value: 1428.4671043114715 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}. Best is trial 6 with value: 1408.7714346542614.\n[I 2025-01-19 13:16:43,443] Trial 9 finished with value: 1451.146686301231 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}. Best is trial 6 with value: 1408.7714346542614.\n[I 2025-01-19 13:16:43,499] Trial 10 finished with value: 1719.8494752132538 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}. Best is trial 6 with value: 1408.7714346542614.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1614.3950, MAE: 1256.2879, R²: -0.4046 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1408.7714, MAE: 1214.9472, R²: -0.0696 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 1584.9888, MAE: 1234.2684, R²: -0.3539 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1428.4671, MAE: 1253.2861, R²: -0.0997 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 1451.1467, MAE: 1261.7717, R²: -0.1349 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1719.8495, MAE: 1110.2826, R²: -0.5941 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 45, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:43,555] Trial 11 finished with value: 1410.290185214361 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 45, 'p': 2, 'outlier_removal': 1}. Best is trial 6 with value: 1408.7714346542614.\n[I 2025-01-19 13:16:43,608] Trial 12 finished with value: 1416.3720720424972 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}. Best is trial 6 with value: 1408.7714346542614.\n[I 2025-01-19 13:16:43,661] Trial 13 finished with value: 1396.0138304001425 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 13 with value: 1396.0138304001425.\n[I 2025-01-19 13:16:43,715] Trial 14 finished with value: 1374.7316392663697 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}. Best is trial 14 with value: 1374.7316392663697.\n[I 2025-01-19 13:16:43,745] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_overige_rentelasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1410.2902, MAE: 1179.0953, R²: -0.0719 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1416.3721, MAE: 1205.0388, R²: -0.0811 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1396.0138, MAE: 1183.5810, R²: -0.0503 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 1374.7316, MAE: 1180.3087, R²: -0.0185 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_autokosten: 0.58 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_autokosten: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:43,777] Trial 0 finished with value: 873.885105669812 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 873.885105669812.\n[I 2025-01-19 13:16:43,807] Trial 1 finished with value: 891.9024064647949 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 873.885105669812.\n[I 2025-01-19 13:16:43,838] Trial 2 finished with value: 1076.4049473023258 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 873.885105669812.\n[I 2025-01-19 13:16:43,868] Trial 3 finished with value: 1305.1310942111995 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 873.885105669812.\n[I 2025-01-19 13:16:43,898] Trial 4 finished with value: 864.74519837104 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}. Best is trial 4 with value: 864.74519837104.\n[I 2025-01-19 13:16:43,929] Trial 5 finished with value: 817.3402281391851 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:43,960] Trial 6 finished with value: 902.350882854592 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 1}. Best is trial 5 with value: 817.3402281391851.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 873.8851, MAE: 719.5512, R²: -0.1452 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 891.9024, MAE: 733.9423, R²: -0.1929 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1076.4049, MAE: 816.7596, R²: -0.7375 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 1305.1311, MAE: 1123.1346, R²: -1.5544 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 864.7452, MAE: 692.8110, R²: -0.1214 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 817.3402, MAE: 639.5258, R²: -0.0018 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 902.3509, MAE: 707.4562, R²: -0.2210 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:43,992] Trial 7 finished with value: 909.0288906511506 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,022] Trial 8 finished with value: 911.252603008839 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,052] Trial 9 finished with value: 876.8302749951538 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,107] Trial 10 finished with value: 834.4052984115738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,167] Trial 11 finished with value: 834.4052984115738 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 909.0289, MAE: 708.0288, R²: -0.2392 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 911.2526, MAE: 717.9663, R²: -0.2452 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 876.8303, MAE: 691.6717, R²: -0.1529 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 834.4053, MAE: 624.0121, R²: -0.0441 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 834.4053, MAE: 624.0121, R²: -0.0441 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:44,224] Trial 12 finished with value: 826.7626065006159 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,283] Trial 13 finished with value: 817.3402281391851 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,342] Trial 14 finished with value: 817.3402281391851 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 817.3402281391851.\n[I 2025-01-19 13:16:44,373] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_pensioenlasten\n[I 2025-01-19 13:16:44,405] Trial 0 finished with value: 607.27793751022 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 48, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 607.27793751022.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 826.7626, MAE: 614.8019, R²: -0.0250 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 817.3402, MAE: 639.5258, R²: -0.0018 in 0.06 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 817.3402, MAE: 639.5258, R²: -0.0018 in 0.06 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_overige_rentelasten: 0.60 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_overige_rentelasten: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 48, 'p': 1, 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 607.2779, MAE: 485.8320, R²: -0.6253 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:44,437] Trial 1 finished with value: 535.2501994955257 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 535.2501994955257.\n[I 2025-01-19 13:16:44,475] Trial 2 finished with value: 674.6168322536876 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 535.2501994955257.\n[I 2025-01-19 13:16:44,507] Trial 3 finished with value: 597.5994146862373 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 535.2501994955257.\n[I 2025-01-19 13:16:44,539] Trial 4 finished with value: 517.5405821446919 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}. Best is trial 4 with value: 517.5405821446919.\n[I 2025-01-19 13:16:44,570] Trial 5 finished with value: 595.5002863083555 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}. Best is trial 4 with value: 517.5405821446919.\n[I 2025-01-19 13:16:44,606] Trial 6 finished with value: 775.0750501295557 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}. Best is trial 4 with value: 517.5405821446919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 535.2502, MAE: 487.7753, R²: -0.2626 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 674.6168, MAE: 526.9827, R²: -1.0057 in 0.04 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 597.5994, MAE: 486.5967, R²: -0.5739 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 517.5406, MAE: 450.9167, R²: -0.1805 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 595.5003, MAE: 489.6407, R²: -0.5629 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 775.0751, MAE: 554.0000, R²: -1.6476 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 577.1989, MAE: 472.2867, R²: -0.4683 in 0.03 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:44,641] Trial 7 finished with value: 577.1988750277787 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}. Best is trial 4 with value: 517.5405821446919.\n[I 2025-01-19 13:16:44,672] Trial 8 finished with value: 593.9569634353429 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}. Best is trial 4 with value: 517.5405821446919.\n[I 2025-01-19 13:16:44,710] Trial 9 finished with value: 509.0960911262235 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 509.0960911262235.\n[I 2025-01-19 13:16:44,774] Trial 10 finished with value: 509.0960911262235 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 509.0960911262235.\n[I 2025-01-19 13:16:44,831] Trial 11 finished with value: 509.0960911262235 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 509.0960911262235.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 8: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 593.9570, MAE: 487.5733, R²: -0.5548 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 509.0961, MAE: 454.1933, R²: -0.1422 in 0.04 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 509.0961, MAE: 454.1933, R²: -0.1422 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 509.0961, MAE: 454.1933, R²: -0.1422 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:44,887] Trial 12 finished with value: 509.0960911262235 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 509.0960911262235.\n[I 2025-01-19 13:16:44,943] Trial 13 finished with value: 540.6120222488582 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}. Best is trial 9 with value: 509.0960911262235.\n[I 2025-01-19 13:16:44,996] Trial 14 finished with value: 499.74845729293315 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 11, 'p': 2, 'outlier_removal': 0}. Best is trial 14 with value: 499.74845729293315.\n[I 2025-01-19 13:16:45,024] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:16:45,055] Trial 0 finished with value: 1046.8299364856646 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 1046.8299364856646.\n[I 2025-01-19 13:16:45,086] Trial 1 finished with value: 1483.7842095955737 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 1046.8299364856646.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 509.0961, MAE: 454.1933, R²: -0.1422 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 540.6120, MAE: 481.6453, R²: -0.2880 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 11, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 499.7485, MAE: 452.3047, R²: -0.1007 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_pensioenlasten: 0.62 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_pensioenlasten: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 11, 'p': 2, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 1046.8299, MAE: 819.5806, R²: 0.0876 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1483.7842, MAE: 1055.3226, R²: -0.8330 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 29, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:45,119] Trial 2 finished with value: 1141.8816283773929 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 29, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 1046.8299364856646.\n[I 2025-01-19 13:16:45,150] Trial 3 finished with value: 1015.3010398955097 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,191] Trial 4 finished with value: 1044.4715339486436 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 1}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,230] Trial 5 finished with value: 1020.4960746411839 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,261] Trial 6 finished with value: 1045.8591394931204 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 1}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,292] Trial 7 finished with value: 1029.097104721008 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 1015.3010398955097.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1141.8816, MAE: 992.2742, R²: -0.0856 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1015.3010, MAE: 869.7903, R²: 0.1418 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 1044.4715, MAE: 858.2223, R²: 0.0918 in 0.04 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 1020.4961, MAE: 860.1287, R²: 0.1330 in 0.04 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1045.8591, MAE: 859.8210, R²: 0.0893 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 1029.0971, MAE: 880.0823, R²: 0.1183 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 1320.9989, MAE: 846.3548, R²: -0.4528 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:45,322] Trial 8 finished with value: 1320.9988767058298 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,353] Trial 9 finished with value: 1062.389422610275 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,405] Trial 10 finished with value: 1046.8299364856646 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1015.3010398955097.\n[I 2025-01-19 13:16:45,463] Trial 11 finished with value: 1008.7182021210496 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}. Best is trial 11 with value: 1008.7182021210496.\n[I 2025-01-19 13:16:45,524] Trial 12 finished with value: 1046.1645586956995 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}. Best is trial 11 with value: 1008.7182021210496.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 1062.3894, MAE: 876.6526, R²: 0.0603 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1046.8299, MAE: 819.5806, R²: 0.0876 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 1008.7182, MAE: 815.6290, R²: 0.1529 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 1046.1646, MAE: 824.5677, R²: 0.0888 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:45,586] Trial 13 finished with value: 1077.929041284797 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}. Best is trial 11 with value: 1008.7182021210496.\n[I 2025-01-19 13:16:45,640] Trial 14 finished with value: 1013.9932039919871 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}. Best is trial 11 with value: 1008.7182021210496.\n[I 2025-01-19 13:16:45,674] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:16:45,708] Trial 0 finished with value: 913.8350243309453 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 913.8350243309453.\n[I 2025-01-19 13:16:45,739] Trial 1 finished with value: 971.123287089375 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 913.8350243309453.\n[I 2025-01-19 13:16:45,771] Trial 2 finished with value: 1042.4922370904924 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 23, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 913.8350243309453.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1077.9290, MAE: 825.7419, R²: 0.0326 in 0.06 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 1013.9932, MAE: 834.1452, R²: 0.1440 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_lonen_en_salarissen: 0.62 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_lonen_en_salarissen: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 913.8350, MAE: 561.2476, R²: -0.0749 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 971.1233, MAE: 595.2552, R²: -0.2139 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 23, 'p': 1, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1042.4922, MAE: 750.0379, R²: -0.3989 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:45,806] Trial 3 finished with value: 980.3515377535538 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 913.8350243309453.\n[I 2025-01-19 13:16:45,838] Trial 4 finished with value: 916.9600190228381 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 913.8350243309453.\n[I 2025-01-19 13:16:45,867] Trial 5 finished with value: 919.7221533381204 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 26, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 913.8350243309453.\n[I 2025-01-19 13:16:45,897] Trial 6 finished with value: 906.6137002813705 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}. Best is trial 6 with value: 906.6137002813705.\n[I 2025-01-19 13:16:45,927] Trial 7 finished with value: 928.0310225328318 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}. Best is trial 6 with value: 906.6137002813705.\n[I 2025-01-19 13:16:45,957] Trial 8 finished with value: 971.4752936704675 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}. Best is trial 6 with value: 906.6137002813705.\n[I 2025-01-19 13:16:45,986] Trial 9 finished with value: 928.4710370639823 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}. Best is trial 6 with value: 906.6137002813705.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 980.3515, MAE: 603.4636, R²: -0.2371 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 916.9600, MAE: 539.2508, R²: -0.0822 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 26, 'p': 1, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 919.7222, MAE: 621.3447, R²: -0.0888 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 906.6137, MAE: 582.5371, R²: -0.0580 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 928.0310, MAE: 548.2647, R²: -0.1085 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 971.4753, MAE: 654.2197, R²: -0.2148 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 928.4710, MAE: 541.1030, R²: -0.1096 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:46,040] Trial 10 finished with value: 906.6137002813705 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}. Best is trial 6 with value: 906.6137002813705.\n[I 2025-01-19 13:16:46,094] Trial 11 finished with value: 906.6137002813705 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}. Best is trial 6 with value: 906.6137002813705.\n[I 2025-01-19 13:16:46,146] Trial 12 finished with value: 906.6137002813705 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}. Best is trial 6 with value: 906.6137002813705.\n[I 2025-01-19 13:16:46,199] Trial 13 finished with value: 903.6922953923614 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}. Best is trial 13 with value: 903.6922953923614.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 906.6137, MAE: 582.5371, R²: -0.0580 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 906.6137, MAE: 582.5371, R²: -0.0580 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 906.6137, MAE: 582.5371, R²: -0.0580 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 903.6923, MAE: 568.1139, R²: -0.0512 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:46,258] Trial 14 finished with value: 903.6922953923614 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}. Best is trial 13 with value: 903.6922953923614.\n[I 2025-01-19 13:16:46,287] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_sociale_lasten\n[I 2025-01-19 13:16:46,318] Trial 0 finished with value: 775.0109636321282 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 775.0109636321282.\n[I 2025-01-19 13:16:46,347] Trial 1 finished with value: 729.2984765147029 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 729.2984765147029.\n[I 2025-01-19 13:16:46,376] Trial 2 finished with value: 1027.2886968455687 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 729.2984765147029.\n[I 2025-01-19 13:16:46,406] Trial 3 finished with value: 768.8082204208449 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 729.2984765147029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 903.6923, MAE: 568.1139, R²: -0.0512 in 0.06 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_overige_personeelskosten: 0.58 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_overige_personeelskosten: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 775.0110, MAE: 600.2083, R²: -0.1513 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 729.2985, MAE: 620.1747, R²: -0.0195 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1027.2887, MAE: 838.9333, R²: -1.0228 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 768.8082, MAE: 607.6220, R²: -0.1329 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 744.7371, MAE: 562.7217, R²: -0.0631 in 0.03 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:46,436] Trial 4 finished with value: 744.7371416255985 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 729.2984765147029.\n[I 2025-01-19 13:16:46,465] Trial 5 finished with value: 727.5250287424252 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 727.5250287424252.\n[I 2025-01-19 13:16:46,494] Trial 6 finished with value: 1027.2886968455687 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}. Best is trial 5 with value: 727.5250287424252.\n[I 2025-01-19 13:16:46,524] Trial 7 finished with value: 775.0109636321282 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}. Best is trial 5 with value: 727.5250287424252.\n[I 2025-01-19 13:16:46,553] Trial 8 finished with value: 718.5356538799356 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 718.5356538799356.\n[I 2025-01-19 13:16:46,581] Trial 9 finished with value: 790.631001953503 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}. Best is trial 8 with value: 718.5356538799356.\n[I 2025-01-19 13:16:46,633] Trial 10 finished with value: 725.3028744761276 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 718.5356538799356.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 5: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 727.5250, MAE: 583.5707, R²: -0.0145 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 1027.2887, MAE: 838.9333, R²: -1.0228 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 775.0110, MAE: 600.2083, R²: -0.1513 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 718.5357, MAE: 573.2883, R²: 0.0104 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 790.6310, MAE: 598.5583, R²: -0.1981 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 725.3029, MAE: 619.3303, R²: -0.0083 in 0.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:46,686] Trial 11 finished with value: 725.3028744761276 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 718.5356538799356.\n[I 2025-01-19 13:16:46,748] Trial 12 finished with value: 725.0165558339569 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 718.5356538799356.\n[I 2025-01-19 13:16:46,802] Trial 13 finished with value: 725.0165558339569 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 718.5356538799356.\n[I 2025-01-19 13:16:46,853] Trial 14 finished with value: 725.0165558339569 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}. Best is trial 8 with value: 718.5356538799356.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 725.3029, MAE: 619.3303, R²: -0.0083 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 725.0166, MAE: 612.4947, R²: -0.0075 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 725.0166, MAE: 612.4947, R²: -0.0075 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 725.0166, MAE: 612.4947, R²: -0.0075 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_sociale_lasten: 0.57 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_sociale_lasten: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:46,885] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:16:46,916] Trial 0 finished with value: 2214.1673073335865 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 2214.1673073335865.\n[I 2025-01-19 13:16:46,947] Trial 1 finished with value: 2214.1673073335865 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 44, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 2214.1673073335865.\n[I 2025-01-19 13:16:46,978] Trial 2 finished with value: 1437.8108397782316 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,010] Trial 3 finished with value: 1447.3991626726215 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,044] Trial 4 finished with value: 1951.666252759975 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,075] Trial 5 finished with value: 1437.8108397782316 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 2214.1673, MAE: 1825.7297, R²: -1.8264 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 44, 'p': 1, 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 2214.1673, MAE: 1825.7297, R²: -1.8264 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1437.8108, MAE: 1312.0541, R²: -0.1918 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1447.3992, MAE: 1313.5862, R²: -0.2078 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 1951.6663, MAE: 1622.4054, R²: -1.1960 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1437.8108, MAE: 1312.0541, R²: -0.1918 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,110] Trial 6 finished with value: 1472.1091832515392 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,141] Trial 7 finished with value: 1535.348904700448 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,186] Trial 8 finished with value: 1493.3733365193805 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,219] Trial 9 finished with value: 1535.348904700448 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,277] Trial 10 finished with value: 1467.995320337375 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1472.1092, MAE: 1352.4803, R²: -0.2494 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 1535.3489, MAE: 1332.2159, R²: -0.3590 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 1493.3733, MAE: 1349.5124, R²: -0.2857 in 0.04 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 1535.3489, MAE: 1332.2159, R²: -0.3590 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1467.9953, MAE: 1284.1738, R²: -0.2424 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,335] Trial 11 finished with value: 1437.8108397782316 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,386] Trial 12 finished with value: 1505.5948937393664 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,438] Trial 13 finished with value: 1544.8934605092754 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1437.8108, MAE: 1312.0541, R²: -0.1918 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1505.5949, MAE: 1370.7378, R²: -0.3069 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 1544.8935, MAE: 1365.3027, R²: -0.3760 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,496] Trial 14 finished with value: 1437.8108397782316 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1437.8108397782316.\n[I 2025-01-19 13:16:47,528] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_kostprijs_van_de_omzet\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1437.8108, MAE: 1312.0541, R²: -0.1918 in 0.06 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_exploitatie-_en_machinekosten: 0.61 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_exploitatie-_en_machinekosten: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 21, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,559] Trial 0 finished with value: 1334.0929004695788 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 21, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1334.0929004695788.\n[I 2025-01-19 13:16:47,591] Trial 1 finished with value: 1308.38181125102 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,623] Trial 2 finished with value: 1412.3978552860615 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,655] Trial 3 finished with value: 1350.9649658461726 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,686] Trial 4 finished with value: 1418.797537192587 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1334.0929, MAE: 1120.8125, R²: -0.0915 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 1308.3818, MAE: 1146.0721, R²: -0.0499 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 1412.3979, MAE: 1212.3012, R²: -0.2234 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1350.9650, MAE: 1156.2810, R²: -0.1193 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 1418.7975, MAE: 1208.3156, R²: -0.2345 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,716] Trial 5 finished with value: 1409.8413741490565 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,745] Trial 6 finished with value: 1395.9848374519809 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}. Best is trial 1 with value: 1308.38181125102.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1409.8414, MAE: 1203.6746, R²: -0.2190 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1395.9848, MAE: 1220.3408, R²: -0.1952 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,775] Trial 7 finished with value: 1358.111681716413 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,807] Trial 8 finished with value: 1418.797537192587 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,837] Trial 9 finished with value: 1321.4355079585798 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n[I 2025-01-19 13:16:47,895] Trial 10 finished with value: 1462.8933231784197 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1358.1117, MAE: 1194.0544, R²: -0.1312 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1418.7975, MAE: 1208.3156, R²: -0.2345 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 1321.4355, MAE: 1112.5456, R²: -0.0709 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 1462.8933, MAE: 1148.6250, R²: -0.3125 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:47,953] Trial 11 finished with value: 1316.1396197568668 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}. Best is trial 1 with value: 1308.38181125102.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1316.1396, MAE: 1119.1077, R²: -0.0623 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,012] Trial 12 finished with value: 1305.6284309728337 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}. Best is trial 12 with value: 1305.6284309728337.\n[I 2025-01-19 13:16:48,071] Trial 13 finished with value: 1482.7132173063676 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}. Best is trial 12 with value: 1305.6284309728337.\n[I 2025-01-19 13:16:48,124] Trial 14 finished with value: 1305.6284309728337 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}. Best is trial 12 with value: 1305.6284309728337.\n[I 2025-01-19 13:16:48,153] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_kantoorkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1305.6284, MAE: 1130.8260, R²: -0.0454 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 1482.7132, MAE: 1221.3537, R²: -0.3483 in 0.06 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 1305.6284, MAE: 1130.8260, R²: -0.0454 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_kostprijs_van_de_omzet: 0.60 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_kostprijs_van_de_omzet: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,184] Trial 0 finished with value: 532.6614380814962 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 532.6614, MAE: 376.6540, R²: 0.0486 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,218] Trial 1 finished with value: 743.2224746503545 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,253] Trial 2 finished with value: 605.2327162943324 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,285] Trial 3 finished with value: 582.2710531746185 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,329] Trial 4 finished with value: 553.8879066874481 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,359] Trial 5 finished with value: 550.7827586839406 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 743.2225, MAE: 582.4365, R²: -0.8523 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 605.2327, MAE: 429.6746, R²: -0.2283 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 582.2711, MAE: 404.8254, R²: -0.1369 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 553.8879, MAE: 384.0651, R²: -0.0288 in 0.04 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 2, 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 550.7828, MAE: 404.3924, R²: -0.0173 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,391] Trial 6 finished with value: 564.1328404855418 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 564.1328, MAE: 395.2413, R²: -0.0672 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 578.1230, MAE: 409.2262, R²: -0.1208 in 0.03 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,421] Trial 7 finished with value: 578.1230242351481 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,452] Trial 8 finished with value: 544.617234354143 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,481] Trial 9 finished with value: 546.6740435797273 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,533] Trial 10 finished with value: 557.047504209499 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,585] Trial 11 finished with value: 573.6678547551406 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 544.6172, MAE: 404.5752, R²: 0.0054 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 546.6740, MAE: 403.8946, R²: -0.0022 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 557.0475, MAE: 396.9337, R²: -0.0405 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 2, 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 573.6679, MAE: 413.8763, R²: -0.1036 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,640] Trial 12 finished with value: 562.3610452962284 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,691] Trial 13 finished with value: 581.2697899017124 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,747] Trial 14 finished with value: 545.1435175822095 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 12, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 532.6614380814962.\n[I 2025-01-19 13:16:48,778] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_verkoopkosten\n[I 2025-01-19 13:16:48,810] Trial 0 finished with value: 450.3784163886164 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 450.3784163886164.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 562.3610, MAE: 405.8159, R²: -0.0605 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 581.2698, MAE: 413.9106, R²: -0.1330 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 12, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 545.1435, MAE: 387.3254, R²: 0.0035 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_kantoorkosten: 0.60 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_kantoorkosten: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 450.3784, MAE: 369.6410, R²: -1.0453 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 537.4909, MAE: 440.3590, R²: -1.9130 in 0.03 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:48,842] Trial 1 finished with value: 537.4909420822949 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 450.3784163886164.\n[I 2025-01-19 13:16:48,873] Trial 2 finished with value: 337.19949374524754 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 337.19949374524754.\n[I 2025-01-19 13:16:48,902] Trial 3 finished with value: 311.26677819467386 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:48,931] Trial 4 finished with value: 352.00872562757405 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 28, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:48,961] Trial 5 finished with value: 327.4017617780708 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 12, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:48,990] Trial 6 finished with value: 393.599272813066 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:49,019] Trial 7 finished with value: 330.98632528108607 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 311.26677819467386.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 2: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 337.1995, MAE: 245.7854, R²: -0.1465 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 311.2668, MAE: 220.2228, R²: 0.0231 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 28, 'p': 2, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 352.0087, MAE: 265.7995, R²: -0.2494 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 12, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 327.4018, MAE: 232.0595, R²: -0.0809 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 393.5993, MAE: 308.5974, R²: -0.5621 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 330.9863, MAE: 242.5128, R²: -0.1046 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 368.4386, MAE: 282.8546, R²: -0.3688 in 0.03 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:49,049] Trial 8 finished with value: 368.4386077204374 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:49,079] Trial 9 finished with value: 322.54004456215023 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 10, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:49,131] Trial 10 finished with value: 311.6937912233407 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:49,184] Trial 11 finished with value: 311.6937912233407 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 311.26677819467386.\n[I 2025-01-19 13:16:49,236] Trial 12 finished with value: 306.1305049844776 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}. Best is trial 12 with value: 306.1305049844776.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 9: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 10, 'p': 1, 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 322.5400, MAE: 212.3336, R²: -0.0490 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 311.6938, MAE: 212.9692, R²: 0.0204 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 311.6938, MAE: 212.9692, R²: 0.0204 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 306.1305, MAE: 209.0549, R²: 0.0550 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:49,298] Trial 13 finished with value: 310.5029218409947 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}. Best is trial 12 with value: 306.1305049844776.\n[I 2025-01-19 13:16:49,354] Trial 14 finished with value: 310.5029218409947 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 1}. Best is trial 12 with value: 306.1305049844776.\n[I 2025-01-19 13:16:49,385] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:16:49,421] Trial 0 finished with value: 1952.2626189458563 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1952.2626189458563.\n[I 2025-01-19 13:16:49,451] Trial 1 finished with value: 1265.7388963236715 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}. Best is trial 1 with value: 1265.7388963236715.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 13 completed with RMSE: 310.5029, MAE: 215.2938, R²: 0.0278 in 0.06 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 310.5029, MAE: 215.2938, R²: 0.0278 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_verkoopkosten: 0.58 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_verkoopkosten: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 42, 'p': 1, 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 1952.2626, MAE: 1541.0667, R²: -1.6273 in 0.03 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 1265.7389, MAE: 1033.2567, R²: -0.1044 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 13, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:49,482] Trial 2 finished with value: 1237.7204831315241 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 13, 'p': 1, 'outlier_removal': 1}. Best is trial 2 with value: 1237.7204831315241.\n[I 2025-01-19 13:16:49,514] Trial 3 finished with value: 1235.947402299143 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,545] Trial 4 finished with value: 1286.9080988788592 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,576] Trial 5 finished with value: 1349.2943155590629 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 13, 'p': 1, 'outlier_removal': 1}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,608] Trial 6 finished with value: 1281.4161461978958 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 34, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,639] Trial 7 finished with value: 1282.9728199121496 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,672] Trial 8 finished with value: 1952.2626189458563 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 36, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 1235.947402299143.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1237.7205, MAE: 1023.5377, R²: -0.0560 in 0.03 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 1235.9474, MAE: 1006.1250, R²: -0.0530 in 0.03 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 1286.9081, MAE: 1039.4720, R²: -0.1416 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 13, 'p': 1, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 1349.2943, MAE: 1141.5000, R²: -0.2550 in 0.03 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 34, 'p': 1, 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 1281.4161, MAE: 1068.2450, R²: -0.1319 in 0.03 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 1282.9728, MAE: 1031.9100, R²: -0.1347 in 0.03 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 36, 'p': 1, 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 1952.2626, MAE: 1541.0667, R²: -1.6273 in 0.03 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:49,702] Trial 9 finished with value: 1256.5880589914898 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,755] Trial 10 finished with value: 1235.947402299143 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,810] Trial 11 finished with value: 1235.947402299143 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,863] Trial 12 finished with value: 1235.947402299143 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1235.947402299143.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1256.5881, MAE: 1039.5000, R²: -0.0885 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1235.9474, MAE: 1006.1250, R²: -0.0530 in 0.05 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 1235.9474, MAE: 1006.1250, R²: -0.0530 in 0.05 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 1235.9474, MAE: 1006.1250, R²: -0.0530 in 0.05 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:49,918] Trial 13 finished with value: 1376.4798324591127 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}. Best is trial 3 with value: 1235.947402299143.\n[I 2025-01-19 13:16:49,971] Trial 14 finished with value: 1234.9416045573437 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}. Best is trial 14 with value: 1234.9416045573437.\n[I 2025-01-19 13:16:50,001] A new study created in memory with name: TrainerKNeighborsRegressor_day_data\n[I 2025-01-19 13:16:50,037] Trial 0 finished with value: 649.306290776897 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,073] Trial 1 finished with value: 662.4585158297207 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,112] Trial 2 finished with value: 664.4821480657406 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 649.306290776897.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1376.4798, MAE: 1140.5333, R²: -0.3061 in 0.05 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 1234.9416, MAE: 1011.9933, R²: -0.0513 in 0.05 seconds\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_huisvestingskosten: 0.59 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_huisvestingskosten: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 649.3063, MAE: 529.2650, R²: 0.0935 in 0.04 seconds\n  Trial 1: Hyperparameters {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 662.4585, MAE: 544.0250, R²: 0.0564 in 0.03 seconds\n  Trial 2: Hyperparameters {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 664.4821, MAE: 542.6545, R²: 0.0506 in 0.04 seconds\n  Trial 3: Hyperparameters {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:50,153] Trial 3 finished with value: 654.8626290024888 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 0}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,189] Trial 4 finished with value: 698.9978206386679 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,232] Trial 5 finished with value: 664.7557615053101 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,277] Trial 6 finished with value: 735.1723029361114 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,315] Trial 7 finished with value: 655.4937312829794 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,353] Trial 8 finished with value: 650.351710947751 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 654.8626, MAE: 536.6004, R²: 0.0779 in 0.04 seconds\n  Trial 4: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 698.9978, MAE: 572.6288, R²: -0.0506 in 0.03 seconds\n  Trial 5: Hyperparameters {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 664.7558, MAE: 542.2136, R²: 0.0498 in 0.04 seconds\n  Trial 6: Hyperparameters {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 735.1723, MAE: 594.2114, R²: -0.1621 in 0.04 seconds\n  Trial 7: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 655.4937, MAE: 537.5625, R²: 0.0761 in 0.04 seconds\n  Trial 8: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 650.3517, MAE: 532.1113, R²: 0.0906 in 0.04 seconds\n  Trial 9: Hyperparameters {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:50,389] Trial 9 finished with value: 698.9978206386679 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,446] Trial 10 finished with value: 651.913102152949 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,503] Trial 11 finished with value: 655.7140048977628 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n[I 2025-01-19 13:16:50,562] Trial 12 finished with value: 657.9756866886186 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}. Best is trial 0 with value: 649.306290776897.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 698.9978, MAE: 572.6288, R²: -0.0506 in 0.03 seconds\n  Trial 10: Hyperparameters {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 651.9131, MAE: 529.5114, R²: 0.0862 in 0.06 seconds\n  Trial 11: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 655.7140, MAE: 536.3316, R²: 0.0755 in 0.06 seconds\n  Trial 12: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 657.9757, MAE: 540.6787, R²: 0.0691 in 0.06 seconds\n  Trial 13: Hyperparameters {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:50,621] Trial 13 finished with value: 647.8109607460642 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}. Best is trial 13 with value: 647.8109607460642.\n[I 2025-01-19 13:16:50,686] Trial 14 finished with value: 657.6205179576382 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}. Best is trial 13 with value: 647.8109607460642.\n[I 2025-01-19 13:16:50,722] A new study created in memory with name: TrainerKNeighborsRegressor_weather_data\n[W 2025-01-19 13:16:50,726] Trial 0 failed with parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_knn.py\", line 49, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:16:50,729] Trial 0 failed with value None.\n[I 2025-01-19 13:16:50,730] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_algemene_kosten\n[I 2025-01-19 13:16:50,733] Trial 0 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,737] Trial 1 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,739] Trial 2 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,742] Trial 3 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,745] Trial 4 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,747] Trial 5 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,750] Trial 6 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,766] Trial 7 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,774] Trial 8 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,777] Trial 9 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,779] Trial 10 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,782] Trial 11 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,785] Trial 12 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,788] Trial 13 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,790] Trial 14 finished with value: 296.8660742143121 and parameters: {'': ''}. Best is trial 0 with value: 296.8660742143121.\n[I 2025-01-19 13:16:50,793] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_autokosten\n[I 2025-01-19 13:16:50,795] Trial 0 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,798] Trial 1 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,801] Trial 2 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,803] Trial 3 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,806] Trial 4 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,808] Trial 5 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,810] Trial 6 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,815] Trial 7 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,819] Trial 8 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,822] Trial 9 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 647.8110, MAE: 529.0989, R²: 0.0977 in 0.06 seconds\n  Trial 14: Hyperparameters {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 657.6205, MAE: 539.8005, R²: 0.0701 in 0.06 seconds\nTotal optimization time for TrainerKNeighborsRegressor_day_data: 0.69 seconds\nBest hyperparameters for TrainerKNeighborsRegressor_day_data: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}\n  Added results for TrainerKNeighborsRegressor on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}\n  Error with trainer TrainerKNeighborsRegressor on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerMajoritySelector\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 296.8661, MAE: 122.2621, R²: -0.1396 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_algemene_kosten: 0.06 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_algemene_kosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:50,825] Trial 10 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,827] Trial 11 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,829] Trial 12 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,833] Trial 13 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,835] Trial 14 finished with value: 97.3926759737781 and parameters: {'': ''}. Best is trial 0 with value: 97.3926759737781.\n[I 2025-01-19 13:16:50,838] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:16:50,840] Trial 0 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,842] Trial 1 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,845] Trial 2 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,847] Trial 3 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,850] Trial 4 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,852] Trial 5 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,854] Trial 6 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,857] Trial 7 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,859] Trial 8 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,863] Trial 9 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,865] Trial 10 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,868] Trial 11 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,870] Trial 12 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,873] Trial 13 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,877] Trial 14 finished with value: 251.60875240284128 and parameters: {'': ''}. Best is trial 0 with value: 251.60875240284128.\n[I 2025-01-19 13:16:50,881] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:16:50,883] Trial 0 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,886] Trial 1 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,889] Trial 2 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,891] Trial 3 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,894] Trial 4 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,897] Trial 5 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,900] Trial 6 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,902] Trial 7 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,904] Trial 8 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,908] Trial 9 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,910] Trial 10 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,913] Trial 11 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,916] Trial 12 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,918] Trial 13 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,921] Trial 14 finished with value: 146.74454517446821 and parameters: {'': ''}. Best is trial 0 with value: 146.74454517446821.\n[I 2025-01-19 13:16:50,923] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_kantoorkosten\n[I 2025-01-19 13:16:50,926] Trial 0 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,928] Trial 1 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,931] Trial 2 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,934] Trial 3 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,936] Trial 4 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,939] Trial 5 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,941] Trial 6 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,944] Trial 7 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,946] Trial 8 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,949] Trial 9 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,951] Trial 10 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,954] Trial 11 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,957] Trial 12 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,959] Trial 13 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,962] Trial 14 finished with value: 408.4655510357988 and parameters: {'': ''}. Best is trial 0 with value: 408.4655510357988.\n[I 2025-01-19 13:16:50,964] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:16:50,968] Trial 0 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,970] Trial 1 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,973] Trial 2 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,976] Trial 3 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,979] Trial 4 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,981] Trial 5 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,984] Trial 6 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,987] Trial 7 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,989] Trial 8 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:50,996] Trial 9 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:51,008] Trial 10 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:51,016] Trial 11 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:51,019] Trial 12 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:51,021] Trial 13 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:51,023] Trial 14 finished with value: 695.8812018288924 and parameters: {'': ''}. Best is trial 0 with value: 695.8812018288924.\n[I 2025-01-19 13:16:51,026] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_overige_bedrijfsopbrengsten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 97.3927, MAE: 62.6667, R²: -0.4283 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_autokosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_autokosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 251.6088, MAE: 198.5357, R²: -0.0671 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_exploitatie-_en_machinekosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_exploitatie-_en_machinekosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 146.7445, MAE: 58.5000, R²: -0.1880 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_huisvestingskosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_huisvestingskosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 408.4656, MAE: 342.5319, R²: -2.3695 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_kantoorkosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_kantoorkosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.01 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 695.8812, MAE: 500.4118, R²: -0.7878 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_lonen_en_salarissen: 0.06 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_lonen_en_salarissen: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:51,028] Trial 0 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,031] Trial 1 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,033] Trial 2 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,035] Trial 3 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,037] Trial 4 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,040] Trial 5 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,042] Trial 6 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,046] Trial 7 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,048] Trial 8 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,051] Trial 9 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,053] Trial 10 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,056] Trial 11 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,059] Trial 12 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,061] Trial 13 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,064] Trial 14 finished with value: 56.08583323491925 and parameters: {'': ''}. Best is trial 0 with value: 56.08583323491925.\n[I 2025-01-19 13:16:51,066] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:16:51,069] Trial 0 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,071] Trial 1 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,075] Trial 2 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,077] Trial 3 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,080] Trial 4 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,082] Trial 5 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,085] Trial 6 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,087] Trial 7 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,090] Trial 8 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,092] Trial 9 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,095] Trial 10 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,098] Trial 11 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,101] Trial 12 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,104] Trial 13 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,106] Trial 14 finished with value: 198.5698629605975 and parameters: {'': ''}. Best is trial 0 with value: 198.5698629605975.\n[I 2025-01-19 13:16:51,109] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_overige_rentelasten\n[I 2025-01-19 13:16:51,112] Trial 0 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,114] Trial 1 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,117] Trial 2 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,120] Trial 3 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,123] Trial 4 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,125] Trial 5 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,128] Trial 6 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,130] Trial 7 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,133] Trial 8 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,135] Trial 9 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,138] Trial 10 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,143] Trial 11 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,146] Trial 12 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,149] Trial 13 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,151] Trial 14 finished with value: 213.98208647766134 and parameters: {'': ''}. Best is trial 0 with value: 213.98208647766134.\n[I 2025-01-19 13:16:51,154] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:51,156] Trial 0 failed with parameters: {'': ''} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:16:51,157] Trial 0 failed with value None.\n[I 2025-01-19 13:16:51,158] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_verkoopkosten\n[I 2025-01-19 13:16:51,161] Trial 0 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,164] Trial 1 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,167] Trial 2 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,170] Trial 3 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,173] Trial 4 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,176] Trial 5 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,179] Trial 6 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,182] Trial 7 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,185] Trial 8 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,187] Trial 9 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,190] Trial 10 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,193] Trial 11 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,196] Trial 12 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,198] Trial 13 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,201] Trial 14 finished with value: 293.247079205174 and parameters: {'': ''}. Best is trial 0 with value: 293.247079205174.\n[I 2025-01-19 13:16:51,204] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_afschrijvingen_mva\n[I 2025-01-19 13:16:51,206] Trial 0 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,209] Trial 1 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,212] Trial 2 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,215] Trial 3 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,217] Trial 4 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,220] Trial 5 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,223] Trial 6 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,225] Trial 7 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,228] Trial 8 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 56.0858, MAE: 11.0000, R²: -0.0317 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_overige_bedrijfsopbrengsten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_overige_bedrijfsopbrengsten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 198.5699, MAE: 54.1048, R²: -0.0718 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_overige_personeelskosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_overige_personeelskosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 213.9821, MAE: 86.9333, R²: -0.1922 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_overige_rentelasten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_overige_rentelasten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'': ''}\n  Error with trainer TrainerMajoritySelector on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 293.2471, MAE: 187.8280, R²: -0.6625 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_verkoopkosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_verkoopkosten: {'': ''}\n  Added results for TrainerMajoritySelector on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:51,230] Trial 9 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,233] Trial 10 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,235] Trial 11 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,237] Trial 12 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,240] Trial 13 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,242] Trial 14 finished with value: 736.9149355402035 and parameters: {'': ''}. Best is trial 0 with value: 736.9149355402035.\n[I 2025-01-19 13:16:51,245] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_afschrijvingen_iva\n[I 2025-01-19 13:16:51,248] Trial 0 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,250] Trial 1 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,253] Trial 2 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,256] Trial 3 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,259] Trial 4 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,261] Trial 5 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,264] Trial 6 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,266] Trial 7 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,269] Trial 8 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,271] Trial 9 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,274] Trial 10 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,280] Trial 11 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,283] Trial 12 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,285] Trial 13 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,288] Trial 14 finished with value: 161.3743060919757 and parameters: {'': ''}. Best is trial 0 with value: 161.3743060919757.\n[I 2025-01-19 13:16:51,290] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_omzet\n[I 2025-01-19 13:16:51,293] Trial 0 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,296] Trial 1 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,298] Trial 2 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,301] Trial 3 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,304] Trial 4 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,306] Trial 5 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,308] Trial 6 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,311] Trial 7 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,313] Trial 8 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,316] Trial 9 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,319] Trial 10 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,322] Trial 11 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,324] Trial 12 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,327] Trial 13 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,329] Trial 14 finished with value: 1042.3283409609328 and parameters: {'': ''}. Best is trial 0 with value: 1042.3283409609328.\n[I 2025-01-19 13:16:51,332] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_algemene_kosten\n[I 2025-01-19 13:16:51,335] Trial 0 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,338] Trial 1 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,340] Trial 2 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,343] Trial 3 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,345] Trial 4 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,347] Trial 5 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,350] Trial 6 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,353] Trial 7 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,361] Trial 8 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,364] Trial 9 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,366] Trial 10 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,370] Trial 11 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,374] Trial 12 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,376] Trial 13 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,379] Trial 14 finished with value: 1429.4480735136183 and parameters: {'': ''}. Best is trial 0 with value: 1429.4480735136183.\n[I 2025-01-19 13:16:51,381] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_autokosten\n[I 2025-01-19 13:16:51,386] Trial 0 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,389] Trial 1 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,391] Trial 2 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,394] Trial 3 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,397] Trial 4 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,400] Trial 5 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,403] Trial 6 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,405] Trial 7 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,408] Trial 8 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,411] Trial 9 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,413] Trial 10 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,416] Trial 11 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,418] Trial 12 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,421] Trial 13 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,424] Trial 14 finished with value: 1710.5826302118846 and parameters: {'': ''}. Best is trial 0 with value: 1710.5826302118846.\n[I 2025-01-19 13:16:51,426] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_overige_rentelasten\n[I 2025-01-19 13:16:51,429] Trial 0 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,433] Trial 1 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 736.9149, MAE: 600.7333, R²: -1.1599 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_mva: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_mva: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 161.3743, MAE: 41.6667, R²: -0.0714 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_iva: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_iva: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 1042.3283, MAE: 778.4815, R²: -0.5362 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_omzet: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_omzet: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 1429.4481, MAE: 966.2564, R²: -0.6380 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_algemene_kosten: 0.05 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_algemene_kosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 1710.5826, MAE: 1092.6957, R²: -0.5769 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_autokosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_autokosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:51,435] Trial 2 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,438] Trial 3 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,441] Trial 4 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,443] Trial 5 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,446] Trial 6 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,449] Trial 7 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,451] Trial 8 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,454] Trial 9 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,457] Trial 10 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,460] Trial 11 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,462] Trial 12 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,465] Trial 13 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,469] Trial 14 finished with value: 821.3638517265517 and parameters: {'': ''}. Best is trial 0 with value: 821.3638517265517.\n[I 2025-01-19 13:16:51,471] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_pensioenlasten\n[I 2025-01-19 13:16:51,474] Trial 0 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,476] Trial 1 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,479] Trial 2 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,482] Trial 3 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,484] Trial 4 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,487] Trial 5 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,491] Trial 6 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,493] Trial 7 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,496] Trial 8 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,498] Trial 9 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,501] Trial 10 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,504] Trial 11 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,506] Trial 12 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,509] Trial 13 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,512] Trial 14 finished with value: 519.4563825128471 and parameters: {'': ''}. Best is trial 0 with value: 519.4563825128471.\n[I 2025-01-19 13:16:51,515] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:16:51,517] Trial 0 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,520] Trial 1 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,523] Trial 2 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,525] Trial 3 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,528] Trial 4 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,530] Trial 5 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,533] Trial 6 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,535] Trial 7 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,537] Trial 8 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,541] Trial 9 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,545] Trial 10 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,547] Trial 11 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,550] Trial 12 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,553] Trial 13 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,555] Trial 14 finished with value: 1145.7227891935377 and parameters: {'': ''}. Best is trial 0 with value: 1145.7227891935377.\n[I 2025-01-19 13:16:51,558] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:16:51,561] Trial 0 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,564] Trial 1 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,567] Trial 2 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,569] Trial 3 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,572] Trial 4 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,574] Trial 5 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,577] Trial 6 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,580] Trial 7 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,582] Trial 8 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,585] Trial 9 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,587] Trial 10 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,590] Trial 11 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,593] Trial 12 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,595] Trial 13 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,598] Trial 14 finished with value: 956.383639899108 and parameters: {'': ''}. Best is trial 0 with value: 956.383639899108.\n[I 2025-01-19 13:16:51,602] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_sociale_lasten\n[I 2025-01-19 13:16:51,604] Trial 0 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,607] Trial 1 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,609] Trial 2 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,613] Trial 3 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,615] Trial 4 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,618] Trial 5 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,621] Trial 6 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,624] Trial 7 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,627] Trial 8 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,629] Trial 9 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,631] Trial 10 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,634] Trial 11 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 821.3639, MAE: 687.3462, R²: -0.0117 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_overige_rentelasten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_overige_rentelasten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 519.4564, MAE: 378.6667, R²: -0.1892 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_pensioenlasten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_pensioenlasten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 1145.7228, MAE: 835.4194, R²: -0.0929 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_lonen_en_salarissen: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_lonen_en_salarissen: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 956.3836, MAE: 443.0606, R²: -0.1773 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_overige_personeelskosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_overige_personeelskosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:51,638] Trial 12 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,641] Trial 13 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,643] Trial 14 finished with value: 780.7639634785065 and parameters: {'': ''}. Best is trial 0 with value: 780.7639634785065.\n[I 2025-01-19 13:16:51,646] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:16:51,648] Trial 0 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,651] Trial 1 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,654] Trial 2 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,656] Trial 3 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,660] Trial 4 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,662] Trial 5 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,665] Trial 6 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,667] Trial 7 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,670] Trial 8 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,673] Trial 9 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,676] Trial 10 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,678] Trial 11 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,680] Trial 12 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,683] Trial 13 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,686] Trial 14 finished with value: 2608.301461394659 and parameters: {'': ''}. Best is trial 0 with value: 2608.301461394659.\n[I 2025-01-19 13:16:51,689] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_kostprijs_van_de_omzet\n[I 2025-01-19 13:16:51,691] Trial 0 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,694] Trial 1 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,697] Trial 2 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,699] Trial 3 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,702] Trial 4 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,705] Trial 5 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,707] Trial 6 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,710] Trial 7 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,712] Trial 8 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,715] Trial 9 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,717] Trial 10 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,720] Trial 11 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,722] Trial 12 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,725] Trial 13 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,728] Trial 14 finished with value: 1279.9722734627235 and parameters: {'': ''}. Best is trial 0 with value: 1279.9722734627235.\n[I 2025-01-19 13:16:51,732] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_kantoorkosten\n[I 2025-01-19 13:16:51,735] Trial 0 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,738] Trial 1 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,740] Trial 2 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,742] Trial 3 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,745] Trial 4 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,748] Trial 5 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,751] Trial 6 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,754] Trial 7 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,756] Trial 8 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,759] Trial 9 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,761] Trial 10 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,764] Trial 11 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,767] Trial 12 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,769] Trial 13 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,772] Trial 14 finished with value: 571.2559679796623 and parameters: {'': ''}. Best is trial 0 with value: 571.2559679796623.\n[I 2025-01-19 13:16:51,775] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_verkoopkosten\n[I 2025-01-19 13:16:51,778] Trial 0 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,782] Trial 1 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,784] Trial 2 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,787] Trial 3 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,789] Trial 4 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,792] Trial 5 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,795] Trial 6 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,798] Trial 7 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,800] Trial 8 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,802] Trial 9 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,806] Trial 10 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,808] Trial 11 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,811] Trial 12 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,814] Trial 13 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,817] Trial 14 finished with value: 359.3702469027929 and parameters: {'': ''}. Best is trial 0 with value: 359.3702469027929.\n[I 2025-01-19 13:16:51,820] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:16:51,823] Trial 0 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,826] Trial 1 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,828] Trial 2 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,831] Trial 3 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,833] Trial 4 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,836] Trial 5 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,838] Trial 6 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 780.7640, MAE: 564.8333, R²: -0.1684 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_sociale_lasten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_sociale_lasten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 2608.3015, MAE: 2275.9730, R²: -2.9222 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_exploitatie-_en_machinekosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_exploitatie-_en_machinekosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 1279.9723, MAE: 1052.8958, R²: -0.0048 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_kostprijs_van_de_omzet: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_kostprijs_van_de_omzet: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 571.2560, MAE: 370.3333, R²: -0.0943 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_kantoorkosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_kantoorkosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 359.3702, MAE: 207.1795, R²: -0.3022 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_verkoopkosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_verkoopkosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:51,841] Trial 7 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,844] Trial 8 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,847] Trial 9 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,849] Trial 10 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,851] Trial 11 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,854] Trial 12 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,857] Trial 13 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,860] Trial 14 finished with value: 1213.6103987688964 and parameters: {'': ''}. Best is trial 0 with value: 1213.6103987688964.\n[I 2025-01-19 13:16:51,863] A new study created in memory with name: TrainerMajoritySelector_day_data\n[I 2025-01-19 13:16:51,866] Trial 0 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,869] Trial 1 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,872] Trial 2 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,875] Trial 3 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,878] Trial 4 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,881] Trial 5 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,884] Trial 6 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,887] Trial 7 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,890] Trial 8 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,893] Trial 9 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,896] Trial 10 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,899] Trial 11 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,902] Trial 12 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,906] Trial 13 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,909] Trial 14 finished with value: 857.1390368252582 and parameters: {'': ''}. Best is trial 0 with value: 857.1390368252582.\n[I 2025-01-19 13:16:51,912] A new study created in memory with name: TrainerMajoritySelector_weather_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 1213.6104, MAE: 940.9333, R²: -0.0153 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_huisvestingskosten: 0.04 seconds\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_huisvestingskosten: {'': ''}\n  Added results for TrainerMajoritySelector on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'': ''}\n  Trial 0 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 1: Hyperparameters {'': ''}\n  Trial 1 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 2: Hyperparameters {'': ''}\n  Trial 2 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 3: Hyperparameters {'': ''}\n  Trial 3 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 4: Hyperparameters {'': ''}\n  Trial 4 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 5: Hyperparameters {'': ''}\n  Trial 5 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 6: Hyperparameters {'': ''}\n  Trial 6 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 7: Hyperparameters {'': ''}\n  Trial 7 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 8: Hyperparameters {'': ''}\n  Trial 8 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 9: Hyperparameters {'': ''}\n  Trial 9 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 10: Hyperparameters {'': ''}\n  Trial 10 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 11: Hyperparameters {'': ''}\n  Trial 11 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 12: Hyperparameters {'': ''}\n  Trial 12 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 13: Hyperparameters {'': ''}\n  Trial 13 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\n  Trial 14: Hyperparameters {'': ''}\n  Trial 14 completed with RMSE: 857.1390, MAE: 665.4686, R²: -0.5797 in 0.00 seconds\nTotal optimization time for TrainerMajoritySelector_day_data: 0.05 seconds\nBest hyperparameters for TrainerMajoritySelector_day_data: {'': ''}\n  Added results for TrainerMajoritySelector on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'': ''}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:51,913] Trial 0 failed with parameters: {'': ''} because of the following error: KeyError('value').\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'value'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_majority_selector.py\", line 55, in predict\n    pdf_test['predictions'] = self.model['value'].value_counts().idxmax()\n                              ~~~~~~~~~~^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'value'\n[W 2025-01-19 13:16:52,290] Trial 0 failed with value None.\n[I 2025-01-19 13:16:52,291] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_algemene_kosten\n[W 2025-01-19 13:16:52,329] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:52,377] Trial 0 failed with value None.\n[I 2025-01-19 13:16:52,379] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_autokosten\n[W 2025-01-19 13:16:52,412] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:52,414] Trial 0 failed with value None.\n[I 2025-01-19 13:16:52,415] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:16:52,449] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:52,452] Trial 0 failed with value None.\n[I 2025-01-19 13:16:52,452] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:16:52,490] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerMajoritySelector on dataset weather_data: 'value'\n\nProcessing Trainer: TrainerMovingAverage\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_algemene_kosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_autokosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_exploitatie-_en_machinekosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:52,493] Trial 0 failed with value None.\n[I 2025-01-19 13:16:52,493] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_kantoorkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_huisvestingskosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:52,789] Trial 0 finished with value: 222.53568454833626 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}. Best is trial 0 with value: 222.53568454833626.\n[W 2025-01-19 13:16:52,822] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:52,825] Trial 1 failed with value None.\n[I 2025-01-19 13:16:52,825] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:52,859] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:52,861] Trial 0 failed with value None.\n[I 2025-01-19 13:16:52,862] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_overige_bedrijfsopbrengsten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 222.5357, MAE: 190.7630, R²: -0.0001 in 0.29 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_kantoorkosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_lonen_en_salarissen: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:53,067] Trial 0 finished with value: 86.95380950372511 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}. Best is trial 0 with value: 86.95380950372511.\n[W 2025-01-19 13:16:53,100] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:53,103] Trial 1 failed with value None.\n[I 2025-01-19 13:16:53,104] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_overige_personeelskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798 in 0.20 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_overige_bedrijfsopbrengsten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:53,735] Trial 0 finished with value: 197.3351994763756 and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}. Best is trial 0 with value: 197.3351994763756.\n[W 2025-01-19 13:16:53,767] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:53,770] Trial 1 failed with value None.\n[I 2025-01-19 13:16:53,770] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:53,804] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:53,806] Trial 0 failed with value None.\n[I 2025-01-19 13:16:53,807] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:53,905] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:16:53,906] Trial 0 failed with value None.\n[I 2025-01-19 13:16:53,907] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_verkoopkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 197.3352, MAE: 52.8000, R²: -0.0585 in 0.63 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_overige_personeelskosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_overige_rentelasten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:53,938] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:53,941] Trial 0 failed with value None.\n[I 2025-01-19 13:16:53,942] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_afschrijvingen_mva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_verkoopkosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:54,219] Trial 0 finished with value: 527.9278543934241 and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}. Best is trial 0 with value: 527.9278543934241.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 527.9279, MAE: 385.1000, R²: -0.1085 in 0.28 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:54,495] Trial 1 finished with value: 527.9278543934241 and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}. Best is trial 0 with value: 527.9278543934241.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 527.9279, MAE: 385.1000, R²: -0.1085 in 0.28 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:54,778] Trial 2 finished with value: 397.75013094487684 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}. Best is trial 2 with value: 397.75013094487684.\n[W 2025-01-19 13:16:54,802] Trial 3 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:54,805] Trial 3 failed with value None.\n[I 2025-01-19 13:16:54,805] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_afschrijvingen_iva\n[W 2025-01-19 13:16:54,830] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:54,832] Trial 0 failed with value None.\n[I 2025-01-19 13:16:54,833] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_omzet\n[W 2025-01-19 13:16:54,864] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:54,866] Trial 0 failed with value None.\n[I 2025-01-19 13:16:54,867] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 397.7501, MAE: 281.8333, R²: nan in 0.28 seconds\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_afschrijvingen_mva: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_afschrijvingen_iva: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_omzet: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:55,350] Trial 0 finished with value: 1634.0180787349489 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1634.0180787349489.\n[W 2025-01-19 13:16:55,374] Trial 1 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:55,379] Trial 1 failed with value None.\n[I 2025-01-19 13:16:55,379] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_autokosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1634.0181, MAE: 1161.2381, R²: nan in 0.48 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_algemene_kosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:55,953] Trial 0 finished with value: 1721.9028969539663 and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}. Best is trial 0 with value: 1721.9028969539663.\n[W 2025-01-19 13:16:55,977] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:55,980] Trial 1 failed with value None.\n[I 2025-01-19 13:16:55,981] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:56,006] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:56,009] Trial 0 failed with value None.\n[I 2025-01-19 13:16:56,010] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_pensioenlasten\n[W 2025-01-19 13:16:56,040] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:56,042] Trial 0 failed with value None.\n[I 2025-01-19 13:16:56,043] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:56,071] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:56,073] Trial 0 failed with value None.\n[I 2025-01-19 13:16:56,074] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_overige_personeelskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1721.9029, MAE: 1257.5577, R²: nan in 0.57 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_autokosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_overige_rentelasten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 1, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_pensioenlasten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'month', 'pattern': 1, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_lonen_en_salarissen: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:56,526] Trial 0 finished with value: 1056.535845197644 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}. Best is trial 0 with value: 1056.535845197644.\n[W 2025-01-19 13:16:56,550] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:56,553] Trial 1 failed with value None.\n[I 2025-01-19 13:16:56,554] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:56,578] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:56,581] Trial 0 failed with value None.\n[I 2025-01-19 13:16:56,582] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_exploitatie-_en_machinekosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1056.5358, MAE: 649.6875, R²: nan in 0.45 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_overige_personeelskosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_sociale_lasten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:56,828] Trial 0 finished with value: 568.2916270132205 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}. Best is trial 0 with value: 568.2916270132205.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 568.2916, MAE: 452.7333, R²: nan in 0.25 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:57,078] Trial 1 finished with value: 568.2916270132205 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}. Best is trial 0 with value: 568.2916270132205.\n[W 2025-01-19 13:16:57,101] Trial 2 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:57,104] Trial 2 failed with value None.\n[I 2025-01-19 13:16:57,104] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_kostprijs_van_de_omzet\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 568.2916, MAE: 452.7333, R²: nan in 0.25 seconds\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_exploitatie-_en_machinekosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:57,410] Trial 0 finished with value: 1345.9856209418015 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}. Best is trial 0 with value: 1345.9856209418015.\n[W 2025-01-19 13:16:57,434] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:57,436] Trial 1 failed with value None.\n[I 2025-01-19 13:16:57,437] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_kantoorkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1345.9856, MAE: 906.1579, R²: nan in 0.30 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'month', 'pattern': 1, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_kostprijs_van_de_omzet: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:57,844] Trial 0 finished with value: 640.0891127196448 and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}. Best is trial 0 with value: 640.0891127196448.\n[W 2025-01-19 13:16:57,866] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:57,869] Trial 1 failed with value None.\n[I 2025-01-19 13:16:57,870] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_verkoopkosten\n[W 2025-01-19 13:16:57,896] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:57,898] Trial 0 failed with value None.\n[I 2025-01-19 13:16:57,899] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_huisvestingskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 640.0891, MAE: 398.8000, R²: nan in 0.41 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_kantoorkosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_verkoopkosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:16:58,094] Trial 0 finished with value: 1324.0944735931798 and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}. Best is trial 0 with value: 1324.0944735931798.\n[W 2025-01-19 13:16:58,118] Trial 1 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:58,121] Trial 1 failed with value None.\n[I 2025-01-19 13:16:58,121] A new study created in memory with name: TrainerMovingAverage_day_data\n[W 2025-01-19 13:16:58,154] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:16:58,156] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,157] A new study created in memory with name: TrainerMovingAverage_weather_data\n[W 2025-01-19 13:16:58,160] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 1, 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 45, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:16:58,163] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,164] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1324.0945, MAE: 1004.1167, R²: -0.2086 in 0.19 seconds\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time': 'month', 'pattern': 0, 'outlier_removal': 1}\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_huisvestingskosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset day_data: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'avg_or_med': 'med', 'time': 'week', 'pattern': 1, 'outlier_removal': 0}\n  Error with trainer TrainerMovingAverage on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerRandomForest\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'max_depth': 67, 'n_estimators': 60, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:58,182] Trial 0 failed with parameters: {'max_depth': 67, 'n_estimators': 60, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,357] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,358] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_autokosten\n[W 2025-01-19 13:16:58,377] Trial 0 failed with parameters: {'max_depth': 203, 'n_estimators': 49, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,380] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,381] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:16:58,399] Trial 0 failed with parameters: {'max_depth': 406, 'n_estimators': 94, 'min_samples_split': 3, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,402] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,403] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:16:58,424] Trial 0 failed with parameters: {'max_depth': 494, 'n_estimators': 39, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,427] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,428] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_kantoorkosten\n[W 2025-01-19 13:16:58,446] Trial 0 failed with parameters: {'max_depth': 472, 'n_estimators': 91, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,448] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,450] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:58,469] Trial 0 failed with parameters: {'max_depth': 334, 'n_estimators': 16, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,471] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,472] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_overige_bedrijfsopbrengsten\n[W 2025-01-19 13:16:58,492] Trial 0 failed with parameters: {'max_depth': 364, 'n_estimators': 85, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,495] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,496] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:16:58,515] Trial 0 failed with parameters: {'max_depth': 300, 'n_estimators': 55, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,518] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,519] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:58,537] Trial 0 failed with parameters: {'max_depth': 284, 'n_estimators': 93, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,540] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,540] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_sociale_lasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset week_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'max_depth': 203, 'n_estimators': 49, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'max_depth': 406, 'n_estimators': 94, 'min_samples_split': 3, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'max_depth': 494, 'n_estimators': 39, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'max_depth': 472, 'n_estimators': 91, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'max_depth': 334, 'n_estimators': 16, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'max_depth': 364, 'n_estimators': 85, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_overige_bedrijfsopbrengsten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'max_depth': 300, 'n_estimators': 55, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'max_depth': 284, 'n_estimators': 93, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'max_depth': 80, 'n_estimators': 56, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:58,557] Trial 0 failed with parameters: {'max_depth': 80, 'n_estimators': 56, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,560] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,561] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_verkoopkosten\n[W 2025-01-19 13:16:58,579] Trial 0 failed with parameters: {'max_depth': 326, 'n_estimators': 32, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,582] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,583] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_afschrijvingen_mva\n[W 2025-01-19 13:16:58,605] Trial 0 failed with parameters: {'max_depth': 108, 'n_estimators': 8, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,608] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,609] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_afschrijvingen_iva\n[W 2025-01-19 13:16:58,629] Trial 0 failed with parameters: {'max_depth': 114, 'n_estimators': 16, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,632] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,632] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_omzet\n[W 2025-01-19 13:16:58,653] Trial 0 failed with parameters: {'max_depth': 67, 'n_estimators': 93, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,656] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,657] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_algemene_kosten\n[W 2025-01-19 13:16:58,678] Trial 0 failed with parameters: {'max_depth': 179, 'n_estimators': 81, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,680] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,681] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_autokosten\n[W 2025-01-19 13:16:58,702] Trial 0 failed with parameters: {'max_depth': 201, 'n_estimators': 32, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,705] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,706] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:58,726] Trial 0 failed with parameters: {'max_depth': 147, 'n_estimators': 98, 'min_samples_split': 2, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,729] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,729] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_pensioenlasten\n[W 2025-01-19 13:16:58,752] Trial 0 failed with parameters: {'max_depth': 173, 'n_estimators': 49, 'min_samples_split': 5, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,755] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,756] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_lonen_en_salarissen\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset week_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'max_depth': 326, 'n_estimators': 32, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'max_depth': 108, 'n_estimators': 8, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_afschrijvingen_mva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'max_depth': 114, 'n_estimators': 16, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_afschrijvingen_iva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'max_depth': 67, 'n_estimators': 93, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'max_depth': 179, 'n_estimators': 81, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'max_depth': 201, 'n_estimators': 32, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'max_depth': 147, 'n_estimators': 98, 'min_samples_split': 2, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'max_depth': 173, 'n_estimators': 49, 'min_samples_split': 5, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_pensioenlasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'max_depth': 327, 'n_estimators': 60, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:58,779] Trial 0 failed with parameters: {'max_depth': 327, 'n_estimators': 60, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,782] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,782] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:16:58,804] Trial 0 failed with parameters: {'max_depth': 374, 'n_estimators': 88, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,808] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,808] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:58,830] Trial 0 failed with parameters: {'max_depth': 492, 'n_estimators': 8, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,833] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,834] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:16:58,854] Trial 0 failed with parameters: {'max_depth': 88, 'n_estimators': 31, 'min_samples_split': 7, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,857] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,858] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_kostprijs_van_de_omzet\n[W 2025-01-19 13:16:58,884] Trial 0 failed with parameters: {'max_depth': 236, 'n_estimators': 48, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,887] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,888] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_kantoorkosten\n[W 2025-01-19 13:16:58,909] Trial 0 failed with parameters: {'max_depth': 215, 'n_estimators': 81, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:58,911] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,912] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_verkoopkosten\n[W 2025-01-19 13:16:58,932] Trial 0 failed with parameters: {'max_depth': 459, 'n_estimators': 10, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,934] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,935] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:16:58,955] Trial 0 failed with parameters: {'max_depth': 126, 'n_estimators': 79, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,958] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,959] A new study created in memory with name: TrainerRandomForest_day_data\n[W 2025-01-19 13:16:58,978] Trial 0 failed with parameters: {'max_depth': 90, 'n_estimators': 58, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:58,981] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,982] A new study created in memory with name: TrainerRandomForest_weather_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset month_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'max_depth': 374, 'n_estimators': 88, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'max_depth': 492, 'n_estimators': 8, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'max_depth': 88, 'n_estimators': 31, 'min_samples_split': 7, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'max_depth': 236, 'n_estimators': 48, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_kostprijs_van_de_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'max_depth': 215, 'n_estimators': 81, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'max_depth': 459, 'n_estimators': 10, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'max_depth': 126, 'n_estimators': 79, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'max_depth': 90, 'n_estimators': 58, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForest on dataset day_data: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'max_depth': 286, 'n_estimators': 92, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:58,985] Trial 0 failed with parameters: {'max_depth': 286, 'n_estimators': 92, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 49, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:16:58,988] Trial 0 failed with value None.\n[I 2025-01-19 13:16:58,989] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_algemene_kosten\n[W 2025-01-19 13:16:59,034] Trial 0 failed with parameters: {'n_estimators': 258, 'max_depth': 79, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,084] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,085] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_autokosten\n[W 2025-01-19 13:16:59,137] Trial 0 failed with parameters: {'n_estimators': 118, 'max_depth': 67, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,140] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,141] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_exploitatie-_en_machinekosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Error with trainer TrainerRandomForest on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerRandomForestPattern\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'n_estimators': 258, 'max_depth': 79, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'n_estimators': 118, 'max_depth': 67, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'n_estimators': 135, 'max_depth': 37, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:59,189] Trial 0 failed with parameters: {'n_estimators': 135, 'max_depth': 37, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,192] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,193] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:16:59,240] Trial 0 failed with parameters: {'n_estimators': 260, 'max_depth': 50, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,243] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,244] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_kantoorkosten\n[W 2025-01-19 13:16:59,291] Trial 0 failed with parameters: {'n_estimators': 256, 'max_depth': 26, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,294] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,295] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:59,339] Trial 0 failed with parameters: {'n_estimators': 290, 'max_depth': 24, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,342] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,343] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_overige_bedrijfsopbrengsten\n[W 2025-01-19 13:16:59,386] Trial 0 failed with parameters: {'n_estimators': 65, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,389] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,390] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_overige_personeelskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'n_estimators': 260, 'max_depth': 50, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'n_estimators': 256, 'max_depth': 26, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'n_estimators': 290, 'max_depth': 24, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'n_estimators': 65, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_overige_bedrijfsopbrengsten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'n_estimators': 285, 'max_depth': 33, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:59,445] Trial 0 failed with parameters: {'n_estimators': 285, 'max_depth': 33, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,449] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,449] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:59,492] Trial 0 failed with parameters: {'n_estimators': 207, 'max_depth': 79, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,495] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,496] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:16:59,535] Trial 0 failed with parameters: {'n_estimators': 70, 'max_depth': 66, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,538] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,539] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_verkoopkosten\n[W 2025-01-19 13:16:59,581] Trial 0 failed with parameters: {'n_estimators': 268, 'max_depth': 28, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,584] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,585] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_afschrijvingen_mva\n[W 2025-01-19 13:16:59,622] Trial 0 failed with parameters: {'n_estimators': 237, 'max_depth': 49, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,625] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,626] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_afschrijvingen_iva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'n_estimators': 207, 'max_depth': 79, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'n_estimators': 70, 'max_depth': 66, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'n_estimators': 268, 'max_depth': 28, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'n_estimators': 237, 'max_depth': 49, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_afschrijvingen_mva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'n_estimators': 214, 'max_depth': 23, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:59,664] Trial 0 failed with parameters: {'n_estimators': 214, 'max_depth': 23, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,668] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,668] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_omzet\n[W 2025-01-19 13:16:59,707] Trial 0 failed with parameters: {'n_estimators': 103, 'max_depth': 43, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,710] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,711] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_algemene_kosten\n[W 2025-01-19 13:16:59,751] Trial 0 failed with parameters: {'n_estimators': 109, 'max_depth': 62, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,753] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,754] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_autokosten\n[W 2025-01-19 13:16:59,792] Trial 0 failed with parameters: {'n_estimators': 168, 'max_depth': 74, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,795] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,795] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:16:59,833] Trial 0 failed with parameters: {'n_estimators': 211, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,836] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,836] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_pensioenlasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_afschrijvingen_iva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'n_estimators': 103, 'max_depth': 43, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'n_estimators': 109, 'max_depth': 62, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'n_estimators': 168, 'max_depth': 74, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'n_estimators': 211, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'n_estimators': 131, 'max_depth': 57, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:16:59,876] Trial 0 failed with parameters: {'n_estimators': 131, 'max_depth': 57, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,879] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,880] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:16:59,920] Trial 0 failed with parameters: {'n_estimators': 158, 'max_depth': 98, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:16:59,923] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,924] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:16:59,964] Trial 0 failed with parameters: {'n_estimators': 58, 'max_depth': 67, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:16:59,967] Trial 0 failed with value None.\n[I 2025-01-19 13:16:59,968] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_sociale_lasten\n[W 2025-01-19 13:17:00,008] Trial 0 failed with parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:17:00,011] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,012] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:17:00,055] Trial 0 failed with parameters: {'n_estimators': 101, 'max_depth': 66, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:17:00,058] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,059] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_kostprijs_van_de_omzet\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_pensioenlasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'n_estimators': 158, 'max_depth': 98, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'n_estimators': 58, 'max_depth': 67, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'n_estimators': 101, 'max_depth': 66, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'n_estimators': 247, 'max_depth': 100, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:17:00,105] Trial 0 failed with parameters: {'n_estimators': 247, 'max_depth': 100, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:17:00,107] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,108] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_kantoorkosten\n[W 2025-01-19 13:17:00,147] Trial 0 failed with parameters: {'n_estimators': 205, 'max_depth': 85, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:17:00,150] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,151] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_verkoopkosten\n[W 2025-01-19 13:17:00,190] Trial 0 failed with parameters: {'n_estimators': 143, 'max_depth': 50, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:17:00,195] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,196] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:17:00,235] Trial 0 failed with parameters: {'n_estimators': 198, 'max_depth': 94, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:17:00,238] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,239] A new study created in memory with name: TrainerRandomForestPattern_day_data\n[W 2025-01-19 13:17:00,285] Trial 0 failed with parameters: {'n_estimators': 122, 'max_depth': 42, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:17:00,288] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,289] A new study created in memory with name: TrainerRandomForestPattern_weather_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_kostprijs_van_de_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'n_estimators': 205, 'max_depth': 85, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'n_estimators': 143, 'max_depth': 50, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'n_estimators': 198, 'max_depth': 94, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'n_estimators': 122, 'max_depth': 42, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerRandomForestPattern on dataset day_data: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'n_estimators': 143, 'max_depth': 16, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:17:00,292] Trial 0 failed with parameters: {'n_estimators': 143, 'max_depth': 16, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 38, in fit\n    pdf_train = self._preprocessing(pdf_train, True)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/abstract_classes/trainer.py\", line 132, in _preprocessing\n    df = df[relevant_columns]\n         ~~^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:17:00,348] Trial 0 failed with value None.\n[I 2025-01-19 13:17:00,348] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_algemene_kosten\n[I 2025-01-19 13:17:00,365] Trial 0 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,381] Trial 1 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,397] Trial 2 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,411] Trial 3 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,428] Trial 4 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,443] Trial 5 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,459] Trial 6 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,474] Trial 7 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,489] Trial 8 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,503] Trial 9 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,525] Trial 10 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,551] Trial 11 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerValueLastYears\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.02 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.02 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.02 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:00,574] Trial 12 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,604] Trial 13 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,627] Trial 14 finished with value: 296.1719357636381 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 296.1719357636381.\n[I 2025-01-19 13:17:00,642] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_autokosten\n[I 2025-01-19 13:17:00,653] Trial 0 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,664] Trial 1 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,674] Trial 2 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,685] Trial 3 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,694] Trial 4 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,705] Trial 5 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,715] Trial 6 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,725] Trial 7 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,735] Trial 8 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,745] Trial 9 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,763] Trial 10 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 90.92671041375392.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.03 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 296.1719, MAE: 121.3883, R²: -0.1343 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_algemene_kosten: 0.28 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_algemene_kosten: {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerValueLastYears on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:00,781] Trial 11 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,798] Trial 12 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,815] Trial 13 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,832] Trial 14 finished with value: 90.92671041375392 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 90.92671041375392.\n[I 2025-01-19 13:17:00,844] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_exploitatie-_en_machinekosten\n[I 2025-01-19 13:17:00,855] Trial 0 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,867] Trial 1 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,878] Trial 2 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,890] Trial 3 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,901] Trial 4 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,913] Trial 5 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,924] Trial 6 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,935] Trial 7 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,946] Trial 8 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,957] Trial 9 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 402.0645381740882.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 90.9267, MAE: 63.0000, R²: -0.2450 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_autokosten: 0.19 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_autokosten: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Added results for TrainerValueLastYears on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:00,977] Trial 10 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:00,995] Trial 11 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:01,013] Trial 12 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:01,031] Trial 13 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:01,049] Trial 14 finished with value: 402.0645381740882 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 402.0645381740882.\n[I 2025-01-19 13:17:01,060] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_huisvestingskosten\n[I 2025-01-19 13:17:01,072] Trial 0 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,086] Trial 1 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,099] Trial 2 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,111] Trial 3 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,124] Trial 4 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,137] Trial 5 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,149] Trial 6 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,162] Trial 7 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,174] Trial 8 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,188] Trial 9 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 402.0645, MAE: 319.8929, R²: -1.7249 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_exploitatie-_en_machinekosten: 0.21 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_exploitatie-_en_machinekosten: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Added results for TrainerValueLastYears on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.01 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:01,218] Trial 10 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,237] Trial 11 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,254] Trial 12 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,273] Trial 13 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,292] Trial 14 finished with value: 147.55151208289504 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 147.55151208289504.\n[I 2025-01-19 13:17:01,304] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_kantoorkosten\n[I 2025-01-19 13:17:01,318] Trial 0 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,333] Trial 1 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,349] Trial 2 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,362] Trial 3 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,376] Trial 4 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,391] Trial 5 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,403] Trial 6 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 367.5471600946156.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.03 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 147.5515, MAE: 60.3718, R²: -0.2011 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_huisvestingskosten: 0.23 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_huisvestingskosten: {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerValueLastYears on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:01,425] Trial 7 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,436] Trial 8 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,448] Trial 9 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,469] Trial 10 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,488] Trial 11 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,507] Trial 12 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,526] Trial 13 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,546] Trial 14 finished with value: 367.5471600946156 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 367.5471600946156.\n[I 2025-01-19 13:17:01,557] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_lonen_en_salarissen\n[I 2025-01-19 13:17:01,567] Trial 0 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,576] Trial 1 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,586] Trial 2 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,596] Trial 3 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,605] Trial 4 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,614] Trial 5 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,623] Trial 6 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 527.6743648256163.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.02 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.02 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 367.5472, MAE: 305.2979, R²: -1.7282 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_kantoorkosten: 0.24 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_kantoorkosten: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerValueLastYears on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:01,632] Trial 7 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,641] Trial 8 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,650] Trial 9 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,665] Trial 10 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,681] Trial 11 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,696] Trial 12 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,711] Trial 13 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,726] Trial 14 finished with value: 527.6743648256163 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 527.6743648256163.\n[I 2025-01-19 13:17:01,735] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_overige_bedrijfsopbrengsten\n[I 2025-01-19 13:17:01,745] Trial 0 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,755] Trial 1 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,765] Trial 2 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,774] Trial 3 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,784] Trial 4 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,793] Trial 5 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,803] Trial 6 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,813] Trial 7 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,822] Trial 8 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 527.6744, MAE: 396.0000, R²: -0.0280 in 0.01 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_lonen_en_salarissen: 0.17 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_lonen_en_salarissen: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerValueLastYears on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:01,833] Trial 9 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,851] Trial 10 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,866] Trial 11 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,882] Trial 12 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,898] Trial 13 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,914] Trial 14 finished with value: 55.919276794692 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 55.919276794692.\n[I 2025-01-19 13:17:01,923] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_overige_personeelskosten\n[I 2025-01-19 13:17:01,938] Trial 0 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:01,954] Trial 1 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:01,968] Trial 2 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:01,983] Trial 3 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,004] Trial 4 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,018] Trial 5 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,034] Trial 6 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.02 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 55.9193, MAE: 11.9310, R²: -0.0256 in 0.01 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_overige_bedrijfsopbrengsten: 0.18 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_overige_bedrijfsopbrengsten: {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerValueLastYears on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.02 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:02,048] Trial 7 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,063] Trial 8 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,076] Trial 9 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,099] Trial 10 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,120] Trial 11 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,140] Trial 12 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,159] Trial 13 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,179] Trial 14 finished with value: 202.96901006710124 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 202.96901006710124.\n[I 2025-01-19 13:17:02,192] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_overige_rentelasten\n[I 2025-01-19 13:17:02,205] Trial 0 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,220] Trial 1 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,232] Trial 2 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,245] Trial 3 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.02 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 202.9690, MAE: 67.0286, R²: -0.1198 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_overige_personeelskosten: 0.26 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_overige_personeelskosten: {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Added results for TrainerValueLastYears on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 0 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:02,258] Trial 4 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,271] Trial 5 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,284] Trial 6 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,297] Trial 7 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,310] Trial 8 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,323] Trial 9 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,342] Trial 10 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,361] Trial 11 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,380] Trial 12 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,398] Trial 13 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,417] Trial 14 finished with value: 215.61916014636134 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 215.61916014636134.\n[I 2025-01-19 13:17:02,430] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:17:02,440] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:17:02,441] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,441] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_verkoopkosten\n[I 2025-01-19 13:17:02,455] Trial 0 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.02 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 215.6192, MAE: 89.9111, R²: -0.2105 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_overige_rentelasten: 0.23 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_overige_rentelasten: {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerValueLastYears on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 0 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:02,476] Trial 1 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,489] Trial 2 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,502] Trial 3 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,515] Trial 4 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,527] Trial 5 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,539] Trial 6 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,551] Trial 7 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,564] Trial 8 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,577] Trial 9 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,600] Trial 10 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,621] Trial 11 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,642] Trial 12 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,662] Trial 13 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 344.771453050727.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.02 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.01 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.02 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.02 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.02 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.02 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:02,686] Trial 14 finished with value: 344.771453050727 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 344.771453050727.\n[I 2025-01-19 13:17:02,699] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_afschrijvingen_mva\n[W 2025-01-19 13:17:02,715] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,765] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,766] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_afschrijvingen_iva\n[W 2025-01-19 13:17:02,781] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,784] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,785] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_omzet\n[W 2025-01-19 13:17:02,802] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: TypeError(\"don't know how to coerce float64 and int64\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 149, in predict\n    predictions.append(mean(values_all_years) * trend)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 484, in mean\n    T, total, n = _sum(data)\n                  ^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 204, in _sum\n    T = reduce(_coerce, types, int)  # or raise TypeError\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 284, in _coerce\n    raise TypeError(msg % (T.__name__, S.__name__))\nTypeError: don't know how to coerce float64 and int64\n[W 2025-01-19 13:17:02,805] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,806] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_algemene_kosten\n[W 2025-01-19 13:17:02,822] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: TypeError(\"don't know how to coerce float64 and int64\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 149, in predict\n    predictions.append(mean(values_all_years) * trend)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 484, in mean\n    T, total, n = _sum(data)\n                  ^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 204, in _sum\n    T = reduce(_coerce, types, int)  # or raise TypeError\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 284, in _coerce\n    raise TypeError(msg % (T.__name__, S.__name__))\nTypeError: don't know how to coerce float64 and int64\n[W 2025-01-19 13:17:02,825] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,826] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_autokosten\n[W 2025-01-19 13:17:02,845] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,848] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,849] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:17:02,866] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,870] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,870] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_pensioenlasten\n[W 2025-01-19 13:17:02,883] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,886] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,887] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_lonen_en_salarissen\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 344.7715, MAE: 259.1183, R²: -1.2981 in 0.02 seconds\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_verkoopkosten: 0.25 seconds\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_verkoopkosten: {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Added results for TrainerValueLastYears on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_afschrijvingen_mva: list index out of range\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_afschrijvingen_iva: list index out of range\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_omzet: don't know how to coerce float64 and int64\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_algemene_kosten: don't know how to coerce float64 and int64\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_autokosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_overige_rentelasten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_pensioenlasten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:17:02,903] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,906] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,907] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:17:02,926] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,929] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,929] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_sociale_lasten\n[W 2025-01-19 13:17:02,943] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,946] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,948] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:17:02,963] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: TypeError(\"don't know how to coerce float64 and int64\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 149, in predict\n    predictions.append(mean(values_all_years) * trend)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 484, in mean\n    T, total, n = _sum(data)\n                  ^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 204, in _sum\n    T = reduce(_coerce, types, int)  # or raise TypeError\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 284, in _coerce\n    raise TypeError(msg % (T.__name__, S.__name__))\nTypeError: don't know how to coerce float64 and int64\n[W 2025-01-19 13:17:02,966] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,967] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_kostprijs_van_de_omzet\n[W 2025-01-19 13:17:02,983] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:02,985] Trial 0 failed with value None.\n[I 2025-01-19 13:17:02,986] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_kantoorkosten\n[W 2025-01-19 13:17:03,002] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:03,004] Trial 0 failed with value None.\n[I 2025-01-19 13:17:03,005] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_verkoopkosten\n[W 2025-01-19 13:17:03,020] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:03,022] Trial 0 failed with value None.\n[I 2025-01-19 13:17:03,023] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:17:03,040] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 39, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:17:03,043] Trial 0 failed with value None.\n[I 2025-01-19 13:17:03,044] A new study created in memory with name: TrainerValueLastYears_day_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_lonen_en_salarissen: list index out of range\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_overige_personeelskosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_sociale_lasten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_exploitatie-_en_machinekosten: don't know how to coerce float64 and int64\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_kostprijs_van_de_omzet: list index out of range\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_kantoorkosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_verkoopkosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_huisvestingskosten: list index out of range\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:03,889] Trial 0 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.84 seconds\n  Trial 1: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:04,704] Trial 1 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.81 seconds\n  Trial 2: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:05,513] Trial 2 finished with value: 874.1008753655184 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 874.1009, MAE: 691.3783, R²: -0.6428 in 0.81 seconds\n  Trial 3: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:06,320] Trial 3 finished with value: 874.1008753655184 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 874.1009, MAE: 691.3783, R²: -0.6428 in 0.81 seconds\n  Trial 4: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:07,177] Trial 4 finished with value: 874.1008753655184 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 874.1009, MAE: 691.3783, R²: -0.6428 in 0.86 seconds\n  Trial 5: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:07,997] Trial 5 finished with value: 874.1008753655184 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 874.1009, MAE: 691.3783, R²: -0.6428 in 0.82 seconds\n  Trial 6: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:08,802] Trial 6 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.80 seconds\n  Trial 7: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:09,605] Trial 7 finished with value: 874.1008753655184 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 874.1009, MAE: 691.3783, R²: -0.6428 in 0.80 seconds\n  Trial 8: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:10,415] Trial 8 finished with value: 874.1008753655184 and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 874.1009, MAE: 691.3783, R²: -0.6428 in 0.81 seconds\n  Trial 9: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:11,304] Trial 9 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.89 seconds\n  Trial 10: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:12,133] Trial 10 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.83 seconds\n  Trial 11: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:12,952] Trial 11 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.82 seconds\n  Trial 12: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:13,760] Trial 12 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.81 seconds\n  Trial 13: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:14,625] Trial 13 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.86 seconds\n  Trial 14: Hyperparameters {'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:15,471] Trial 14 finished with value: 872.6672416170404 and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 872.6672416170404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 872.6672, MAE: 690.1918, R²: -0.6375 in 0.84 seconds\nTotal optimization time for TrainerValueLastYears_day_data: 12.43 seconds\nBest hyperparameters for TrainerValueLastYears_day_data: {'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:16,287] A new study created in memory with name: TrainerValueLastYears_weather_data\n[W 2025-01-19 13:17:16,290] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 51, in fit\n    df = pdf_train[['category', 'value', 'date', 'year']]\n         ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:17:16,293] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,293] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_algemene_kosten\n[W 2025-01-19 13:17:16,301] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 378, 'max_depth': 16, 'learning_rate': 0.0230831016228502, 'subsample': 0.7835506932861092, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,350] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,355] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_autokosten\n[W 2025-01-19 13:17:16,363] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 14, 'learning_rate': 0.07508182444820297, 'subsample': 0.8225829162861316, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,367] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,368] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:17:16,376] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 399, 'max_depth': 20, 'learning_rate': 0.00840900825540316, 'subsample': 0.8750638770817032, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,380] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,380] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:17:16,389] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 103, 'max_depth': 7, 'learning_rate': 0.047172168105569616, 'subsample': 0.7846868167358365, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,393] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,393] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_kantoorkosten\n[W 2025-01-19 13:17:16,401] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 371, 'max_depth': 21, 'learning_rate': 0.1125014137533477, 'subsample': 0.9469974124824287, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,404] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,404] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:17:16,412] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 456, 'max_depth': 7, 'learning_rate': 0.04188389185661078, 'subsample': 0.7178102847784065, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,416] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,417] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_overige_bedrijfsopbrengsten\n[W 2025-01-19 13:17:16,425] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 209, 'max_depth': 7, 'learning_rate': 0.18119627390900453, 'subsample': 0.6537772830743576, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,428] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,428] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:17:16,436] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.16310251222382527, 'subsample': 0.6971847591208213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,439] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,440] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:17:16,448] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 15, 'learning_rate': 0.0017516424908115805, 'subsample': 0.8500767216876925, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,451] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,452] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_sociale_lasten\n[W 2025-01-19 13:17:16,459] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 442, 'max_depth': 21, 'learning_rate': 0.019467537340501995, 'subsample': 0.8767882496199894, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,463] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,463] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_verkoopkosten\n[W 2025-01-19 13:17:16,470] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 104, 'max_depth': 20, 'learning_rate': 0.1324455895353244, 'subsample': 0.9151156569390699, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,474] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,475] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_afschrijvingen_mva\n[W 2025-01-19 13:17:16,483] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 264, 'max_depth': 26, 'learning_rate': 0.14380153379469077, 'subsample': 0.7871267981335148, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,487] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,488] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_afschrijvingen_iva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerValueLastYears on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerValueLastYears on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerXGBoost\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 378, 'max_depth': 16, 'learning_rate': 0.0230831016228502, 'subsample': 0.7835506932861092, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_algemene_kosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 14, 'learning_rate': 0.07508182444820297, 'subsample': 0.8225829162861316, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_autokosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 399, 'max_depth': 20, 'learning_rate': 0.00840900825540316, 'subsample': 0.8750638770817032, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_exploitatie-_en_machinekosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 103, 'max_depth': 7, 'learning_rate': 0.047172168105569616, 'subsample': 0.7846868167358365, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_huisvestingskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 371, 'max_depth': 21, 'learning_rate': 0.1125014137533477, 'subsample': 0.9469974124824287, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_kantoorkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 456, 'max_depth': 7, 'learning_rate': 0.04188389185661078, 'subsample': 0.7178102847784065, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_lonen_en_salarissen: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 209, 'max_depth': 7, 'learning_rate': 0.18119627390900453, 'subsample': 0.6537772830743576, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_overige_bedrijfsopbrengsten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.16310251222382527, 'subsample': 0.6971847591208213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_overige_personeelskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 15, 'learning_rate': 0.0017516424908115805, 'subsample': 0.8500767216876925, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_overige_rentelasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 442, 'max_depth': 21, 'learning_rate': 0.019467537340501995, 'subsample': 0.8767882496199894, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_sociale_lasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 104, 'max_depth': 20, 'learning_rate': 0.1324455895353244, 'subsample': 0.9151156569390699, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_verkoopkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 264, 'max_depth': 26, 'learning_rate': 0.14380153379469077, 'subsample': 0.7871267981335148, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_afschrijvingen_mva: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 360, 'max_depth': 23, 'learning_rate': 0.028313062300129956, 'subsample': 0.5794388383574256, 'prediction_mode': 'Zero', 'outlier_removal': 0}"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:17:16,495] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 360, 'max_depth': 23, 'learning_rate': 0.028313062300129956, 'subsample': 0.5794388383574256, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,498] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,499] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_omzet\n[W 2025-01-19 13:17:16,508] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 155, 'max_depth': 16, 'learning_rate': 0.09739749263868243, 'subsample': 0.7130039810916653, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,512] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,512] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_algemene_kosten\n[W 2025-01-19 13:17:16,522] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 28, 'learning_rate': 0.12263993735516804, 'subsample': 0.6658919290916354, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,525] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,526] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_autokosten\n[W 2025-01-19 13:17:16,534] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.1624679525157211, 'subsample': 0.8368836527108265, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,537] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,538] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_overige_rentelasten\n[W 2025-01-19 13:17:16,545] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.18661186890887385, 'subsample': 0.682477327907011, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,549] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,549] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_pensioenlasten\n[W 2025-01-19 13:17:16,557] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 182, 'max_depth': 16, 'learning_rate': 0.04949057996473413, 'subsample': 0.6754638686852819, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,561] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,561] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_lonen_en_salarissen\n[W 2025-01-19 13:17:16,570] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 276, 'max_depth': 22, 'learning_rate': 0.14599679907385488, 'subsample': 0.7812987212545511, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,574] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,574] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_overige_personeelskosten\n[W 2025-01-19 13:17:16,582] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 219, 'max_depth': 22, 'learning_rate': 0.1369366073315967, 'subsample': 0.8391697702371417, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,586] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,586] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_sociale_lasten\n[W 2025-01-19 13:17:16,594] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 369, 'max_depth': 12, 'learning_rate': 0.17471701322983316, 'subsample': 0.523656416713586, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,598] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,599] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_exploitatie-_en_machinekosten\n[W 2025-01-19 13:17:16,606] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 243, 'max_depth': 21, 'learning_rate': 0.13074677208156169, 'subsample': 0.7350563636260643, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,610] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,610] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_kostprijs_van_de_omzet\n[W 2025-01-19 13:17:16,618] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 491, 'max_depth': 5, 'learning_rate': 0.013736168354036387, 'subsample': 0.73603282223066, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,621] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,622] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_kantoorkosten\n[W 2025-01-19 13:17:16,630] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 416, 'max_depth': 5, 'learning_rate': 0.059266168855294135, 'subsample': 0.5407949194523359, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,634] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,635] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_verkoopkosten\n[W 2025-01-19 13:17:16,644] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 52, 'max_depth': 17, 'learning_rate': 0.049522024158200145, 'subsample': 0.7377897904641076, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,650] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,651] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_huisvestingskosten\n[W 2025-01-19 13:17:16,659] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 234, 'max_depth': 11, 'learning_rate': 0.14354424714459946, 'subsample': 0.6448091668423024, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,663] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,663] A new study created in memory with name: TrainerXGBoost_day_data\n[W 2025-01-19 13:17:16,672] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 176, 'max_depth': 19, 'learning_rate': 0.09374164626728258, 'subsample': 0.5836356825975808, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:17:16,676] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,677] A new study created in memory with name: TrainerXGBoost_weather_data\n[W 2025-01-19 13:17:16,679] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 87, 'max_depth': 22, 'learning_rate': 0.10535559752458058, 'subsample': 0.8707685227162514, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 52, in fit\n    trainset = df_train[[\n               ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:17:16,682] Trial 0 failed with value None.\n[I 2025-01-19 13:17:16,682] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_afschrijvingen_iva: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 155, 'max_depth': 16, 'learning_rate': 0.09739749263868243, 'subsample': 0.7130039810916653, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_omzet: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 28, 'learning_rate': 0.12263993735516804, 'subsample': 0.6658919290916354, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_algemene_kosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.1624679525157211, 'subsample': 0.8368836527108265, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_autokosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.18661186890887385, 'subsample': 0.682477327907011, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_overige_rentelasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 182, 'max_depth': 16, 'learning_rate': 0.04949057996473413, 'subsample': 0.6754638686852819, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_pensioenlasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 276, 'max_depth': 22, 'learning_rate': 0.14599679907385488, 'subsample': 0.7812987212545511, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_lonen_en_salarissen: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 219, 'max_depth': 22, 'learning_rate': 0.1369366073315967, 'subsample': 0.8391697702371417, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_overige_personeelskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 369, 'max_depth': 12, 'learning_rate': 0.17471701322983316, 'subsample': 0.523656416713586, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_sociale_lasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 243, 'max_depth': 21, 'learning_rate': 0.13074677208156169, 'subsample': 0.7350563636260643, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_exploitatie-_en_machinekosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 491, 'max_depth': 5, 'learning_rate': 0.013736168354036387, 'subsample': 0.73603282223066, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_kostprijs_van_de_omzet: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 416, 'max_depth': 5, 'learning_rate': 0.059266168855294135, 'subsample': 0.5407949194523359, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_kantoorkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 52, 'max_depth': 17, 'learning_rate': 0.049522024158200145, 'subsample': 0.7377897904641076, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_verkoopkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 234, 'max_depth': 11, 'learning_rate': 0.14354424714459946, 'subsample': 0.6448091668423024, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_huisvestingskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 176, 'max_depth': 19, 'learning_rate': 0.09374164626728258, 'subsample': 0.5836356825975808, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Error with trainer TrainerXGBoost on dataset day_data: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 87, 'max_depth': 22, 'learning_rate': 0.10535559752458058, 'subsample': 0.8707685227162514, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Error with trainer TrainerXGBoost on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerXGBoostPattern\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 294, 'max_depth': 21, 'learning_rate': 0.1790680723546797, 'subsample': 0.8197698318336288, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:19,410] Trial 0 finished with value: 294.4261273742236 and parameters: {'objective': 'reg:linear', 'n_estimators': 294, 'max_depth': 21, 'learning_rate': 0.1790680723546797, 'subsample': 0.8197698318336288, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 294.4261273742236.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 294.4261, MAE: 123.3653, R²: -0.1210 in 2.73 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 173, 'max_depth': 17, 'learning_rate': 0.013663587232927255, 'subsample': 0.6955531861664823, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:21,848] Trial 1 finished with value: 286.92134422662866 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 173, 'max_depth': 17, 'learning_rate': 0.013663587232927255, 'subsample': 0.6955531861664823, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 286.9213, MAE: 128.4779, R²: -0.0646 in 2.44 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 204, 'max_depth': 30, 'learning_rate': 0.1992103719483571, 'subsample': 0.6957414967246311, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:24,725] Trial 2 finished with value: 298.2122452490924 and parameters: {'objective': 'reg:linear', 'n_estimators': 204, 'max_depth': 30, 'learning_rate': 0.1992103719483571, 'subsample': 0.6957414967246311, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 298.2122, MAE: 129.4817, R²: -0.1500 in 2.88 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 83, 'max_depth': 7, 'learning_rate': 0.1861769573586588, 'subsample': 0.9774596983574672, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:26,953] Trial 3 finished with value: 290.84798078247456 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 83, 'max_depth': 7, 'learning_rate': 0.1861769573586588, 'subsample': 0.9774596983574672, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 290.8480, MAE: 130.4450, R²: -0.0939 in 2.23 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 28, 'learning_rate': 0.14369118956286972, 'subsample': 0.6386862532836421, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:29,879] Trial 4 finished with value: 294.8518814854909 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 28, 'learning_rate': 0.14369118956286972, 'subsample': 0.6386862532836421, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 294.8519, MAE: 127.8614, R²: -0.1242 in 2.92 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 6, 'learning_rate': 0.047163200007409006, 'subsample': 0.8410004437127765, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:32,099] Trial 5 finished with value: 287.42374701569753 and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 6, 'learning_rate': 0.047163200007409006, 'subsample': 0.8410004437127765, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 287.4237, MAE: 133.0702, R²: -0.0683 in 2.22 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 171, 'max_depth': 18, 'learning_rate': 0.15205909901958245, 'subsample': 0.9417171043777213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:34,873] Trial 6 finished with value: 293.8088605585585 and parameters: {'objective': 'reg:linear', 'n_estimators': 171, 'max_depth': 18, 'learning_rate': 0.15205909901958245, 'subsample': 0.9417171043777213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 293.8089, MAE: 122.1178, R²: -0.1163 in 2.77 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 179, 'max_depth': 28, 'learning_rate': 0.12674757481397747, 'subsample': 0.6879311109856168, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:37,600] Trial 7 finished with value: 297.04427984451996 and parameters: {'objective': 'reg:linear', 'n_estimators': 179, 'max_depth': 28, 'learning_rate': 0.12674757481397747, 'subsample': 0.6879311109856168, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 297.0443, MAE: 129.5672, R²: -0.1410 in 2.73 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 294, 'max_depth': 15, 'learning_rate': 0.01690821409501302, 'subsample': 0.795886333119912, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:40,360] Trial 8 finished with value: 291.7839786820619 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 294, 'max_depth': 15, 'learning_rate': 0.01690821409501302, 'subsample': 0.795886333119912, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 291.7840, MAE: 120.5186, R²: -0.1009 in 2.76 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 176, 'max_depth': 18, 'learning_rate': 0.023526036649083086, 'subsample': 0.5434229485303826, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:42,827] Trial 9 finished with value: 289.44299436066166 and parameters: {'objective': 'reg:linear', 'n_estimators': 176, 'max_depth': 18, 'learning_rate': 0.023526036649083086, 'subsample': 0.5434229485303826, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 289.4430, MAE: 131.3386, R²: -0.0834 in 2.47 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.07882233823196423, 'subsample': 0.5105771872101237, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:45,300] Trial 10 finished with value: 292.6314058376583 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 115, 'max_depth': 10, 'learning_rate': 0.07882233823196423, 'subsample': 0.5105771872101237, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 292.6314, MAE: 131.0135, R²: -0.1073 in 2.47 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 74, 'max_depth': 12, 'learning_rate': 0.06286448696253388, 'subsample': 0.8679830683387735, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:47,741] Trial 11 finished with value: 292.05604527645767 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 74, 'max_depth': 12, 'learning_rate': 0.06286448696253388, 'subsample': 0.8679830683387735, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 292.0560, MAE: 119.0130, R²: -0.1030 in 2.44 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.047740532152081246, 'subsample': 0.8762571043019809, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:50,104] Trial 12 finished with value: 289.3790595479472 and parameters: {'objective': 'reg:linear', 'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.047740532152081246, 'subsample': 0.8762571043019809, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 289.3791, MAE: 129.6464, R²: -0.0829 in 2.36 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 50, 'max_depth': 22, 'learning_rate': 0.0931676125262241, 'subsample': 0.742582167201695, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:52,529] Trial 13 finished with value: 292.5879279706782 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 50, 'max_depth': 22, 'learning_rate': 0.0931676125262241, 'subsample': 0.742582167201695, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 286.92134422662866.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 292.5879, MAE: 121.6445, R²: -0.1070 in 2.42 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 229, 'max_depth': 5, 'learning_rate': 0.04524778688942673, 'subsample': 0.6085351717454752, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:54,913] Trial 14 finished with value: 286.13629214336544 and parameters: {'objective': 'reg:linear', 'n_estimators': 229, 'max_depth': 5, 'learning_rate': 0.04524778688942673, 'subsample': 0.6085351717454752, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 14 with value: 286.13629214336544.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 286.1363, MAE: 137.6897, R²: -0.0587 in 2.38 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_algemene_kosten: 38.23 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_algemene_kosten: {'objective': 'reg:linear', 'n_estimators': 229, 'max_depth': 5, 'learning_rate': 0.04524778688942673, 'subsample': 0.6085351717454752, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:57,502] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_autokosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 226, 'max_depth': 30, 'learning_rate': 0.062001519996177805, 'subsample': 0.8133857054793026, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:57,766] Trial 0 finished with value: 855.9348170665022 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 226, 'max_depth': 30, 'learning_rate': 0.062001519996177805, 'subsample': 0.8133857054793026, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 855.9348170665022.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 855.9348, MAE: 852.0467, R²: -109.3202 in 0.26 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 252, 'max_depth': 24, 'learning_rate': 0.03124879650229013, 'subsample': 0.519817502634375, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:58,098] Trial 1 finished with value: 834.9144395884726 and parameters: {'objective': 'reg:linear', 'n_estimators': 252, 'max_depth': 24, 'learning_rate': 0.03124879650229013, 'subsample': 0.519817502634375, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 834.9144395884726.\n[I 2025-01-19 13:17:58,283] Trial 2 finished with value: 855.5864076176058 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 100, 'max_depth': 24, 'learning_rate': 0.12923026670608348, 'subsample': 0.8824118617628793, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 834.9144395884726.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 834.9144, MAE: 830.9233, R²: -103.9682 in 0.33 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 100, 'max_depth': 24, 'learning_rate': 0.12923026670608348, 'subsample': 0.8824118617628793, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 855.5864, MAE: 851.6967, R²: -109.2304 in 0.18 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 112, 'max_depth': 25, 'learning_rate': 0.14249915101624916, 'subsample': 0.640176277798628, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:58,543] Trial 3 finished with value: 844.6171598817222 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 112, 'max_depth': 25, 'learning_rate': 0.14249915101624916, 'subsample': 0.640176277798628, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 834.9144395884726.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 844.6172, MAE: 840.6767, R²: -106.4221 in 0.26 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 270, 'max_depth': 25, 'learning_rate': 0.1604118886678791, 'subsample': 0.5523761663358222, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:58,836] Trial 4 finished with value: 832.4554228105351 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 270, 'max_depth': 25, 'learning_rate': 0.1604118886678791, 'subsample': 0.5523761663358222, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 832.4554228105351.\n[I 2025-01-19 13:17:59,034] Trial 5 finished with value: 856.1438633586453 and parameters: {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 9, 'learning_rate': 0.1716054396477079, 'subsample': 0.8962355839735792, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 832.4554228105351.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 832.4554, MAE: 828.4233, R²: -103.3508 in 0.29 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 9, 'learning_rate': 0.1716054396477079, 'subsample': 0.8962355839735792, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 856.1439, MAE: 852.2567, R²: -109.3741 in 0.20 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 283, 'max_depth': 6, 'learning_rate': 0.13116210678980503, 'subsample': 0.6402088797372611, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:59,355] Trial 6 finished with value: 841.8159485699156 and parameters: {'objective': 'reg:linear', 'n_estimators': 283, 'max_depth': 6, 'learning_rate': 0.13116210678980503, 'subsample': 0.6402088797372611, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 832.4554228105351.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 841.8159, MAE: 837.8600, R²: -105.7107 in 0.32 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 203, 'max_depth': 5, 'learning_rate': 0.13702861698095967, 'subsample': 0.7297257046363003, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:59,640] Trial 7 finished with value: 852.796309052363 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 203, 'max_depth': 5, 'learning_rate': 0.13702861698095967, 'subsample': 0.7297257046363003, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 832.4554228105351.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 852.7963, MAE: 848.8933, R²: -108.5127 in 0.28 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 12, 'learning_rate': 0.11665829838063471, 'subsample': 0.8774864010577762, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:17:59,855] Trial 8 finished with value: 856.2732732019609 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 12, 'learning_rate': 0.11665829838063471, 'subsample': 0.8774864010577762, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 832.4554228105351.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 856.2733, MAE: 852.3867, R²: -109.4075 in 0.21 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 298, 'max_depth': 14, 'learning_rate': 0.14463852343739048, 'subsample': 0.8678720172073775, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:00,140] Trial 9 finished with value: 856.5520027023073 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 298, 'max_depth': 14, 'learning_rate': 0.14463852343739048, 'subsample': 0.8678720172073775, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 832.4554228105351.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 856.5520, MAE: 852.6667, R²: -109.4794 in 0.28 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 159, 'max_depth': 19, 'learning_rate': 0.19530979844503485, 'subsample': 0.9983934209655786, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:00,426] Trial 10 finished with value: 856.5520027023073 and parameters: {'objective': 'reg:linear', 'n_estimators': 159, 'max_depth': 19, 'learning_rate': 0.19530979844503485, 'subsample': 0.9983934209655786, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 832.4554228105351.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 856.5520, MAE: 852.6667, R²: -109.4794 in 0.28 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 249, 'max_depth': 22, 'learning_rate': 0.010266253565970468, 'subsample': 0.518844523350593, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:00,720] Trial 11 finished with value: 644.4993992239248 and parameters: {'objective': 'reg:linear', 'n_estimators': 249, 'max_depth': 22, 'learning_rate': 0.010266253565970468, 'subsample': 0.518844523350593, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 11 with value: 644.4993992239248.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 644.4994, MAE: 639.3267, R²: -61.5488 in 0.29 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 251, 'max_depth': 19, 'learning_rate': 0.07135096779917986, 'subsample': 0.50492103268085, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:01,023] Trial 12 finished with value: 831.3822541807509 and parameters: {'objective': 'reg:linear', 'n_estimators': 251, 'max_depth': 19, 'learning_rate': 0.07135096779917986, 'subsample': 0.50492103268085, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 644.4993992239248.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 831.3823, MAE: 827.2900, R²: -103.0819 in 0.30 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 199, 'max_depth': 19, 'learning_rate': 0.07762993240249409, 'subsample': 0.597296989517518, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:01,275] Trial 13 finished with value: 841.2069176090585 and parameters: {'objective': 'reg:linear', 'n_estimators': 199, 'max_depth': 19, 'learning_rate': 0.07762993240249409, 'subsample': 0.597296989517518, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 11 with value: 644.4993992239248.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 841.2069, MAE: 837.2367, R²: -105.5564 in 0.25 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 244, 'max_depth': 17, 'learning_rate': 0.012974199493178937, 'subsample': 0.5104752433372504, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:01,635] Trial 14 finished with value: 700.4135112679271 and parameters: {'objective': 'reg:linear', 'n_estimators': 244, 'max_depth': 17, 'learning_rate': 0.012974199493178937, 'subsample': 0.5104752433372504, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 644.4993992239248.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 700.4135, MAE: 695.6567, R²: -72.8725 in 0.36 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_autokosten: 4.13 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_autokosten: {'objective': 'reg:linear', 'n_estimators': 249, 'max_depth': 22, 'learning_rate': 0.010266253565970468, 'subsample': 0.518844523350593, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:01,922] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_exploitatie-_en_machinekosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 174, 'max_depth': 6, 'learning_rate': 0.10704056400607789, 'subsample': 0.534471178715192, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:02,795] Trial 0 finished with value: 246.59590589377476 and parameters: {'objective': 'reg:linear', 'n_estimators': 174, 'max_depth': 6, 'learning_rate': 0.10704056400607789, 'subsample': 0.534471178715192, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 246.59590589377476.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 246.5959, MAE: 208.2439, R²: -0.0250 in 0.87 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 195, 'max_depth': 16, 'learning_rate': 0.1930276153582227, 'subsample': 0.5941105513506664, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:03,772] Trial 1 finished with value: 243.30870695182986 and parameters: {'objective': 'reg:linear', 'n_estimators': 195, 'max_depth': 16, 'learning_rate': 0.1930276153582227, 'subsample': 0.5941105513506664, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 243.30870695182986.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 243.3087, MAE: 219.4986, R²: 0.0021 in 0.98 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 10, 'learning_rate': 0.1072530411095853, 'subsample': 0.6964447582912756, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:04,799] Trial 2 finished with value: 241.96861377046406 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 10, 'learning_rate': 0.1072530411095853, 'subsample': 0.6964447582912756, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 241.96861377046406.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 241.9686, MAE: 218.2164, R²: 0.0131 in 1.03 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 297, 'max_depth': 19, 'learning_rate': 0.06288115857063997, 'subsample': 0.503158291570259, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:05,800] Trial 3 finished with value: 243.13836221084372 and parameters: {'objective': 'reg:linear', 'n_estimators': 297, 'max_depth': 19, 'learning_rate': 0.06288115857063997, 'subsample': 0.503158291570259, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 241.96861377046406.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 243.1384, MAE: 206.0443, R²: 0.0035 in 1.00 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.1339151959934779, 'subsample': 0.9363297924922961, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:06,667] Trial 4 finished with value: 360.5437483014866 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 117, 'max_depth': 10, 'learning_rate': 0.1339151959934779, 'subsample': 0.9363297924922961, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 241.96861377046406.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 360.5437, MAE: 285.3482, R²: -1.1912 in 0.87 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 300, 'max_depth': 11, 'learning_rate': 0.150205962822073, 'subsample': 0.9951784859683819, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:07,622] Trial 5 finished with value: 384.4145408837407 and parameters: {'objective': 'reg:linear', 'n_estimators': 300, 'max_depth': 11, 'learning_rate': 0.150205962822073, 'subsample': 0.9951784859683819, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 241.96861377046406.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 384.4145, MAE: 307.2671, R²: -1.4910 in 0.95 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 277, 'max_depth': 26, 'learning_rate': 0.10046432324269924, 'subsample': 0.6240599675679229, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:08,719] Trial 6 finished with value: 242.49290446909401 and parameters: {'objective': 'reg:linear', 'n_estimators': 277, 'max_depth': 26, 'learning_rate': 0.10046432324269924, 'subsample': 0.6240599675679229, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 241.96861377046406.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 242.4929, MAE: 219.5461, R²: 0.0088 in 1.10 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 248, 'max_depth': 28, 'learning_rate': 0.16780571367533267, 'subsample': 0.5917861614682192, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:09,778] Trial 7 finished with value: 240.36937200156885 and parameters: {'objective': 'reg:linear', 'n_estimators': 248, 'max_depth': 28, 'learning_rate': 0.16780571367533267, 'subsample': 0.5917861614682192, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 240.3694, MAE: 216.7804, R²: 0.0261 in 1.06 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 94, 'max_depth': 20, 'learning_rate': 0.0634226843713435, 'subsample': 0.5803109777172919, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:10,571] Trial 8 finished with value: 260.25465683359334 and parameters: {'objective': 'reg:linear', 'n_estimators': 94, 'max_depth': 20, 'learning_rate': 0.0634226843713435, 'subsample': 0.5803109777172919, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 260.2547, MAE: 232.9646, R²: -0.1417 in 0.79 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 22, 'learning_rate': 0.034014257738771814, 'subsample': 0.5793798672209325, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:11,299] Trial 9 finished with value: 273.313136379972 and parameters: {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 22, 'learning_rate': 0.034014257738771814, 'subsample': 0.5793798672209325, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 273.3131, MAE: 239.2811, R²: -0.2592 in 0.73 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 30, 'learning_rate': 0.19170062409373378, 'subsample': 0.8079957590341871, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:12,250] Trial 10 finished with value: 296.2096989947686 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 30, 'learning_rate': 0.19170062409373378, 'subsample': 0.8079957590341871, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 296.2097, MAE: 247.7393, R²: -0.4790 in 0.95 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 237, 'max_depth': 14, 'learning_rate': 0.15362330913414535, 'subsample': 0.6883022653493023, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:13,281] Trial 11 finished with value: 245.51625803745523 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 237, 'max_depth': 14, 'learning_rate': 0.15362330913414535, 'subsample': 0.6883022653493023, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 245.5163, MAE: 222.8304, R²: -0.0161 in 1.03 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 245, 'max_depth': 5, 'learning_rate': 0.11454023168088696, 'subsample': 0.7667936090189633, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:14,102] Trial 12 finished with value: 242.22676475626247 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 245, 'max_depth': 5, 'learning_rate': 0.11454023168088696, 'subsample': 0.7667936090189633, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 242.2268, MAE: 219.4250, R²: 0.0110 in 0.82 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 24, 'learning_rate': 0.1678033452483734, 'subsample': 0.6857088979648334, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:15,645] Trial 13 finished with value: 241.62352187856217 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 24, 'learning_rate': 0.1678033452483734, 'subsample': 0.6857088979648334, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 241.6235, MAE: 218.9525, R²: 0.0159 in 1.54 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 26, 'learning_rate': 0.17108552570818192, 'subsample': 0.6950029326648646, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:16,613] Trial 14 finished with value: 240.7325830222644 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 26, 'learning_rate': 0.17108552570818192, 'subsample': 0.6950029326648646, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 7 with value: 240.36937200156885.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 240.7326, MAE: 217.2286, R²: 0.0231 in 0.97 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_exploitatie-_en_machinekosten: 14.69 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_exploitatie-_en_machinekosten: {'objective': 'reg:linear', 'n_estimators': 248, 'max_depth': 28, 'learning_rate': 0.16780571367533267, 'subsample': 0.5917861614682192, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:17,759] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_huisvestingskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 211, 'max_depth': 5, 'learning_rate': 0.12086796722940646, 'subsample': 0.871589115939626, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:19,636] Trial 0 finished with value: 141.4203506372367 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 211, 'max_depth': 5, 'learning_rate': 0.12086796722940646, 'subsample': 0.871589115939626, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 141.4204, MAE: 54.9659, R²: -0.1033 in 1.88 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 71, 'max_depth': 7, 'learning_rate': 0.17720775855711782, 'subsample': 0.9310544899901849, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:21,416] Trial 1 finished with value: 142.2261567462909 and parameters: {'objective': 'reg:linear', 'n_estimators': 71, 'max_depth': 7, 'learning_rate': 0.17720775855711782, 'subsample': 0.9310544899901849, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 142.2262, MAE: 54.9299, R²: -0.1159 in 1.78 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 270, 'max_depth': 20, 'learning_rate': 0.07762779228223264, 'subsample': 0.9273280428666402, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:23,914] Trial 2 finished with value: 141.73109518488766 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 270, 'max_depth': 20, 'learning_rate': 0.07762779228223264, 'subsample': 0.9273280428666402, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 141.7311, MAE: 54.6201, R²: -0.1082 in 2.50 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 76, 'max_depth': 15, 'learning_rate': 0.19574137319339896, 'subsample': 0.9923373076749107, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:25,852] Trial 3 finished with value: 144.18728363326102 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 76, 'max_depth': 15, 'learning_rate': 0.19574137319339896, 'subsample': 0.9923373076749107, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 144.1873, MAE: 55.3362, R²: -0.1469 in 1.94 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 289, 'max_depth': 19, 'learning_rate': 0.018555978373421458, 'subsample': 0.9102424571031651, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:28,280] Trial 4 finished with value: 142.8826863962001 and parameters: {'objective': 'reg:linear', 'n_estimators': 289, 'max_depth': 19, 'learning_rate': 0.018555978373421458, 'subsample': 0.9102424571031651, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 142.8827, MAE: 54.7741, R²: -0.1263 in 2.43 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 295, 'max_depth': 25, 'learning_rate': 0.1053172604310376, 'subsample': 0.9516114587225633, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:30,566] Trial 5 finished with value: 143.7893778172676 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 295, 'max_depth': 25, 'learning_rate': 0.1053172604310376, 'subsample': 0.9516114587225633, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 143.7894, MAE: 55.2176, R²: -0.1406 in 2.29 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.1757984004946021, 'subsample': 0.8009976229923113, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:32,410] Trial 6 finished with value: 143.02292152676537 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.1757984004946021, 'subsample': 0.8009976229923113, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 143.0229, MAE: 54.8626, R²: -0.1285 in 1.84 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 69, 'max_depth': 6, 'learning_rate': 0.10820898349787633, 'subsample': 0.9612023026673708, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:34,135] Trial 7 finished with value: 143.0651756171256 and parameters: {'objective': 'reg:linear', 'n_estimators': 69, 'max_depth': 6, 'learning_rate': 0.10820898349787633, 'subsample': 0.9612023026673708, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 143.0652, MAE: 54.8641, R²: -0.1291 in 1.72 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.10873237951019268, 'subsample': 0.6038961431368818, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:35,913] Trial 8 finished with value: 142.07984077668513 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.10873237951019268, 'subsample': 0.6038961431368818, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 142.0798, MAE: 54.4424, R²: -0.1136 in 1.78 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 171, 'max_depth': 27, 'learning_rate': 0.12973182632884966, 'subsample': 0.9567476535568475, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:38,226] Trial 9 finished with value: 145.2509571794226 and parameters: {'objective': 'reg:linear', 'n_estimators': 171, 'max_depth': 27, 'learning_rate': 0.12973182632884966, 'subsample': 0.9567476535568475, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 145.2510, MAE: 56.4118, R²: -0.1639 in 2.31 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 16, 'learning_rate': 0.05481980568527409, 'subsample': 0.7690709800464756, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:40,479] Trial 10 finished with value: 142.73233616521338 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 16, 'learning_rate': 0.05481980568527409, 'subsample': 0.7690709800464756, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 142.7323, MAE: 55.1185, R²: -0.1239 in 2.25 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 21, 'learning_rate': 0.06317231516528207, 'subsample': 0.8561802163806046, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:43,271] Trial 11 finished with value: 142.29877106339973 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 21, 'learning_rate': 0.06317231516528207, 'subsample': 0.8561802163806046, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 142.2988, MAE: 55.0095, R²: -0.1171 in 2.79 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 12, 'learning_rate': 0.06683420285279182, 'subsample': 0.6658551601077478, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:45,432] Trial 12 finished with value: 142.48860082161858 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 12, 'learning_rate': 0.06683420285279182, 'subsample': 0.6658551601077478, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 142.4886, MAE: 54.7346, R²: -0.1201 in 2.16 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 182, 'max_depth': 23, 'learning_rate': 0.13960747810908453, 'subsample': 0.8566447711960447, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:47,847] Trial 13 finished with value: 141.69690196656762 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 182, 'max_depth': 23, 'learning_rate': 0.13960747810908453, 'subsample': 0.8566447711960447, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 141.6969, MAE: 55.2873, R²: -0.1076 in 2.41 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 24, 'learning_rate': 0.14144230114033232, 'subsample': 0.8405800723849285, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:49,923] Trial 14 finished with value: 142.71107762961196 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 24, 'learning_rate': 0.14144230114033232, 'subsample': 0.8405800723849285, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 141.4203506372367.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 142.7111, MAE: 55.1458, R²: -0.1236 in 2.07 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_huisvestingskosten: 32.16 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_huisvestingskosten: {'objective': 'reg:squarederror', 'n_estimators': 211, 'max_depth': 5, 'learning_rate': 0.12086796722940646, 'subsample': 0.871589115939626, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:51,844] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_kantoorkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 68, 'max_depth': 23, 'learning_rate': 0.14100100879587318, 'subsample': 0.7694692533888183, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:53,013] Trial 0 finished with value: 194.41751252000958 and parameters: {'objective': 'reg:linear', 'n_estimators': 68, 'max_depth': 23, 'learning_rate': 0.14100100879587318, 'subsample': 0.7694692533888183, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 194.41751252000958.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 194.4175, MAE: 160.9140, R²: 0.2366 in 1.17 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 142, 'max_depth': 8, 'learning_rate': 0.05762837190394182, 'subsample': 0.5248871771910708, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:54,235] Trial 1 finished with value: 225.58296435792892 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 142, 'max_depth': 8, 'learning_rate': 0.05762837190394182, 'subsample': 0.5248871771910708, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 194.41751252000958.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 225.5830, MAE: 180.9502, R²: -0.0277 in 1.22 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 123, 'max_depth': 18, 'learning_rate': 0.18684992767474273, 'subsample': 0.9048937238415669, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:55,567] Trial 2 finished with value: 185.03939614452895 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 123, 'max_depth': 18, 'learning_rate': 0.18684992767474273, 'subsample': 0.9048937238415669, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 185.0394, MAE: 155.6645, R²: 0.3085 in 1.33 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 282, 'max_depth': 7, 'learning_rate': 0.19766985379107901, 'subsample': 0.7915297900866078, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:56,864] Trial 3 finished with value: 218.0512794168361 and parameters: {'objective': 'reg:linear', 'n_estimators': 282, 'max_depth': 7, 'learning_rate': 0.19766985379107901, 'subsample': 0.7915297900866078, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 218.0513, MAE: 173.4966, R²: 0.0398 in 1.30 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 292, 'max_depth': 27, 'learning_rate': 0.1518535821767204, 'subsample': 0.8070861287384481, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:58,362] Trial 4 finished with value: 186.15155736828606 and parameters: {'objective': 'reg:linear', 'n_estimators': 292, 'max_depth': 27, 'learning_rate': 0.1518535821767204, 'subsample': 0.8070861287384481, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 186.1516, MAE: 159.8702, R²: 0.3002 in 1.50 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 203, 'max_depth': 5, 'learning_rate': 0.1872776852769315, 'subsample': 0.9786400291699486, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:18:59,511] Trial 5 finished with value: 210.60444721618305 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 203, 'max_depth': 5, 'learning_rate': 0.1872776852769315, 'subsample': 0.9786400291699486, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 210.6044, MAE: 165.4391, R²: 0.1042 in 1.15 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 120, 'max_depth': 12, 'learning_rate': 0.09138399122688437, 'subsample': 0.7645311653965057, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:00,778] Trial 6 finished with value: 195.3593169880632 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 120, 'max_depth': 12, 'learning_rate': 0.09138399122688437, 'subsample': 0.7645311653965057, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 195.3593, MAE: 162.9326, R²: 0.2292 in 1.27 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 222, 'max_depth': 30, 'learning_rate': 0.1093468436646401, 'subsample': 0.5221549803456321, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:02,149] Trial 7 finished with value: 237.22706299455228 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 222, 'max_depth': 30, 'learning_rate': 0.1093468436646401, 'subsample': 0.5221549803456321, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 237.2271, MAE: 187.8996, R²: -0.1365 in 1.37 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 11, 'learning_rate': 0.1388368679940798, 'subsample': 0.5433930395683618, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:03,304] Trial 8 finished with value: 222.0677132404209 and parameters: {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 11, 'learning_rate': 0.1388368679940798, 'subsample': 0.5433930395683618, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 222.0677, MAE: 171.0609, R²: 0.0041 in 1.15 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 276, 'max_depth': 12, 'learning_rate': 0.192339130458559, 'subsample': 0.6192058655671597, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:04,764] Trial 9 finished with value: 205.89273492706022 and parameters: {'objective': 'reg:linear', 'n_estimators': 276, 'max_depth': 12, 'learning_rate': 0.192339130458559, 'subsample': 0.6192058655671597, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 205.8927, MAE: 168.7343, R²: 0.1439 in 1.46 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 116, 'max_depth': 18, 'learning_rate': 0.013215704914745663, 'subsample': 0.959217957728855, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:05,932] Trial 10 finished with value: 185.66303366640534 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 116, 'max_depth': 18, 'learning_rate': 0.013215704914745663, 'subsample': 0.959217957728855, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 185.6630, MAE: 162.0904, R²: 0.3038 in 1.17 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 116, 'max_depth': 18, 'learning_rate': 0.01069952840032238, 'subsample': 0.9730595673077881, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:07,223] Trial 11 finished with value: 186.27615304600053 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 116, 'max_depth': 18, 'learning_rate': 0.01069952840032238, 'subsample': 0.9730595673077881, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 186.2762, MAE: 163.8883, R²: 0.2992 in 1.29 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 18, 'learning_rate': 0.02583031580182296, 'subsample': 0.8926753117614918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:08,665] Trial 12 finished with value: 187.58134034247877 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 18, 'learning_rate': 0.02583031580182296, 'subsample': 0.8926753117614918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 187.5813, MAE: 158.9215, R²: 0.2894 in 1.44 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 95, 'max_depth': 22, 'learning_rate': 0.057996084399670765, 'subsample': 0.902708420224518, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:09,870] Trial 13 finished with value: 189.58856981997354 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 95, 'max_depth': 22, 'learning_rate': 0.057996084399670765, 'subsample': 0.902708420224518, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 185.03939614452895.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 189.5886, MAE: 159.1857, R²: 0.2741 in 1.20 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.09628306190346324, 'subsample': 0.8783449303956197, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:11,279] Trial 14 finished with value: 184.53235757310793 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.09628306190346324, 'subsample': 0.8783449303956197, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 14 with value: 184.53235757310793.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 184.5324, MAE: 155.9153, R²: 0.3123 in 1.41 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_kantoorkosten: 19.44 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_kantoorkosten: {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.09628306190346324, 'subsample': 0.8783449303956197, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:12,745] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_lonen_en_salarissen\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 138, 'max_depth': 14, 'learning_rate': 0.10066205868246826, 'subsample': 0.9912243978524283, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:13,296] Trial 0 finished with value: 572.6598490840275 and parameters: {'objective': 'reg:linear', 'n_estimators': 138, 'max_depth': 14, 'learning_rate': 0.10066205868246826, 'subsample': 0.9912243978524283, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 572.6598490840275.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 572.6598, MAE: 417.3635, R²: -0.2107 in 0.55 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 17, 'learning_rate': 0.16449779783578908, 'subsample': 0.5379586773766951, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:13,829] Trial 1 finished with value: 520.9732659224294 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 17, 'learning_rate': 0.16449779783578908, 'subsample': 0.5379586773766951, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 520.9733, MAE: 381.6300, R²: -0.0020 in 0.53 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 206, 'max_depth': 11, 'learning_rate': 0.11284586515420295, 'subsample': 0.7868279332384052, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:14,528] Trial 2 finished with value: 557.6542931675818 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 206, 'max_depth': 11, 'learning_rate': 0.11284586515420295, 'subsample': 0.7868279332384052, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 557.6543, MAE: 415.1900, R²: -0.1481 in 0.70 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 257, 'max_depth': 22, 'learning_rate': 0.13615127977491706, 'subsample': 0.860220173151988, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:15,217] Trial 3 finished with value: 582.8847554695726 and parameters: {'objective': 'reg:linear', 'n_estimators': 257, 'max_depth': 22, 'learning_rate': 0.13615127977491706, 'subsample': 0.860220173151988, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 582.8848, MAE: 430.1747, R²: -0.2544 in 0.69 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 14, 'learning_rate': 0.08563614621718697, 'subsample': 0.5542302762080118, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:15,759] Trial 4 finished with value: 522.1959507300143 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 14, 'learning_rate': 0.08563614621718697, 'subsample': 0.5542302762080118, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 522.1960, MAE: 374.7924, R²: -0.0067 in 0.54 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 208, 'max_depth': 30, 'learning_rate': 0.17815596957215152, 'subsample': 0.9160056723422316, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:16,330] Trial 5 finished with value: 553.4318190750382 and parameters: {'objective': 'reg:linear', 'n_estimators': 208, 'max_depth': 30, 'learning_rate': 0.17815596957215152, 'subsample': 0.9160056723422316, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 553.4318, MAE: 408.1776, R²: -0.1308 in 0.57 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 126, 'max_depth': 17, 'learning_rate': 0.08320137389585631, 'subsample': 0.5181932460707206, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:16,831] Trial 6 finished with value: 524.8813884387708 and parameters: {'objective': 'reg:linear', 'n_estimators': 126, 'max_depth': 17, 'learning_rate': 0.08320137389585631, 'subsample': 0.5181932460707206, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 524.8814, MAE: 377.8765, R²: -0.0171 in 0.50 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 82, 'max_depth': 7, 'learning_rate': 0.035397123815951136, 'subsample': 0.5430806027586059, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:17,319] Trial 7 finished with value: 523.7433862673814 and parameters: {'objective': 'reg:linear', 'n_estimators': 82, 'max_depth': 7, 'learning_rate': 0.035397123815951136, 'subsample': 0.5430806027586059, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 523.7434, MAE: 376.0953, R²: -0.0127 in 0.49 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 86, 'max_depth': 29, 'learning_rate': 0.11554797097412155, 'subsample': 0.8726580314019177, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:17,837] Trial 8 finished with value: 573.9522481418282 and parameters: {'objective': 'reg:linear', 'n_estimators': 86, 'max_depth': 29, 'learning_rate': 0.11554797097412155, 'subsample': 0.8726580314019177, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 573.9522, MAE: 422.5771, R²: -0.2162 in 0.52 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 103, 'max_depth': 7, 'learning_rate': 0.03646340733129186, 'subsample': 0.5959133404279302, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:18,351] Trial 9 finished with value: 525.9098402656441 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 103, 'max_depth': 7, 'learning_rate': 0.03646340733129186, 'subsample': 0.5959133404279302, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 525.9098, MAE: 374.5653, R²: -0.0211 in 0.51 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 23, 'learning_rate': 0.1920108695842122, 'subsample': 0.6639953446762911, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:19,100] Trial 10 finished with value: 526.4928428539846 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 23, 'learning_rate': 0.1920108695842122, 'subsample': 0.6639953446762911, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 526.4928, MAE: 388.6294, R²: -0.0234 in 0.75 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 171, 'max_depth': 20, 'learning_rate': 0.15205220805959102, 'subsample': 0.6487963471350389, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:19,720] Trial 11 finished with value: 523.8811875180231 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 171, 'max_depth': 20, 'learning_rate': 0.15205220805959102, 'subsample': 0.6487963471350389, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 523.8812, MAE: 380.4776, R²: -0.0133 in 0.62 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 51, 'max_depth': 15, 'learning_rate': 0.0677700660137978, 'subsample': 0.7109484886679585, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:20,230] Trial 12 finished with value: 527.3760949377254 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 51, 'max_depth': 15, 'learning_rate': 0.0677700660137978, 'subsample': 0.7109484886679585, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 527.3761, MAE: 380.3759, R²: -0.0268 in 0.51 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 11, 'learning_rate': 0.15384358089202477, 'subsample': 0.5001995280171834, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:20,852] Trial 13 finished with value: 524.1874730700166 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 11, 'learning_rate': 0.15384358089202477, 'subsample': 0.5001995280171834, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 524.1875, MAE: 386.8912, R²: -0.0144 in 0.62 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 210, 'max_depth': 25, 'learning_rate': 0.06693309575344417, 'subsample': 0.5984898908863956, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:21,519] Trial 14 finished with value: 521.256076629836 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 210, 'max_depth': 25, 'learning_rate': 0.06693309575344417, 'subsample': 0.5984898908863956, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 520.9732659224294.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 521.2561, MAE: 371.2624, R²: -0.0031 in 0.67 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_lonen_en_salarissen: 8.77 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_lonen_en_salarissen: {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 17, 'learning_rate': 0.16449779783578908, 'subsample': 0.5379586773766951, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:22,082] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_overige_bedrijfsopbrengsten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.19487942793518578, 'subsample': 0.6910161120682111, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:22,910] Trial 0 finished with value: 56.03141975713269 and parameters: {'objective': 'reg:linear', 'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.19487942793518578, 'subsample': 0.6910161120682111, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 56.03141975713269.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 56.0314, MAE: 12.9262, R²: -0.0297 in 0.83 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 182, 'max_depth': 15, 'learning_rate': 0.08065493806755258, 'subsample': 0.6787015337254938, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:23,888] Trial 1 finished with value: 56.035712750426185 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 182, 'max_depth': 15, 'learning_rate': 0.08065493806755258, 'subsample': 0.6787015337254938, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 56.03141975713269.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 56.0357, MAE: 12.1021, R²: -0.0298 in 0.98 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 19, 'learning_rate': 0.03963604653871661, 'subsample': 0.6476859760379161, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:24,872] Trial 2 finished with value: 55.86608372120626 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 19, 'learning_rate': 0.03963604653871661, 'subsample': 0.6476859760379161, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 55.8661, MAE: 13.0131, R²: -0.0236 in 0.98 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 27, 'learning_rate': 0.13086532875864307, 'subsample': 0.9752924793614304, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:25,959] Trial 3 finished with value: 56.171301176508884 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 27, 'learning_rate': 0.13086532875864307, 'subsample': 0.9752924793614304, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 56.1713, MAE: 11.0641, R²: -0.0348 in 1.09 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 251, 'max_depth': 16, 'learning_rate': 0.04472170839732527, 'subsample': 0.5694977809801918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:26,908] Trial 4 finished with value: 55.86962520627515 and parameters: {'objective': 'reg:linear', 'n_estimators': 251, 'max_depth': 16, 'learning_rate': 0.04472170839732527, 'subsample': 0.5694977809801918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 55.8696, MAE: 13.4290, R²: -0.0237 in 0.95 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 165, 'max_depth': 8, 'learning_rate': 0.07683246609088358, 'subsample': 0.7823667979867828, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:27,800] Trial 5 finished with value: 56.092582212894655 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 165, 'max_depth': 8, 'learning_rate': 0.07683246609088358, 'subsample': 0.7823667979867828, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 56.0926, MAE: 11.2200, R²: -0.0319 in 0.89 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 64, 'max_depth': 18, 'learning_rate': 0.0666919892922439, 'subsample': 0.9768723892323743, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:28,575] Trial 6 finished with value: 56.343998119923405 and parameters: {'objective': 'reg:linear', 'n_estimators': 64, 'max_depth': 18, 'learning_rate': 0.0666919892922439, 'subsample': 0.9768723892323743, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 56.3440, MAE: 11.2490, R²: -0.0412 in 0.77 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 124, 'max_depth': 11, 'learning_rate': 0.04641248413338618, 'subsample': 0.9192315027428677, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:29,372] Trial 7 finished with value: 56.20488152195102 and parameters: {'objective': 'reg:linear', 'n_estimators': 124, 'max_depth': 11, 'learning_rate': 0.04641248413338618, 'subsample': 0.9192315027428677, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 56.2049, MAE: 11.0141, R²: -0.0361 in 0.79 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 174, 'max_depth': 29, 'learning_rate': 0.06923089615341019, 'subsample': 0.6903373161703521, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:30,463] Trial 8 finished with value: 56.06310926705417 and parameters: {'objective': 'reg:linear', 'n_estimators': 174, 'max_depth': 29, 'learning_rate': 0.06923089615341019, 'subsample': 0.6903373161703521, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 56.0631, MAE: 12.1262, R²: -0.0308 in 1.09 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.16248974685434, 'subsample': 0.8987680325619443, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:31,387] Trial 9 finished with value: 56.10535459110034 and parameters: {'objective': 'reg:linear', 'n_estimators': 100, 'max_depth': 16, 'learning_rate': 0.16248974685434, 'subsample': 0.8987680325619443, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 56.1054, MAE: 11.1752, R²: -0.0324 in 0.92 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 236, 'max_depth': 23, 'learning_rate': 0.010709204999756097, 'subsample': 0.5123805966134665, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:32,274] Trial 10 finished with value: 57.19196486244888 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 236, 'max_depth': 23, 'learning_rate': 0.010709204999756097, 'subsample': 0.5123805966134665, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 57.1920, MAE: 14.9293, R²: -0.0728 in 0.89 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 21, 'learning_rate': 0.013839141123865816, 'subsample': 0.5417152520890277, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:33,267] Trial 11 finished with value: 56.29020175654998 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 21, 'learning_rate': 0.013839141123865816, 'subsample': 0.5417152520890277, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 56.2902, MAE: 11.1779, R²: -0.0392 in 0.99 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 241, 'max_depth': 22, 'learning_rate': 0.038895339356726975, 'subsample': 0.5989080945969463, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:34,258] Trial 12 finished with value: 55.939285806593254 and parameters: {'objective': 'reg:linear', 'n_estimators': 241, 'max_depth': 22, 'learning_rate': 0.038895339356726975, 'subsample': 0.5989080945969463, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 55.86608372120626.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 55.9393, MAE: 12.3379, R²: -0.0263 in 0.99 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 241, 'max_depth': 13, 'learning_rate': 0.09955617216651888, 'subsample': 0.6121440723428887, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:35,318] Trial 13 finished with value: 55.632469928494345 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 241, 'max_depth': 13, 'learning_rate': 0.09955617216651888, 'subsample': 0.6121440723428887, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 13 with value: 55.632469928494345.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 55.6325, MAE: 13.7917, R²: -0.0151 in 1.06 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 210, 'max_depth': 12, 'learning_rate': 0.11794100509315363, 'subsample': 0.7670636878751247, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:36,340] Trial 14 finished with value: 56.25012380063004 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 210, 'max_depth': 12, 'learning_rate': 0.11794100509315363, 'subsample': 0.7670636878751247, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 13 with value: 55.632469928494345.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 56.2501, MAE: 11.1717, R²: -0.0377 in 1.02 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_overige_bedrijfsopbrengsten: 14.26 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_overige_bedrijfsopbrengsten: {'objective': 'reg:squarederror', 'n_estimators': 241, 'max_depth': 13, 'learning_rate': 0.09955617216651888, 'subsample': 0.6121440723428887, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:37,394] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_overige_personeelskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 299, 'max_depth': 26, 'learning_rate': 0.013004623437539817, 'subsample': 0.611433248210369, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:40,306] Trial 0 finished with value: 236.725397591306 and parameters: {'objective': 'reg:linear', 'n_estimators': 299, 'max_depth': 26, 'learning_rate': 0.013004623437539817, 'subsample': 0.611433248210369, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 236.725397591306.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 236.7254, MAE: 188.9625, R²: -0.5232 in 2.91 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 156, 'max_depth': 20, 'learning_rate': 0.057397174639843514, 'subsample': 0.645752418915867, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:42,990] Trial 1 finished with value: 205.2534038625008 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 156, 'max_depth': 20, 'learning_rate': 0.057397174639843514, 'subsample': 0.645752418915867, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 205.2534038625008.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 205.2534, MAE: 102.7130, R²: -0.1451 in 2.68 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 88, 'max_depth': 5, 'learning_rate': 0.09640757924673579, 'subsample': 0.6516261788828787, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:45,409] Trial 2 finished with value: 209.20448814042024 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 88, 'max_depth': 5, 'learning_rate': 0.09640757924673579, 'subsample': 0.6516261788828787, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 205.2534038625008.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 209.2045, MAE: 107.7290, R²: -0.1896 in 2.42 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 192, 'max_depth': 7, 'learning_rate': 0.1861000965961549, 'subsample': 0.5896292175466147, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:47,863] Trial 3 finished with value: 231.13542952542943 and parameters: {'objective': 'reg:linear', 'n_estimators': 192, 'max_depth': 7, 'learning_rate': 0.1861000965961549, 'subsample': 0.5896292175466147, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 205.2534038625008.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 231.1354, MAE: 58.1252, R²: -0.4521 in 2.45 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 191, 'max_depth': 6, 'learning_rate': 0.09884312087221814, 'subsample': 0.6523767055094727, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:50,322] Trial 4 finished with value: 212.7040328204786 and parameters: {'objective': 'reg:linear', 'n_estimators': 191, 'max_depth': 6, 'learning_rate': 0.09884312087221814, 'subsample': 0.6523767055094727, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 205.2534038625008.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 212.7040, MAE: 54.1793, R²: -0.2298 in 2.46 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 19, 'learning_rate': 0.15181612044684384, 'subsample': 0.919034150167676, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:53,023] Trial 5 finished with value: 198.80120887818708 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 19, 'learning_rate': 0.15181612044684384, 'subsample': 0.919034150167676, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 198.80120887818708.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 198.8012, MAE: 56.8592, R²: -0.0743 in 2.70 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.011609134136504665, 'subsample': 0.9846967957323727, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:55,350] Trial 6 finished with value: 194.12053510518615 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.011609134136504665, 'subsample': 0.9846967957323727, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 194.12053510518615.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 194.1205, MAE: 64.2704, R²: -0.0243 in 2.33 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.06107820056396928, 'subsample': 0.5383213878352291, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:19:58,011] Trial 7 finished with value: 227.99564566852922 and parameters: {'objective': 'reg:linear', 'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.06107820056396928, 'subsample': 0.5383213878352291, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 194.12053510518615.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 227.9956, MAE: 138.7004, R²: -0.4129 in 2.66 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 294, 'max_depth': 15, 'learning_rate': 0.16653919215257584, 'subsample': 0.7594521546910947, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:00,867] Trial 8 finished with value: 200.52689275054973 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 294, 'max_depth': 15, 'learning_rate': 0.16653919215257584, 'subsample': 0.7594521546910947, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 6 with value: 194.12053510518615.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 200.5269, MAE: 56.2368, R²: -0.0930 in 2.85 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 167, 'max_depth': 14, 'learning_rate': 0.11175968420373238, 'subsample': 0.5208896587906856, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:03,411] Trial 9 finished with value: 218.59812483184757 and parameters: {'objective': 'reg:linear', 'n_estimators': 167, 'max_depth': 14, 'learning_rate': 0.11175968420373238, 'subsample': 0.5208896587906856, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 194.12053510518615.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 218.5981, MAE: 71.4690, R²: -0.2989 in 2.54 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 90, 'max_depth': 29, 'learning_rate': 0.012612871122802252, 'subsample': 0.9888425145799585, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:05,866] Trial 10 finished with value: 193.9363172477477 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 90, 'max_depth': 29, 'learning_rate': 0.012612871122802252, 'subsample': 0.9888425145799585, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 10 with value: 193.9363172477477.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 193.9363, MAE: 66.3584, R²: -0.0223 in 2.45 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 54, 'max_depth': 30, 'learning_rate': 0.015518940799173018, 'subsample': 0.9939304359699228, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:08,259] Trial 11 finished with value: 193.62147658326984 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 54, 'max_depth': 30, 'learning_rate': 0.015518940799173018, 'subsample': 0.9939304359699228, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 193.62147658326984.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 193.6215, MAE: 67.1811, R²: -0.0190 in 2.39 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 52, 'max_depth': 30, 'learning_rate': 0.04439050358803585, 'subsample': 0.8774870089475602, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:10,683] Trial 12 finished with value: 197.3766916643932 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 52, 'max_depth': 30, 'learning_rate': 0.04439050358803585, 'subsample': 0.8774870089475602, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 193.62147658326984.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 197.3767, MAE: 111.6675, R²: -0.0589 in 2.42 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 30, 'learning_rate': 0.03534972742418771, 'subsample': 0.9850105400418973, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:13,142] Trial 13 finished with value: 194.59222145663625 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 30, 'learning_rate': 0.03534972742418771, 'subsample': 0.9850105400418973, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 193.62147658326984.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 194.5922, MAE: 64.4741, R²: -0.0293 in 2.46 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 110, 'max_depth': 25, 'learning_rate': 0.07948375347395359, 'subsample': 0.8227679129352528, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:15,734] Trial 14 finished with value: 194.59855216267547 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 110, 'max_depth': 25, 'learning_rate': 0.07948375347395359, 'subsample': 0.8227679129352528, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 193.62147658326984.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 194.5986, MAE: 53.7485, R²: -0.0293 in 2.59 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_overige_personeelskosten: 38.34 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_overige_personeelskosten: {'objective': 'reg:squarederror', 'n_estimators': 54, 'max_depth': 30, 'learning_rate': 0.015518940799173018, 'subsample': 0.9939304359699228, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:18,150] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_overige_rentelasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 83, 'max_depth': 18, 'learning_rate': 0.14548920434419008, 'subsample': 0.539370878435955, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:20,178] Trial 0 finished with value: 214.84062276487657 and parameters: {'objective': 'reg:linear', 'n_estimators': 83, 'max_depth': 18, 'learning_rate': 0.14548920434419008, 'subsample': 0.539370878435955, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 214.84062276487657.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 214.8406, MAE: 88.2246, R²: -0.2018 in 2.03 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 231, 'max_depth': 17, 'learning_rate': 0.16618014204203577, 'subsample': 0.7652352536646743, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:22,587] Trial 1 finished with value: 214.6800958842922 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 231, 'max_depth': 17, 'learning_rate': 0.16618014204203577, 'subsample': 0.7652352536646743, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 214.6800958842922.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 214.6801, MAE: 87.9056, R²: -0.2000 in 2.41 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 69, 'max_depth': 30, 'learning_rate': 0.06765152272279637, 'subsample': 0.9828792283349983, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:24,575] Trial 2 finished with value: 213.89618404990563 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 69, 'max_depth': 30, 'learning_rate': 0.06765152272279637, 'subsample': 0.9828792283349983, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 213.8962, MAE: 86.8896, R²: -0.1912 in 1.99 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 67, 'max_depth': 16, 'learning_rate': 0.16558207273071157, 'subsample': 0.6662055786724019, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:26,652] Trial 3 finished with value: 214.45481258297747 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 67, 'max_depth': 16, 'learning_rate': 0.16558207273071157, 'subsample': 0.6662055786724019, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 214.4548, MAE: 87.5633, R²: -0.1974 in 2.08 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 279, 'max_depth': 18, 'learning_rate': 0.06605024181111753, 'subsample': 0.5317021810028213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:29,112] Trial 4 finished with value: 214.6521727663928 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 279, 'max_depth': 18, 'learning_rate': 0.06605024181111753, 'subsample': 0.5317021810028213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 214.6522, MAE: 87.8804, R²: -0.1996 in 2.46 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 203, 'max_depth': 22, 'learning_rate': 0.08752079066327073, 'subsample': 0.6846552287608405, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:31,807] Trial 5 finished with value: 214.5700821772587 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 203, 'max_depth': 22, 'learning_rate': 0.08752079066327073, 'subsample': 0.6846552287608405, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 214.5701, MAE: 87.7763, R²: -0.1987 in 2.69 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 202, 'max_depth': 22, 'learning_rate': 0.19234331310625652, 'subsample': 0.6773507984979993, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:34,104] Trial 6 finished with value: 214.27067966320857 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 202, 'max_depth': 22, 'learning_rate': 0.19234331310625652, 'subsample': 0.6773507984979993, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 214.2707, MAE: 87.3552, R²: -0.1954 in 2.30 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 94, 'max_depth': 21, 'learning_rate': 0.15520022915907022, 'subsample': 0.5095427986927702, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:36,327] Trial 7 finished with value: 215.3478910094599 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 94, 'max_depth': 21, 'learning_rate': 0.15520022915907022, 'subsample': 0.5095427986927702, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 215.3479, MAE: 89.0920, R²: -0.2074 in 2.22 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 121, 'max_depth': 13, 'learning_rate': 0.04465423744015879, 'subsample': 0.760038134853104, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:38,385] Trial 8 finished with value: 214.06317072303682 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 121, 'max_depth': 13, 'learning_rate': 0.04465423744015879, 'subsample': 0.760038134853104, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 214.0632, MAE: 87.0367, R²: -0.1931 in 2.06 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 82, 'max_depth': 6, 'learning_rate': 0.1948610027675665, 'subsample': 0.8099047874758241, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:40,421] Trial 9 finished with value: 214.63091589983023 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 82, 'max_depth': 6, 'learning_rate': 0.1948610027675665, 'subsample': 0.8099047874758241, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 213.89618404990563.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 214.6309, MAE: 87.9022, R²: -0.1994 in 2.03 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 144, 'max_depth': 30, 'learning_rate': 0.021900362096669984, 'subsample': 0.9918501234991833, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:42,449] Trial 10 finished with value: 212.27325522909277 and parameters: {'objective': 'reg:linear', 'n_estimators': 144, 'max_depth': 30, 'learning_rate': 0.021900362096669984, 'subsample': 0.9918501234991833, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 212.27325522909277.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 212.2733, MAE: 87.6163, R²: -0.1732 in 2.03 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 142, 'max_depth': 30, 'learning_rate': 0.0220357767857911, 'subsample': 0.9909713188901634, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:44,562] Trial 11 finished with value: 212.1778783133519 and parameters: {'objective': 'reg:linear', 'n_estimators': 142, 'max_depth': 30, 'learning_rate': 0.0220357767857911, 'subsample': 0.9909713188901634, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 212.1778783133519.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 212.1779, MAE: 87.6748, R²: -0.1721 in 2.11 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 147, 'max_depth': 30, 'learning_rate': 0.011237245700270699, 'subsample': 0.9991147998849008, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:46,610] Trial 12 finished with value: 207.238578588919 and parameters: {'objective': 'reg:linear', 'n_estimators': 147, 'max_depth': 30, 'learning_rate': 0.011237245700270699, 'subsample': 0.9991147998849008, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 207.238578588919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 207.2386, MAE: 94.3076, R²: -0.1182 in 2.05 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 157, 'max_depth': 26, 'learning_rate': 0.011668862803328284, 'subsample': 0.8910885492410016, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:48,647] Trial 13 finished with value: 208.18266807995545 and parameters: {'objective': 'reg:linear', 'n_estimators': 157, 'max_depth': 26, 'learning_rate': 0.011668862803328284, 'subsample': 0.8910885492410016, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 207.238578588919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 208.1827, MAE: 92.5413, R²: -0.1284 in 2.04 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 174, 'max_depth': 26, 'learning_rate': 0.013538224379384426, 'subsample': 0.8669227025117046, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:50,743] Trial 14 finished with value: 210.30838965671342 and parameters: {'objective': 'reg:linear', 'n_estimators': 174, 'max_depth': 26, 'learning_rate': 0.013538224379384426, 'subsample': 0.8669227025117046, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 12 with value: 207.238578588919.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 210.3084, MAE: 89.3580, R²: -0.1516 in 2.10 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_overige_rentelasten: 32.59 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_overige_rentelasten: {'objective': 'reg:linear', 'n_estimators': 147, 'max_depth': 30, 'learning_rate': 0.011237245700270699, 'subsample': 0.9991147998849008, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:52,908] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_sociale_lasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 55, 'max_depth': 25, 'learning_rate': 0.10493880934501963, 'subsample': 0.9262201063133824, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:20:53,281] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 55, 'max_depth': 25, 'learning_rate': 0.10493880934501963, 'subsample': 0.9262201063133824, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 44, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:20:53,282] Trial 0 failed with value None.\n[I 2025-01-19 13:20:53,283] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_verkoopkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerXGBoostPattern on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 245, 'max_depth': 21, 'learning_rate': 0.11182435202400741, 'subsample': 0.9713625495255958, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:56,023] Trial 0 finished with value: 277.3132484029296 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 245, 'max_depth': 21, 'learning_rate': 0.11182435202400741, 'subsample': 0.9713625495255958, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 277.3132484029296.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 277.3132, MAE: 173.2953, R²: -0.4868 in 2.74 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 62, 'max_depth': 20, 'learning_rate': 0.04561058811183442, 'subsample': 0.7480030722329533, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:20:58,166] Trial 1 finished with value: 261.98229583744404 and parameters: {'objective': 'reg:linear', 'n_estimators': 62, 'max_depth': 20, 'learning_rate': 0.04561058811183442, 'subsample': 0.7480030722329533, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 261.9823, MAE: 162.4418, R²: -0.3269 in 2.14 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 242, 'max_depth': 22, 'learning_rate': 0.04580522872425006, 'subsample': 0.6974509218274305, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:00,679] Trial 2 finished with value: 269.52351560980105 and parameters: {'objective': 'reg:linear', 'n_estimators': 242, 'max_depth': 22, 'learning_rate': 0.04580522872425006, 'subsample': 0.6974509218274305, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 269.5235, MAE: 166.3667, R²: -0.4044 in 2.51 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 219, 'max_depth': 15, 'learning_rate': 0.11878942099057782, 'subsample': 0.7920398386898313, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:03,208] Trial 3 finished with value: 281.0765684798132 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 219, 'max_depth': 15, 'learning_rate': 0.11878942099057782, 'subsample': 0.7920398386898313, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 281.0766, MAE: 176.5667, R²: -0.5274 in 2.53 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 185, 'max_depth': 24, 'learning_rate': 0.1613378163356518, 'subsample': 0.7205960876599761, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:05,658] Trial 4 finished with value: 266.877742856646 and parameters: {'objective': 'reg:linear', 'n_estimators': 185, 'max_depth': 24, 'learning_rate': 0.1613378163356518, 'subsample': 0.7205960876599761, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 266.8777, MAE: 164.1366, R²: -0.3770 in 2.45 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 6, 'learning_rate': 0.1510229205686532, 'subsample': 0.9442069742379242, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:07,780] Trial 5 finished with value: 285.27986694638344 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 6, 'learning_rate': 0.1510229205686532, 'subsample': 0.9442069742379242, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 285.2799, MAE: 179.5971, R²: -0.5734 in 2.12 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 161, 'max_depth': 28, 'learning_rate': 0.1303897919580299, 'subsample': 0.6697689742435464, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:10,224] Trial 6 finished with value: 264.6371728271285 and parameters: {'objective': 'reg:linear', 'n_estimators': 161, 'max_depth': 28, 'learning_rate': 0.1303897919580299, 'subsample': 0.6697689742435464, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 264.6372, MAE: 161.9846, R²: -0.3539 in 2.44 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 98, 'max_depth': 14, 'learning_rate': 0.12643478936264488, 'subsample': 0.5589439004689307, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:12,372] Trial 7 finished with value: 282.5691027025965 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 98, 'max_depth': 14, 'learning_rate': 0.12643478936264488, 'subsample': 0.5589439004689307, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 282.5691, MAE: 177.2854, R²: -0.5436 in 2.15 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 211, 'max_depth': 6, 'learning_rate': 0.17148832912550008, 'subsample': 0.8343077396401815, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:14,661] Trial 8 finished with value: 268.72981414764524 and parameters: {'objective': 'reg:linear', 'n_estimators': 211, 'max_depth': 6, 'learning_rate': 0.17148832912550008, 'subsample': 0.8343077396401815, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 268.7298, MAE: 165.0932, R²: -0.3961 in 2.29 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 102, 'max_depth': 26, 'learning_rate': 0.1555087539243206, 'subsample': 0.9162892310114332, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:16,961] Trial 9 finished with value: 274.1497930474451 and parameters: {'objective': 'reg:linear', 'n_estimators': 102, 'max_depth': 26, 'learning_rate': 0.1555087539243206, 'subsample': 0.9162892310114332, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 261.98229583744404.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 274.1498, MAE: 170.6622, R²: -0.4530 in 2.30 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 11, 'learning_rate': 0.013235388075324567, 'subsample': 0.572592121525157, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:18,971] Trial 10 finished with value: 244.54099962332327 and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 11, 'learning_rate': 0.013235388075324567, 'subsample': 0.572592121525157, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 10 with value: 244.54099962332327.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 244.5410, MAE: 153.0617, R²: -0.1561 in 2.01 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 11, 'learning_rate': 0.012039728709307465, 'subsample': 0.5001628713035424, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:21,056] Trial 11 finished with value: 242.30879042273526 and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 11, 'learning_rate': 0.012039728709307465, 'subsample': 0.5001628713035424, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 242.30879042273526.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 242.3088, MAE: 152.9391, R²: -0.1351 in 2.08 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 11, 'learning_rate': 0.01289516565808324, 'subsample': 0.504263574836401, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:23,145] Trial 12 finished with value: 244.39591359676143 and parameters: {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 11, 'learning_rate': 0.01289516565808324, 'subsample': 0.504263574836401, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 242.30879042273526.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 244.3959, MAE: 153.1794, R²: -0.1547 in 2.09 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.011155461797377045, 'subsample': 0.5067411189595725, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:25,581] Trial 13 finished with value: 262.0212058232602 and parameters: {'objective': 'reg:linear', 'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.011155461797377045, 'subsample': 0.5067411189595725, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 242.30879042273526.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 262.0212, MAE: 161.6753, R²: -0.3273 in 2.43 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 89, 'max_depth': 10, 'learning_rate': 0.073481861071443, 'subsample': 0.6156311904500948, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:27,674] Trial 14 finished with value: 264.8763015373951 and parameters: {'objective': 'reg:linear', 'n_estimators': 89, 'max_depth': 10, 'learning_rate': 0.073481861071443, 'subsample': 0.6156311904500948, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 242.30879042273526.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 264.8763, MAE: 163.2695, R²: -0.3564 in 2.09 seconds\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_verkoopkosten: 34.39 seconds\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_verkoopkosten: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 11, 'learning_rate': 0.012039728709307465, 'subsample': 0.5001628713035424, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:29,785] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_mva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 254, 'max_depth': 23, 'learning_rate': 0.14762135601723111, 'subsample': 0.6971033280196326, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:31,028] Trial 0 finished with value: 590.7659167950252 and parameters: {'objective': 'reg:linear', 'n_estimators': 254, 'max_depth': 23, 'learning_rate': 0.14762135601723111, 'subsample': 0.6971033280196326, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 590.7659167950252.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 590.7659, MAE: 444.5153, R²: -0.3881 in 1.24 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 213, 'max_depth': 26, 'learning_rate': 0.010697105299332179, 'subsample': 0.5045940653677399, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:32,255] Trial 1 finished with value: 495.67758475534157 and parameters: {'objective': 'reg:linear', 'n_estimators': 213, 'max_depth': 26, 'learning_rate': 0.010697105299332179, 'subsample': 0.5045940653677399, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 495.6776, MAE: 362.4993, R²: 0.0228 in 1.23 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 150, 'max_depth': 21, 'learning_rate': 0.056927457878670526, 'subsample': 0.7999604465287904, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:33,461] Trial 2 finished with value: 505.94331944069256 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 150, 'max_depth': 21, 'learning_rate': 0.056927457878670526, 'subsample': 0.7999604465287904, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 505.9433, MAE: 380.3700, R²: -0.0181 in 1.21 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.022511257374566607, 'subsample': 0.7270311492197619, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:34,697] Trial 3 finished with value: 502.06310743216784 and parameters: {'objective': 'reg:linear', 'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.022511257374566607, 'subsample': 0.7270311492197619, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 502.0631, MAE: 369.2684, R²: -0.0026 in 1.23 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 242, 'max_depth': 8, 'learning_rate': 0.011139693928799679, 'subsample': 0.5163747581741803, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:35,889] Trial 4 finished with value: 560.7169179600938 and parameters: {'objective': 'reg:linear', 'n_estimators': 242, 'max_depth': 8, 'learning_rate': 0.011139693928799679, 'subsample': 0.5163747581741803, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 560.7169, MAE: 431.9002, R²: -0.2505 in 1.19 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 288, 'max_depth': 20, 'learning_rate': 0.0574870732674105, 'subsample': 0.5946763482346473, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:37,150] Trial 5 finished with value: 554.1114794295057 and parameters: {'objective': 'reg:linear', 'n_estimators': 288, 'max_depth': 20, 'learning_rate': 0.0574870732674105, 'subsample': 0.5946763482346473, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 554.1115, MAE: 426.4191, R²: -0.2212 in 1.26 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 54, 'max_depth': 18, 'learning_rate': 0.044581744068956736, 'subsample': 0.8247377122065075, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:38,163] Trial 6 finished with value: 560.2165819375376 and parameters: {'objective': 'reg:linear', 'n_estimators': 54, 'max_depth': 18, 'learning_rate': 0.044581744068956736, 'subsample': 0.8247377122065075, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 560.2166, MAE: 430.7464, R²: -0.2483 in 1.01 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 74, 'max_depth': 17, 'learning_rate': 0.023247706375182624, 'subsample': 0.7402393390809953, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:39,232] Trial 7 finished with value: 496.3980509698509 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 74, 'max_depth': 17, 'learning_rate': 0.023247706375182624, 'subsample': 0.7402393390809953, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 496.3981, MAE: 366.2482, R²: 0.0199 in 1.07 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 184, 'max_depth': 11, 'learning_rate': 0.06115862926428241, 'subsample': 0.5267120115800505, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:40,482] Trial 8 finished with value: 500.6006148839834 and parameters: {'objective': 'reg:linear', 'n_estimators': 184, 'max_depth': 11, 'learning_rate': 0.06115862926428241, 'subsample': 0.5267120115800505, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 500.6006, MAE: 375.8116, R²: 0.0033 in 1.25 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 198, 'max_depth': 29, 'learning_rate': 0.0227595335007766, 'subsample': 0.8991902760405717, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:41,754] Trial 9 finished with value: 566.8535764512345 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 198, 'max_depth': 29, 'learning_rate': 0.0227595335007766, 'subsample': 0.8991902760405717, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 566.8536, MAE: 434.7487, R²: -0.2780 in 1.27 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 122, 'max_depth': 30, 'learning_rate': 0.10545453553000175, 'subsample': 0.9592521248309931, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:42,939] Trial 10 finished with value: 512.8153648027502 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 122, 'max_depth': 30, 'learning_rate': 0.10545453553000175, 'subsample': 0.9592521248309931, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 512.8154, MAE: 380.9871, R²: -0.0460 in 1.18 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 54, 'max_depth': 25, 'learning_rate': 0.19568322020928178, 'subsample': 0.6081749153598436, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:44,076] Trial 11 finished with value: 509.8116653693466 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 54, 'max_depth': 25, 'learning_rate': 0.19568322020928178, 'subsample': 0.6081749153598436, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 509.8117, MAE: 411.6076, R²: -0.0338 in 1.14 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 115, 'max_depth': 15, 'learning_rate': 0.0942358682320091, 'subsample': 0.6476348934976041, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:45,458] Trial 12 finished with value: 516.1367359226515 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 115, 'max_depth': 15, 'learning_rate': 0.0942358682320091, 'subsample': 0.6476348934976041, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 516.1367, MAE: 408.5329, R²: -0.0596 in 1.38 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 216, 'max_depth': 15, 'learning_rate': 0.09642316975390355, 'subsample': 0.830330890111828, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:46,793] Trial 13 finished with value: 508.1957903253867 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 216, 'max_depth': 15, 'learning_rate': 0.09642316975390355, 'subsample': 0.830330890111828, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 508.1958, MAE: 381.4798, R²: -0.0272 in 1.33 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 26, 'learning_rate': 0.1295494108368158, 'subsample': 0.9753825432667572, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:48,006] Trial 14 finished with value: 513.4997157026153 and parameters: {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 26, 'learning_rate': 0.1295494108368158, 'subsample': 0.9753825432667572, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 495.67758475534157.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 513.4997, MAE: 379.5329, R²: -0.0488 in 1.21 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_mva: 18.22 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_mva: {'objective': 'reg:linear', 'n_estimators': 213, 'max_depth': 26, 'learning_rate': 0.010697105299332179, 'subsample': 0.5045940653677399, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:49,186] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_iva\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 138, 'max_depth': 19, 'learning_rate': 0.11627752557141638, 'subsample': 0.7518205294286182, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:49,580] Trial 0 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 138, 'max_depth': 19, 'learning_rate': 0.11627752557141638, 'subsample': 0.7518205294286182, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.39 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 28, 'learning_rate': 0.07141865508581602, 'subsample': 0.5990738790483734, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:50,063] Trial 1 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 28, 'learning_rate': 0.07141865508581602, 'subsample': 0.5990738790483734, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.48 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 114, 'max_depth': 21, 'learning_rate': 0.17470725932510683, 'subsample': 0.9324705947750733, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:50,482] Trial 2 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 114, 'max_depth': 21, 'learning_rate': 0.17470725932510683, 'subsample': 0.9324705947750733, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.42 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 164, 'max_depth': 11, 'learning_rate': 0.1032066718951033, 'subsample': 0.7407493653719208, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:50,884] Trial 3 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 164, 'max_depth': 11, 'learning_rate': 0.1032066718951033, 'subsample': 0.7407493653719208, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.40 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 19, 'learning_rate': 0.1390893546153009, 'subsample': 0.8468019082988805, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:51,279] Trial 4 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 19, 'learning_rate': 0.1390893546153009, 'subsample': 0.8468019082988805, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.39 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 81, 'max_depth': 16, 'learning_rate': 0.1779201300968951, 'subsample': 0.8999444519167465, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:51,669] Trial 5 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 81, 'max_depth': 16, 'learning_rate': 0.1779201300968951, 'subsample': 0.8999444519167465, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.39 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 219, 'max_depth': 10, 'learning_rate': 0.08455902223862374, 'subsample': 0.7553878265594652, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:52,153] Trial 6 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 219, 'max_depth': 10, 'learning_rate': 0.08455902223862374, 'subsample': 0.7553878265594652, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.48 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 158, 'max_depth': 8, 'learning_rate': 0.08075370922504732, 'subsample': 0.8813194992603792, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:52,588] Trial 7 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 158, 'max_depth': 8, 'learning_rate': 0.08075370922504732, 'subsample': 0.8813194992603792, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.43 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 178, 'max_depth': 17, 'learning_rate': 0.1353337416410802, 'subsample': 0.970875431120239, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:52,957] Trial 8 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 178, 'max_depth': 17, 'learning_rate': 0.1353337416410802, 'subsample': 0.970875431120239, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.37 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 248, 'max_depth': 19, 'learning_rate': 0.18715879661988424, 'subsample': 0.6081212659270437, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:53,373] Trial 9 finished with value: 0.0 and parameters: {'objective': 'reg:linear', 'n_estimators': 248, 'max_depth': 19, 'learning_rate': 0.18715879661988424, 'subsample': 0.6081212659270437, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.41 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 143, 'max_depth': 26, 'learning_rate': 0.02066922786459295, 'subsample': 0.5229660309183704, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:53,805] Trial 10 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 143, 'max_depth': 26, 'learning_rate': 0.02066922786459295, 'subsample': 0.5229660309183704, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.43 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 289, 'max_depth': 30, 'learning_rate': 0.04360195755206811, 'subsample': 0.6777125525138361, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:54,265] Trial 11 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 289, 'max_depth': 30, 'learning_rate': 0.04360195755206811, 'subsample': 0.6777125525138361, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.46 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 215, 'max_depth': 25, 'learning_rate': 0.057511654467328595, 'subsample': 0.5943680887350379, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:54,702] Trial 12 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 215, 'max_depth': 25, 'learning_rate': 0.057511654467328595, 'subsample': 0.5943680887350379, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.44 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 280, 'max_depth': 30, 'learning_rate': 0.1309924362346855, 'subsample': 0.7768358885600981, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:55,195] Trial 13 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 280, 'max_depth': 30, 'learning_rate': 0.1309924362346855, 'subsample': 0.7768358885600981, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.49 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 113, 'max_depth': 24, 'learning_rate': 0.09967403956242123, 'subsample': 0.6709351205544718, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:55,628] Trial 14 finished with value: 0.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 113, 'max_depth': 24, 'learning_rate': 0.09967403956242123, 'subsample': 0.6709351205544718, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 0.0000, MAE: 0.0000, R²: 1.0000 in 0.43 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_iva: 6.44 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_iva: {'objective': 'reg:squarederror', 'n_estimators': 138, 'max_depth': 19, 'learning_rate': 0.11627752557141638, 'subsample': 0.7518205294286182, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:56,057] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_omzet\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 237, 'max_depth': 22, 'learning_rate': 0.18646267833348598, 'subsample': 0.7048590436246724, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:57,566] Trial 0 finished with value: 963.5582482729391 and parameters: {'objective': 'reg:linear', 'n_estimators': 237, 'max_depth': 22, 'learning_rate': 0.18646267833348598, 'subsample': 0.7048590436246724, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 963.5582482729391.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 963.5582, MAE: 750.5985, R²: -0.3128 in 1.51 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 104, 'max_depth': 12, 'learning_rate': 0.10357218410182238, 'subsample': 0.71215695141818, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:58,760] Trial 1 finished with value: 961.1633042270146 and parameters: {'objective': 'reg:linear', 'n_estimators': 104, 'max_depth': 12, 'learning_rate': 0.10357218410182238, 'subsample': 0.71215695141818, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 961.1633042270146.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 961.1633, MAE: 748.6344, R²: -0.3063 in 1.19 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 69, 'max_depth': 28, 'learning_rate': 0.05961083480812686, 'subsample': 0.5292641047384344, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:21:59,947] Trial 2 finished with value: 928.9004892812992 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 69, 'max_depth': 28, 'learning_rate': 0.05961083480812686, 'subsample': 0.5292641047384344, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 928.9004892812992.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 928.9005, MAE: 721.4928, R²: -0.2201 in 1.19 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 29, 'learning_rate': 0.06761808846853742, 'subsample': 0.5047093323537557, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:01,435] Trial 3 finished with value: 1337.8597670740965 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 29, 'learning_rate': 0.06761808846853742, 'subsample': 0.5047093323537557, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 928.9004892812992.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1337.8598, MAE: 1096.7448, R²: -1.5308 in 1.49 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 69, 'max_depth': 12, 'learning_rate': 0.026390488242254824, 'subsample': 0.9201295026785642, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:02,728] Trial 4 finished with value: 926.7190969959759 and parameters: {'objective': 'reg:linear', 'n_estimators': 69, 'max_depth': 12, 'learning_rate': 0.026390488242254824, 'subsample': 0.9201295026785642, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 926.7191, MAE: 726.0004, R²: -0.2143 in 1.29 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 276, 'max_depth': 26, 'learning_rate': 0.13242060981470793, 'subsample': 0.8997228702366702, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:04,208] Trial 5 finished with value: 1002.4275959020312 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 276, 'max_depth': 26, 'learning_rate': 0.13242060981470793, 'subsample': 0.8997228702366702, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1002.4276, MAE: 768.9759, R²: -0.4209 in 1.48 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 27, 'learning_rate': 0.17832979650961844, 'subsample': 0.8570587546212247, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:05,749] Trial 6 finished with value: 1102.0944360507742 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 27, 'learning_rate': 0.17832979650961844, 'subsample': 0.8570587546212247, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1102.0944, MAE: 857.2737, R²: -0.7174 in 1.54 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 290, 'max_depth': 14, 'learning_rate': 0.14197665352766115, 'subsample': 0.851575579152081, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:07,527] Trial 7 finished with value: 1065.3169532958864 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 290, 'max_depth': 14, 'learning_rate': 0.14197665352766115, 'subsample': 0.851575579152081, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1065.3170, MAE: 819.2669, R²: -0.6047 in 1.78 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 70, 'max_depth': 30, 'learning_rate': 0.05705242420804522, 'subsample': 0.6595873213355312, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:08,739] Trial 8 finished with value: 946.588807984677 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 70, 'max_depth': 30, 'learning_rate': 0.05705242420804522, 'subsample': 0.6595873213355312, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 946.5888, MAE: 735.3980, R²: -0.2670 in 1.21 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 243, 'max_depth': 26, 'learning_rate': 0.0669440665341204, 'subsample': 0.817379959899492, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:10,279] Trial 9 finished with value: 935.640810630162 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 243, 'max_depth': 26, 'learning_rate': 0.0669440665341204, 'subsample': 0.817379959899492, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 935.6408, MAE: 712.7069, R²: -0.2378 in 1.54 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 151, 'max_depth': 5, 'learning_rate': 0.011724314337315743, 'subsample': 0.9743276210856814, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:11,572] Trial 10 finished with value: 937.5582576940861 and parameters: {'objective': 'reg:linear', 'n_estimators': 151, 'max_depth': 5, 'learning_rate': 0.011724314337315743, 'subsample': 0.9743276210856814, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 926.7190969959759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 937.5583, MAE: 731.9689, R²: -0.2429 in 1.29 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 19, 'learning_rate': 0.019555708825995485, 'subsample': 0.5007588379180337, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:12,799] Trial 11 finished with value: 851.1501163001611 and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 19, 'learning_rate': 0.019555708825995485, 'subsample': 0.5007588379180337, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 851.1501163001611.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 851.1501, MAE: 647.3559, R²: -0.0244 in 1.23 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 128, 'max_depth': 18, 'learning_rate': 0.015240740261764986, 'subsample': 0.5984288483425543, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:14,103] Trial 12 finished with value: 918.6242847686243 and parameters: {'objective': 'reg:linear', 'n_estimators': 128, 'max_depth': 18, 'learning_rate': 0.015240740261764986, 'subsample': 0.5984288483425543, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 851.1501163001611.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 918.6243, MAE: 707.2056, R²: -0.1932 in 1.30 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 143, 'max_depth': 20, 'learning_rate': 0.03732917002605263, 'subsample': 0.6126418251041874, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:15,494] Trial 13 finished with value: 976.2132618344629 and parameters: {'objective': 'reg:linear', 'n_estimators': 143, 'max_depth': 20, 'learning_rate': 0.03732917002605263, 'subsample': 0.6126418251041874, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 851.1501163001611.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 976.2133, MAE: 746.6737, R²: -0.3475 in 1.39 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 119, 'max_depth': 18, 'learning_rate': 0.09195794346330523, 'subsample': 0.5872659794238395, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:16,851] Trial 14 finished with value: 948.797710020814 and parameters: {'objective': 'reg:linear', 'n_estimators': 119, 'max_depth': 18, 'learning_rate': 0.09195794346330523, 'subsample': 0.5872659794238395, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 11 with value: 851.1501163001611.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 948.7977, MAE: 759.6667, R²: -0.2729 in 1.36 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_omzet: 20.80 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_omzet: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 19, 'learning_rate': 0.019555708825995485, 'subsample': 0.5007588379180337, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:18,098] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_algemene_kosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 181, 'max_depth': 14, 'learning_rate': 0.02545272260213558, 'subsample': 0.8399429302629279, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:20,028] Trial 0 finished with value: 1107.6046638441132 and parameters: {'objective': 'reg:linear', 'n_estimators': 181, 'max_depth': 14, 'learning_rate': 0.02545272260213558, 'subsample': 0.8399429302629279, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 1107.6046638441132.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1107.6047, MAE: 923.3256, R²: 0.0165 in 1.93 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 165, 'max_depth': 23, 'learning_rate': 0.010763720029000898, 'subsample': 0.5860770226294839, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:21,936] Trial 1 finished with value: 1098.3990635664206 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 165, 'max_depth': 23, 'learning_rate': 0.010763720029000898, 'subsample': 0.5860770226294839, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1098.3991, MAE: 921.8756, R²: 0.0328 in 1.91 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 22, 'learning_rate': 0.017205564750727653, 'subsample': 0.8659997835677743, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:23,751] Trial 2 finished with value: 1107.2243580365666 and parameters: {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 22, 'learning_rate': 0.017205564750727653, 'subsample': 0.8659997835677743, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1107.2244, MAE: 923.0129, R²: 0.0172 in 1.81 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 116, 'max_depth': 28, 'learning_rate': 0.11548515166853339, 'subsample': 0.6474549988829816, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:25,562] Trial 3 finished with value: 1174.907458065506 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 116, 'max_depth': 28, 'learning_rate': 0.11548515166853339, 'subsample': 0.6474549988829816, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1174.9075, MAE: 928.6251, R²: -0.1066 in 1.81 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 191, 'max_depth': 16, 'learning_rate': 0.09447074080559743, 'subsample': 0.9907382195761286, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:27,479] Trial 4 finished with value: 1114.150630188755 and parameters: {'objective': 'reg:linear', 'n_estimators': 191, 'max_depth': 16, 'learning_rate': 0.09447074080559743, 'subsample': 0.9907382195761286, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1114.1506, MAE: 936.6396, R²: 0.0049 in 1.92 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.17135189371790757, 'subsample': 0.8554860848833594, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:29,262] Trial 5 finished with value: 1194.3619779614553 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 184, 'max_depth': 5, 'learning_rate': 0.17135189371790757, 'subsample': 0.8554860848833594, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1194.3620, MAE: 972.7618, R²: -0.1436 in 1.78 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 96, 'max_depth': 13, 'learning_rate': 0.09468781256320839, 'subsample': 0.7783964822480055, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:30,976] Trial 6 finished with value: 1558.7557423532498 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 96, 'max_depth': 13, 'learning_rate': 0.09468781256320839, 'subsample': 0.7783964822480055, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1558.7557, MAE: 1331.3476, R²: -0.9478 in 1.71 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 149, 'max_depth': 23, 'learning_rate': 0.1259529176721806, 'subsample': 0.5807947521665608, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:32,844] Trial 7 finished with value: 1223.3773981424936 and parameters: {'objective': 'reg:linear', 'n_estimators': 149, 'max_depth': 23, 'learning_rate': 0.1259529176721806, 'subsample': 0.5807947521665608, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1223.3774, MAE: 969.2847, R²: -0.1998 in 1.87 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 50, 'max_depth': 11, 'learning_rate': 0.08405959607345023, 'subsample': 0.7181225872655665, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:34,533] Trial 8 finished with value: 1464.5894194597984 and parameters: {'objective': 'reg:linear', 'n_estimators': 50, 'max_depth': 11, 'learning_rate': 0.08405959607345023, 'subsample': 0.7181225872655665, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 1464.5894, MAE: 1267.7278, R²: -0.7196 in 1.69 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 108, 'max_depth': 27, 'learning_rate': 0.14379921643687898, 'subsample': 0.528294979746783, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:36,367] Trial 9 finished with value: 1149.4639781532064 and parameters: {'objective': 'reg:linear', 'n_estimators': 108, 'max_depth': 27, 'learning_rate': 0.14379921643687898, 'subsample': 0.528294979746783, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1149.4640, MAE: 961.9290, R²: -0.0592 in 1.83 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 258, 'max_depth': 21, 'learning_rate': 0.05331822127304377, 'subsample': 0.5024421027532028, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:38,446] Trial 10 finished with value: 1343.889101588352 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 258, 'max_depth': 21, 'learning_rate': 0.05331822127304377, 'subsample': 0.5024421027532028, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1343.8891, MAE: 1087.5686, R²: -0.4478 in 2.08 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 21, 'learning_rate': 0.010617379166892718, 'subsample': 0.8556449798648478, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:40,484] Trial 11 finished with value: 1103.5795309739192 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 21, 'learning_rate': 0.010617379166892718, 'subsample': 0.8556449798648478, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1103.5795, MAE: 919.1954, R²: 0.0237 in 2.04 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 251, 'max_depth': 19, 'learning_rate': 0.0543868942628445, 'subsample': 0.6784120712591274, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:42,504] Trial 12 finished with value: 1125.604672265944 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 251, 'max_depth': 19, 'learning_rate': 0.0543868942628445, 'subsample': 0.6784120712591274, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1125.6047, MAE: 930.4278, R²: -0.0157 in 2.02 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 294, 'max_depth': 26, 'learning_rate': 0.04653791846120092, 'subsample': 0.9612605680319687, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:44,664] Trial 13 finished with value: 1111.4821266767158 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 294, 'max_depth': 26, 'learning_rate': 0.04653791846120092, 'subsample': 0.9612605680319687, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1111.4821, MAE: 942.1455, R²: 0.0096 in 2.16 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 223, 'max_depth': 30, 'learning_rate': 0.01181855391218229, 'subsample': 0.6088020209735134, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:46,556] Trial 14 finished with value: 1101.9591943675964 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 223, 'max_depth': 30, 'learning_rate': 0.01181855391218229, 'subsample': 0.6088020209735134, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1098.3990635664206.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1101.9592, MAE: 922.4379, R²: 0.0265 in 1.89 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_algemene_kosten: 28.46 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_algemene_kosten: {'objective': 'reg:squarederror', 'n_estimators': 165, 'max_depth': 23, 'learning_rate': 0.010763720029000898, 'subsample': 0.5860770226294839, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:48,417] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_autokosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 218, 'max_depth': 27, 'learning_rate': 0.03805105651140274, 'subsample': 0.949034451115072, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:50,589] Trial 0 finished with value: 1373.565203941284 and parameters: {'objective': 'reg:linear', 'n_estimators': 218, 'max_depth': 27, 'learning_rate': 0.03805105651140274, 'subsample': 0.949034451115072, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 1373.565203941284.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1373.5652, MAE: 1207.3946, R²: -0.0168 in 2.17 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 96, 'max_depth': 7, 'learning_rate': 0.044778977347654444, 'subsample': 0.8413117636916593, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:52,637] Trial 1 finished with value: 1364.6779250554673 and parameters: {'objective': 'reg:linear', 'n_estimators': 96, 'max_depth': 7, 'learning_rate': 0.044778977347654444, 'subsample': 0.8413117636916593, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1364.6779, MAE: 1201.9760, R²: -0.0037 in 2.05 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 286, 'max_depth': 29, 'learning_rate': 0.013028585599208237, 'subsample': 0.7004860222741229, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:54,907] Trial 2 finished with value: 1366.3376692012341 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 286, 'max_depth': 29, 'learning_rate': 0.013028585599208237, 'subsample': 0.7004860222741229, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1366.3377, MAE: 1186.1604, R²: -0.0061 in 2.27 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 150, 'max_depth': 27, 'learning_rate': 0.06455015301823888, 'subsample': 0.6508306576443343, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:56,989] Trial 3 finished with value: 1514.1233887801507 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 150, 'max_depth': 27, 'learning_rate': 0.06455015301823888, 'subsample': 0.6508306576443343, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1514.1234, MAE: 1346.3588, R²: -0.2355 in 2.08 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 212, 'max_depth': 24, 'learning_rate': 0.09437360200544824, 'subsample': 0.5561150711133578, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:22:59,112] Trial 4 finished with value: 2015.7540358893862 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 212, 'max_depth': 24, 'learning_rate': 0.09437360200544824, 'subsample': 0.5561150711133578, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 2015.7540, MAE: 1739.3533, R²: -1.1898 in 2.12 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 63, 'max_depth': 30, 'learning_rate': 0.19665832932373017, 'subsample': 0.7491921807177635, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:01,123] Trial 5 finished with value: 1648.3621826531592 and parameters: {'objective': 'reg:linear', 'n_estimators': 63, 'max_depth': 30, 'learning_rate': 0.19665832932373017, 'subsample': 0.7491921807177635, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1648.3622, MAE: 1486.7877, R²: -0.4643 in 2.01 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 220, 'max_depth': 29, 'learning_rate': 0.12368746313154433, 'subsample': 0.7237869663839978, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:03,314] Trial 6 finished with value: 1585.1989189805033 and parameters: {'objective': 'reg:linear', 'n_estimators': 220, 'max_depth': 29, 'learning_rate': 0.12368746313154433, 'subsample': 0.7237869663839978, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1585.1989, MAE: 1279.1985, R²: -0.3542 in 2.19 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 172, 'max_depth': 22, 'learning_rate': 0.1003393177319395, 'subsample': 0.9967846581552935, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:05,451] Trial 7 finished with value: 1546.0356341255106 and parameters: {'objective': 'reg:linear', 'n_estimators': 172, 'max_depth': 22, 'learning_rate': 0.1003393177319395, 'subsample': 0.9967846581552935, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1546.0356, MAE: 1388.7499, R²: -0.2882 in 2.14 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 207, 'max_depth': 29, 'learning_rate': 0.0301796832173463, 'subsample': 0.775226519979695, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:07,594] Trial 8 finished with value: 1478.365864689205 and parameters: {'objective': 'reg:linear', 'n_estimators': 207, 'max_depth': 29, 'learning_rate': 0.0301796832173463, 'subsample': 0.775226519979695, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 1478.3659, MAE: 1326.2837, R²: -0.1779 in 2.14 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 158, 'max_depth': 8, 'learning_rate': 0.09482268513099766, 'subsample': 0.7909498673797652, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:09,947] Trial 9 finished with value: 1377.1285216631966 and parameters: {'objective': 'reg:linear', 'n_estimators': 158, 'max_depth': 8, 'learning_rate': 0.09482268513099766, 'subsample': 0.7909498673797652, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1377.1285, MAE: 1226.9463, R²: -0.0221 in 2.35 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.1413967148613993, 'subsample': 0.8721149095351649, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:12,000] Trial 10 finished with value: 1383.552314838353 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 5, 'learning_rate': 0.1413967148613993, 'subsample': 0.8721149095351649, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1364.6779250554673.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1383.5523, MAE: 1218.7840, R²: -0.0316 in 2.05 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 275, 'max_depth': 14, 'learning_rate': 0.01007286658061504, 'subsample': 0.6320114779184912, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:14,328] Trial 11 finished with value: 1362.981231302002 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 275, 'max_depth': 14, 'learning_rate': 0.01007286658061504, 'subsample': 0.6320114779184912, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1362.981231302002.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1362.9812, MAE: 1183.6068, R²: -0.0012 in 2.33 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 113, 'max_depth': 13, 'learning_rate': 0.058123381130796285, 'subsample': 0.5148491941159928, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:16,712] Trial 12 finished with value: 1400.5043395404882 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 113, 'max_depth': 13, 'learning_rate': 0.058123381130796285, 'subsample': 0.5148491941159928, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1362.981231302002.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1400.5043, MAE: 1226.6085, R²: -0.0571 in 2.38 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 289, 'max_depth': 14, 'learning_rate': 0.014505817598825682, 'subsample': 0.8627849091926705, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:19,075] Trial 13 finished with value: 1364.6243151803803 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 289, 'max_depth': 14, 'learning_rate': 0.014505817598825682, 'subsample': 0.8627849091926705, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1362.981231302002.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1364.6243, MAE: 1197.3060, R²: -0.0036 in 2.36 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 15, 'learning_rate': 0.018409818964768107, 'subsample': 0.6228755657202887, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:21,344] Trial 14 finished with value: 1376.2653625391436 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 15, 'learning_rate': 0.018409818964768107, 'subsample': 0.6228755657202887, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1362.981231302002.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1376.2654, MAE: 1219.0566, R²: -0.0208 in 2.27 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_autokosten: 32.93 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_autokosten: {'objective': 'reg:squarederror', 'n_estimators': 275, 'max_depth': 14, 'learning_rate': 0.01007286658061504, 'subsample': 0.6320114779184912, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:23,653] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_overige_rentelasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 23, 'learning_rate': 0.15063027454437014, 'subsample': 0.6378599758418997, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:25,034] Trial 0 finished with value: 1748.3921526208455 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 225, 'max_depth': 23, 'learning_rate': 0.15063027454437014, 'subsample': 0.6378599758418997, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 1748.3921526208455.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1748.3922, MAE: 1485.7338, R²: -3.5841 in 1.38 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 14, 'learning_rate': 0.10341051766718319, 'subsample': 0.8038137238185352, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:26,278] Trial 1 finished with value: 1200.1410635973975 and parameters: {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 14, 'learning_rate': 0.10341051766718319, 'subsample': 0.8038137238185352, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1200.1410635973975.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1200.1411, MAE: 1042.8440, R²: -1.1599 in 1.24 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 18, 'learning_rate': 0.029720383174010247, 'subsample': 0.8402103695870412, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:27,631] Trial 2 finished with value: 863.221507975079 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 18, 'learning_rate': 0.029720383174010247, 'subsample': 0.8402103695870412, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 863.221507975079.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 863.2215, MAE: 597.0458, R²: -0.1174 in 1.35 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 201, 'max_depth': 27, 'learning_rate': 0.06287092467225783, 'subsample': 0.802456663492723, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:29,061] Trial 3 finished with value: 1136.8050535661168 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 201, 'max_depth': 27, 'learning_rate': 0.06287092467225783, 'subsample': 0.802456663492723, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 863.221507975079.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1136.8051, MAE: 968.3171, R²: -0.9380 in 1.43 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 11, 'learning_rate': 0.15869058108969353, 'subsample': 0.655645125318642, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:30,437] Trial 4 finished with value: 1559.3329306235162 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 11, 'learning_rate': 0.15869058108969353, 'subsample': 0.655645125318642, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 863.221507975079.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1559.3329, MAE: 1242.9858, R²: -2.6463 in 1.37 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 27, 'learning_rate': 0.05983176424664897, 'subsample': 0.8545144548971304, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:31,755] Trial 5 finished with value: 837.7068567948778 and parameters: {'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 27, 'learning_rate': 0.05983176424664897, 'subsample': 0.8545144548971304, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 837.7069, MAE: 584.9237, R²: -0.0523 in 1.32 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 102, 'max_depth': 13, 'learning_rate': 0.11698306239898582, 'subsample': 0.5653959870338437, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:33,096] Trial 6 finished with value: 889.6971814676828 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 102, 'max_depth': 13, 'learning_rate': 0.11698306239898582, 'subsample': 0.5653959870338437, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 889.6972, MAE: 659.9719, R²: -0.1870 in 1.34 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 205, 'max_depth': 17, 'learning_rate': 0.10826028681153403, 'subsample': 0.6948392455331172, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:34,447] Trial 7 finished with value: 847.6143118539325 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 205, 'max_depth': 17, 'learning_rate': 0.10826028681153403, 'subsample': 0.6948392455331172, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 847.6143, MAE: 659.9510, R²: -0.0774 in 1.35 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 162, 'max_depth': 21, 'learning_rate': 0.16802192694648288, 'subsample': 0.8031532342021138, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:35,806] Trial 8 finished with value: 1769.6916164117624 and parameters: {'objective': 'reg:linear', 'n_estimators': 162, 'max_depth': 21, 'learning_rate': 0.16802192694648288, 'subsample': 0.8031532342021138, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 1769.6916, MAE: 1478.2110, R²: -3.6964 in 1.36 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 182, 'max_depth': 7, 'learning_rate': 0.06025839132286487, 'subsample': 0.6758739535684181, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:37,373] Trial 9 finished with value: 1266.6010202225664 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 182, 'max_depth': 7, 'learning_rate': 0.06025839132286487, 'subsample': 0.6758739535684181, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1266.6010, MAE: 1146.8544, R²: -1.4058 in 1.57 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 297, 'max_depth': 30, 'learning_rate': 0.011800001533782009, 'subsample': 0.9510642986596882, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:38,820] Trial 10 finished with value: 847.096847655386 and parameters: {'objective': 'reg:linear', 'n_estimators': 297, 'max_depth': 30, 'learning_rate': 0.011800001533782009, 'subsample': 0.9510642986596882, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 847.0968, MAE: 584.9427, R²: -0.0761 in 1.45 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 296, 'max_depth': 29, 'learning_rate': 0.02462518732042751, 'subsample': 0.990745457311314, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:40,407] Trial 11 finished with value: 840.1018184960586 and parameters: {'objective': 'reg:linear', 'n_estimators': 296, 'max_depth': 29, 'learning_rate': 0.02462518732042751, 'subsample': 0.990745457311314, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 840.1018, MAE: 583.5821, R²: -0.0584 in 1.59 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 131, 'max_depth': 26, 'learning_rate': 0.05129814187980332, 'subsample': 0.9978211716298548, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:41,702] Trial 12 finished with value: 840.9370920426076 and parameters: {'objective': 'reg:linear', 'n_estimators': 131, 'max_depth': 26, 'learning_rate': 0.05129814187980332, 'subsample': 0.9978211716298548, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 840.9371, MAE: 585.4000, R²: -0.0605 in 1.29 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 285, 'max_depth': 30, 'learning_rate': 0.08620365748347758, 'subsample': 0.9130679624644142, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:43,287] Trial 13 finished with value: 871.9494742628771 and parameters: {'objective': 'reg:linear', 'n_estimators': 285, 'max_depth': 30, 'learning_rate': 0.08620365748347758, 'subsample': 0.9130679624644142, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 871.9495, MAE: 614.8790, R²: -0.1401 in 1.58 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 50, 'max_depth': 25, 'learning_rate': 0.027171387169119786, 'subsample': 0.889800031421629, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:44,544] Trial 14 finished with value: 840.8219043190372 and parameters: {'objective': 'reg:linear', 'n_estimators': 50, 'max_depth': 25, 'learning_rate': 0.027171387169119786, 'subsample': 0.889800031421629, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 837.7068567948778.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 840.8219, MAE: 582.0425, R²: -0.0602 in 1.26 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_overige_rentelasten: 20.89 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_overige_rentelasten: {'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 27, 'learning_rate': 0.05983176424664897, 'subsample': 0.8545144548971304, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:45,778] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_pensioenlasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 113, 'max_depth': 8, 'learning_rate': 0.05116295977666133, 'subsample': 0.7521962464337062, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:46,248] Trial 0 finished with value: 522.0659041347175 and parameters: {'objective': 'reg:linear', 'n_estimators': 113, 'max_depth': 8, 'learning_rate': 0.05116295977666133, 'subsample': 0.7521962464337062, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 522.0659041347175.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 522.0659, MAE: 344.5113, R²: -0.2012 in 0.47 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 113, 'max_depth': 13, 'learning_rate': 0.16072726458863984, 'subsample': 0.6426449687163154, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:46,729] Trial 1 finished with value: 814369.5901243733 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 113, 'max_depth': 13, 'learning_rate': 0.16072726458863984, 'subsample': 0.6426449687163154, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 522.0659041347175.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 814369.5901, MAE: 597440.1553, R²: -2922823.0989 in 0.48 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 71, 'max_depth': 7, 'learning_rate': 0.09319348570901456, 'subsample': 0.9206204571113972, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:47,142] Trial 2 finished with value: 998659.0873468288 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 71, 'max_depth': 7, 'learning_rate': 0.09319348570901456, 'subsample': 0.9206204571113972, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 522.0659041347175.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 998659.0873, MAE: 821235.4440, R²: -4395355.4409 in 0.41 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 290, 'max_depth': 27, 'learning_rate': 0.13370810320950988, 'subsample': 0.6877988392190719, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:47,845] Trial 3 finished with value: 882661.2236810394 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 290, 'max_depth': 27, 'learning_rate': 0.13370810320950988, 'subsample': 0.6877988392190719, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 522.0659041347175.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 882661.2237, MAE: 669455.1587, R²: -3433583.0219 in 0.70 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 221, 'max_depth': 7, 'learning_rate': 0.03195564760875778, 'subsample': 0.9793073030745962, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:48,447] Trial 4 finished with value: 518.6751805063872 and parameters: {'objective': 'reg:linear', 'n_estimators': 221, 'max_depth': 7, 'learning_rate': 0.03195564760875778, 'subsample': 0.9793073030745962, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 518.6751805063872.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 518.6752, MAE: 307.1207, R²: -0.1856 in 0.60 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 61, 'max_depth': 26, 'learning_rate': 0.10579767475009054, 'subsample': 0.8293629863114464, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:48,842] Trial 5 finished with value: 509.85723858743046 and parameters: {'objective': 'reg:linear', 'n_estimators': 61, 'max_depth': 26, 'learning_rate': 0.10579767475009054, 'subsample': 0.8293629863114464, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 509.85723858743046.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 509.8572, MAE: 321.6180, R²: -0.1457 in 0.39 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 21, 'learning_rate': 0.07597283781277135, 'subsample': 0.7473212769284205, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:49,344] Trial 6 finished with value: 875019.1567172192 and parameters: {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 21, 'learning_rate': 0.07597283781277135, 'subsample': 0.7473212769284205, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 509.85723858743046.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 875019.1567, MAE: 682536.9967, R²: -3374384.5730 in 0.50 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.19690092213952393, 'subsample': 0.7092831363520352, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:50,043] Trial 7 finished with value: 568.1367814062619 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.19690092213952393, 'subsample': 0.7092831363520352, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 5 with value: 509.85723858743046.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 568.1368, MAE: 363.1853, R²: -0.4225 in 0.70 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 137, 'max_depth': 23, 'learning_rate': 0.01579070170606265, 'subsample': 0.8754818636678916, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:50,525] Trial 8 finished with value: 503.312439213126 and parameters: {'objective': 'reg:linear', 'n_estimators': 137, 'max_depth': 23, 'learning_rate': 0.01579070170606265, 'subsample': 0.8754818636678916, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 503.312439213126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 503.3124, MAE: 334.5440, R²: -0.1164 in 0.48 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 225, 'max_depth': 15, 'learning_rate': 0.02087436435052156, 'subsample': 0.7817537297365634, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:51,054] Trial 9 finished with value: 517.2433664726886 and parameters: {'objective': 'reg:linear', 'n_estimators': 225, 'max_depth': 15, 'learning_rate': 0.02087436435052156, 'subsample': 0.7817537297365634, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 503.312439213126.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 517.2434, MAE: 340.6267, R²: -0.1791 in 0.53 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 21, 'learning_rate': 0.012447139670037652, 'subsample': 0.526739992409691, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:51,577] Trial 10 finished with value: 490.4305326411343 and parameters: {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 21, 'learning_rate': 0.012447139670037652, 'subsample': 0.526739992409691, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 490.4305326411343.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 490.4305, MAE: 346.6707, R²: -0.0600 in 0.52 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 168, 'max_depth': 22, 'learning_rate': 0.010150344868786495, 'subsample': 0.5193779949442866, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:52,056] Trial 11 finished with value: 482.55698478003603 and parameters: {'objective': 'reg:linear', 'n_estimators': 168, 'max_depth': 22, 'learning_rate': 0.010150344868786495, 'subsample': 0.5193779949442866, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 482.55698478003603.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 482.5570, MAE: 351.2333, R²: -0.0263 in 0.48 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 180, 'max_depth': 19, 'learning_rate': 0.05303099600682976, 'subsample': 0.516112352959187, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:52,567] Trial 12 finished with value: 542.3647690991737 and parameters: {'objective': 'reg:linear', 'n_estimators': 180, 'max_depth': 19, 'learning_rate': 0.05303099600682976, 'subsample': 0.516112352959187, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 482.55698478003603.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 542.3648, MAE: 367.0413, R²: -0.2964 in 0.51 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 173, 'max_depth': 29, 'learning_rate': 0.011431653950719914, 'subsample': 0.5008150839452921, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:53,082] Trial 13 finished with value: 487.505648945049 and parameters: {'objective': 'reg:linear', 'n_estimators': 173, 'max_depth': 29, 'learning_rate': 0.011431653950719914, 'subsample': 0.5008150839452921, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 482.55698478003603.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 487.5056, MAE: 344.3153, R²: -0.0474 in 0.51 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 195, 'max_depth': 29, 'learning_rate': 0.05619082649794448, 'subsample': 0.5964051231396619, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:53,600] Trial 14 finished with value: 533.1574366357465 and parameters: {'objective': 'reg:linear', 'n_estimators': 195, 'max_depth': 29, 'learning_rate': 0.05619082649794448, 'subsample': 0.5964051231396619, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 482.55698478003603.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 533.1574, MAE: 353.4440, R²: -0.2528 in 0.52 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_pensioenlasten: 7.82 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_pensioenlasten: {'objective': 'reg:linear', 'n_estimators': 168, 'max_depth': 22, 'learning_rate': 0.010150344868786495, 'subsample': 0.5193779949442866, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:54,051] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_lonen_en_salarissen\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 87, 'max_depth': 19, 'learning_rate': 0.17896933360127407, 'subsample': 0.9178139021251941, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:54,941] Trial 0 finished with value: 993.6285837938933 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 87, 'max_depth': 19, 'learning_rate': 0.17896933360127407, 'subsample': 0.9178139021251941, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 993.6285837938933.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 993.6286, MAE: 821.9055, R²: 0.1780 in 0.89 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 19, 'learning_rate': 0.011557015338148388, 'subsample': 0.809243765948825, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:55,739] Trial 1 finished with value: 1016.3410053717207 and parameters: {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 19, 'learning_rate': 0.011557015338148388, 'subsample': 0.809243765948825, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 993.6285837938933.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1016.3410, MAE: 811.8348, R²: 0.1400 in 0.80 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 129, 'max_depth': 18, 'learning_rate': 0.05565390952685984, 'subsample': 0.6461175743561997, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:56,624] Trial 2 finished with value: 975.2888917996256 and parameters: {'objective': 'reg:linear', 'n_estimators': 129, 'max_depth': 18, 'learning_rate': 0.05565390952685984, 'subsample': 0.6461175743561997, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 975.2888917996256.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 975.2889, MAE: 822.8674, R²: 0.2081 in 0.88 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 94, 'max_depth': 23, 'learning_rate': 0.03630584045583356, 'subsample': 0.8891238392779559, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:57,429] Trial 3 finished with value: 983.3984146972336 and parameters: {'objective': 'reg:linear', 'n_estimators': 94, 'max_depth': 23, 'learning_rate': 0.03630584045583356, 'subsample': 0.8891238392779559, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 975.2888917996256.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 983.3984, MAE: 817.6861, R²: 0.1949 in 0.80 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 236, 'max_depth': 16, 'learning_rate': 0.08484297717649002, 'subsample': 0.6943180666530453, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:58,421] Trial 4 finished with value: 982.621460127564 and parameters: {'objective': 'reg:linear', 'n_estimators': 236, 'max_depth': 16, 'learning_rate': 0.08484297717649002, 'subsample': 0.6943180666530453, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 975.2888917996256.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 982.6215, MAE: 832.6187, R²: 0.1961 in 0.99 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 205, 'max_depth': 11, 'learning_rate': 0.1764594466444385, 'subsample': 0.9963835117247684, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:23:59,323] Trial 5 finished with value: 966.2862136417934 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 205, 'max_depth': 11, 'learning_rate': 0.1764594466444385, 'subsample': 0.9963835117247684, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 5 with value: 966.2862136417934.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 966.2862, MAE: 826.1339, R²: 0.2226 in 0.90 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 286, 'max_depth': 14, 'learning_rate': 0.18758364887813267, 'subsample': 0.592118449651927, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:00,328] Trial 6 finished with value: 1109.7912483653793 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 286, 'max_depth': 14, 'learning_rate': 0.18758364887813267, 'subsample': 0.592118449651927, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 5 with value: 966.2862136417934.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1109.7912, MAE: 865.9587, R²: -0.0254 in 1.00 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 191, 'max_depth': 28, 'learning_rate': 0.18955250673698928, 'subsample': 0.8611758780444743, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:01,231] Trial 7 finished with value: 1013.9231192207438 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 191, 'max_depth': 28, 'learning_rate': 0.18955250673698928, 'subsample': 0.8611758780444743, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 5 with value: 966.2862136417934.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1013.9231, MAE: 844.0535, R²: 0.1441 in 0.90 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 163, 'max_depth': 27, 'learning_rate': 0.16140528139572463, 'subsample': 0.9355405275116129, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:02,144] Trial 8 finished with value: 963.4911283385524 and parameters: {'objective': 'reg:linear', 'n_estimators': 163, 'max_depth': 27, 'learning_rate': 0.16140528139572463, 'subsample': 0.9355405275116129, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 963.4911, MAE: 813.2006, R²: 0.2271 in 0.91 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 10, 'learning_rate': 0.030561531337529278, 'subsample': 0.6164317002351132, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:03,227] Trial 9 finished with value: 980.3588098982746 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 10, 'learning_rate': 0.030561531337529278, 'subsample': 0.6164317002351132, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 980.3588, MAE: 828.5474, R²: 0.1998 in 1.08 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 145, 'max_depth': 30, 'learning_rate': 0.13752765233047057, 'subsample': 0.5164797540330583, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:04,125] Trial 10 finished with value: 1096.8256678015823 and parameters: {'objective': 'reg:linear', 'n_estimators': 145, 'max_depth': 30, 'learning_rate': 0.13752765233047057, 'subsample': 0.5164797540330583, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1096.8257, MAE: 815.1981, R²: -0.0016 in 0.90 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.14219674311202823, 'subsample': 0.973405737939674, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:05,038] Trial 11 finished with value: 977.135215606018 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.14219674311202823, 'subsample': 0.973405737939674, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 977.1352, MAE: 821.2306, R²: 0.2051 in 0.91 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.14177920649406917, 'subsample': 0.9983448567773622, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:06,030] Trial 12 finished with value: 969.2274398732351 and parameters: {'objective': 'reg:linear', 'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.14177920649406917, 'subsample': 0.9983448567773622, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 969.2274, MAE: 822.1216, R²: 0.2179 in 0.99 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 157, 'max_depth': 24, 'learning_rate': 0.11086779815532388, 'subsample': 0.781368943054066, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:06,977] Trial 13 finished with value: 1053.0344544465831 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 157, 'max_depth': 24, 'learning_rate': 0.11086779815532388, 'subsample': 0.781368943054066, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1053.0345, MAE: 861.0206, R²: 0.0768 in 0.95 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 237, 'max_depth': 12, 'learning_rate': 0.1641697214589249, 'subsample': 0.9341604433163847, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:08,035] Trial 14 finished with value: 966.9424051634232 and parameters: {'objective': 'reg:linear', 'n_estimators': 237, 'max_depth': 12, 'learning_rate': 0.1641697214589249, 'subsample': 0.9341604433163847, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 963.4911283385524.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 966.9424, MAE: 811.2839, R²: 0.2216 in 1.06 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_lonen_en_salarissen: 13.99 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_lonen_en_salarissen: {'objective': 'reg:linear', 'n_estimators': 163, 'max_depth': 27, 'learning_rate': 0.16140528139572463, 'subsample': 0.9355405275116129, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:08,915] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_overige_personeelskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 172, 'max_depth': 24, 'learning_rate': 0.14424429755206367, 'subsample': 0.7763127841084964, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:10,625] Trial 0 finished with value: 1308.5740953106867 and parameters: {'objective': 'reg:linear', 'n_estimators': 172, 'max_depth': 24, 'learning_rate': 0.14424429755206367, 'subsample': 0.7763127841084964, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 1308.5740953106867.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1308.5741, MAE: 1104.6006, R²: -1.2041 in 1.71 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 220, 'max_depth': 30, 'learning_rate': 0.03921158577015516, 'subsample': 0.530620344221825, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:12,244] Trial 1 finished with value: 975.9165631025426 and parameters: {'objective': 'reg:linear', 'n_estimators': 220, 'max_depth': 30, 'learning_rate': 0.03921158577015516, 'subsample': 0.530620344221825, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 975.9165631025426.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 975.9166, MAE: 743.3256, R²: -0.2259 in 1.62 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 86, 'max_depth': 20, 'learning_rate': 0.07850406783891455, 'subsample': 0.6107800962297648, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:13,780] Trial 2 finished with value: 1044.6681213029651 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 86, 'max_depth': 20, 'learning_rate': 0.07850406783891455, 'subsample': 0.6107800962297648, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 975.9165631025426.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1044.6681, MAE: 894.1988, R²: -0.4047 in 1.53 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 79, 'max_depth': 8, 'learning_rate': 0.19663985799123707, 'subsample': 0.5800323604774904, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:15,315] Trial 3 finished with value: 955.0504911965903 and parameters: {'objective': 'reg:linear', 'n_estimators': 79, 'max_depth': 8, 'learning_rate': 0.19663985799123707, 'subsample': 0.5800323604774904, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 955.0504911965903.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 955.0505, MAE: 509.0053, R²: -0.1740 in 1.53 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 183, 'max_depth': 23, 'learning_rate': 0.11088017319857973, 'subsample': 0.8242505445492851, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:16,979] Trial 4 finished with value: 953.3006207049084 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 183, 'max_depth': 23, 'learning_rate': 0.11088017319857973, 'subsample': 0.8242505445492851, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 953.3006207049084.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 953.3006, MAE: 541.8164, R²: -0.1697 in 1.66 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 275, 'max_depth': 7, 'learning_rate': 0.06212142815724783, 'subsample': 0.9905440953600759, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:18,598] Trial 5 finished with value: 1080.6955836692039 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 275, 'max_depth': 7, 'learning_rate': 0.06212142815724783, 'subsample': 0.9905440953600759, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 953.3006207049084.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1080.6956, MAE: 891.8417, R²: -0.5033 in 1.62 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 13, 'learning_rate': 0.15365074711718374, 'subsample': 0.5544167129626573, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:20,022] Trial 6 finished with value: 927.9603014905456 and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 13, 'learning_rate': 0.15365074711718374, 'subsample': 0.5544167129626573, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 927.9603014905456.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 927.9603, MAE: 528.3070, R²: -0.1084 in 1.42 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 266, 'max_depth': 9, 'learning_rate': 0.18243381650720442, 'subsample': 0.7175267790969806, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:21,821] Trial 7 finished with value: 1025.7985256108796 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 266, 'max_depth': 9, 'learning_rate': 0.18243381650720442, 'subsample': 0.7175267790969806, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 927.9603014905456.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1025.7985, MAE: 821.1027, R²: -0.3544 in 1.80 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 175, 'max_depth': 21, 'learning_rate': 0.060356240293519284, 'subsample': 0.9925437244598281, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:23,449] Trial 8 finished with value: 897.0154458435029 and parameters: {'objective': 'reg:linear', 'n_estimators': 175, 'max_depth': 21, 'learning_rate': 0.060356240293519284, 'subsample': 0.9925437244598281, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 897.0154458435029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 897.0154, MAE: 529.5876, R²: -0.0357 in 1.63 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 254, 'max_depth': 16, 'learning_rate': 0.06920161289723481, 'subsample': 0.7813542847835846, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:25,122] Trial 9 finished with value: 921.3836540546456 and parameters: {'objective': 'reg:linear', 'n_estimators': 254, 'max_depth': 16, 'learning_rate': 0.06920161289723481, 'subsample': 0.7813542847835846, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 897.0154458435029.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 921.3837, MAE: 523.5950, R²: -0.0927 in 1.67 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 127, 'max_depth': 30, 'learning_rate': 0.016871603311796025, 'subsample': 0.9862973310092535, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:26,750] Trial 10 finished with value: 888.924239349468 and parameters: {'objective': 'reg:linear', 'n_estimators': 127, 'max_depth': 30, 'learning_rate': 0.016871603311796025, 'subsample': 0.9862973310092535, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 10 with value: 888.924239349468.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 888.9242, MAE: 534.8133, R²: -0.0171 in 1.63 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 139, 'max_depth': 29, 'learning_rate': 0.025223001349939315, 'subsample': 0.9759748984703913, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:28,386] Trial 11 finished with value: 891.9293140273012 and parameters: {'objective': 'reg:linear', 'n_estimators': 139, 'max_depth': 29, 'learning_rate': 0.025223001349939315, 'subsample': 0.9759748984703913, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 10 with value: 888.924239349468.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 891.9293, MAE: 508.4630, R²: -0.0240 in 1.63 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 129, 'max_depth': 30, 'learning_rate': 0.012660459515858702, 'subsample': 0.9002762742020817, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:30,029] Trial 12 finished with value: 888.8628131315777 and parameters: {'objective': 'reg:linear', 'n_estimators': 129, 'max_depth': 30, 'learning_rate': 0.012660459515858702, 'subsample': 0.9002762742020817, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 12 with value: 888.8628131315777.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 888.8628, MAE: 484.2462, R²: -0.0169 in 1.64 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 125, 'max_depth': 27, 'learning_rate': 0.013701391237281266, 'subsample': 0.8894129372457792, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:31,598] Trial 13 finished with value: 887.2121640924657 and parameters: {'objective': 'reg:linear', 'n_estimators': 125, 'max_depth': 27, 'learning_rate': 0.013701391237281266, 'subsample': 0.8894129372457792, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 13 with value: 887.2121640924657.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 887.2122, MAE: 477.6686, R²: -0.0132 in 1.57 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 116, 'max_depth': 26, 'learning_rate': 0.010010020990636914, 'subsample': 0.8864846251658632, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:33,133] Trial 14 finished with value: 886.2578935375276 and parameters: {'objective': 'reg:linear', 'n_estimators': 116, 'max_depth': 26, 'learning_rate': 0.010010020990636914, 'subsample': 0.8864846251658632, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 14 with value: 886.2578935375276.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 886.2579, MAE: 473.3985, R²: -0.0110 in 1.53 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_overige_personeelskosten: 24.22 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_overige_personeelskosten: {'objective': 'reg:linear', 'n_estimators': 116, 'max_depth': 26, 'learning_rate': 0.010010020990636914, 'subsample': 0.8864846251658632, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:34,646] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_sociale_lasten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 266, 'max_depth': 24, 'learning_rate': 0.11555712579683777, 'subsample': 0.9847083668696202, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:35,587] Trial 0 finished with value: 687.8307106645743 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 266, 'max_depth': 24, 'learning_rate': 0.11555712579683777, 'subsample': 0.9847083668696202, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 0 with value: 687.8307106645743.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 687.8307, MAE: 522.0867, R²: 0.0932 in 0.94 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 28, 'learning_rate': 0.18945417653710353, 'subsample': 0.8222659933294039, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:36,489] Trial 1 finished with value: 872.380877808923 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 28, 'learning_rate': 0.18945417653710353, 'subsample': 0.8222659933294039, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 687.8307106645743.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 872.3809, MAE: 675.6040, R²: -0.4587 in 0.90 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.07868222128489333, 'subsample': 0.5395356504593892, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:37,345] Trial 2 finished with value: 638.9841760351608 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.07868222128489333, 'subsample': 0.5395356504593892, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 638.9841760351608.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 638.9842, MAE: 486.6297, R²: 0.2174 in 0.85 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 273, 'max_depth': 13, 'learning_rate': 0.1606837241849188, 'subsample': 0.5007695653878639, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:38,227] Trial 3 finished with value: 2439.4147216385054 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 273, 'max_depth': 13, 'learning_rate': 0.1606837241849188, 'subsample': 0.5007695653878639, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 638.9841760351608.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 2439.4147, MAE: 1949.9987, R²: -10.4060 in 0.88 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.0679380413343631, 'subsample': 0.5650893699555776, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:39,188] Trial 4 finished with value: 757.7995299681836 and parameters: {'objective': 'reg:linear', 'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.0679380413343631, 'subsample': 0.5650893699555776, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 638.9841760351608.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 757.7995, MAE: 575.8580, R²: -0.1007 in 0.96 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.01220694006958395, 'subsample': 0.5418149241702932, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:39,948] Trial 5 finished with value: 1719.0132853704188 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.01220694006958395, 'subsample': 0.5418149241702932, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 638.9841760351608.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1719.0133, MAE: 1436.2787, R²: -4.6640 in 0.76 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 229, 'max_depth': 22, 'learning_rate': 0.08561795483352248, 'subsample': 0.5178560572321306, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:40,873] Trial 6 finished with value: 637.7397394601238 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 229, 'max_depth': 22, 'learning_rate': 0.08561795483352248, 'subsample': 0.5178560572321306, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 637.7397, MAE: 474.7220, R²: 0.2204 in 0.92 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 267, 'max_depth': 20, 'learning_rate': 0.042314403999150624, 'subsample': 0.7271422659852412, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:41,909] Trial 7 finished with value: 661.4812639145571 and parameters: {'objective': 'reg:linear', 'n_estimators': 267, 'max_depth': 20, 'learning_rate': 0.042314403999150624, 'subsample': 0.7271422659852412, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 661.4813, MAE: 496.9050, R²: 0.1613 in 1.03 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 253, 'max_depth': 17, 'learning_rate': 0.16747121014839922, 'subsample': 0.8534193636091163, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:42,864] Trial 8 finished with value: 1937.3916497015603 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 253, 'max_depth': 17, 'learning_rate': 0.16747121014839922, 'subsample': 0.8534193636091163, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 1937.3916, MAE: 1566.0087, R²: -6.1945 in 0.95 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 87, 'max_depth': 8, 'learning_rate': 0.013630781213291742, 'subsample': 0.5086446602369612, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:43,670] Trial 9 finished with value: 1688.1520875067308 and parameters: {'objective': 'reg:linear', 'n_estimators': 87, 'max_depth': 8, 'learning_rate': 0.013630781213291742, 'subsample': 0.5086446602369612, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1688.1521, MAE: 1436.0853, R²: -4.4624 in 0.80 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 109, 'max_depth': 22, 'learning_rate': 0.11564958075679432, 'subsample': 0.6517954542997846, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:44,572] Trial 10 finished with value: 744.7136962529067 and parameters: {'objective': 'reg:linear', 'n_estimators': 109, 'max_depth': 22, 'learning_rate': 0.11564958075679432, 'subsample': 0.6517954542997846, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 744.7137, MAE: 566.5780, R²: -0.0630 in 0.90 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 151, 'max_depth': 15, 'learning_rate': 0.0818871765859744, 'subsample': 0.6333119629717013, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:45,477] Trial 11 finished with value: 682.700725518388 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 151, 'max_depth': 15, 'learning_rate': 0.0818871765859744, 'subsample': 0.6333119629717013, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 682.7007, MAE: 513.7603, R²: 0.1066 in 0.90 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 153, 'max_depth': 30, 'learning_rate': 0.08636790454857615, 'subsample': 0.6318438697164839, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:46,336] Trial 12 finished with value: 652.2997331135435 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 153, 'max_depth': 30, 'learning_rate': 0.08636790454857615, 'subsample': 0.6318438697164839, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 6 with value: 637.7397394601238.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 652.2997, MAE: 477.3120, R²: 0.1844 in 0.86 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 213, 'max_depth': 25, 'learning_rate': 0.050668886056654684, 'subsample': 0.5964600909736242, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:47,383] Trial 13 finished with value: 622.9336352079034 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 213, 'max_depth': 25, 'learning_rate': 0.050668886056654684, 'subsample': 0.5964600909736242, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 13 with value: 622.9336352079034.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 622.9336, MAE: 464.8787, R²: 0.2562 in 1.05 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 229, 'max_depth': 26, 'learning_rate': 0.05218490244298289, 'subsample': 0.7367592859050967, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:48,388] Trial 14 finished with value: 700.0889490438577 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 229, 'max_depth': 26, 'learning_rate': 0.05218490244298289, 'subsample': 0.7367592859050967, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 13 with value: 622.9336352079034.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 700.0889, MAE: 540.0633, R²: 0.0606 in 1.00 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_sociale_lasten: 13.74 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_sociale_lasten: {'objective': 'reg:squarederror', 'n_estimators': 213, 'max_depth': 25, 'learning_rate': 0.050668886056654684, 'subsample': 0.5964600909736242, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:49,275] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_exploitatie-_en_machinekosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 123, 'max_depth': 18, 'learning_rate': 0.18639070288989526, 'subsample': 0.570783676633502, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:50,290] Trial 0 finished with value: 1894.8276954404346 and parameters: {'objective': 'reg:linear', 'n_estimators': 123, 'max_depth': 18, 'learning_rate': 0.18639070288989526, 'subsample': 0.570783676633502, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 1894.8276954404346.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1894.8277, MAE: 1434.0927, R²: -1.0699 in 1.01 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 146, 'max_depth': 12, 'learning_rate': 0.09791151828942711, 'subsample': 0.7424166054894559, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:51,257] Trial 1 finished with value: 1380.4367745743727 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 146, 'max_depth': 12, 'learning_rate': 0.09791151828942711, 'subsample': 0.7424166054894559, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 1380.4367745743727.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1380.4368, MAE: 1015.9727, R²: -0.0986 in 0.97 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 227, 'max_depth': 10, 'learning_rate': 0.06282008699836776, 'subsample': 0.9392428878057365, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:52,368] Trial 2 finished with value: 1263.8813393412909 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 227, 'max_depth': 10, 'learning_rate': 0.06282008699836776, 'subsample': 0.9392428878057365, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 2 with value: 1263.8813393412909.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1263.8813, MAE: 944.8622, R²: 0.0791 in 1.11 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.18407343649064886, 'subsample': 0.5899458620570106, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:53,454] Trial 3 finished with value: 27271.07011415037 and parameters: {'objective': 'reg:linear', 'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.18407343649064886, 'subsample': 0.5899458620570106, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 1263.8813393412909.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 27271.0701, MAE: 19076.3630, R²: -427.7677 in 1.08 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.17808212738521756, 'subsample': 0.8194312939138588, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:54,426] Trial 4 finished with value: 27996.917316377887 and parameters: {'objective': 'reg:linear', 'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.17808212738521756, 'subsample': 0.8194312939138588, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 1263.8813393412909.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 27996.9173, MAE: 20600.0722, R²: -450.8956 in 0.97 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 87, 'max_depth': 22, 'learning_rate': 0.057411657158706456, 'subsample': 0.8775216477130545, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:55,399] Trial 5 finished with value: 1319.5524184645624 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 87, 'max_depth': 22, 'learning_rate': 0.057411657158706456, 'subsample': 0.8775216477130545, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1263.8813393412909.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1319.5524, MAE: 998.9757, R²: -0.0039 in 0.97 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 215, 'max_depth': 14, 'learning_rate': 0.09859563713357766, 'subsample': 0.639159176478376, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:56,510] Trial 6 finished with value: 1220.3951425299967 and parameters: {'objective': 'reg:linear', 'n_estimators': 215, 'max_depth': 14, 'learning_rate': 0.09859563713357766, 'subsample': 0.639159176478376, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1220.3951, MAE: 967.9484, R²: 0.1413 in 1.11 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 178, 'max_depth': 13, 'learning_rate': 0.1589191462353116, 'subsample': 0.7004253739846953, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:57,546] Trial 7 finished with value: 1442.137786790565 and parameters: {'objective': 'reg:linear', 'n_estimators': 178, 'max_depth': 13, 'learning_rate': 0.1589191462353116, 'subsample': 0.7004253739846953, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1442.1378, MAE: 1106.1289, R²: -0.1990 in 1.03 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 212, 'max_depth': 5, 'learning_rate': 0.010951380066862922, 'subsample': 0.7090680278070977, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:58,536] Trial 8 finished with value: 21921.321652810744 and parameters: {'objective': 'reg:linear', 'n_estimators': 212, 'max_depth': 5, 'learning_rate': 0.010951380066862922, 'subsample': 0.7090680278070977, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 21921.3217, MAE: 17538.4389, R²: -276.0455 in 0.99 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 159, 'max_depth': 7, 'learning_rate': 0.18273754547646093, 'subsample': 0.5370462991231723, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:24:59,482] Trial 9 finished with value: 1867.1428693088299 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 159, 'max_depth': 7, 'learning_rate': 0.18273754547646093, 'subsample': 0.5370462991231723, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1867.1429, MAE: 1416.6373, R²: -1.0099 in 0.95 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 286, 'max_depth': 30, 'learning_rate': 0.125967515294589, 'subsample': 0.6534626759290516, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:00,775] Trial 10 finished with value: 23792.642397226784 and parameters: {'objective': 'reg:linear', 'n_estimators': 286, 'max_depth': 30, 'learning_rate': 0.125967515294589, 'subsample': 0.6534626759290516, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 23792.6424, MAE: 19250.5524, R²: -325.3646 in 1.29 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 247, 'max_depth': 14, 'learning_rate': 0.07441839374123857, 'subsample': 0.9550283873138895, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:01,938] Trial 11 finished with value: 1287.8256680251113 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 247, 'max_depth': 14, 'learning_rate': 0.07441839374123857, 'subsample': 0.9550283873138895, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1287.8257, MAE: 945.0100, R²: 0.0438 in 1.16 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 244, 'max_depth': 19, 'learning_rate': 0.035746909200564086, 'subsample': 0.9903983104027231, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:03,035] Trial 12 finished with value: 1270.2053048164237 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 244, 'max_depth': 19, 'learning_rate': 0.035746909200564086, 'subsample': 0.9903983104027231, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1270.2053, MAE: 946.5465, R²: 0.0698 in 1.10 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 11, 'learning_rate': 0.1186223359599858, 'subsample': 0.8320756720109909, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:04,235] Trial 13 finished with value: 1584.1307910367786 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 11, 'learning_rate': 0.1186223359599858, 'subsample': 0.8320756720109909, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1584.1308, MAE: 1169.0024, R²: -0.4468 in 1.20 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 233, 'max_depth': 23, 'learning_rate': 0.08697074399772102, 'subsample': 0.6414063001087001, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:05,535] Trial 14 finished with value: 1288.3786894566153 and parameters: {'objective': 'reg:linear', 'n_estimators': 233, 'max_depth': 23, 'learning_rate': 0.08697074399772102, 'subsample': 0.6414063001087001, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 6 with value: 1220.3951425299967.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1288.3787, MAE: 1012.4522, R²: 0.0430 in 1.30 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_exploitatie-_en_machinekosten: 16.26 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_exploitatie-_en_machinekosten: {'objective': 'reg:linear', 'n_estimators': 215, 'max_depth': 14, 'learning_rate': 0.09859563713357766, 'subsample': 0.639159176478376, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:06,552] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_kostprijs_van_de_omzet\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 212, 'max_depth': 8, 'learning_rate': 0.10337483439066708, 'subsample': 0.9643951282898229, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:07,879] Trial 0 finished with value: 1455.2608590000284 and parameters: {'objective': 'reg:linear', 'n_estimators': 212, 'max_depth': 8, 'learning_rate': 0.10337483439066708, 'subsample': 0.9643951282898229, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1455.2608590000284.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1455.2609, MAE: 1279.7283, R²: -0.2988 in 1.33 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 115, 'max_depth': 22, 'learning_rate': 0.15496842034127714, 'subsample': 0.8099214386739788, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:09,024] Trial 1 finished with value: 1701.062838641869 and parameters: {'objective': 'reg:linear', 'n_estimators': 115, 'max_depth': 22, 'learning_rate': 0.15496842034127714, 'subsample': 0.8099214386739788, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1455.2608590000284.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1701.0628, MAE: 1471.1225, R²: -0.7746 in 1.14 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 141, 'max_depth': 20, 'learning_rate': 0.14493895721481131, 'subsample': 0.810555909140322, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:10,213] Trial 2 finished with value: 1386.2003566208723 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 141, 'max_depth': 20, 'learning_rate': 0.14493895721481131, 'subsample': 0.810555909140322, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 1386.2003566208723.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 1386.2004, MAE: 1145.5650, R²: -0.1785 in 1.19 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.09137788475685532, 'subsample': 0.75216479539967, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:11,375] Trial 3 finished with value: 1325.9503850658402 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.09137788475685532, 'subsample': 0.75216479539967, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 3 with value: 1325.9503850658402.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1325.9504, MAE: 1058.9444, R²: -0.0782 in 1.16 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 72, 'max_depth': 6, 'learning_rate': 0.03173429678929188, 'subsample': 0.885057013200389, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:12,475] Trial 4 finished with value: 1291.4962896360755 and parameters: {'objective': 'reg:linear', 'n_estimators': 72, 'max_depth': 6, 'learning_rate': 0.03173429678929188, 'subsample': 0.885057013200389, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1291.4963, MAE: 1034.6777, R²: -0.0229 in 1.10 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 231, 'max_depth': 21, 'learning_rate': 0.11973639499529103, 'subsample': 0.5894118377670625, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:13,706] Trial 5 finished with value: 1966.857703423047 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 231, 'max_depth': 21, 'learning_rate': 0.11973639499529103, 'subsample': 0.5894118377670625, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1966.8577, MAE: 1627.8835, R²: -1.3725 in 1.23 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 177, 'max_depth': 15, 'learning_rate': 0.024513753171567627, 'subsample': 0.8226856420242215, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:14,980] Trial 6 finished with value: 1480.3218483956452 and parameters: {'objective': 'reg:linear', 'n_estimators': 177, 'max_depth': 15, 'learning_rate': 0.024513753171567627, 'subsample': 0.8226856420242215, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1480.3218, MAE: 1306.6163, R²: -0.3439 in 1.27 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 204, 'max_depth': 22, 'learning_rate': 0.14498688630621312, 'subsample': 0.928232387560435, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:16,354] Trial 7 finished with value: 1452.6897791876454 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 204, 'max_depth': 22, 'learning_rate': 0.14498688630621312, 'subsample': 0.928232387560435, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1452.6898, MAE: 1252.1469, R²: -0.2942 in 1.37 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 221, 'max_depth': 13, 'learning_rate': 0.055099631603755236, 'subsample': 0.7287420534335401, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:17,651] Trial 8 finished with value: 1544.983891291427 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 221, 'max_depth': 13, 'learning_rate': 0.055099631603755236, 'subsample': 0.7287420534335401, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 1544.9839, MAE: 1355.9204, R²: -0.4639 in 1.30 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 260, 'max_depth': 14, 'learning_rate': 0.14185383013354957, 'subsample': 0.8735368308821487, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:19,031] Trial 9 finished with value: 1360.863849077122 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 260, 'max_depth': 14, 'learning_rate': 0.14185383013354957, 'subsample': 0.8735368308821487, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1360.8638, MAE: 1148.8008, R²: -0.1358 in 1.38 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 29, 'learning_rate': 0.1969193761663351, 'subsample': 0.5086027064837717, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:20,119] Trial 10 finished with value: 1426.8883204174565 and parameters: {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 29, 'learning_rate': 0.1969193761663351, 'subsample': 0.5086027064837717, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1426.8883, MAE: 1073.9506, R²: -0.2487 in 1.09 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 55, 'max_depth': 6, 'learning_rate': 0.0683605403592299, 'subsample': 0.695519970180545, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:21,268] Trial 11 finished with value: 1317.675349245152 and parameters: {'objective': 'reg:linear', 'n_estimators': 55, 'max_depth': 6, 'learning_rate': 0.0683605403592299, 'subsample': 0.695519970180545, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1317.6753, MAE: 1044.1050, R²: -0.0648 in 1.15 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 102, 'max_depth': 9, 'learning_rate': 0.017660121623172556, 'subsample': 0.6823433762236455, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:22,433] Trial 12 finished with value: 1299.2678825047333 and parameters: {'objective': 'reg:linear', 'n_estimators': 102, 'max_depth': 9, 'learning_rate': 0.017660121623172556, 'subsample': 0.6823433762236455, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1299.2679, MAE: 1042.1163, R²: -0.0353 in 1.16 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 104, 'max_depth': 10, 'learning_rate': 0.01466899496186315, 'subsample': 0.6462469060137256, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:23,649] Trial 13 finished with value: 1298.4451351472267 and parameters: {'objective': 'reg:linear', 'n_estimators': 104, 'max_depth': 10, 'learning_rate': 0.01466899496186315, 'subsample': 0.6462469060137256, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1298.4451, MAE: 1036.8367, R²: -0.0340 in 1.21 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 140, 'max_depth': 11, 'learning_rate': 0.044947746315272825, 'subsample': 0.6152563182300795, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:24,782] Trial 14 finished with value: 1322.0476791452465 and parameters: {'objective': 'reg:linear', 'n_estimators': 140, 'max_depth': 11, 'learning_rate': 0.044947746315272825, 'subsample': 0.6152563182300795, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 1291.4962896360755.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1322.0477, MAE: 1066.2200, R²: -0.0719 in 1.13 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_kostprijs_van_de_omzet: 18.23 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_kostprijs_van_de_omzet: {'objective': 'reg:linear', 'n_estimators': 72, 'max_depth': 6, 'learning_rate': 0.03173429678929188, 'subsample': 0.885057013200389, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:25,830] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_kantoorkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 17, 'learning_rate': 0.09825229336568266, 'subsample': 0.5800002909252282, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:27,240] Trial 0 finished with value: 618.0065678594851 and parameters: {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 17, 'learning_rate': 0.09825229336568266, 'subsample': 0.5800002909252282, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 618.0065678594851.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 618.0066, MAE: 489.7086, R²: -0.2807 in 1.41 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 100, 'max_depth': 23, 'learning_rate': 0.06143717890155539, 'subsample': 0.5402899542483036, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:28,678] Trial 1 finished with value: 574.9621903386759 and parameters: {'objective': 'reg:linear', 'n_estimators': 100, 'max_depth': 23, 'learning_rate': 0.06143717890155539, 'subsample': 0.5402899542483036, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 574.9621903386759.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 574.9622, MAE: 397.4840, R²: -0.1086 in 1.44 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 121, 'max_depth': 10, 'learning_rate': 0.07031154460802691, 'subsample': 0.9432083987544972, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:30,111] Trial 2 finished with value: 552.7575155943443 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 121, 'max_depth': 10, 'learning_rate': 0.07031154460802691, 'subsample': 0.9432083987544972, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 552.7575155943443.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 552.7575, MAE: 389.0529, R²: -0.0246 in 1.43 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 93, 'max_depth': 7, 'learning_rate': 0.0906925734638538, 'subsample': 0.5641365338315182, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:31,569] Trial 3 finished with value: 591.1373168704758 and parameters: {'objective': 'reg:linear', 'n_estimators': 93, 'max_depth': 7, 'learning_rate': 0.0906925734638538, 'subsample': 0.5641365338315182, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 552.7575155943443.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 591.1373, MAE: 464.3416, R²: -0.1718 in 1.46 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 168, 'max_depth': 7, 'learning_rate': 0.04154545446674242, 'subsample': 0.5095709643474082, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:32,986] Trial 4 finished with value: 627.6508978382353 and parameters: {'objective': 'reg:linear', 'n_estimators': 168, 'max_depth': 7, 'learning_rate': 0.04154545446674242, 'subsample': 0.5095709643474082, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 2 with value: 552.7575155943443.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 627.6509, MAE: 470.6208, R²: -0.3210 in 1.42 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 178, 'max_depth': 19, 'learning_rate': 0.05284104788198375, 'subsample': 0.7418227514914405, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:34,567] Trial 5 finished with value: 566.1898033457495 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 178, 'max_depth': 19, 'learning_rate': 0.05284104788198375, 'subsample': 0.7418227514914405, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 2 with value: 552.7575155943443.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 566.1898, MAE: 436.5657, R²: -0.0750 in 1.58 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 204, 'max_depth': 30, 'learning_rate': 0.16508227420466234, 'subsample': 0.7775833067328018, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:36,209] Trial 6 finished with value: 562.780669389146 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 204, 'max_depth': 30, 'learning_rate': 0.16508227420466234, 'subsample': 0.7775833067328018, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 2 with value: 552.7575155943443.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 562.7807, MAE: 454.4251, R²: -0.0621 in 1.64 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 235, 'max_depth': 27, 'learning_rate': 0.0431551451535345, 'subsample': 0.823344399887355, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:37,992] Trial 7 finished with value: 549.5053480133183 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 235, 'max_depth': 27, 'learning_rate': 0.0431551451535345, 'subsample': 0.823344399887355, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 7 with value: 549.5053480133183.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 549.5053, MAE: 412.0156, R²: -0.0126 in 1.78 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 242, 'max_depth': 25, 'learning_rate': 0.13356582074571835, 'subsample': 0.8901692504261591, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:39,790] Trial 8 finished with value: 556.8306059111379 and parameters: {'objective': 'reg:linear', 'n_estimators': 242, 'max_depth': 25, 'learning_rate': 0.13356582074571835, 'subsample': 0.8901692504261591, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 7 with value: 549.5053480133183.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 556.8306, MAE: 408.0625, R²: -0.0397 in 1.80 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 180, 'max_depth': 22, 'learning_rate': 0.16735978062477552, 'subsample': 0.9120249341750661, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:41,268] Trial 9 finished with value: 549.0204823065014 and parameters: {'objective': 'reg:linear', 'n_estimators': 180, 'max_depth': 22, 'learning_rate': 0.16735978062477552, 'subsample': 0.9120249341750661, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 9 with value: 549.0204823065014.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 549.0205, MAE: 409.1563, R²: -0.0108 in 1.48 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 296, 'max_depth': 15, 'learning_rate': 0.19763625612030442, 'subsample': 0.9886693931872558, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:43,197] Trial 10 finished with value: 569.0638375674421 and parameters: {'objective': 'reg:linear', 'n_estimators': 296, 'max_depth': 15, 'learning_rate': 0.19763625612030442, 'subsample': 0.9886693931872558, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 9 with value: 549.0204823065014.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 569.0638, MAE: 390.9310, R²: -0.0859 in 1.93 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 240, 'max_depth': 30, 'learning_rate': 0.012348580232827727, 'subsample': 0.8296213775881288, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:44,890] Trial 11 finished with value: 545.9741298598226 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 240, 'max_depth': 30, 'learning_rate': 0.012348580232827727, 'subsample': 0.8296213775881288, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 11 with value: 545.9741298598226.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 545.9741, MAE: 401.0813, R²: 0.0004 in 1.69 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 281, 'max_depth': 30, 'learning_rate': 0.012842726521721632, 'subsample': 0.6875193357930894, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:46,611] Trial 12 finished with value: 552.9379182810815 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 281, 'max_depth': 30, 'learning_rate': 0.012842726521721632, 'subsample': 0.6875193357930894, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 11 with value: 545.9741298598226.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 552.9379, MAE: 412.5660, R²: -0.0252 in 1.72 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 152, 'max_depth': 21, 'learning_rate': 0.13537429508390564, 'subsample': 0.87052615464749, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:48,135] Trial 13 finished with value: 562.9621186824461 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 152, 'max_depth': 21, 'learning_rate': 0.13537429508390564, 'subsample': 0.87052615464749, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 11 with value: 545.9741298598226.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 562.9621, MAE: 423.3421, R²: -0.0628 in 1.52 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 227, 'max_depth': 13, 'learning_rate': 0.19899886547228457, 'subsample': 0.6755729252458333, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:49,853] Trial 14 finished with value: 700.9037746401156 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 227, 'max_depth': 13, 'learning_rate': 0.19899886547228457, 'subsample': 0.6755729252458333, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 11 with value: 545.9741298598226.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 700.9038, MAE: 513.0749, R²: -0.6474 in 1.72 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_kantoorkosten: 24.02 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_kantoorkosten: {'objective': 'reg:squarederror', 'n_estimators': 240, 'max_depth': 30, 'learning_rate': 0.012348580232827727, 'subsample': 0.8296213775881288, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:51,497] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_verkoopkosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 18, 'learning_rate': 0.13564350703431424, 'subsample': 0.9565031907796134, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:52,419] Trial 0 finished with value: 357.47250156032266 and parameters: {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 18, 'learning_rate': 0.13564350703431424, 'subsample': 0.9565031907796134, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 357.47250156032266.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 357.4725, MAE: 263.8931, R²: -0.2885 in 0.92 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 18, 'learning_rate': 0.01492672071738491, 'subsample': 0.9924154028295469, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:53,491] Trial 1 finished with value: 325.9257448151854 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 18, 'learning_rate': 0.01492672071738491, 'subsample': 0.9924154028295469, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 325.9257448151854.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 325.9257, MAE: 228.9708, R²: -0.0711 in 1.07 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 30, 'learning_rate': 0.18040105938598172, 'subsample': 0.968266267779718, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:54,639] Trial 2 finished with value: 347.15590505988615 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 30, 'learning_rate': 0.18040105938598172, 'subsample': 0.968266267779718, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 1 with value: 325.9257448151854.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 347.1559, MAE: 265.1618, R²: -0.2152 in 1.15 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 210, 'max_depth': 20, 'learning_rate': 0.05475369559609145, 'subsample': 0.5812175630965, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:55,674] Trial 3 finished with value: 349.66655272174324 and parameters: {'objective': 'reg:linear', 'n_estimators': 210, 'max_depth': 20, 'learning_rate': 0.05475369559609145, 'subsample': 0.5812175630965, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 325.9257448151854.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 349.6666, MAE: 242.6462, R²: -0.2329 in 1.03 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.11271706611603863, 'subsample': 0.8587100937219341, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:56,685] Trial 4 finished with value: 324.80104670950453 and parameters: {'objective': 'reg:linear', 'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.11271706611603863, 'subsample': 0.8587100937219341, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 324.80104670950453.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 324.8010, MAE: 236.4210, R²: -0.0637 in 1.01 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.15670519135756783, 'subsample': 0.5405750133428103, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:57,784] Trial 5 finished with value: 330.43165377334026 and parameters: {'objective': 'reg:linear', 'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.15670519135756783, 'subsample': 0.5405750133428103, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 324.80104670950453.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 330.4317, MAE: 212.8513, R²: -0.1009 in 1.10 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 99, 'max_depth': 23, 'learning_rate': 0.04549561914187397, 'subsample': 0.7310525118584814, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:58,714] Trial 6 finished with value: 341.9870545383185 and parameters: {'objective': 'reg:linear', 'n_estimators': 99, 'max_depth': 23, 'learning_rate': 0.04549561914187397, 'subsample': 0.7310525118584814, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 324.80104670950453.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 341.9871, MAE: 245.6928, R²: -0.1793 in 0.93 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 17, 'learning_rate': 0.17864018084417474, 'subsample': 0.9058486184062771, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:25:59,783] Trial 7 finished with value: 366.90400543620154 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 17, 'learning_rate': 0.17864018084417474, 'subsample': 0.9058486184062771, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 4 with value: 324.80104670950453.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 366.9040, MAE: 293.0318, R²: -0.3574 in 1.07 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.19413075457859194, 'subsample': 0.7331724866631488, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:00,813] Trial 8 finished with value: 318.24205053821726 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.19413075457859194, 'subsample': 0.7331724866631488, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 8 with value: 318.24205053821726.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 318.2421, MAE: 218.9818, R²: -0.0212 in 1.03 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 8, 'learning_rate': 0.1789138345224656, 'subsample': 0.9242302071764448, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:01,708] Trial 9 finished with value: 369.9463919480559 and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 8, 'learning_rate': 0.1789138345224656, 'subsample': 0.9242302071764448, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 8 with value: 318.24205053821726.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 369.9464, MAE: 289.5644, R²: -0.3800 in 0.89 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.08558417463501194, 'subsample': 0.7281194347501879, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:02,774] Trial 10 finished with value: 339.63971815545653 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.08558417463501194, 'subsample': 0.7281194347501879, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 8 with value: 318.24205053821726.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 339.6397, MAE: 249.0646, R²: -0.1632 in 1.06 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 212, 'max_depth': 12, 'learning_rate': 0.10449760477017196, 'subsample': 0.8241743017681624, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:03,963] Trial 11 finished with value: 320.8039091415702 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 212, 'max_depth': 12, 'learning_rate': 0.10449760477017196, 'subsample': 0.8241743017681624, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 8 with value: 318.24205053821726.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 320.8039, MAE: 237.3649, R²: -0.0377 in 1.19 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 243, 'max_depth': 12, 'learning_rate': 0.10212389316812427, 'subsample': 0.7994339970315004, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:05,179] Trial 12 finished with value: 318.19008464543117 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 243, 'max_depth': 12, 'learning_rate': 0.10212389316812427, 'subsample': 0.7994339970315004, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 12 with value: 318.19008464543117.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 318.1901, MAE: 212.4864, R²: -0.0209 in 1.21 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 282, 'max_depth': 14, 'learning_rate': 0.13820417998557544, 'subsample': 0.6478507128121819, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:06,434] Trial 13 finished with value: 330.5432268484481 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 282, 'max_depth': 14, 'learning_rate': 0.13820417998557544, 'subsample': 0.6478507128121819, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 12 with value: 318.19008464543117.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 330.5432, MAE: 235.5769, R²: -0.1017 in 1.25 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 244, 'max_depth': 5, 'learning_rate': 0.08334876417832393, 'subsample': 0.7923981447723379, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:07,582] Trial 14 finished with value: 319.30313424465714 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 244, 'max_depth': 5, 'learning_rate': 0.08334876417832393, 'subsample': 0.7923981447723379, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 12 with value: 318.19008464543117.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 319.3031, MAE: 220.8856, R²: -0.0280 in 1.15 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_verkoopkosten: 16.09 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_verkoopkosten: {'objective': 'reg:squarederror', 'n_estimators': 243, 'max_depth': 12, 'learning_rate': 0.10212389316812427, 'subsample': 0.7994339970315004, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:08,706] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_huisvestingskosten\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 298, 'max_depth': 13, 'learning_rate': 0.16138907997324947, 'subsample': 0.8130352157971954, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:09,735] Trial 0 finished with value: 1959.134735892353 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 298, 'max_depth': 13, 'learning_rate': 0.16138907997324947, 'subsample': 0.8130352157971954, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 0 with value: 1959.134735892353.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 1959.1347, MAE: 1425.4587, R²: -1.6459 in 1.03 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 185, 'max_depth': 7, 'learning_rate': 0.13727508177149583, 'subsample': 0.5953746279399752, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:10,665] Trial 1 finished with value: 1433.5484889043692 and parameters: {'objective': 'reg:linear', 'n_estimators': 185, 'max_depth': 7, 'learning_rate': 0.13727508177149583, 'subsample': 0.5953746279399752, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 1433.5484889043692.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 1433.5485, MAE: 1109.7747, R²: -0.4166 in 0.93 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 12, 'learning_rate': 0.09556143253980473, 'subsample': 0.7161845259726605, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:11,659] Trial 2 finished with value: 3009.725380058785 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 12, 'learning_rate': 0.09556143253980473, 'subsample': 0.7161845259726605, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 1 with value: 1433.5484889043692.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 3009.7254, MAE: 2540.6450, R²: -5.2444 in 0.99 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 247, 'max_depth': 18, 'learning_rate': 0.0322345214903056, 'subsample': 0.627936623454588, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:12,616] Trial 3 finished with value: 1483.930140135759 and parameters: {'objective': 'reg:linear', 'n_estimators': 247, 'max_depth': 18, 'learning_rate': 0.0322345214903056, 'subsample': 0.627936623454588, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}. Best is trial 1 with value: 1433.5484889043692.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 1483.9301, MAE: 1156.6350, R²: -0.5180 in 0.95 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 26, 'learning_rate': 0.1024474780896187, 'subsample': 0.5927994446510682, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:13,591] Trial 4 finished with value: 1483.831881814783 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 233, 'max_depth': 26, 'learning_rate': 0.1024474780896187, 'subsample': 0.5927994446510682, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 1 with value: 1433.5484889043692.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 1483.8319, MAE: 1151.6310, R²: -0.5178 in 0.97 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 19, 'learning_rate': 0.16936155433712585, 'subsample': 0.992733082983777, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:14,527] Trial 5 finished with value: 1272.8183850233045 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 19, 'learning_rate': 0.16936155433712585, 'subsample': 0.992733082983777, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 1272.8183850233045.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 1272.8184, MAE: 1023.7773, R²: -0.1168 in 0.93 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 186, 'max_depth': 9, 'learning_rate': 0.07867540451303473, 'subsample': 0.6583425461398813, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:15,438] Trial 6 finished with value: 1329.6672610256048 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 186, 'max_depth': 9, 'learning_rate': 0.07867540451303473, 'subsample': 0.6583425461398813, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 1272.8183850233045.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 1329.6673, MAE: 1025.4050, R²: -0.2188 in 0.91 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 26, 'learning_rate': 0.08844516854261276, 'subsample': 0.5860247735385881, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:16,382] Trial 7 finished with value: 1368.3033304875544 and parameters: {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 26, 'learning_rate': 0.08844516854261276, 'subsample': 0.5860247735385881, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 1272.8183850233045.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 1368.3033, MAE: 1080.7143, R²: -0.2906 in 0.94 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 29, 'learning_rate': 0.19578739416593038, 'subsample': 0.5168219860476708, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:17,146] Trial 8 finished with value: 1318.615955936375 and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 29, 'learning_rate': 0.19578739416593038, 'subsample': 0.5168219860476708, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 5 with value: 1272.8183850233045.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 1318.6160, MAE: 1029.0983, R²: -0.1986 in 0.76 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 65, 'max_depth': 21, 'learning_rate': 0.0868000260515632, 'subsample': 0.6936986596276307, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:17,855] Trial 9 finished with value: 1731.5764453940037 and parameters: {'objective': 'reg:linear', 'n_estimators': 65, 'max_depth': 21, 'learning_rate': 0.0868000260515632, 'subsample': 0.6936986596276307, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 5 with value: 1272.8183850233045.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 1731.5764, MAE: 1405.3997, R²: -1.0669 in 0.71 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 20, 'learning_rate': 0.19816674773824391, 'subsample': 0.9884191693932957, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:18,788] Trial 10 finished with value: 1268.916877135772 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 20, 'learning_rate': 0.19816674773824391, 'subsample': 0.9884191693932957, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 10 with value: 1268.916877135772.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 1268.9169, MAE: 1035.2047, R²: -0.1100 in 0.93 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 127, 'max_depth': 20, 'learning_rate': 0.19818605847563517, 'subsample': 0.9960731493510898, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:19,653] Trial 11 finished with value: 1266.2259504343344 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 127, 'max_depth': 20, 'learning_rate': 0.19818605847563517, 'subsample': 0.9960731493510898, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1266.2259504343344.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 1266.2260, MAE: 1017.1060, R²: -0.1052 in 0.86 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 111, 'max_depth': 22, 'learning_rate': 0.19653456067324165, 'subsample': 0.9866984629285023, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:20,480] Trial 12 finished with value: 1293.6320113553672 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 111, 'max_depth': 22, 'learning_rate': 0.19653456067324165, 'subsample': 0.9866984629285023, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1266.2259504343344.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 1293.6320, MAE: 1043.6843, R²: -0.1536 in 0.82 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 117, 'max_depth': 15, 'learning_rate': 0.1401158328795037, 'subsample': 0.8710799335993059, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:21,298] Trial 13 finished with value: 1302.4039599090088 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 117, 'max_depth': 15, 'learning_rate': 0.1401158328795037, 'subsample': 0.8710799335993059, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1266.2259504343344.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 1302.4040, MAE: 1003.5753, R²: -0.1693 in 0.82 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 119, 'max_depth': 24, 'learning_rate': 0.1699852256920286, 'subsample': 0.9084162269315837, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:22,141] Trial 14 finished with value: 1304.9031929419132 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 119, 'max_depth': 24, 'learning_rate': 0.1699852256920286, 'subsample': 0.9084162269315837, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 11 with value: 1266.2259504343344.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 1304.9032, MAE: 992.1943, R²: -0.1738 in 0.84 seconds\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_huisvestingskosten: 13.44 seconds\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_huisvestingskosten: {'objective': 'reg:squarederror', 'n_estimators': 127, 'max_depth': 20, 'learning_rate': 0.19818605847563517, 'subsample': 0.9960731493510898, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:23,019] A new study created in memory with name: TrainerXGBoostPattern_day_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 53, 'max_depth': 21, 'learning_rate': 0.17594371865573374, 'subsample': 0.5762025425515267, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:31,871] Trial 0 finished with value: 727.0626999997982 and parameters: {'objective': 'reg:linear', 'n_estimators': 53, 'max_depth': 21, 'learning_rate': 0.17594371865573374, 'subsample': 0.5762025425515267, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 727.0626999997982.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0 completed with RMSE: 727.0627, MAE: 587.5605, R²: -0.1366 in 8.85 seconds\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 171, 'max_depth': 29, 'learning_rate': 0.17250831919127765, 'subsample': 0.6482988671047925, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:41,645] Trial 1 finished with value: 735.1914051658949 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 171, 'max_depth': 29, 'learning_rate': 0.17250831919127765, 'subsample': 0.6482988671047925, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 0 with value: 727.0626999997982.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1 completed with RMSE: 735.1914, MAE: 597.6212, R²: -0.1622 in 9.77 seconds\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 128, 'max_depth': 24, 'learning_rate': 0.04856637046538002, 'subsample': 0.856884117794354, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:26:51,140] Trial 2 finished with value: 735.7774920602046 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 128, 'max_depth': 24, 'learning_rate': 0.04856637046538002, 'subsample': 0.856884117794354, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 0 with value: 727.0626999997982.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2 completed with RMSE: 735.7775, MAE: 596.5305, R²: -0.1640 in 9.49 seconds\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.12852325811853818, 'subsample': 0.6373753053330342, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:00,205] Trial 3 finished with value: 723.6154375687395 and parameters: {'objective': 'reg:linear', 'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.12852325811853818, 'subsample': 0.6373753053330342, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 3 with value: 723.6154375687395.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3 completed with RMSE: 723.6154, MAE: 589.3513, R²: -0.1259 in 9.06 seconds\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 268, 'max_depth': 25, 'learning_rate': 0.05831853515968258, 'subsample': 0.6551130964464049, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:10,815] Trial 4 finished with value: 711.9908697733857 and parameters: {'objective': 'reg:linear', 'n_estimators': 268, 'max_depth': 25, 'learning_rate': 0.05831853515968258, 'subsample': 0.6551130964464049, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4 completed with RMSE: 711.9909, MAE: 576.8606, R²: -0.0900 in 10.61 seconds\n  Trial 5: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 21, 'learning_rate': 0.11857827815573252, 'subsample': 0.6981129527584606, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:20,404] Trial 5 finished with value: 720.913834927467 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 21, 'learning_rate': 0.11857827815573252, 'subsample': 0.6981129527584606, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5 completed with RMSE: 720.9138, MAE: 584.8297, R²: -0.1175 in 9.59 seconds\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 221, 'max_depth': 6, 'learning_rate': 0.144482599547801, 'subsample': 0.7358837312328923, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:30,017] Trial 6 finished with value: 732.3989526820118 and parameters: {'objective': 'reg:linear', 'n_estimators': 221, 'max_depth': 6, 'learning_rate': 0.144482599547801, 'subsample': 0.7358837312328923, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6 completed with RMSE: 732.3990, MAE: 588.1709, R²: -0.1534 in 9.61 seconds\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 152, 'max_depth': 22, 'learning_rate': 0.04961783539048379, 'subsample': 0.9200128828599179, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:39,910] Trial 7 finished with value: 741.7777475943208 and parameters: {'objective': 'reg:linear', 'n_estimators': 152, 'max_depth': 22, 'learning_rate': 0.04961783539048379, 'subsample': 0.9200128828599179, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7 completed with RMSE: 741.7777, MAE: 595.9223, R²: -0.1831 in 9.89 seconds\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 147, 'max_depth': 20, 'learning_rate': 0.18477106054166562, 'subsample': 0.8538921849051722, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:49,456] Trial 8 finished with value: 726.138231402031 and parameters: {'objective': 'reg:linear', 'n_estimators': 147, 'max_depth': 20, 'learning_rate': 0.18477106054166562, 'subsample': 0.8538921849051722, 'prediction_mode': 'Zero', 'outlier_removal': 0}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8 completed with RMSE: 726.1382, MAE: 589.6736, R²: -0.1337 in 9.54 seconds\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.1570349689318597, 'subsample': 0.5155167503967146, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:27:57,926] Trial 9 finished with value: 743.1006886692315 and parameters: {'objective': 'reg:linear', 'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.1570349689318597, 'subsample': 0.5155167503967146, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9 completed with RMSE: 743.1007, MAE: 591.6720, R²: -0.1873 in 8.47 seconds\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 291, 'max_depth': 14, 'learning_rate': 0.01647381916334798, 'subsample': 0.9965255645161012, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:28:07,954] Trial 10 finished with value: 773.4650210961565 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 291, 'max_depth': 14, 'learning_rate': 0.01647381916334798, 'subsample': 0.9965255645161012, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10 completed with RMSE: 773.4650, MAE: 613.2822, R²: -0.2863 in 10.03 seconds\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 288, 'max_depth': 29, 'learning_rate': 0.08870656113204221, 'subsample': 0.741974143981537, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:28:19,031] Trial 11 finished with value: 729.5910785051705 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 288, 'max_depth': 29, 'learning_rate': 0.08870656113204221, 'subsample': 0.741974143981537, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11 completed with RMSE: 729.5911, MAE: 585.4011, R²: -0.1445 in 11.08 seconds\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 248, 'max_depth': 15, 'learning_rate': 0.10138650688113963, 'subsample': 0.6716218844532457, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:28:28,996] Trial 12 finished with value: 717.7838167201294 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 248, 'max_depth': 15, 'learning_rate': 0.10138650688113963, 'subsample': 0.6716218844532457, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12 completed with RMSE: 717.7838, MAE: 583.4862, R²: -0.1078 in 9.96 seconds\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 247, 'max_depth': 14, 'learning_rate': 0.08635304392816599, 'subsample': 0.5833988336107452, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:28:38,543] Trial 13 finished with value: 714.1861153701046 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 247, 'max_depth': 14, 'learning_rate': 0.08635304392816599, 'subsample': 0.5833988336107452, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13 completed with RMSE: 714.1861, MAE: 579.0442, R²: -0.0967 in 9.55 seconds\n  Trial 14: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 247, 'max_depth': 12, 'learning_rate': 0.08165261493591011, 'subsample': 0.5818444739585357, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:28:48,172] Trial 14 finished with value: 726.0262222128497 and parameters: {'objective': 'reg:linear', 'n_estimators': 247, 'max_depth': 12, 'learning_rate': 0.08165261493591011, 'subsample': 0.5818444739585357, 'prediction_mode': 'Zero', 'outlier_removal': 1}. Best is trial 4 with value: 711.9908697733857.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14 completed with RMSE: 726.0262, MAE: 587.4649, R²: -0.1334 in 9.63 seconds\nTotal optimization time for TrainerXGBoostPattern_day_data: 145.15 seconds\nBest hyperparameters for TrainerXGBoostPattern_day_data: {'objective': 'reg:linear', 'n_estimators': 268, 'max_depth': 25, 'learning_rate': 0.05831853515968258, 'subsample': 0.6551130964464049, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:28:58,410] A new study created in memory with name: TrainerXGBoostPattern_weather_data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 0: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 154, 'max_depth': 28, 'learning_rate': 0.02768279387306835, 'subsample': 0.8955483945841087, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:28:58,413] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 154, 'max_depth': 28, 'learning_rate': 0.02768279387306835, 'subsample': 0.8955483945841087, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-2421172219023142-3848143328\", line 36, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost_pattern.py\", line 41, in fit\n    pdf_train = self._preprocessing(pdf_train, True)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/abstract_classes/trainer.py\", line 132, in _preprocessing\n    df = df[relevant_columns]\n         ~~^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:28:59,810] Trial 0 failed with value None.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerXGBoostPattern on dataset weather_data: \"['category', 'value'] not in index\"\n\nResults saved to 'optuna_hpo_results_with_metrics.csv'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trainer</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Best_Hyperparameters</th>\n",
       "      <th>Best_RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Total_Time</th>\n",
       "      <th>Average_Trial_Time</th>\n",
       "      <th>Combined_Performance_Score</th>\n",
       "      <th>Trial_Times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrainerAverageLastYear</td>\n",
       "      <td>week_data_cleaned_algemene_kosten</td>\n",
       "      <td>{'avg_or_med': 'avg', 'time_period': 'week', '...</td>\n",
       "      <td>295.308880</td>\n",
       "      <td>122.717672</td>\n",
       "      <td>-0.127706</td>\n",
       "      <td>0.423952</td>\n",
       "      <td>0.026712</td>\n",
       "      <td>0.683779</td>\n",
       "      <td>[0.0261075496673584, 0.02474689483642578, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrainerAverageLastYear</td>\n",
       "      <td>week_data_cleaned_autokosten</td>\n",
       "      <td>{'avg_or_med': 'avg', 'time_period': 'week', '...</td>\n",
       "      <td>37.215146</td>\n",
       "      <td>30.703704</td>\n",
       "      <td>0.791449</td>\n",
       "      <td>0.238969</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>1.427119</td>\n",
       "      <td>[0.009681224822998047, 0.010091543197631836, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrainerAverageLastYear</td>\n",
       "      <td>week_data_cleaned_exploitatie-_en_machinekosten</td>\n",
       "      <td>{'avg_or_med': 'avg', 'time_period': 'month', ...</td>\n",
       "      <td>395.344125</td>\n",
       "      <td>317.629066</td>\n",
       "      <td>-1.634613</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.688542</td>\n",
       "      <td>[0.01653885841369629, 0.013790130615234375, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrainerAverageLastYear</td>\n",
       "      <td>week_data_cleaned_huisvestingskosten</td>\n",
       "      <td>{'avg_or_med': 'med', 'time_period': 'year', '...</td>\n",
       "      <td>147.548254</td>\n",
       "      <td>60.307692</td>\n",
       "      <td>-0.201018</td>\n",
       "      <td>0.268957</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>1.078605</td>\n",
       "      <td>[0.014884710311889648, 0.013087749481201172, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrainerAverageLastYear</td>\n",
       "      <td>week_data_cleaned_kantoorkosten</td>\n",
       "      <td>{'avg_or_med': 'avg', 'time_period': 'year', '...</td>\n",
       "      <td>359.524693</td>\n",
       "      <td>295.606853</td>\n",
       "      <td>-1.610429</td>\n",
       "      <td>0.291191</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.709557</td>\n",
       "      <td>[0.014386177062988281, 0.014801979064941406, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Trainer  ...                                        Trial_Times\n",
       "0  TrainerAverageLastYear  ...  [0.0261075496673584, 0.02474689483642578, 0.02...\n",
       "1  TrainerAverageLastYear  ...  [0.009681224822998047, 0.010091543197631836, 0...\n",
       "2  TrainerAverageLastYear  ...  [0.01653885841369629, 0.013790130615234375, 0....\n",
       "3  TrainerAverageLastYear  ...  [0.014884710311889648, 0.013087749481201172, 0...\n",
       "4  TrainerAverageLastYear  ...  [0.014386177062988281, 0.014801979064941406, 0...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Hyperparameter optimization with Optuna\n",
    "def perform_optuna_hpo(trainer, train_data, test_data, study_name=\"optuna_hpo\", n_trials=15):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter optimization using Optuna for a given trainer instance.\n",
    "    \"\"\"\n",
    "    trial_times = []\n",
    "\n",
    "    def objective(trial):\n",
    "        # Start timer for the trial\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Define the hyperparameter space based on the trainer's allowed hyperparameters\n",
    "        hyperparameters = {}\n",
    "        if hasattr(trainer, \"space_hyperparameters\"):\n",
    "            for param, values in trainer.space_hyperparameters.items():\n",
    "                if isinstance(values[0], int):\n",
    "                    hyperparameters[param] = trial.suggest_int(param, min(values), max(values))\n",
    "                elif isinstance(values[0], float):\n",
    "                    hyperparameters[param] = trial.suggest_float(param, min(values), max(values))\n",
    "                elif isinstance(values[0], bool):\n",
    "                    hyperparameters[param] = trial.suggest_categorical(param, [True, False])\n",
    "                else:\n",
    "                    hyperparameters[param] = trial.suggest_categorical(param, values)\n",
    "\n",
    "        print(f\"  Trial {trial.number}: Hyperparameters {hyperparameters}\")\n",
    "\n",
    "        # Set the hyperparameters\n",
    "        trainer.hyperparameters = hyperparameters\n",
    "\n",
    "        # Fit the model\n",
    "        trainer.fit(train_data)\n",
    "\n",
    "        # Predict\n",
    "        predictions = trainer.predict(test_data)\n",
    "\n",
    "        # Evaluate metrics\n",
    "        rmse = ((test_data['value'] - predictions) ** 2).mean() ** 0.5\n",
    "        mae = abs(test_data['value'] - predictions).mean()\n",
    "        r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "\n",
    "        # End timer for the trial\n",
    "        trial_time = time.time() - start_time\n",
    "        trial_times.append(trial_time)\n",
    "\n",
    "        print(f\"  Trial {trial.number} completed with RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f} in {trial_time:.2f} seconds\")\n",
    "        return rmse\n",
    "\n",
    "    # Start timer for the entire optimization process\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create a study and optimize\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=study_name)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # End timer for the entire optimization process\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total optimization time for {study_name}: {total_time:.2f} seconds\")\n",
    "\n",
    "    print(f\"Best hyperparameters for {study_name}: {study.best_params}\")\n",
    "    return study.best_params, total_time, trial_times\n",
    "\n",
    "def run_trainers_with_hpo(trainers, data_splits, n_trials=15):\n",
    "    results = []\n",
    "\n",
    "    # Define weights for combined performance score\n",
    "    w1, w2, w3 = 0.5, 0.3, 0.2\n",
    "\n",
    "    for trainer in trainers:\n",
    "        trainer_name = trainer.__class__.__name__\n",
    "        print(f\"\\nProcessing Trainer: {trainer_name}\")\n",
    "        for dataset_name, splits in data_splits.items():\n",
    "            train_data = splits['train']\n",
    "            test_data = splits['test']\n",
    "\n",
    "            print(f\"  Optimizing on Dataset: {dataset_name} (Train: {len(train_data)}, Test: {len(test_data)})\")\n",
    "\n",
    "            try:\n",
    "                # Perform hyperparameter optimization\n",
    "                best_hyperparams, total_time, trial_times = perform_optuna_hpo(\n",
    "                    trainer, train_data, test_data, \n",
    "                    study_name=f\"{trainer_name}_{dataset_name}\", \n",
    "                    n_trials=n_trials\n",
    "                )\n",
    "\n",
    "                # Fit the model with the best hyperparameters\n",
    "                trainer.hyperparameters = best_hyperparams\n",
    "                trainer.fit(train_data)\n",
    "\n",
    "                # Predict on the test dataset\n",
    "                predictions = trainer.predict(test_data)\n",
    "\n",
    "                # Compute metrics\n",
    "                best_rmse = ((test_data['value'] - predictions) ** 2).mean() ** 0.5\n",
    "                mae = abs(test_data['value'] - predictions).mean()\n",
    "                r2 = 1 - (sum((test_data['value'] - predictions) ** 2) / sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "\n",
    "                # Calculate combined performance score\n",
    "                combined_performance_score = (\n",
    "                    w1 * (1 / best_rmse) + w2 * (1 / total_time) + w3 * r2\n",
    "                )\n",
    "\n",
    "                # Store results in a list of dictionaries\n",
    "                results.append({\n",
    "                    \"Trainer\": trainer_name,\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Best_Hyperparameters\": best_hyperparams,\n",
    "                    \"Best_RMSE\": best_rmse,\n",
    "                    \"MAE\": mae,\n",
    "                    \"R2\": r2,\n",
    "                    \"Total_Time\": total_time,\n",
    "                    \"Average_Trial_Time\": np.mean(trial_times),\n",
    "                    \"Combined_Performance_Score\": combined_performance_score,\n",
    "                    \"Trial_Times\": trial_times\n",
    "                })\n",
    "\n",
    "                print(f\"  Added results for {trainer_name} on {dataset_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error with trainer {trainer_name} on dataset {dataset_name}: {e}\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_df.to_csv(\"optuna_hpo_results_with_metrics.csv\", index=False)\n",
    "\n",
    "    print(\"\\nResults saved to 'optuna_hpo_results_with_metrics.csv'\")\n",
    "    return results_df\n",
    "\n",
    "# Run the optimization\n",
    "optuna_results_df = run_trainers_with_hpo(trainers, data_splits, n_trials=15)\n",
    "\n",
    "# Display the results\n",
    "optuna_results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "655b06ad-59c2-4b9a-8f51-42231a0624c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4998c65-7b0a-46a9-be58-f0a94e233d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nProcessing Trainer: TrainerAverageLastYear\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 2 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 4 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 5 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 6 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 8 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 9 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 10 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 11 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 12 completed with RMSE: 296.1720, MAE: 121.3981, R²: -0.1343\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 14 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277\n  Trial 15: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 15 completed with RMSE: 295.3089, MAE: 122.7177, R²: -0.1277\nTotal optimization time: 0.48 seconds\nBest hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 2 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 3 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 4 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 6 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 7 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 8 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 9 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 10 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 11 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 12 completed with RMSE: 92.6319, MAE: 64.0000, R²: -0.2921\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 13 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\n  Trial 15: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 15 completed with RMSE: 37.2151, MAE: 30.7037, R²: 0.7914\nTotal optimization time: 0.13 seconds\nBest hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 1 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 2 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 4 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 5 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 6 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 7 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 8 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 9 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 10 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 11 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 12 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 13 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 397.4713, MAE: 317.2500, R²: -1.6630\n  Trial 15: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 15 completed with RMSE: 395.3441, MAE: 317.6291, R²: -1.6346\nTotal optimization time: 0.20 seconds\nBest hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 1 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 2 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 4 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 6 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 7 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 8 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 10 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 12 completed with RMSE: 147.5745, MAE: 60.5654, R²: -0.2014\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 13 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 14 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\n  Trial 15: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 15 completed with RMSE: 147.5483, MAE: 60.3077, R²: -0.2010\nTotal optimization time: 0.18 seconds\nBest hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 1 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 2 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 3: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 4 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 6 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 7 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 8 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 9 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 10 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 11 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 12 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 13 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 14 completed with RMSE: 359.5247, MAE: 295.6069, R²: -1.6104\n  Trial 15: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 15 completed with RMSE: 360.4504, MAE: 297.2340, R²: -1.6239\nTotal optimization time: 0.25 seconds\nBest hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 1 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 2 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 4 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 5 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 6 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 7 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 8 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 9 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 10: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 10 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 11: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 11 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 12 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 13 completed with RMSE: 525.6161, MAE: 394.1041, R²: -0.0200\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 14 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028\n  Trial 15: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 15 completed with RMSE: 519.7038, MAE: 387.8235, R²: 0.0028\nTotal optimization time: 0.18 seconds\nBest hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 1 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 2 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 3 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 4 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 5 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 6 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 7 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 8 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 9 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 10 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 11 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 12 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798\n  Trial 13: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 13 completed with RMSE: 86.9538, MAE: 67.1709, R²: -1.4798\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 14 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\n  Trial 15: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 15 completed with RMSE: 62.7593, MAE: 29.8276, R²: -0.2918\nTotal optimization time: 1.33 seconds\nBest hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 1 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 2 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 3 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 4 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 5 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 6 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\n  Trial 7: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 7 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 8 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\n  Trial 9: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}\n  Trial 9 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 10 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 11 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 12: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\n  Trial 12 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 13 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 14: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 202.0294, MAE: 66.4619, R²: -0.1094\n  Trial 15: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\n  Trial 15 completed with RMSE: 200.7784, MAE: 66.7244, R²: -0.0957\nTotal optimization time: 0.33 seconds\nBest hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 1: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 1 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 2: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 2 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}\n  Trial 3 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 4: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 4 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 5: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 5 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 6: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}\n  Trial 6 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Trial 7 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008\n  Trial 8: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\n  Trial 8 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008\n  Trial 9: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}\n  Trial 9 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 10: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 10 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 11: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 11 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 12: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\n  Trial 12 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 13: Hyperparameters {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}\n  Trial 13 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\n  Trial 14: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\n  Trial 14 completed with RMSE: 214.7551, MAE: 90.6628, R²: -0.2008\n  Trial 15: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\n  Trial 15 completed with RMSE: 215.5445, MAE: 89.7778, R²: -0.2096\nTotal optimization time: 0.27 seconds\nBest hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Trial 1: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\nError in trial 1: float division by zero\n  Trial 1 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 2: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}\nError in trial 2: float division by zero\n  Trial 2 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 3: Hyperparameters {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}\nError in trial 3: float division by zero\n  Trial 3 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 4: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\nError in trial 4: float division by zero\n  Trial 4 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 5: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}\nError in trial 5: float division by zero\n  Trial 5 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 6: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}\nError in trial 6: float division by zero\n  Trial 6 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 7: Hyperparameters {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}\nError in trial 7: float division by zero\n  Trial 7 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 8: Hyperparameters {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}\nError in trial 8: float division by zero\n  Trial 8 completed with RMSE: inf, \n\n*** WARNING: max output size exceeded, skipping output. ***\n\n²: -0.1724\nTotal optimization time: 17.88 seconds\nBest hyperparameters: {'objective': 'reg:linear', 'n_estimators': 78, 'max_depth': 11, 'learning_rate': 0.014507979827771553, 'subsample': 0.8361903925809371, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Added results for TrainerXGBoostPattern on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 158, 'max_depth': 21, 'learning_rate': 0.1427819163569789, 'subsample': 0.5934013110570772, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 756.7201, MAE: 523.2917, R²: -0.9202\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.03713588488367196, 'subsample': 0.7498506017315507, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 552.4559, MAE: 414.0362, R²: -0.0235\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 142, 'max_depth': 25, 'learning_rate': 0.06272314137299555, 'subsample': 0.56805093023966, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 616.2813, MAE: 462.4292, R²: -0.2736\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 73, 'max_depth': 26, 'learning_rate': 0.1211545032116953, 'subsample': 0.7028356005480851, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 591.0680, MAE: 417.8648, R²: -0.1715\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 143, 'max_depth': 28, 'learning_rate': 0.02450296302555409, 'subsample': 0.9344075730279804, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 563.4436, MAE: 375.4251, R²: -0.0646\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 226, 'max_depth': 26, 'learning_rate': 0.10665175372200589, 'subsample': 0.596897879731284, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 686.9140, MAE: 483.1562, R²: -0.5823\n  Trial 7: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 75, 'max_depth': 21, 'learning_rate': 0.06133473033569343, 'subsample': 0.5954155719567022, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 7 completed with RMSE: 561.9682, MAE: 403.8919, R²: -0.0590\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 282, 'max_depth': 8, 'learning_rate': 0.18166625378452342, 'subsample': 0.5861248680163547, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 898.1550, MAE: 672.3440, R²: -1.7051\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 112, 'max_depth': 21, 'learning_rate': 0.13038443690797785, 'subsample': 0.8897337694858868, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 537.9356, MAE: 374.1283, R²: 0.0296\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 8, 'learning_rate': 0.10439790672401782, 'subsample': 0.8457694192385476, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 539.4622, MAE: 409.2076, R²: 0.0241\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 94, 'max_depth': 5, 'learning_rate': 0.1430886518605997, 'subsample': 0.5305340319871279, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 674.1195, MAE: 517.3646, R²: -0.5239\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 68, 'max_depth': 22, 'learning_rate': 0.02170166998409824, 'subsample': 0.6264352694416329, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 545.7369, MAE: 371.6557, R²: 0.0013\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 63, 'max_depth': 15, 'learning_rate': 0.025786836256483522, 'subsample': 0.9211404333735627, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 560.9234, MAE: 371.0492, R²: -0.0551\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 13, 'learning_rate': 0.17550238487704345, 'subsample': 0.6379421276472794, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 935.5132, MAE: 667.6648, R²: -1.9348\n  Trial 15: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.053193425157598354, 'subsample': 0.8222113745165488, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 15 completed with RMSE: 558.3492, MAE: 420.5659, R²: -0.0454\nTotal optimization time: 22.13 seconds\nBest hyperparameters: {'objective': 'reg:linear', 'n_estimators': 112, 'max_depth': 21, 'learning_rate': 0.13038443690797785, 'subsample': 0.8897337694858868, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Added results for TrainerXGBoostPattern on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.08886035277967957, 'subsample': 0.9180884244391194, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 350.7583, MAE: 276.3974, R²: -0.2406\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 277, 'max_depth': 23, 'learning_rate': 0.09022809856080231, 'subsample': 0.9151239144681995, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 2 completed with RMSE: 346.0913, MAE: 270.9797, R²: -0.2078\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 299, 'max_depth': 29, 'learning_rate': 0.16929054253198736, 'subsample': 0.880155712259969, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 378.0929, MAE: 303.9072, R²: -0.4415\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 173, 'max_depth': 17, 'learning_rate': 0.07843949981814373, 'subsample': 0.7644876551356891, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 342.6861, MAE: 255.7685, R²: -0.1841\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 283, 'max_depth': 29, 'learning_rate': 0.12084314523140692, 'subsample': 0.8782377462328252, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 349.7633, MAE: 279.8764, R²: -0.2335\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 190, 'max_depth': 26, 'learning_rate': 0.10172192611527013, 'subsample': 0.6120977074378795, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 6 completed with RMSE: 357.0450, MAE: 274.1331, R²: -0.2854\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 161, 'max_depth': 6, 'learning_rate': 0.034578117326461856, 'subsample': 0.9432412768501506, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 353.2598, MAE: 275.3023, R²: -0.2583\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 197, 'max_depth': 19, 'learning_rate': 0.0437724985182445, 'subsample': 0.6429572969174312, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 326.3777, MAE: 236.5977, R²: -0.0741\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 215, 'max_depth': 21, 'learning_rate': 0.09635332514545, 'subsample': 0.5754813693260002, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 9 completed with RMSE: 308.1034, MAE: 210.8846, R²: 0.0428\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 117, 'max_depth': 9, 'learning_rate': 0.1957196777099391, 'subsample': 0.8306047143655482, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 336.9013, MAE: 254.5164, R²: -0.1445\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 191, 'max_depth': 10, 'learning_rate': 0.18362935298915667, 'subsample': 0.8706942676625569, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 11 completed with RMSE: 326.8446, MAE: 226.6413, R²: -0.0772\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 191, 'max_depth': 6, 'learning_rate': 0.1860732157126064, 'subsample': 0.7989063346086993, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 360.8837, MAE: 262.4100, R²: -0.3132\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 196, 'max_depth': 23, 'learning_rate': 0.04303309754409417, 'subsample': 0.5148973224505531, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 317.2644, MAE: 197.5346, R²: -0.0150\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 160, 'max_depth': 23, 'learning_rate': 0.05072057231876703, 'subsample': 0.6738074399903982, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 14 completed with RMSE: 336.9052, MAE: 246.7408, R²: -0.1445\n  Trial 15: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 277, 'max_depth': 23, 'learning_rate': 0.1226575537270914, 'subsample': 0.8957157412044334, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 15 completed with RMSE: 332.9417, MAE: 249.1741, R²: -0.1177\nTotal optimization time: 16.89 seconds\nBest hyperparameters: {'objective': 'reg:linear', 'n_estimators': 215, 'max_depth': 21, 'learning_rate': 0.09635332514545, 'subsample': 0.5754813693260002, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerXGBoostPattern on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 222, 'max_depth': 8, 'learning_rate': 0.10628066709456187, 'subsample': 0.8526421146818529, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 1 completed with RMSE: 1251.9313, MAE: 950.5370, R²: -0.0804\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 164, 'max_depth': 15, 'learning_rate': 0.03449438841062474, 'subsample': 0.8622664408711742, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 1275.3256, MAE: 970.2297, R²: -0.1212\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 246, 'max_depth': 15, 'learning_rate': 0.1740776594689395, 'subsample': 0.7061047685509148, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 3 completed with RMSE: 1540.8048, MAE: 1233.2660, R²: -0.6366\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 255, 'max_depth': 13, 'learning_rate': 0.1596274399824253, 'subsample': 0.5019797279191451, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 4 completed with RMSE: 3035.5852, MAE: 2459.3807, R²: -5.3522\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 193, 'max_depth': 21, 'learning_rate': 0.12856197013776052, 'subsample': 0.6563165255503112, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 5 completed with RMSE: 1874.3766, MAE: 1444.4483, R²: -1.4219\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 105, 'max_depth': 21, 'learning_rate': 0.0776372866872079, 'subsample': 0.5708454534645941, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 1244.3350, MAE: 995.2280, R²: -0.0674\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 245, 'max_depth': 6, 'learning_rate': 0.06748566321356357, 'subsample': 0.6313884003841745, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 1878.5240, MAE: 1500.3723, R²: -1.4326\n  Trial 8: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 183, 'max_depth': 23, 'learning_rate': 0.04467585411226854, 'subsample': 0.9370176807623939, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 8 completed with RMSE: 1259.7950, MAE: 982.6560, R²: -0.0941\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 151, 'max_depth': 8, 'learning_rate': 0.07718515535113996, 'subsample': 0.9199810114364233, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 1336.4613, MAE: 1051.1997, R²: -0.2313\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 271, 'max_depth': 12, 'learning_rate': 0.14048556753686806, 'subsample': 0.8073631406135374, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 10 completed with RMSE: 1124.5058, MAE: 919.3920, R²: 0.1283\n  Trial 11: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 198, 'max_depth': 23, 'learning_rate': 0.19798078717710474, 'subsample': 0.8881619792030941, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 2012.2189, MAE: 1598.4080, R²: -1.7912\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 286, 'max_depth': 8, 'learning_rate': 0.05673915792006786, 'subsample': 0.845606622181115, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 12 completed with RMSE: 1401.9832, MAE: 1105.8213, R²: -0.3549\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 218, 'max_depth': 29, 'learning_rate': 0.10430764116180315, 'subsample': 0.5233277371195817, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 13 completed with RMSE: 1710.8250, MAE: 1405.5757, R²: -1.0177\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 90, 'max_depth': 24, 'learning_rate': 0.1503087392940115, 'subsample': 0.9327316449689473, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 1338.3610, MAE: 1060.3727, R²: -0.2348\n  Trial 15: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 10, 'learning_rate': 0.13553727863396975, 'subsample': 0.9636765662729756, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 15 completed with RMSE: 1249.1172, MAE: 956.0290, R²: -0.0756\nTotal optimization time: 13.38 seconds\nBest hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 271, 'max_depth': 12, 'learning_rate': 0.14048556753686806, 'subsample': 0.8073631406135374, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Added results for TrainerXGBoostPattern on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 1: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 192, 'max_depth': 7, 'learning_rate': 0.12218436115815887, 'subsample': 0.8878499856436853, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 1 completed with RMSE: 727.0742, MAE: 586.9409, R²: -0.1367\n  Trial 2: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 71, 'max_depth': 14, 'learning_rate': 0.0770264449020933, 'subsample': 0.8158401860899522, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 2 completed with RMSE: 714.7488, MAE: 581.1763, R²: -0.0984\n  Trial 3: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 21, 'learning_rate': 0.187075009659364, 'subsample': 0.5707012980449635, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 3 completed with RMSE: 734.4723, MAE: 590.9025, R²: -0.1599\n  Trial 4: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 265, 'max_depth': 19, 'learning_rate': 0.030167710073961435, 'subsample': 0.8458041739854686, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 4 completed with RMSE: 728.6939, MAE: 587.0875, R²: -0.1417\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 86, 'max_depth': 11, 'learning_rate': 0.14683204609016917, 'subsample': 0.6377296136775, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 5 completed with RMSE: 714.5555, MAE: 575.7213, R²: -0.0979\n  Trial 6: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 282, 'max_depth': 18, 'learning_rate': 0.17235101665974004, 'subsample': 0.6684798188787013, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 6 completed with RMSE: 724.7105, MAE: 590.0325, R²: -0.1293\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 253, 'max_depth': 23, 'learning_rate': 0.11994572303316833, 'subsample': 0.6267351071526572, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 7 completed with RMSE: 721.6349, MAE: 589.2543, R²: -0.1197\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 159, 'max_depth': 6, 'learning_rate': 0.11841208709569463, 'subsample': 0.8698426477746262, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 8 completed with RMSE: 699.3653, MAE: 564.6545, R²: -0.0517\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 214, 'max_depth': 20, 'learning_rate': 0.1704625279127958, 'subsample': 0.5115879503577953, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 9 completed with RMSE: 761.7738, MAE: 620.7900, R²: -0.2477\n  Trial 10: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.056306532370260294, 'subsample': 0.7446151499731377, 'prediction_mode': 'Zero', 'outlier_removal': 0}\n  Trial 10 completed with RMSE: 704.3951, MAE: 570.6158, R²: -0.0669\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 87, 'max_depth': 13, 'learning_rate': 0.14142363762525936, 'subsample': 0.9292835315673829, 'prediction_mode': 'Zero', 'outlier_removal': 1}\n  Trial 11 completed with RMSE: 737.5452, MAE: 591.6829, R²: -0.1696\n  Trial 12: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 57, 'max_depth': 26, 'learning_rate': 0.06309815098142686, 'subsample': 0.6267379722822736, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 12 completed with RMSE: 692.5392, MAE: 568.1091, R²: -0.0312\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 286, 'max_depth': 25, 'learning_rate': 0.03537012561845026, 'subsample': 0.8529498280531991, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Trial 13 completed with RMSE: 730.3666, MAE: 589.2726, R²: -0.1470\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 175, 'max_depth': 19, 'learning_rate': 0.0657330102244578, 'subsample': 0.5979317157487726, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 14 completed with RMSE: 709.6983, MAE: 573.0650, R²: -0.0830\n  Trial 15: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 114, 'max_depth': 30, 'learning_rate': 0.0557728962725358, 'subsample': 0.9353232940750251, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\n  Trial 15 completed with RMSE: 745.3302, MAE: 594.0236, R²: -0.1945\nTotal optimization time: 141.61 seconds\nBest hyperparameters: {'objective': 'reg:linear', 'n_estimators': 57, 'max_depth': 26, 'learning_rate': 0.06309815098142686, 'subsample': 0.6267379722822736, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\n  Added results for TrainerXGBoostPattern on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Trial 1: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 198, 'max_depth': 5, 'learning_rate': 0.044584689869770676, 'subsample': 0.6782699187655288, 'prediction_mode': 'Zero', 'outlier_removal': 1}\nError in trial 1: \"['category', 'value'] not in index\"\n  Trial 1 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 2: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 191, 'max_depth': 22, 'learning_rate': 0.04950263976205597, 'subsample': 0.7071612988816076, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\nError in trial 2: \"['category', 'value'] not in index\"\n  Trial 2 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 3: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 108, 'max_depth': 30, 'learning_rate': 0.04851876665306748, 'subsample': 0.569428568729222, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\nError in trial 3: \"['category', 'value'] not in index\"\n  Trial 3 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 4: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 139, 'max_depth': 30, 'learning_rate': 0.08135449387989524, 'subsample': 0.7262644975215742, 'prediction_mode': 'Zero', 'outlier_removal': 0}\nError in trial 4: \"['category', 'value'] not in index\"\n  Trial 4 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 5: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 290, 'max_depth': 18, 'learning_rate': 0.14673739347018, 'subsample': 0.685500867372619, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\nError in trial 5: \"['category', 'value'] not in index\"\n  Trial 5 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 6: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 107, 'max_depth': 29, 'learning_rate': 0.0820100743371741, 'subsample': 0.787105534619229, 'prediction_mode': 'Zero', 'outlier_removal': 1}\nError in trial 6: \"['category', 'value'] not in index\"\n  Trial 6 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 7: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 84, 'max_depth': 17, 'learning_rate': 0.03425469627463888, 'subsample': 0.9888716626194726, 'prediction_mode': 'Zero', 'outlier_removal': 0}\nError in trial 7: \"['category', 'value'] not in index\"\n  Trial 7 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 8: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 199, 'max_depth': 14, 'learning_rate': 0.07034888171801873, 'subsample': 0.9321261285217687, 'prediction_mode': 'Zero', 'outlier_removal': 1}\nError in trial 8: \"['category', 'value'] not in index\"\n  Trial 8 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 9: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 228, 'max_depth': 13, 'learning_rate': 0.1843291089371518, 'subsample': 0.5350733966036803, 'prediction_mode': 'Zero', 'outlier_removal': 0}\nError in trial 9: \"['category', 'value'] not in index\"\n  Trial 9 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 10: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 87, 'max_depth': 14, 'learning_rate': 0.044293153103356145, 'subsample': 0.676096076058984, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\nError in trial 10: \"['category', 'value'] not in index\"\n  Trial 10 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 11: Hyperparameters {'objective': 'reg:linear', 'n_estimators': 192, 'max_depth': 11, 'learning_rate': 0.19398313028033937, 'subsample': 0.8280508677250106, 'prediction_mode': 'Zero', 'outlier_removal': 0}\nError in trial 11: \"['category', 'value'] not in index\"\n  Trial 11 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 12: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 237, 'max_depth': 7, 'learning_rate': 0.018354147459830966, 'subsample': 0.8326378792565843, 'prediction_mode': 'Zero', 'outlier_removal': 1}\nError in trial 12: \"['category', 'value'] not in index\"\n  Trial 12 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 13: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 147, 'max_depth': 15, 'learning_rate': 0.050448735601202915, 'subsample': 0.8813879839451761, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\nError in trial 13: \"['category', 'value'] not in index\"\n  Trial 13 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 14: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 27, 'learning_rate': 0.17927316753970515, 'subsample': 0.8119920553392462, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}\nError in trial 14: \"['category', 'value'] not in index\"\n  Trial 14 completed with RMSE: inf, MAE: inf, R²: -inf\n  Trial 15: Hyperparameters {'objective': 'reg:squarederror', 'n_estimators': 54, 'max_depth': 27, 'learning_rate': 0.17781950908468513, 'subsample': 0.5763857305730966, 'prediction_mode': 'Zero', 'outlier_removal': 0}\nError in trial 15: \"['category', 'value'] not in index\"\n  Trial 15 completed with RMSE: inf, MAE: inf, R²: -inf\nTotal optimization time: 0.01 seconds\nBest hyperparameters: None\n  Error with trainer TrainerXGBoostPattern on dataset weather_data: \"['category', 'value'] not in index\"\n\nResults saved to 'random_search_results_with_metrics.csv'\n                  Trainer  ...                                        Trial_Times\n0  TrainerAverageLastYear  ...  [0.034682512283325195, 0.03330636024475098, 0....\n1  TrainerAverageLastYear  ...  [0.008357763290405273, 0.008372068405151367, 0...\n2  TrainerAverageLastYear  ...  [0.012052774429321289, 0.012204170227050781, 0...\n3  TrainerAverageLastYear  ...  [0.011630535125732422, 0.011757135391235352, 0...\n4  TrainerAverageLastYear  ...  [0.01299595832824707, 0.012857675552368164, 0....\n\n[5 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def perform_random_search_hpo(trainer, train_data, test_data, n_trials=15):\n",
    "    \"\"\"\n",
    "    Perform Random Search hyperparameter optimization for a given trainer instance.\n",
    "    \"\"\"\n",
    "    trial_times = []\n",
    "    best_hyperparameters = None\n",
    "    best_rmse = float(\"inf\")  # Start with a very high RMSE\n",
    "    w1, w2, w3 = 0.5, 0.3, 0.2  # Weights for combined performance score\n",
    "\n",
    "    def evaluate_metrics(predictions, test_data):\n",
    "        rmse = ((test_data['value'] - predictions) ** 2).mean() ** 0.5\n",
    "        mae = abs(test_data['value'] - predictions).mean()\n",
    "        r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n",
    "                  sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        trial_start_time = time.time()\n",
    "\n",
    "        # Sample hyperparameters randomly\n",
    "        hyperparameters = {}\n",
    "        if hasattr(trainer, \"space_hyperparameters\"):\n",
    "            for param, values in trainer.space_hyperparameters.items():\n",
    "                if isinstance(values[0], int):\n",
    "                    hyperparameters[param] = random.randint(min(values), max(values))\n",
    "                elif isinstance(values[0], float):\n",
    "                    hyperparameters[param] = random.uniform(min(values), max(values))\n",
    "                elif isinstance(values[0], bool):\n",
    "                    hyperparameters[param] = random.choice([True, False])\n",
    "                else:\n",
    "                    hyperparameters[param] = random.choice(values)\n",
    "\n",
    "        print(f\"  Trial {trial + 1}: Hyperparameters {hyperparameters}\")\n",
    "\n",
    "        # Set the hyperparameters\n",
    "        trainer.hyperparameters = hyperparameters\n",
    "\n",
    "        try:\n",
    "            # Train the model\n",
    "            trainer.fit(train_data)\n",
    "\n",
    "            # Predict\n",
    "            predictions = trainer.predict(test_data)\n",
    "\n",
    "            # Evaluate metrics\n",
    "            rmse, mae, r2 = evaluate_metrics(predictions, test_data)\n",
    "\n",
    "            # Calculate combined performance score\n",
    "            combined_score = w1 * (1 / rmse) + w2 * (1 / mae) + w3 * r2\n",
    "\n",
    "            # Update the best results\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_hyperparameters = hyperparameters\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in trial {trial + 1}: {e}\")\n",
    "            rmse, mae, r2, combined_score = float(\"inf\"), float(\"inf\"), float(\"-inf\"), float(\"-inf\")\n",
    "\n",
    "        trial_times.append(time.time() - trial_start_time)\n",
    "        print(f\"  Trial {trial + 1} completed with RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total optimization time: {total_time:.2f} seconds\")\n",
    "    print(f\"Best hyperparameters: {best_hyperparameters}\")\n",
    "    return best_hyperparameters, best_rmse, total_time, trial_times\n",
    "\n",
    "\n",
    "def run_trainers_with_random_search(trainers, data_splits, n_trials=15):\n",
    "    \"\"\"\n",
    "    Run Random Search optimization for all trainers and datasets.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for trainer in trainers:\n",
    "        trainer_name = trainer.__class__.__name__\n",
    "        print(f\"\\nProcessing Trainer: {trainer_name}\")\n",
    "\n",
    "        for dataset_name, splits in data_splits.items():\n",
    "            train_data = splits['train']\n",
    "            test_data = splits['test']\n",
    "\n",
    "            print(f\"  Optimizing on Dataset: {dataset_name} (Train: {len(train_data)}, Test: {len(test_data)})\")\n",
    "\n",
    "            try:\n",
    "                # Perform Random Search optimization\n",
    "                best_hyperparams, best_rmse, total_time, trial_times = perform_random_search_hpo(\n",
    "                    trainer, train_data, test_data, n_trials=n_trials\n",
    "                )\n",
    "\n",
    "                # Fit the model with the best hyperparameters\n",
    "                trainer.hyperparameters = best_hyperparams\n",
    "                trainer.fit(train_data)\n",
    "\n",
    "                # Predict on the test dataset\n",
    "                predictions = trainer.predict(test_data)\n",
    "\n",
    "                # Compute metrics\n",
    "                mae = abs(test_data['value'] - predictions).mean()\n",
    "                r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n",
    "                          sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "\n",
    "                # Calculate combined performance score\n",
    "                combined_performance_score = (\n",
    "                    0.5 * (1 / best_rmse) + 0.3 * (1 / total_time) + 0.2 * r2\n",
    "                )\n",
    "\n",
    "                # Store results in a list of dictionaries\n",
    "                results.append({\n",
    "                    \"Trainer\": trainer_name,\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Best_Hyperparameters\": best_hyperparams,\n",
    "                    \"Best_RMSE\": best_rmse,\n",
    "                    \"MAE\": mae,\n",
    "                    \"R2\": r2,\n",
    "                    \"Total_Time\": total_time,\n",
    "                    \"Average_Trial_Time\": np.mean(trial_times),\n",
    "                    \"Combined_Performance_Score\": combined_performance_score,\n",
    "                    \"Trial_Times\": trial_times\n",
    "                })\n",
    "\n",
    "                print(f\"  Added results for {trainer_name} on {dataset_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error with trainer {trainer_name} on dataset {dataset_name}: {e}\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_df.to_csv(\"random_search_results_with_metrics.csv\", index=False)\n",
    "\n",
    "    print(\"\\nResults saved to 'random_search_results_with_metrics.csv'\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Run the optimization\n",
    "random_search_results_df = run_trainers_with_random_search(trainers, data_splits, n_trials=15)\n",
    "\n",
    "# Display results\n",
    "print(random_search_results_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09124b6e-0993-4e7a-93f6-337403e43166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize_random_search_results(random_search_results):\n",
    "    \"\"\"\n",
    "    Create an aggregated summary for Random Search results.\n",
    "\n",
    "    Args:\n",
    "        random_search_results: Dictionary of Random Search results with metrics.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with averaged metrics across all trainers and datasets.\n",
    "    \"\"\"\n",
    "    # Extract all metrics for aggregation\n",
    "    metrics_data = {\n",
    "        \"Best_RMSE\": [],\n",
    "        \"MAE\": [],\n",
    "        \"R2\": [],\n",
    "        \"Combined_Performance_Score\": [],\n",
    "        \"Total_Time\": [],\n",
    "        \"Avg_Trial_Time\": []\n",
    "    }\n",
    "\n",
    "    for key, value in random_search_results.items():\n",
    "        metrics_data[\"Best_RMSE\"].append(value.get(\"best_rmse\", np.nan))\n",
    "        metrics_data[\"MAE\"].append(value.get(\"mae\", np.nan))\n",
    "        metrics_data[\"R2\"].append(value.get(\"r2\", np.nan))\n",
    "        metrics_data[\"Combined_Performance_Score\"].append(value.get(\"combined_performance_score\", np.nan))\n",
    "        metrics_data[\"Total_Time\"].append(value.get(\"total_time\", np.nan))\n",
    "        metrics_data[\"Avg_Trial_Time\"].append(np.mean(value.get(\"trial_times\", [])) if value.get(\"trial_times\") else np.nan)\n",
    "\n",
    "    # Calculate aggregated metrics\n",
    "    aggregated_summary = {\n",
    "        \"Average_Best_RMSE\": np.mean(metrics_data[\"Best_RMSE\"]),\n",
    "        \"Average_MAE\": np.mean(metrics_data[\"MAE\"]),\n",
    "        \"Average_R2\": np.mean(metrics_data[\"R2\"]),\n",
    "        \"Average_Combined_Performance_Score\": np.mean(metrics_data[\"Combined_Performance_Score\"]),\n",
    "        \"Average_Total_Time\": np.mean(metrics_data[\"Total_Time\"]),\n",
    "        \"Average_Trial_Time\": np.mean(metrics_data[\"Avg_Trial_Time\"])\n",
    "    }\n",
    "\n",
    "    # Create a one-row summary DataFrame\n",
    "    aggregated_summary_df = pd.DataFrame([aggregated_summary])\n",
    "\n",
    "    # Save the aggregated summary to a CSV file\n",
    "    aggregated_summary_df.to_csv(\"random_search_aggregated_summary.csv\", index=False)\n",
    "    print(\"\\nAggregated summary saved to 'random_search_aggregated_summary.csv'\")\n",
    "    return aggregated_summary_df\n",
    "\n",
    "\n",
    "# Example usage (replace with your actual results):\n",
    "random_search_summary_df = summarize_random_search_results(random_search_results)\n",
    "print(random_search_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edc4d589-4cc0-4be4-b2c9-4d6503f396c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize_random_search_performance(results):\n",
    "    \"\"\"\n",
    "    Summarize the performance of Random Search hyperparameter optimization.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary of results with keys being trainer-dataset combinations\n",
    "                 and values containing 'best_rmse', 'mae', 'r2', 'combined_performance_score', \n",
    "                 'total_time', 'trial_times', and 'best_hyperparameters'.\n",
    "\n",
    "    Returns:\n",
    "        Summary DataFrame containing generalized metrics for Random Search optimization.\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for key, value in results.items():\n",
    "        trainer_name = value.get('trainer', 'Unknown')\n",
    "        dataset_name = value.get('dataset', 'Unknown')\n",
    "        best_rmse = value.get('best_rmse', None)\n",
    "        mae = value.get('mae', None)\n",
    "        r2 = value.get('r2', None)\n",
    "        combined_performance_score = value.get('combined_performance_score', None)\n",
    "        total_time = value.get('total_time', None)\n",
    "        trial_times = value.get('trial_times', [])\n",
    "        avg_trial_time = np.mean(trial_times) if trial_times else 0\n",
    "        best_hyperparameters = value.get('best_hyperparameters', {})\n",
    "\n",
    "        summary_data.append({\n",
    "            \"Trainer\": trainer_name,\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Best_RMSE\": best_rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2,\n",
    "            \"Combined_Performance_Score\": combined_performance_score,\n",
    "            \"Total_Time\": total_time,\n",
    "            \"Avg_Trial_Time\": avg_trial_time,\n",
    "            \"Best_Hyperparameters\": best_hyperparameters\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for easier analysis\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Debug: Check the contents of the DataFrame\n",
    "    print(\"Random Search Results DataFrame:\")\n",
    "    print(summary_df)\n",
    "\n",
    "    # Ensure the DataFrame is not empty\n",
    "    if summary_df.empty:\n",
    "        print(\"The results DataFrame is empty. Ensure the results dictionary is populated correctly.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Check for missing columns\n",
    "    required_columns = [\"Best_RMSE\", \"MAE\", \"R2\", \"Combined_Performance_Score\", \"Total_Time\", \"Avg_Trial_Time\"]\n",
    "    for col in required_columns:\n",
    "        if col not in summary_df.columns:\n",
    "            print(f\"Missing column: {col}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_avg_rmse = summary_df[\"Best_RMSE\"].mean()\n",
    "    overall_avg_mae = summary_df[\"MAE\"].mean()\n",
    "    overall_avg_r2 = summary_df[\"R2\"].mean()\n",
    "    overall_avg_score = summary_df[\"Combined_Performance_Score\"].mean()\n",
    "    overall_avg_time = summary_df[\"Total_Time\"].mean()\n",
    "    overall_avg_trial_time = summary_df[\"Avg_Trial_Time\"].mean()\n",
    "\n",
    "    # Print generalized metrics\n",
    "    print(\"\\n=== Generalized Random Search Performance Summary ===\")\n",
    "    print(f\"Average RMSE Across All Trainers and Datasets: {overall_avg_rmse:.4f}\")\n",
    "    print(f\"Average MAE Across All Trainers and Datasets: {overall_avg_mae:.4f}\")\n",
    "    print(f\"Average R² Across All Trainers and Datasets: {overall_avg_r2:.4f}\")\n",
    "    print(f\"Average Combined Performance Score Across All Trainers and Datasets: {overall_avg_score:.4f}\")\n",
    "    print(f\"Average Total Optimization Time: {overall_avg_time:.2f} seconds\")\n",
    "    print(f\"Average Time Per Trial: {overall_avg_trial_time:.2f} seconds\")\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "# Summarize the performance\n",
    "random_search_summary_df = summarize_random_search_performance(random_search_results)\n",
    "\n",
    "# Save summary to a CSV file\n",
    "random_search_summary_df.to_csv(\"random_search_summary_metrics.csv\", index=False)\n",
    "print(\"\\nRandom Search Summary saved to 'random_search_summary_metrics.csv'\")\n",
    "\n",
    "# Display the summary DataFrame\n",
    "random_search_summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac544e26-0f9c-4b52-b590-569f257ac098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Trajectory-Based Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f55a1b8-6f2d-4a4e-b8eb-aafbe528e7aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:53,689] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:43:53,718] Trial 0 finished with values: [295.3088804318189, 122.71767207216776, -0.12770584712894628] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:53,743] Trial 1 finished with values: [295.3088804318189, 122.71767207216776, -0.12770584712894628] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:53,768] Trial 2 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:53,799] Trial 3 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:53,823] Trial 4 finished with values: [295.3088804318189, 122.71767207216776, -0.12770584712894628] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:53,853] Trial 5 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:53,879] Trial 6 finished with values: [295.3088804318189, 122.71767207216776, -0.12770584712894628] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nProcessing Trainer: TrainerAverageLastYear\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: RMSE=295.3089, MAE=122.7177, R²=-0.1277, Time=0.03s\n  Trial 1: RMSE=295.3089, MAE=122.7177, R²=-0.1277, Time=0.02s\n  Trial 2: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.02s\n  Trial 3: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.02s\n  Trial 4: RMSE=295.3089, MAE=122.7177, R²=-0.1277, Time=0.02s\n  Trial 5: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.03s\n  Trial 6: RMSE=295.3089, MAE=122.7177, R²=-0.1277, Time=0.02s\n  Trial 7: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.02s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:53,905] Trial 7 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:53,933] Trial 8 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:53,959] Trial 9 finished with values: [295.3088804318189, 122.71767207216776, -0.12770584712894628] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:53,995] Trial 10 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,094] Trial 11 finished with values: [295.3088804318189, 122.71767207216776, -0.12770584712894628] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 8: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.03s\n  Trial 9: RMSE=295.3089, MAE=122.7177, R²=-0.1277, Time=0.02s\n  Trial 10: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.03s\n  Trial 11: RMSE=295.3089, MAE=122.7177, R²=-0.1277, Time=0.06s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:54,192] Trial 12 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:54,220] Trial 13 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,246] Trial 14 finished with values: [296.17201771549907, 121.39805825242719, -0.13430766316508636] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:54,271] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:43:54,282] Trial 0 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,293] Trial 1 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,305] Trial 2 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:54,316] Trial 3 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:54,327] Trial 4 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,338] Trial 5 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:54,349] Trial 6 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:54,360] Trial 7 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:54,370] Trial 8 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,381] Trial 9 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,392] Trial 10 finished with values: [92.63188795801727, 64.0, -0.292096104939098] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.07s\n  Trial 13: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.03s\n  Trial 14: RMSE=296.1720, MAE=121.3981, R²=-0.1343, Time=0.02s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_algemene_kosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_algemene_kosten_trajectory: 0.56 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\n  Trial 1: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 2: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 3: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 4: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\n  Trial 5: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 6: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 7: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 8: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 9: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\n  Trial 10: RMSE=92.6319, MAE=64.0000, R²=-0.2921, Time=0.01s\n  Trial 11: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:54,403] Trial 11 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,414] Trial 12 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,425] Trial 13 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,435] Trial 14 finished with values: [37.21514581711727, 30.703703703703706, 0.7914485392901937] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:54,448] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[I 2025-01-19 13:43:54,463] Trial 0 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,478] Trial 1 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,493] Trial 2 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,508] Trial 3 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:54,524] Trial 4 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,540] Trial 5 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,556] Trial 6 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:54,572] Trial 7 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,588] Trial 8 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,603] Trial 9 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\n  Trial 13: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\n  Trial 14: RMSE=37.2151, MAE=30.7037, R²=0.7914, Time=0.01s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_autokosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_autokosten_trajectory: 0.17 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n  Trial 1: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 2: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n  Trial 3: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n  Trial 4: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 5: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n  Trial 6: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 7: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 8: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n  Trial 9: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 10: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:54,618] Trial 10 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:54,635] Trial 11 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,649] Trial 12 finished with values: [395.344124713736, 317.6290661166076, -1.6346130398616965] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,664] Trial 13 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,680] Trial 14 finished with values: [397.4713376908004, 317.25, -1.6630412386949138] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:54,695] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:43:54,710] Trial 0 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,725] Trial 1 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,740] Trial 2 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,755] Trial 3 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:54,770] Trial 4 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,784] Trial 5 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,799] Trial 6 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,814] Trial 7 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:54,828] Trial 8 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 12: RMSE=395.3441, MAE=317.6291, R²=-1.6346, Time=0.01s\n  Trial 13: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\n  Trial 14: RMSE=397.4713, MAE=317.2500, R²=-1.6630, Time=0.01s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.23 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.01s\n  Trial 1: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n  Trial 2: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n  Trial 3: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n  Trial 4: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.01s\n  Trial 5: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n  Trial 6: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.01s\n  Trial 7: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n  Trial 8: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n  Trial 9: RMSE=147.5745, MAE=60.5654, R²=-0.2014, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:54,842] Trial 9 finished with values: [147.5745315041416, 60.56535733769777, -0.2014458358918474] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:54,881] Trial 10 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,916] Trial 11 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,931] Trial 12 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,945] Trial 13 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:54,960] Trial 14 finished with values: [147.54825373242198, 60.30769230769231, -0.2010180045008465] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:54,976] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:43:54,992] Trial 0 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:55,008] Trial 1 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:55,023] Trial 2 finished with values: [359.5246930770254, 295.6068531501486, -1.6104293859817456] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:55,038] Trial 3 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,055] Trial 4 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:55,071] Trial 5 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:55,087] Trial 6 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.03s\n  Trial 11: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.02s\n  Trial 12: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.01s\n  Trial 13: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.01s\n  Trial 14: RMSE=147.5483, MAE=60.3077, R²=-0.2010, Time=0.01s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_huisvestingskosten_trajectory: [{'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_huisvestingskosten_trajectory: 0.27 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.02s\n  Trial 1: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.01s\n  Trial 2: RMSE=359.5247, MAE=295.6069, R²=-1.6104, Time=0.01s\n  Trial 3: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.01s\n  Trial 4: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.02s\n  Trial 5: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.02s\n  Trial 6: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:55,104] Trial 7 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:55,119] Trial 8 finished with values: [359.5246930770254, 295.6068531501486, -1.6104293859817456] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,135] Trial 9 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,151] Trial 10 finished with values: [359.5246930770254, 295.6068531501486, -1.6104293859817456] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,166] Trial 11 finished with values: [360.45042743531025, 297.2340425531915, -1.6238897986054774] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:55,181] Trial 12 finished with values: [359.5246930770254, 295.6068531501486, -1.6104293859817456] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,197] Trial 13 finished with values: [359.5246930770254, 295.6068531501486, -1.6104293859817456] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,212] Trial 14 finished with values: [359.5246930770254, 295.6068531501486, -1.6104293859817456] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,228] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_lonen_en_salarissen_trajectory\n[I 2025-01-19 13:43:55,243] Trial 0 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:55,256] Trial 1 finished with values: [525.6161347527756, 394.10413354531, -0.019978234746915957] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,270] Trial 2 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:55,284] Trial 3 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:55,298] Trial 4 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.01s\n  Trial 8: RMSE=359.5247, MAE=295.6069, R²=-1.6104, Time=0.01s\n  Trial 9: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.01s\n  Trial 10: RMSE=359.5247, MAE=295.6069, R²=-1.6104, Time=0.01s\n  Trial 11: RMSE=360.4504, MAE=297.2340, R²=-1.6239, Time=0.01s\n  Trial 12: RMSE=359.5247, MAE=295.6069, R²=-1.6104, Time=0.01s\n  Trial 13: RMSE=359.5247, MAE=295.6069, R²=-1.6104, Time=0.01s\n  Trial 14: RMSE=359.5247, MAE=295.6069, R²=-1.6104, Time=0.01s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_kantoorkosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_kantoorkosten_trajectory: 0.24 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 1: RMSE=525.6161, MAE=394.1041, R²=-0.0200, Time=0.01s\n  Trial 2: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 3: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 4: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 5: RMSE=525.6161, MAE=394.1041, R²=-0.0200, Time=0.01s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:55,313] Trial 5 finished with values: [525.6161347527756, 394.10413354531, -0.019978234746915957] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:55,327] Trial 6 finished with values: [525.6161347527756, 394.10413354531, -0.019978234746915957] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,340] Trial 7 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,354] Trial 8 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,367] Trial 9 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,380] Trial 10 finished with values: [525.6161347527756, 394.10413354531, -0.019978234746915957] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:55,394] Trial 11 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:55,408] Trial 12 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,422] Trial 13 finished with values: [519.7038183653546, 387.8235294117647, 0.002838864679987285] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:55,436] Trial 14 finished with values: [525.6161347527756, 394.10413354531, -0.019978234746915957] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:55,452] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 6: RMSE=525.6161, MAE=394.1041, R²=-0.0200, Time=0.01s\n  Trial 7: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 8: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 9: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 10: RMSE=525.6161, MAE=394.1041, R²=-0.0200, Time=0.01s\n  Trial 11: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 12: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 13: RMSE=519.7038, MAE=387.8235, R²=0.0028, Time=0.01s\n  Trial 14: RMSE=525.6161, MAE=394.1041, R²=-0.0200, Time=0.01s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_lonen_en_salarissen_trajectory: [{'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_lonen_en_salarissen_trajectory: 0.21 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:55,540] Trial 0 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:55,625] Trial 1 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:55,712] Trial 2 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:55,797] Trial 3 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\n  Trial 2: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n  Trial 3: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\n  Trial 4: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:55,885] Trial 4 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:55,973] Trial 5 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:56,060] Trial 6 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:56,144] Trial 7 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.09s\n  Trial 6: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n  Trial 7: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\n  Trial 8: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:56,229] Trial 8 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:56,325] Trial 9 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:56,411] Trial 10 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:56,494] Trial 11 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n  Trial 10: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n  Trial 11: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\n  Trial 12: RMSE=86.9538, MAE=67.1709, R²=-1.4798, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:56,581] Trial 12 finished with values: [86.95380950372511, 67.1708697889861, -1.4797860553893543] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:56,668] Trial 13 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:56,753] Trial 14 finished with values: [62.7592553965631, 29.82758620689655, -0.2917918823574377] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:56,850] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_overige_personeelskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\n  Trial 14: RMSE=62.7593, MAE=29.8276, R²=-0.2918, Time=0.08s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: [{'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: 1.30 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:56,876] Trial 0 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:56,908] Trial 1 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:56,942] Trial 2 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:56,966] Trial 3 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:56,991] Trial 4 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,015] Trial 5 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,040] Trial 6 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:57,064] Trial 7 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,092] Trial 8 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.03s\n  Trial 2: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.03s\n  Trial 3: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.02s\n  Trial 4: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.02s\n  Trial 5: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.02s\n  Trial 6: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.02s\n  Trial 7: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.02s\n  Trial 8: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.02s\n  Trial 9: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:57,116] Trial 9 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:57,142] Trial 10 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:57,169] Trial 11 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,193] Trial 12 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,216] Trial 13 finished with values: [200.77836340135713, 66.7244207147931, -0.09573156103066505] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:57,240] Trial 14 finished with values: [202.02937669462588, 66.46190476190476, -0.10942870696705853] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,268] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:43:57,288] Trial 0 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:57,311] Trial 1 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,334] Trial 2 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.02s\n  Trial 11: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.03s\n  Trial 12: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.02s\n  Trial 13: RMSE=200.7784, MAE=66.7244, R²=-0.0957, Time=0.02s\n  Trial 14: RMSE=202.0294, MAE=66.4619, R²=-0.1094, Time=0.02s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_overige_personeelskosten_trajectory: [{'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_overige_personeelskosten_trajectory: 0.39 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n  Trial 1: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n  Trial 2: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n  Trial 3: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:57,355] Trial 3 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,377] Trial 4 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,397] Trial 5 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,418] Trial 6 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,440] Trial 7 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:57,460] Trial 8 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:57,482] Trial 9 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:57,502] Trial 10 finished with values: [214.75505922039076, 90.66275994583735, -0.2007966721211225] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,524] Trial 11 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,546] Trial 12 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:57,566] Trial 13 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n  Trial 5: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n  Trial 6: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n  Trial 7: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n  Trial 8: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n  Trial 9: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n  Trial 10: RMSE=214.7551, MAE=90.6628, R²=-0.2008, Time=0.02s\n  Trial 11: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n  Trial 12: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n  Trial 13: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:57,588] Trial 14 finished with values: [215.54453007312537, 89.77777777777777, -0.20964150639934198] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,610] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:43:57,618] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:43:57,619] Trial 0 failed with value None.\n[I 2025-01-19 13:43:57,620] A new study created in memory with name: TrainerAverageLastYear_week_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:43:57,641] Trial 0 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,663] Trial 1 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,687] Trial 2 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,708] Trial 3 finished with values: [343.3029164937552, 256.6559139784946, -1.2785254392968568] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:57,729] Trial 4 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,751] Trial 5 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,772] Trial 6 finished with values: [343.3029164937552, 256.6559139784946, -1.2785254392968568] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=215.5445, MAE=89.7778, R²=-0.2096, Time=0.02s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_overige_rentelasten_trajectory: [{'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_overige_rentelasten_trajectory: 0.32 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerAverageLastYear on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 1: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 2: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 3: RMSE=343.3029, MAE=256.6559, R²=-1.2785, Time=0.02s\n  Trial 4: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 5: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 6: RMSE=343.3029, MAE=256.6559, R²=-1.2785, Time=0.02s\n  Trial 7: RMSE=343.3029, MAE=256.6559, R²=-1.2785, Time=0.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:57,791] Trial 7 finished with values: [343.3029164937552, 256.6559139784946, -1.2785254392968568] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:57,812] Trial 8 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,833] Trial 9 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,854] Trial 10 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,874] Trial 11 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:57,894] Trial 12 finished with values: [343.3029164937552, 256.6559139784946, -1.2785254392968568] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:43:57,918] Trial 13 finished with values: [343.3029164937552, 256.6559139784946, -1.2785254392968568] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:43:57,940] Trial 14 finished with values: [343.141546353643, 257.07600146929923, -1.2763838929480844] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:57,961] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_afschrijvingen_mva_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 9: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 10: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 11: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\n  Trial 12: RMSE=343.3029, MAE=256.6559, R²=-1.2785, Time=0.02s\n  Trial 13: RMSE=343.3029, MAE=256.6559, R²=-1.2785, Time=0.02s\n  Trial 14: RMSE=343.1415, MAE=257.0760, R²=-1.2764, Time=0.02s\nBest hyperparameters for TrainerAverageLastYear_week_data_cleaned_verkoopkosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_week_data_cleaned_verkoopkosten_trajectory: 0.32 seconds\n  Added results for TrainerAverageLastYear on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:58,098] Trial 0 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:58,234] Trial 1 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.13s\n  Trial 1: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.13s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:58,357] Trial 2 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:43:58,487] Trial 3 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.12s\n  Trial 3: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.13s\n  Trial 4: RMSE=495.2964, MAE=364.3300, R²=0.0243, Time=0.13s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:58,618] Trial 4 finished with values: [495.2963649169409, 364.33001441520344, 0.024266732192647078] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:58,745] Trial 5 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 5: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.13s\n  Trial 6: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:58,869] Trial 6 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:58,984] Trial 7 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:59,105] Trial 8 finished with values: [495.2963649169409, 364.33001441520344, 0.024266732192647078] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.11s\n  Trial 8: RMSE=495.2964, MAE=364.3300, R²=0.0243, Time=0.12s\n  Trial 9: RMSE=495.2964, MAE=364.3300, R²=0.0243, Time=0.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:59,226] Trial 9 finished with values: [495.2963649169409, 364.33001441520344, 0.024266732192647078] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:43:59,348] Trial 10 finished with values: [495.2963649169409, 364.33001441520344, 0.024266732192647078] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=495.2964, MAE=364.3300, R²=0.0243, Time=0.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:59,475] Trial 11 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.12s\n  Trial 12: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.12s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:59,597] Trial 12 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 13: RMSE=495.2964, MAE=364.3300, R²=0.0243, Time=0.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:43:59,718] Trial 13 finished with values: [495.2963649169409, 364.33001441520344, 0.024266732192647078] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:43:59,835] Trial 14 finished with values: [491.024959763871, 364.4, 0.041023491111708665] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:43:59,954] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_afschrijvingen_iva_trajectory\n[I 2025-01-19 13:43:59,997] Trial 0 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=491.0250, MAE=364.4000, R²=0.0410, Time=0.12s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_mva_trajectory: [{'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_mva_trajectory: 1.88 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.04s\n  Trial 1: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:00,043] Trial 1 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:00,090] Trial 2 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:00,135] Trial 3 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:00,182] Trial 4 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:00,226] Trial 5 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:00,275] Trial 6 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 3: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.04s\n  Trial 4: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 5: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.04s\n  Trial 6: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 7: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:00,322] Trial 7 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:00,370] Trial 8 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:00,417] Trial 9 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:00,463] Trial 10 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:00,512] Trial 11 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:00,564] Trial 12 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 9: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 10: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.04s\n  Trial 11: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 12: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:00,613] Trial 13 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:00,659] Trial 14 finished with values: [0.0, 0.0, 1.0] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:00,706] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_omzet_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.05s\n  Trial 14: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.04s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_iva_trajectory: [{'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_afschrijvingen_iva_trajectory: 0.71 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: RMSE=851.2408, MAE=667.8426, R²=-0.0246, Time=0.14s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:00,848] Trial 0 finished with values: [851.2408018755784, 667.8425925925926, -0.024589811721686727] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:00,990] Trial 1 finished with values: [851.2408018755784, 667.8425925925926, -0.024589811721686727] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 1: RMSE=851.2408, MAE=667.8426, R²=-0.0246, Time=0.14s\n  Trial 2: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:01,141] Trial 2 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:01,292] Trial 3 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:01,449] Trial 4 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.15s\n  Trial 4: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.16s\n  Trial 5: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:01,596] Trial 5 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:01,756] Trial 6 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:01,919] Trial 7 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:02,083] Trial 8 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.16s\n  Trial 7: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.16s\n  Trial 8: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.16s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:02,247] Trial 9 finished with values: [851.2408018755784, 667.8425925925926, -0.024589811721686727] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:02,407] Trial 10 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=851.2408, MAE=667.8426, R²=-0.0246, Time=0.16s\n  Trial 10: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.16s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:02,577] Trial 11 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:02,749] Trial 12 finished with values: [832.0836507536724, 662.7669893595457, 0.02100799213937976] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.17s\n  Trial 12: RMSE=832.0837, MAE=662.7670, R²=0.0210, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:02,921] Trial 13 finished with values: [851.2408018755784, 667.8425925925926, -0.024589811721686727] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:03,064] Trial 14 finished with values: [851.2408018755784, 667.8425925925926, -0.024589811721686727] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=851.2408, MAE=667.8426, R²=-0.0246, Time=0.17s\n  Trial 14: RMSE=851.2408, MAE=667.8426, R²=-0.0246, Time=0.14s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_omzet_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_omzet_trajectory: 2.36 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_omzet"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:03,216] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:03,416] Trial 0 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:03,621] Trial 1 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n  Trial 2: RMSE=1121.0508, MAE=903.6408, R²=-0.0075, Time=0.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:03,826] Trial 2 finished with values: [1121.0507904219921, 903.6407752025461, -0.007476027707430388] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:04,040] Trial 3 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.21s\n  Trial 4: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:04,245] Trial 4 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:04,443] Trial 5 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n  Trial 6: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:04,644] Trial 6 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:04,857] Trial 7 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.21s\n  Trial 8: RMSE=1121.0508, MAE=903.6408, R²=-0.0075, Time=0.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:05,063] Trial 8 finished with values: [1121.0507904219921, 903.6407752025461, -0.007476027707430388] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:05,261] Trial 9 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n  Trial 10: RMSE=1121.0508, MAE=903.6408, R²=-0.0075, Time=0.21s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:05,468] Trial 10 finished with values: [1121.0507904219921, 903.6407752025461, -0.007476027707430388] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 11: RMSE=1121.0508, MAE=903.6408, R²=-0.0075, Time=0.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:05,679] Trial 11 finished with values: [1121.0507904219921, 903.6407752025461, -0.007476027707430388] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:05,877] Trial 12 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\n  Trial 13: RMSE=1121.0508, MAE=903.6408, R²=-0.0075, Time=0.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:06,082] Trial 13 finished with values: [1121.0507904219921, 903.6407752025461, -0.007476027707430388] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:06,283] Trial 14 finished with values: [1247.3781246668693, 905.4871794871794, -0.24732719092706068] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1247.3781, MAE=905.4872, R²=-0.2473, Time=0.20s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_algemene_kosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_algemene_kosten_trajectory: 3.07 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:06,519] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_autokosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.27s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:06,792] Trial 0 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 1: RMSE=1520.7092, MAE=1023.6304, R²=-0.2463, Time=0.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:07,044] Trial 1 finished with values: [1520.7091809558717, 1023.6304347826087, -0.2462964355155064] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1520.7092, MAE=1023.6304, R²=-0.2463, Time=0.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:07,289] Trial 2 finished with values: [1520.7091809558717, 1023.6304347826087, -0.2462964355155064] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1520.7092, MAE=1023.6304, R²=-0.2463, Time=0.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:07,530] Trial 3 finished with values: [1520.7091809558717, 1023.6304347826087, -0.2462964355155064] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:07,792] Trial 4 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.26s\n  Trial 5: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:08,041] Trial 5 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:08,286] Trial 6 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.24s\n  Trial 7: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.25s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:08,535] Trial 7 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:08,778] Trial 8 finished with values: [1520.7091809558717, 1023.6304347826087, -0.2462964355155064] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1520.7092, MAE=1023.6304, R²=-0.2463, Time=0.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:09,052] Trial 9 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.27s\n  Trial 10: RMSE=1520.7092, MAE=1023.6304, R²=-0.2463, Time=0.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:09,307] Trial 10 finished with values: [1520.7091809558717, 1023.6304347826087, -0.2462964355155064] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:09,568] Trial 11 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.26s\n  Trial 12: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:09,821] Trial 12 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:10,073] Trial 13 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.25s\n  Trial 14: RMSE=1351.9612, MAE=1143.7006, R²=0.0150, Time=0.26s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:10,329] Trial 14 finished with values: [1351.9611806413977, 1143.70056221775, 0.014951848086309116] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for TrainerAverageLastYear_month_data_cleaned_autokosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_autokosten_trajectory: 3.81 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:10,592] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:44:10,727] Trial 0 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.13s\n  Trial 1: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:10,870] Trial 1 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:11,009] Trial 2 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 2: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s\n  Trial 3: RMSE=821.2668, MAE=577.4654, R²=-0.0114, Time=0.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:11,160] Trial 3 finished with values: [821.2668118811828, 577.4653817288081, -0.011444986786519395] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:11,313] Trial 4 finished with values: [821.2668118811828, 577.4653817288081, -0.011444986786519395] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:11,456] Trial 5 finished with values: [821.2668118811828, 577.4653817288081, -0.011444986786519395] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=821.2668, MAE=577.4654, R²=-0.0114, Time=0.15s\n  Trial 5: RMSE=821.2668, MAE=577.4654, R²=-0.0114, Time=0.14s\n  Trial 6: RMSE=821.2668, MAE=577.4654, R²=-0.0114, Time=0.14s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:11,603] Trial 6 finished with values: [821.2668118811828, 577.4653817288081, -0.011444986786519395] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:11,749] Trial 7 finished with values: [821.2668118811828, 577.4653817288081, -0.011444986786519395] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 7: RMSE=821.2668, MAE=577.4654, R²=-0.0114, Time=0.14s\n  Trial 8: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:11,894] Trial 8 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:12,032] Trial 9 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 9: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s\n  Trial 10: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:12,171] Trial 10 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:12,310] Trial 11 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:12,448] Trial 12 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s\n  Trial 12: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:12,593] Trial 13 finished with values: [881.8884009997572, 603.4435096153846, -0.16627504070939025] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:12,738] Trial 14 finished with values: [821.2668118811828, 577.4653817288081, -0.011444986786519395] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=881.8884, MAE=603.4435, R²=-0.1663, Time=0.14s\n  Trial 14: RMSE=821.2668, MAE=577.4654, R²=-0.0114, Time=0.14s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_overige_rentelasten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_overige_rentelasten_trajectory: 2.15 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:12,885] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_pensioenlasten_trajectory\n[I 2025-01-19 13:44:12,933] Trial 0 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:12,977] Trial 1 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:13,020] Trial 2 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:13,065] Trial 3 finished with values: [460.64666502646037, 297.3666666666667, 0.06481949239769424] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:13,111] Trial 4 finished with values: [460.64666502646037, 297.3666666666667, 0.06481949239769424] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.05s\n  Trial 1: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.04s\n  Trial 2: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.04s\n  Trial 3: RMSE=460.6467, MAE=297.3667, R²=0.0648, Time=0.04s\n  Trial 4: RMSE=460.6467, MAE=297.3667, R²=0.0648, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:13,160] Trial 5 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:13,213] Trial 6 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:13,259] Trial 7 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:13,304] Trial 8 finished with values: [460.64666502646037, 297.3666666666667, 0.06481949239769424] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:13,351] Trial 9 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.05s\n  Trial 6: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.05s\n  Trial 7: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.04s\n  Trial 8: RMSE=460.6467, MAE=297.3667, R²=0.0648, Time=0.04s\n  Trial 9: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.05s\n  Trial 10: RMSE=460.6467, MAE=297.3667, R²=0.0648, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:13,395] Trial 10 finished with values: [460.64666502646037, 297.3666666666667, 0.06481949239769424] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:13,439] Trial 11 finished with values: [460.64666502646037, 297.3666666666667, 0.06481949239769424] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:13,486] Trial 12 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:13,531] Trial 13 finished with values: [433.478201814724, 389.1784190230177, 0.17187840549848254] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:13,577] Trial 14 finished with values: [460.64666502646037, 297.3666666666667, 0.06481949239769424] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:13,624] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=460.6467, MAE=297.3667, R²=0.0648, Time=0.04s\n  Trial 12: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.05s\n  Trial 13: RMSE=433.4782, MAE=389.1784, R²=0.1719, Time=0.04s\n  Trial 14: RMSE=460.6467, MAE=297.3667, R²=0.0648, Time=0.04s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_pensioenlasten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_pensioenlasten_trajectory: 0.69 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: RMSE=1100.3729, MAE=810.4741, R²=-0.0081, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:13,717] Trial 0 finished with values: [1100.372875203784, 810.4740884469238, -0.008072229909770856] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:13,804] Trial 1 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:13,895] Trial 2 finished with values: [1100.372875203784, 810.4740884469238, -0.008072229909770856] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:13,991] Trial 3 finished with values: [1100.372875203784, 810.4740884469238, -0.008072229909770856] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.09s\n  Trial 2: RMSE=1100.3729, MAE=810.4741, R²=-0.0081, Time=0.09s\n  Trial 3: RMSE=1100.3729, MAE=810.4741, R²=-0.0081, Time=0.09s\n  Trial 4: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.09s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:14,082] Trial 4 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:14,173] Trial 5 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:14,264] Trial 6 finished with values: [1100.372875203784, 810.4740884469238, -0.008072229909770856] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 5: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.09s\n  Trial 6: RMSE=1100.3729, MAE=810.4741, R²=-0.0081, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:14,353] Trial 7 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:14,438] Trial 8 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:14,528] Trial 9 finished with values: [1100.372875203784, 810.4740884469238, -0.008072229909770856] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.09s\n  Trial 8: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.08s\n  Trial 9: RMSE=1100.3729, MAE=810.4741, R²=-0.0081, Time=0.09s\n  Trial 10: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:14,618] Trial 10 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:14,710] Trial 11 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:14,796] Trial 12 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:14,883] Trial 13 finished with values: [1100.372875203784, 810.4740884469238, -0.008072229909770856] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.09s\n  Trial 12: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.08s\n  Trial 13: RMSE=1100.3729, MAE=810.4741, R²=-0.0081, Time=0.09s\n  Trial 14: RMSE=1093.8553, MAE=804.9677, R²=0.0038, Time=0.08s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:14,969] Trial 14 finished with values: [1093.8553304121015, 804.9677419354839, 0.0038340946359253225] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:15,058] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_overige_personeelskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_lonen_en_salarissen_trajectory: [{'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_lonen_en_salarissen_trajectory: 1.35 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:15,251] Trial 0 finished with values: [874.1253483191928, 481.07414927695373, 0.016502545026078064] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:15,433] Trial 1 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=874.1253, MAE=481.0741, R²=0.0165, Time=0.19s\n  Trial 1: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:15,629] Trial 2 finished with values: [874.1253483191928, 481.07414927695373, 0.016502545026078064] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:15,806] Trial 3 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=874.1253, MAE=481.0741, R²=0.0165, Time=0.19s\n  Trial 3: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:15,986] Trial 4 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:16,157] Trial 5 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\n  Trial 5: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:16,336] Trial 6 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:16,513] Trial 7 finished with values: [874.1253483191928, 481.07414927695373, 0.016502545026078064] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\n  Trial 7: RMSE=874.1253, MAE=481.0741, R²=0.0165, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:16,696] Trial 8 finished with values: [874.1253483191928, 481.07414927695373, 0.016502545026078064] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:16,875] Trial 9 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=874.1253, MAE=481.0741, R²=0.0165, Time=0.18s\n  Trial 9: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\n  Trial 10: RMSE=874.1253, MAE=481.0741, R²=0.0165, Time=0.18s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:17,059] Trial 10 finished with values: [874.1253483191928, 481.07414927695373, 0.016502545026078064] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:17,238] Trial 11 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 11: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:17,439] Trial 12 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:17,618] Trial 13 finished with values: [874.1253483191928, 481.07414927695373, 0.016502545026078064] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.20s\n  Trial 13: RMSE=874.1253, MAE=481.0741, R²=0.0165, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:17,800] Trial 14 finished with values: [909.1485443851163, 401.0151515151515, -0.06388701258444662] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:17,992] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_sociale_lasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=909.1485, MAE=401.0152, R²=-0.0639, Time=0.18s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_overige_personeelskosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_overige_personeelskosten_trajectory: 2.74 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:18,082] Trial 0 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:18,168] Trial 1 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:18,259] Trial 2 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:18,343] Trial 3 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.08s\n  Trial 2: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.09s\n  Trial 3: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.08s\n  Trial 4: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.09s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:18,432] Trial 4 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:18,520] Trial 5 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:18,608] Trial 6 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 5: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.09s\n  Trial 6: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:18,699] Trial 7 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:18,782] Trial 8 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:18,868] Trial 9 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.09s\n  Trial 8: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.08s\n  Trial 9: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.08s\n  Trial 10: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.08s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:18,953] Trial 10 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:19,036] Trial 11 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:19,118] Trial 12 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 11: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.08s\n  Trial 12: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.08s\n  Trial 13: RMSE=743.5846, MAE=530.4000, R²=-0.0598, Time=0.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:19,200] Trial 13 finished with values: [743.5845950529099, 530.4, -0.05979917511295296] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:19,282] Trial 14 finished with values: [708.2698013537029, 501.3493266492823, 0.03847571050265208] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:19,370] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=708.2698, MAE=501.3493, R²=0.0385, Time=0.08s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_sociale_lasten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_sociale_lasten_trajectory: 1.29 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: RMSE=1194.7979, MAE=937.8255, R²=0.1770, Time=0.11s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:19,484] Trial 0 finished with values: [1194.7978837047015, 937.8254761557791, 0.1769871894845637] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:19,585] Trial 1 finished with values: [1194.7978837047015, 937.8254761557791, 0.1769871894845637] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:19,684] Trial 2 finished with values: [1194.7978837047015, 937.8254761557791, 0.1769871894845637] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 1: RMSE=1194.7979, MAE=937.8255, R²=0.1770, Time=0.10s\n  Trial 2: RMSE=1194.7979, MAE=937.8255, R²=0.1770, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:19,786] Trial 3 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:19,889] Trial 4 finished with values: [1194.7978837047015, 937.8254761557791, 0.1769871894845637] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n  Trial 4: RMSE=1194.7979, MAE=937.8255, R²=0.1770, Time=0.10s\n  Trial 5: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:19,987] Trial 5 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:20,084] Trial 6 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:20,183] Trial 7 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:20,280] Trial 8 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n  Trial 7: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n  Trial 8: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:20,382] Trial 9 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:20,486] Trial 10 finished with values: [1194.7978837047015, 937.8254761557791, 0.1769871894845637] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n  Trial 10: RMSE=1194.7979, MAE=937.8255, R²=0.1770, Time=0.10s\n  Trial 11: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:20,590] Trial 11 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:20,693] Trial 12 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:20,796] Trial 13 finished with values: [1194.7978837047015, 937.8254761557791, 0.1769871894845637] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:20,896] Trial 14 finished with values: [1367.0604029340732, 997.5675675675676, -0.07744004797119453] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n  Trial 13: RMSE=1194.7979, MAE=937.8255, R²=0.1770, Time=0.10s\n  Trial 14: RMSE=1367.0604, MAE=997.5676, R²=-0.0774, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:20,999] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[I 2025-01-19 13:44:21,130] Trial 0 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for TrainerAverageLastYear_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: 1.53 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.13s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:21,262] Trial 1 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:21,392] Trial 2 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.13s\n  Trial 2: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.13s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:21,534] Trial 3 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:21,671] Trial 4 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.14s\n  Trial 4: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.14s\n  Trial 5: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.13s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:21,804] Trial 5 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:21,929] Trial 6 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:22,066] Trial 7 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.12s\n  Trial 7: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.13s\n  Trial 8: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.14s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:22,209] Trial 8 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:22,346] Trial 9 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 9: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.14s\n  Trial 10: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.13s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:22,478] Trial 10 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:22,618] Trial 11 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:22,741] Trial 12 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.14s\n  Trial 12: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:22,871] Trial 13 finished with values: [1284.8064530123156, 984.0262928398515, -0.012364379415756854] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:23,012] Trial 14 finished with values: [1371.1733574942605, 984.265625, -0.15304476856204619] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1284.8065, MAE=984.0263, R²=-0.0124, Time=0.13s\n  Trial 14: RMSE=1371.1734, MAE=984.2656, R²=-0.1530, Time=0.14s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_kostprijs_van_de_omzet_trajectory: [{'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_kostprijs_van_de_omzet_trajectory: 2.01 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:23,147] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:44:23,325] Trial 0 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:23,495] Trial 1 finished with values: [570.065743911132, 365.46031746031747, -0.0897497505326903] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.18s\n  Trial 1: RMSE=570.0657, MAE=365.4603, R²=-0.0897, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:23,673] Trial 2 finished with values: [570.065743911132, 365.46031746031747, -0.0897497505326903] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:23,860] Trial 3 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:24,039] Trial 4 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=570.0657, MAE=365.4603, R²=-0.0897, Time=0.18s\n  Trial 3: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.19s\n  Trial 4: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:24,224] Trial 5 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:24,397] Trial 6 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.18s\n  Trial 6: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:24,576] Trial 7 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:24,753] Trial 8 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.18s\n  Trial 8: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:24,931] Trial 9 finished with values: [570.065743911132, 365.46031746031747, -0.0897497505326903] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:25,101] Trial 10 finished with values: [570.065743911132, 365.46031746031747, -0.0897497505326903] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=570.0657, MAE=365.4603, R²=-0.0897, Time=0.18s\n  Trial 10: RMSE=570.0657, MAE=365.4603, R²=-0.0897, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:25,278] Trial 11 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:25,445] Trial 12 finished with values: [552.8550348997708, 375.72258519616406, -0.02494232499209681] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:25,614] Trial 13 finished with values: [570.065743911132, 365.46031746031747, -0.0897497505326903] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.18s\n  Trial 12: RMSE=552.8550, MAE=375.7226, R²=-0.0249, Time=0.17s\n  Trial 13: RMSE=570.0657, MAE=365.4603, R²=-0.0897, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:25,787] Trial 14 finished with values: [570.065743911132, 365.46031746031747, -0.0897497505326903] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:25,954] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_verkoopkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=570.0657, MAE=365.4603, R²=-0.0897, Time=0.17s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_kantoorkosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_kantoorkosten_trajectory: 2.64 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:26,064] Trial 0 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:26,170] Trial 1 finished with values: [348.4839461110302, 195.21794871794873, -0.2245301369038435] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:26,272] Trial 2 finished with values: [348.4839461110302, 195.21794871794873, -0.2245301369038435] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=348.4839, MAE=195.2179, R²=-0.2245, Time=0.10s\n  Trial 2: RMSE=348.4839, MAE=195.2179, R²=-0.2245, Time=0.10s\n  Trial 3: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:26,376] Trial 3 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:26,479] Trial 4 finished with values: [348.4839461110302, 195.21794871794873, -0.2245301369038435] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:26,578] Trial 5 finished with values: [348.4839461110302, 195.21794871794873, -0.2245301369038435] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:26,687] Trial 6 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=348.4839, MAE=195.2179, R²=-0.2245, Time=0.10s\n  Trial 5: RMSE=348.4839, MAE=195.2179, R²=-0.2245, Time=0.10s\n  Trial 6: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:26,800] Trial 7 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}.\n[I 2025-01-19 13:44:26,904] Trial 8 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.11s\n  Trial 8: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.10s\n  Trial 9: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:27,007] Trial 9 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:27,110] Trial 10 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}.\n[I 2025-01-19 13:44:27,218] Trial 11 finished with values: [348.4839461110302, 195.21794871794873, -0.2245301369038435] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.10s\n  Trial 11: RMSE=348.4839, MAE=195.2179, R²=-0.2245, Time=0.11s\n  Trial 12: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:27,324] Trial 12 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:27,428] Trial 13 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:27,537] Trial 14 finished with values: [319.4535478518266, 193.36251614848118, -0.029009437164476903] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:27,651] A new study created in memory with name: TrainerAverageLastYear_month_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.10s\n  Trial 14: RMSE=319.4535, MAE=193.3625, R²=-0.0290, Time=0.11s\nBest hyperparameters for TrainerAverageLastYear_month_data_cleaned_verkoopkosten_trajectory: [{'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_verkoopkosten_trajectory: 1.58 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:27,753] Trial 0 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:27,834] Trial 1 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:27,918] Trial 2 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.10s\n  Trial 1: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s\n  Trial 2: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s\n  Trial 3: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:28,002] Trial 3 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:28,082] Trial 4 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:28,164] Trial 5 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n  Trial 4: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n  Trial 5: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n  Trial 6: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:28,244] Trial 6 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n[I 2025-01-19 13:44:28,328] Trial 7 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:28,411] Trial 8 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:28,490] Trial 9 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n  Trial 8: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s\n  Trial 9: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n  Trial 10: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:28,576] Trial 10 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n[I 2025-01-19 13:44:28,660] Trial 11 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n[I 2025-01-19 13:44:28,742] Trial 12 finished with values: [1213.8206632211966, 955.5428009574297, -0.01565602660019083] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:28,825] Trial 13 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s\n  Trial 12: RMSE=1213.8207, MAE=955.5428, R²=-0.0157, Time=0.08s\n  Trial 13: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n  Trial 14: RMSE=1232.1917, MAE=953.4333, R²=-0.0466, Time=0.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:28,909] Trial 14 finished with values: [1232.191665285884, 953.4333333333333, -0.04663229401015756] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n[I 2025-01-19 13:44:28,992] A new study created in memory with name: TrainerAverageLastYear_day_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for TrainerAverageLastYear_month_data_cleaned_huisvestingskosten_trajectory: [{'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}, {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}]\nTotal optimization time for TrainerAverageLastYear_month_data_cleaned_huisvestingskosten_trajectory: 1.26 seconds\n  Added results for TrainerAverageLastYear on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:30,155] Trial 0 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.16s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:31,299] Trial 1 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:32,572] Trial 2 finished with values: [689.4241188933919, 558.2878094253687, -0.021988338555825937] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=689.4241, MAE=558.2878, R²=-0.0220, Time=1.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:33,712] Trial 3 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:34,983] Trial 4 finished with values: [689.4241188933919, 558.2878094253687, -0.021988338555825937] and parameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=689.4241, MAE=558.2878, R²=-0.0220, Time=1.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:36,127] Trial 5 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:37,269] Trial 6 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:38,416] Trial 7 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:39,634] Trial 8 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.22s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:40,948] Trial 9 finished with values: [689.4241188933919, 558.2878094253687, -0.021988338555825937] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=689.4241, MAE=558.2878, R²=-0.0220, Time=1.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:42,090] Trial 10 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:43,231] Trial 11 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:44,373] Trial 12 finished with values: [695.3738748006145, 559.4041288782817, -0.03970404883739542] and parameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=695.3739, MAE=559.4041, R²=-0.0397, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:45,643] Trial 13 finished with values: [689.4241188933919, 558.2878094253687, -0.021988338555825937] and parameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=689.4241, MAE=558.2878, R²=-0.0220, Time=1.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:46,918] Trial 14 finished with values: [689.4241188933919, 558.2878094253687, -0.021988338555825937] and parameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=689.4241, MAE=558.2878, R²=-0.0220, Time=1.27s\nBest hyperparameters for TrainerAverageLastYear_day_data_trajectory: [{'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1}, {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0}, {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0}]\nTotal optimization time for TrainerAverageLastYear_day_data_trajectory: 17.93 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:48,202] A new study created in memory with name: TrainerAverageLastYear_weather_data_trajectory\n[W 2025-01-19 13:44:48,205] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_average_last_year.py\", line 32, in fit\n    trainset = pdf_train[[\n               ^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:44:48,278] Trial 0 failed with value None.\n[I 2025-01-19 13:44:48,279] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:44:48,316] Trial 0 finished with values: [172.49102537509438, 113.1, 0.6152524830240758] and parameters: {'max_depth': 14, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,351] Trial 1 finished with values: [183.3364683609564, 118.80873786407766, 0.5653491428340841] and parameters: {'max_depth': 7, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,388] Trial 2 finished with values: [183.3364683609564, 118.80873786407766, 0.5653491428340841] and parameters: {'max_depth': 83, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerAverageLastYear on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerAverageLastYear on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerDecisionTree\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: RMSE=172.4910, MAE=113.1000, R²=0.6153, Time=0.04s\n  Trial 1: RMSE=183.3365, MAE=118.8087, R²=0.5653, Time=0.03s\n  Trial 2: RMSE=183.3365, MAE=118.8087, R²=0.5653, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:48,424] Trial 3 finished with values: [174.71167075237813, 115.4419417475728, 0.6052822544020652] and parameters: {'max_depth': 76, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,458] Trial 4 finished with values: [176.48267881673289, 67.66019417475728, 0.5972393875961455] and parameters: {'max_depth': 72, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,492] Trial 5 finished with values: [179.33639392065967, 117.5271844660194, 0.5841088455283776] and parameters: {'max_depth': 100, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,526] Trial 6 finished with values: [165.2536223770537, 63.907766990291265, 0.6468617226962219] and parameters: {'max_depth': 7, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,559] Trial 7 finished with values: [183.3364683609564, 118.80873786407766, 0.5653491428340841] and parameters: {'max_depth': 56, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,608] Trial 8 finished with values: [173.35635459830036, 114.43009708737863, 0.6113825033986369] and parameters: {'max_depth': 91, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=174.7117, MAE=115.4419, R²=0.6053, Time=0.03s\n  Trial 4: RMSE=176.4827, MAE=67.6602, R²=0.5972, Time=0.03s\n  Trial 5: RMSE=179.3364, MAE=117.5272, R²=0.5841, Time=0.03s\n  Trial 6: RMSE=165.2536, MAE=63.9078, R²=0.6469, Time=0.03s\n  Trial 7: RMSE=183.3365, MAE=118.8087, R²=0.5653, Time=0.03s\n  Trial 8: RMSE=173.3564, MAE=114.4301, R²=0.6114, Time=0.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:48,643] Trial 9 finished with values: [206.48539523802148, 110.02912621359224, 0.44865746765632053] and parameters: {'max_depth': 64, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,678] Trial 10 finished with values: [215.97554697975391, 115.83495145631068, 0.3968129858611795] and parameters: {'max_depth': 53, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,716] Trial 11 finished with values: [205.25104211979567, 108.70873786407768, 0.45522952794643146] and parameters: {'max_depth': 20, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,752] Trial 12 finished with values: [211.62430073173113, 113.7378640776699, 0.4208728971474327] and parameters: {'max_depth': 45, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,786] Trial 13 finished with values: [183.3364683609564, 118.80873786407766, 0.5653491428340841] and parameters: {'max_depth': 78, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,822] Trial 14 finished with values: [185.19318501688724, 120.02427184466019, 0.5565008214184803] and parameters: {'max_depth': 68, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=206.4854, MAE=110.0291, R²=0.4487, Time=0.03s\n  Trial 10: RMSE=215.9755, MAE=115.8350, R²=0.3968, Time=0.03s\n  Trial 11: RMSE=205.2510, MAE=108.7087, R²=0.4552, Time=0.04s\n  Trial 12: RMSE=211.6243, MAE=113.7379, R²=0.4209, Time=0.03s\n  Trial 13: RMSE=183.3365, MAE=118.8087, R²=0.5653, Time=0.03s\n  Trial 14: RMSE=185.1932, MAE=120.0243, R²=0.5565, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_algemene_kosten_trajectory: [{'max_depth': 7, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_algemene_kosten_trajectory: 0.54 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:48,860] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:44:48,894] Trial 0 finished with values: [96.41873953404148, 62.06666666666666, -0.399898942577968] and parameters: {'max_depth': 75, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,927] Trial 1 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 93, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,961] Trial 2 finished with values: [96.41873953404148, 62.06666666666666, -0.399898942577968] and parameters: {'max_depth': 14, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:48,994] Trial 3 finished with values: [101.39526616169022, 65.0, -0.5481361263552404] and parameters: {'max_depth': 21, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,027] Trial 4 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 66, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: RMSE=96.4187, MAE=62.0667, R²=-0.3999, Time=0.03s\n  Trial 1: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 2: RMSE=96.4187, MAE=62.0667, R²=-0.3999, Time=0.03s\n  Trial 3: RMSE=101.3953, MAE=65.0000, R²=-0.5481, Time=0.03s\n  Trial 4: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 5: RMSE=96.4187, MAE=62.0667, R²=-0.3999, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,060] Trial 5 finished with values: [96.41873953404148, 62.06666666666666, -0.399898942577968] and parameters: {'max_depth': 68, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,093] Trial 6 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 91, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,126] Trial 7 finished with values: [96.41873953404148, 62.06666666666666, -0.399898942577968] and parameters: {'max_depth': 9, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,159] Trial 8 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 43, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,192] Trial 9 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 53, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,224] Trial 10 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 18, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,256] Trial 11 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'max_depth': 25, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,288] Trial 12 finished with values: [99.09423124817441, 63.666666666666664, -0.4786675143889709] and parameters: {'max_depth': 36, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 7: RMSE=96.4187, MAE=62.0667, R²=-0.3999, Time=0.03s\n  Trial 8: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 9: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 10: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 11: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n  Trial 12: RMSE=99.0942, MAE=63.6667, R²=-0.4787, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,322] Trial 13 finished with values: [96.41873953404148, 62.06666666666666, -0.399898942577968] and parameters: {'max_depth': 51, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,362] Trial 14 finished with values: [96.41873953404148, 62.06666666666666, -0.399898942577968] and parameters: {'max_depth': 74, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,396] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=96.4187, MAE=62.0667, R²=-0.3999, Time=0.03s\n  Trial 14: RMSE=96.4187, MAE=62.0667, R²=-0.3999, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_autokosten_trajectory: [{'max_depth': 75, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 14, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 68, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 9, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 51, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 74, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_autokosten_trajectory: 0.50 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,437] Trial 0 finished with values: [140.0907780690792, 106.11928571428572, 0.6691848778759473] and parameters: {'max_depth': 70, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,473] Trial 1 finished with values: [141.66499742854114, 106.9825, 0.6617082746297595] and parameters: {'max_depth': 31, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,507] Trial 2 finished with values: [332.96621450231254, 258.7142857142857, -0.8688162259552821] and parameters: {'max_depth': 72, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=140.0908, MAE=106.1193, R²=0.6692, Time=0.04s\n  Trial 1: RMSE=141.6650, MAE=106.9825, R²=0.6617, Time=0.03s\n  Trial 2: RMSE=332.9662, MAE=258.7143, R²=-0.8688, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,543] Trial 3 finished with values: [141.66499742854114, 106.9825, 0.6617082746297595] and parameters: {'max_depth': 89, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,576] Trial 4 finished with values: [312.974782188141, 252.42857142857142, -0.6511439996898756] and parameters: {'max_depth': 51, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,610] Trial 5 finished with values: [141.66499742854114, 106.9825, 0.6617082746297595] and parameters: {'max_depth': 100, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=141.6650, MAE=106.9825, R²=0.6617, Time=0.03s\n  Trial 4: RMSE=312.9748, MAE=252.4286, R²=-0.6511, Time=0.03s\n  Trial 5: RMSE=141.6650, MAE=106.9825, R²=0.6617, Time=0.03s\n  Trial 6: RMSE=317.3553, MAE=246.2143, R²=-0.6977, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,642] Trial 6 finished with values: [317.3552538447365, 246.21428571428572, -0.6976870814468454] and parameters: {'max_depth': 61, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,675] Trial 7 finished with values: [310.69248692005965, 244.25, -0.6271506413053554] and parameters: {'max_depth': 75, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,708] Trial 8 finished with values: [310.69248692005965, 244.25, -0.6271506413053554] and parameters: {'max_depth': 89, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,741] Trial 9 finished with values: [141.66499742854114, 106.9825, 0.6617082746297595] and parameters: {'max_depth': 87, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=310.6925, MAE=244.2500, R²=-0.6272, Time=0.03s\n  Trial 8: RMSE=310.6925, MAE=244.2500, R²=-0.6272, Time=0.03s\n  Trial 9: RMSE=141.6650, MAE=106.9825, R²=0.6617, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,775] Trial 10 finished with values: [311.033702813239, 250.39285714285714, -0.6307266179407598] and parameters: {'max_depth': 22, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,808] Trial 11 finished with values: [141.66499742854114, 106.9825, 0.6617082746297595] and parameters: {'max_depth': 17, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,842] Trial 12 finished with values: [312.3626841166714, 254.53571428571428, -0.6446918903312984] and parameters: {'max_depth': 29, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,873] Trial 13 finished with values: [307.55031579634016, 244.70250000000001, -0.5944048747579329] and parameters: {'max_depth': 76, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=311.0337, MAE=250.3929, R²=-0.6307, Time=0.03s\n  Trial 11: RMSE=141.6650, MAE=106.9825, R²=0.6617, Time=0.03s\n  Trial 12: RMSE=312.3627, MAE=254.5357, R²=-0.6447, Time=0.03s\n  Trial 13: RMSE=307.5503, MAE=244.7025, R²=-0.5944, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:49,906] Trial 14 finished with values: [313.8614086037248, 261.4760714285714, -0.6605123039676462] and parameters: {'max_depth': 90, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:49,941] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:44:49,975] Trial 0 finished with values: [142.38779815736515, 54.677948717948716, -0.11847664177735484] and parameters: {'max_depth': 61, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=313.8614, MAE=261.4761, R²=-0.6605, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'max_depth': 70, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.51 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: RMSE=142.3878, MAE=54.6779, R²=-0.1185, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,008] Trial 1 finished with values: [139.36176636035052, 54.90384615384615, -0.07144197074479797] and parameters: {'max_depth': 48, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,040] Trial 2 finished with values: [139.2382830268185, 53.90397435897436, -0.06954408132661616] and parameters: {'max_depth': 36, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,094] Trial 3 finished with values: [140.05179252141522, 53.968589743589746, -0.08207836443381278] and parameters: {'max_depth': 70, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=139.3618, MAE=54.9038, R²=-0.0714, Time=0.03s\n  Trial 2: RMSE=139.2383, MAE=53.9040, R²=-0.0695, Time=0.03s\n  Trial 3: RMSE=140.0518, MAE=53.9686, R²=-0.0821, Time=0.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,129] Trial 4 finished with values: [139.10879343253757, 54.92307692307692, -0.06755568521814914] and parameters: {'max_depth': 75, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,165] Trial 5 finished with values: [139.36176636035052, 54.90384615384615, -0.07144197074479797] and parameters: {'max_depth': 79, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,198] Trial 6 finished with values: [142.38779815736515, 54.677948717948716, -0.11847664177735484] and parameters: {'max_depth': 50, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=139.1088, MAE=54.9231, R²=-0.0676, Time=0.03s\n  Trial 5: RMSE=139.3618, MAE=54.9038, R²=-0.0714, Time=0.03s\n  Trial 6: RMSE=142.3878, MAE=54.6779, R²=-0.1185, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,232] Trial 7 finished with values: [139.2382830268185, 53.90397435897436, -0.06954408132661616] and parameters: {'max_depth': 81, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,268] Trial 8 finished with values: [139.2382830268185, 53.90397435897436, -0.06954408132661616] and parameters: {'max_depth': 78, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,301] Trial 9 finished with values: [139.80323408368068, 53.95628205128205, -0.07824091211202622] and parameters: {'max_depth': 6, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=139.2383, MAE=53.9040, R²=-0.0695, Time=0.03s\n  Trial 8: RMSE=139.2383, MAE=53.9040, R²=-0.0695, Time=0.03s\n  Trial 9: RMSE=139.8032, MAE=53.9563, R²=-0.0782, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,335] Trial 10 finished with values: [139.2382830268185, 53.90397435897436, -0.06954408132661616] and parameters: {'max_depth': 72, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,369] Trial 11 finished with values: [139.36176636035052, 54.90384615384615, -0.07144197074479797] and parameters: {'max_depth': 86, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,402] Trial 12 finished with values: [142.5258291930957, 54.99846153846154, -0.12064620014725236] and parameters: {'max_depth': 28, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=139.2383, MAE=53.9040, R²=-0.0695, Time=0.03s\n  Trial 11: RMSE=139.3618, MAE=54.9038, R²=-0.0714, Time=0.03s\n  Trial 12: RMSE=142.5258, MAE=54.9985, R²=-0.1206, Time=0.03s\n  Trial 13: RMSE=140.0518, MAE=53.9686, R²=-0.0821, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,436] Trial 13 finished with values: [140.05179252141522, 53.968589743589746, -0.08207836443381278] and parameters: {'max_depth': 51, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,471] Trial 14 finished with values: [139.2382830268185, 53.90397435897436, -0.06954408132661616] and parameters: {'max_depth': 23, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,508] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_kantoorkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=139.2383, MAE=53.9040, R²=-0.0695, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_huisvestingskosten_trajectory: [{'max_depth': 36, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 75, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 81, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 78, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 72, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 23, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_huisvestingskosten_trajectory: 0.53 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: RMSE=203.8350, MAE=101.8298, R²=0.1609, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,542] Trial 0 finished with values: [203.83503968713356, 101.82978723404256, 0.160902966269318] and parameters: {'max_depth': 59, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,577] Trial 1 finished with values: [165.84722291596012, 80.22340425531915, 0.44451682548212523] and parameters: {'max_depth': 60, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,610] Trial 2 finished with values: [205.89993179914757, 102.37234042553192, 0.1438163958894808] and parameters: {'max_depth': 35, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,644] Trial 3 finished with values: [205.95934064761423, 102.37234042553192, 0.1433222508002545] and parameters: {'max_depth': 19, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=165.8472, MAE=80.2234, R²=0.4445, Time=0.03s\n  Trial 2: RMSE=205.8999, MAE=102.3723, R²=0.1438, Time=0.03s\n  Trial 3: RMSE=205.9593, MAE=102.3723, R²=0.1433, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,678] Trial 4 finished with values: [172.81923898021924, 86.87234042553192, 0.3968314648919743] and parameters: {'max_depth': 41, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,710] Trial 5 finished with values: [171.55321424895814, 86.18085106382979, 0.405636378422069] and parameters: {'max_depth': 65, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,743] Trial 6 finished with values: [163.2832677646883, 79.55319148936171, 0.46155931528404015] and parameters: {'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,775] Trial 7 finished with values: [178.6459956855123, 92.91489361702128, 0.35547306205484097] and parameters: {'max_depth': 74, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=172.8192, MAE=86.8723, R²=0.3968, Time=0.03s\n  Trial 5: RMSE=171.5532, MAE=86.1809, R²=0.4056, Time=0.03s\n  Trial 6: RMSE=163.2833, MAE=79.5532, R²=0.4616, Time=0.03s\n  Trial 7: RMSE=178.6460, MAE=92.9149, R²=0.3555, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,809] Trial 8 finished with values: [171.99857681251876, 86.00638297872341, 0.402546364568636] and parameters: {'max_depth': 44, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,842] Trial 9 finished with values: [172.73029113793487, 86.87234042553192, 0.3974521913044544] and parameters: {'max_depth': 62, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,875] Trial 10 finished with values: [169.6453748013466, 86.27659574468085, 0.41878267882955367] and parameters: {'max_depth': 21, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=171.9986, MAE=86.0064, R²=0.4025, Time=0.03s\n  Trial 9: RMSE=172.7303, MAE=86.8723, R²=0.3975, Time=0.03s\n  Trial 10: RMSE=169.6454, MAE=86.2766, R²=0.4188, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:50,908] Trial 11 finished with values: [178.6459956855123, 92.91489361702128, 0.35547306205484097] and parameters: {'max_depth': 60, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,942] Trial 12 finished with values: [187.0551652389027, 113.65617021276596, 0.2933670062002638] and parameters: {'max_depth': 42, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:50,976] Trial 13 finished with values: [185.8861232045039, 112.96468085106383, 0.3021719197303586] and parameters: {'max_depth': 13, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,008] Trial 14 finished with values: [187.0551652389027, 113.65617021276596, 0.2933670062002638] and parameters: {'max_depth': 41, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=178.6460, MAE=92.9149, R²=0.3555, Time=0.03s\n  Trial 12: RMSE=187.0552, MAE=113.6562, R²=0.2934, Time=0.03s\n  Trial 13: RMSE=185.8861, MAE=112.9647, R²=0.3022, Time=0.03s\n  Trial 14: RMSE=187.0552, MAE=113.6562, R²=0.2934, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_kantoorkosten_trajectory: [{'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_kantoorkosten_trajectory: 0.50 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,043] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_lonen_en_salarissen_trajectory\n[I 2025-01-19 13:44:51,075] Trial 0 finished with values: [461.31865437091125, 369.5658823529412, 0.21430215649626216] and parameters: {'max_depth': 82, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,107] Trial 1 finished with values: [470.3718311894013, 393.26235294117646, 0.18316161277222998] and parameters: {'max_depth': 25, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: RMSE=461.3187, MAE=369.5659, R²=0.2143, Time=0.03s\n  Trial 1: RMSE=470.3718, MAE=393.2624, R²=0.1832, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,139] Trial 2 finished with values: [461.31865437091125, 369.5658823529412, 0.21430215649626216] and parameters: {'max_depth': 87, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,171] Trial 3 finished with values: [635.6116718470762, 447.3129411764706, -0.49154807280967483] and parameters: {'max_depth': 44, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,203] Trial 4 finished with values: [423.08439956224004, 337.94823529411764, 0.3391429130083552] and parameters: {'max_depth': 69, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,234] Trial 5 finished with values: [470.3718311894013, 393.26235294117646, 0.18316161277222998] and parameters: {'max_depth': 90, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=461.3187, MAE=369.5659, R²=0.2143, Time=0.03s\n  Trial 3: RMSE=635.6117, MAE=447.3129, R²=-0.4915, Time=0.03s\n  Trial 4: RMSE=423.0844, MAE=337.9482, R²=0.3391, Time=0.03s\n  Trial 5: RMSE=470.3718, MAE=393.2624, R²=0.1832, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,266] Trial 6 finished with values: [423.08439956224004, 337.94823529411764, 0.3391429130083552] and parameters: {'max_depth': 96, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,297] Trial 7 finished with values: [461.31865437091125, 369.5658823529412, 0.21430215649626216] and parameters: {'max_depth': 97, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,329] Trial 8 finished with values: [423.08439956224004, 337.94823529411764, 0.3391429130083552] and parameters: {'max_depth': 85, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=423.0844, MAE=337.9482, R²=0.3391, Time=0.03s\n  Trial 7: RMSE=461.3187, MAE=369.5659, R²=0.2143, Time=0.03s\n  Trial 8: RMSE=423.0844, MAE=337.9482, R²=0.3391, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,362] Trial 9 finished with values: [635.6116718470762, 447.3129411764706, -0.49154807280967483] and parameters: {'max_depth': 37, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,394] Trial 10 finished with values: [632.77553868093, 424.88235294117646, -0.47826703537257864] and parameters: {'max_depth': 47, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,425] Trial 11 finished with values: [470.3718311894013, 393.26235294117646, 0.18316161277222998] and parameters: {'max_depth': 43, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,457] Trial 12 finished with values: [470.3718311894013, 393.26235294117646, 0.18316161277222998] and parameters: {'max_depth': 49, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=635.6117, MAE=447.3129, R²=-0.4915, Time=0.03s\n  Trial 10: RMSE=632.7755, MAE=424.8824, R²=-0.4783, Time=0.03s\n  Trial 11: RMSE=470.3718, MAE=393.2624, R²=0.1832, Time=0.03s\n  Trial 12: RMSE=470.3718, MAE=393.2624, R²=0.1832, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,491] Trial 13 finished with values: [634.9284813824218, 423.3529411764706, -0.4883433998270901] and parameters: {'max_depth': 69, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,525] Trial 14 finished with values: [632.77553868093, 424.88235294117646, -0.47826703537257864] and parameters: {'max_depth': 38, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,560] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=634.9285, MAE=423.3529, R²=-0.4883, Time=0.03s\n  Trial 14: RMSE=632.7755, MAE=424.8824, R²=-0.4783, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_lonen_en_salarissen_trajectory: [{'max_depth': 69, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 96, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 85, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_lonen_en_salarissen_trajectory: 0.48 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,595] Trial 0 finished with values: [56.11568518817116, 10.995172413793103, -0.03277454873604024] and parameters: {'max_depth': 5, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,627] Trial 1 finished with values: [56.11568518817116, 10.995172413793103, -0.03277454873604024] and parameters: {'max_depth': 51, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,658] Trial 2 finished with values: [56.11568518817116, 10.995172413793103, -0.03277454873604024] and parameters: {'max_depth': 5, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,690] Trial 3 finished with values: [56.083304910241985, 10.884827586206896, -0.0315830145516689] and parameters: {'max_depth': 39, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=56.1157, MAE=10.9952, R²=-0.0328, Time=0.03s\n  Trial 1: RMSE=56.1157, MAE=10.9952, R²=-0.0328, Time=0.03s\n  Trial 2: RMSE=56.1157, MAE=10.9952, R²=-0.0328, Time=0.03s\n  Trial 3: RMSE=56.0833, MAE=10.8848, R²=-0.0316, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,725] Trial 4 finished with values: [56.11568518817116, 10.995172413793103, -0.03277454873604024] and parameters: {'max_depth': 63, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,758] Trial 5 finished with values: [56.08275904472751, 10.655172413793103, -0.031562933607670596] and parameters: {'max_depth': 28, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,791] Trial 6 finished with values: [56.11566060840095, 10.989655172413794, -0.03277364398524041] and parameters: {'max_depth': 55, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=56.1157, MAE=10.9952, R²=-0.0328, Time=0.03s\n  Trial 5: RMSE=56.0828, MAE=10.6552, R²=-0.0316, Time=0.03s\n  Trial 6: RMSE=56.1157, MAE=10.9897, R²=-0.0328, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,824] Trial 7 finished with values: [56.11568518817116, 10.995172413793103, -0.03277454873604024] and parameters: {'max_depth': 67, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,858] Trial 8 finished with values: [56.08337389624671, 10.862068965517242, -0.03158555237766203] and parameters: {'max_depth': 60, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,891] Trial 9 finished with values: [56.08369361637277, 10.83448275862069, -0.03159731413805722] and parameters: {'max_depth': 27, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,925] Trial 10 finished with values: [56.081836754809515, 10.724137931034482, -0.03152900545268378] and parameters: {'max_depth': 99, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=56.1157, MAE=10.9952, R²=-0.0328, Time=0.03s\n  Trial 8: RMSE=56.0834, MAE=10.8621, R²=-0.0316, Time=0.03s\n  Trial 9: RMSE=56.0837, MAE=10.8345, R²=-0.0316, Time=0.03s\n  Trial 10: RMSE=56.0818, MAE=10.7241, R²=-0.0315, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:51,959] Trial 11 finished with values: [56.08275904472751, 10.655172413793103, -0.031562933607670596] and parameters: {'max_depth': 52, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:51,991] Trial 12 finished with values: [56.08337389624671, 10.862068965517242, -0.03158555237766203] and parameters: {'max_depth': 21, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,024] Trial 13 finished with values: [56.08275904472751, 10.655172413793103, -0.031562933607670596] and parameters: {'max_depth': 22, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=56.0828, MAE=10.6552, R²=-0.0316, Time=0.03s\n  Trial 12: RMSE=56.0834, MAE=10.8621, R²=-0.0316, Time=0.03s\n  Trial 13: RMSE=56.0828, MAE=10.6552, R²=-0.0316, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,058] Trial 14 finished with values: [56.11566060840095, 10.989655172413794, -0.03277364398524041] and parameters: {'max_depth': 31, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,092] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_overige_personeelskosten_trajectory\n[I 2025-01-19 13:44:52,127] Trial 0 finished with values: [615.7107468686281, 606.047619047619, -9.30442634718575] and parameters: {'max_depth': 25, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=56.1157, MAE=10.9897, R²=-0.0328, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: [{'max_depth': 28, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 99, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 52, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 22, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: 0.50 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: RMSE=615.7107, MAE=606.0476, R²=-9.3044, Time=0.03s\n  Trial 1: RMSE=605.2874, MAE=595.0762, R²=-8.9585, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,161] Trial 1 finished with values: [605.2874248377102, 595.0761904761905, -8.958493723595609] and parameters: {'max_depth': 89, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,196] Trial 2 finished with values: [605.2874248377102, 595.0761904761905, -8.958493723595609] and parameters: {'max_depth': 48, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,229] Trial 3 finished with values: [605.2874248377102, 595.0761904761905, -8.958493723595609] and parameters: {'max_depth': 88, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=605.2874, MAE=595.0762, R²=-8.9585, Time=0.03s\n  Trial 3: RMSE=605.2874, MAE=595.0762, R²=-8.9585, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,265] Trial 4 finished with values: [618.0424935306016, 607.2285714285714, -9.382621533976437] and parameters: {'max_depth': 68, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,300] Trial 5 finished with values: [613.2863169523289, 604.6730476190476, -9.223436453096205] and parameters: {'max_depth': 28, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,335] Trial 6 finished with values: [636.0011006279785, 344.3333333333333, -9.99476840564087] and parameters: {'max_depth': 37, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,370] Trial 7 finished with values: [192.4349240652538, 56.32380952380952, -0.0065564519894769635] and parameters: {'max_depth': 68, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=618.0425, MAE=607.2286, R²=-9.3826, Time=0.03s\n  Trial 5: RMSE=613.2863, MAE=604.6730, R²=-9.2234, Time=0.03s\n  Trial 6: RMSE=636.0011, MAE=344.3333, R²=-9.9948, Time=0.03s\n  Trial 7: RMSE=192.4349, MAE=56.3238, R²=-0.0066, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,405] Trial 8 finished with values: [618.0884913443875, 607.2507619047619, -9.38416704474243] and parameters: {'max_depth': 23, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,440] Trial 9 finished with values: [615.7107468686281, 606.047619047619, -9.30442634718575] and parameters: {'max_depth': 20, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=618.0885, MAE=607.2508, R²=-9.3842, Time=0.03s\n  Trial 9: RMSE=615.7107, MAE=606.0476, R²=-9.3044, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,475] Trial 10 finished with values: [605.2874248377102, 595.0761904761905, -8.958493723595609] and parameters: {'max_depth': 98, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,510] Trial 11 finished with values: [613.2863169523289, 604.6730476190476, -9.223436453096205] and parameters: {'max_depth': 26, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,544] Trial 12 finished with values: [618.0884913443875, 607.2507619047619, -9.38416704474243] and parameters: {'max_depth': 55, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,579] Trial 13 finished with values: [617.9883075061256, 607.202380952381, -9.38080104969527] and parameters: {'max_depth': 86, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=605.2874, MAE=595.0762, R²=-8.9585, Time=0.03s\n  Trial 11: RMSE=613.2863, MAE=604.6730, R²=-9.2234, Time=0.03s\n  Trial 12: RMSE=618.0885, MAE=607.2508, R²=-9.3842, Time=0.03s\n  Trial 13: RMSE=617.9883, MAE=607.2024, R²=-9.3808, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,616] Trial 14 finished with values: [617.9833870474729, 607.2, -9.380635745276455] and parameters: {'max_depth': 67, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,651] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_overige_rentelasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=617.9834, MAE=607.2000, R²=-9.3806, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_overige_personeelskosten_trajectory: [{'max_depth': 68, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_overige_personeelskosten_trajectory: 0.52 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,685] Trial 0 finished with values: [85.31937510189452, 30.043000000000003, 0.8104699837136203] and parameters: {'max_depth': 97, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,720] Trial 1 finished with values: [94.73110092959615, 33.89211111111111, 0.7663488961242368] and parameters: {'max_depth': 82, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,754] Trial 2 finished with values: [85.31108652064708, 29.89211111111111, 0.8105068067360717] and parameters: {'max_depth': 75, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,789] Trial 3 finished with values: [85.31937510189452, 30.043000000000003, 0.8104699837136203] and parameters: {'max_depth': 81, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=85.3194, MAE=30.0430, R²=0.8105, Time=0.03s\n  Trial 1: RMSE=94.7311, MAE=33.8921, R²=0.7663, Time=0.03s\n  Trial 2: RMSE=85.3111, MAE=29.8921, R²=0.8105, Time=0.03s\n  Trial 3: RMSE=85.3194, MAE=30.0430, R²=0.8105, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,823] Trial 4 finished with values: [85.31108652064708, 29.89211111111111, 0.8105068067360717] and parameters: {'max_depth': 60, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,858] Trial 5 finished with values: [85.31108652064708, 29.89211111111111, 0.8105068067360717] and parameters: {'max_depth': 84, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=85.3111, MAE=29.8921, R²=0.8105, Time=0.03s\n  Trial 5: RMSE=85.3111, MAE=29.8921, R²=0.8105, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:52,892] Trial 6 finished with values: [92.96725827468029, 33.422222222222224, 0.7749688111612745] and parameters: {'max_depth': 51, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,927] Trial 7 finished with values: [94.7350887416531, 34.03655555555555, 0.7663292240990691] and parameters: {'max_depth': 52, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,960] Trial 8 finished with values: [94.73856536689681, 34.043000000000006, 0.7663120731017855] and parameters: {'max_depth': 11, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:52,994] Trial 9 finished with values: [85.31551464352125, 30.036555555555555, 0.810487134710904] and parameters: {'max_depth': 86, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=92.9673, MAE=33.4222, R²=0.7750, Time=0.03s\n  Trial 7: RMSE=94.7351, MAE=34.0366, R²=0.7663, Time=0.03s\n  Trial 8: RMSE=94.7386, MAE=34.0430, R²=0.7663, Time=0.03s\n  Trial 9: RMSE=85.3155, MAE=30.0366, R²=0.8105, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,029] Trial 10 finished with values: [85.31215557521033, 29.894444444444446, 0.8105020575331134] and parameters: {'max_depth': 78, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,064] Trial 11 finished with values: [94.73384256841784, 33.931, 0.7663353716069341] and parameters: {'max_depth': 20, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=85.3122, MAE=29.8944, R²=0.8105, Time=0.03s\n  Trial 11: RMSE=94.7338, MAE=33.9310, R²=0.7663, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,098] Trial 12 finished with values: [85.31937510189452, 30.043000000000003, 0.8104699837136203] and parameters: {'max_depth': 42, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,132] Trial 13 finished with values: [85.31367504685284, 29.964333333333332, 0.8104953072801833] and parameters: {'max_depth': 46, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,166] Trial 14 finished with values: [85.31108652064708, 29.89211111111111, 0.8105068067360717] and parameters: {'max_depth': 47, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,201] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_sociale_lasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=85.3194, MAE=30.0430, R²=0.8105, Time=0.03s\n  Trial 13: RMSE=85.3137, MAE=29.9643, R²=0.8105, Time=0.03s\n  Trial 14: RMSE=85.3111, MAE=29.8921, R²=0.8105, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_overige_rentelasten_trajectory: [{'max_depth': 75, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 60, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 84, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 47, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_overige_rentelasten_trajectory: 0.52 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:44:53,234] Trial 0 failed with parameters: {'max_depth': 36, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:44:53,236] Trial 0 failed with value None.\n[I 2025-01-19 13:44:53,237] A new study created in memory with name: TrainerDecisionTree_week_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:44:53,270] Trial 0 finished with values: [234.36955011584882, 151.50537634408602, -0.0619431518260356] and parameters: {'max_depth': 26, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerDecisionTree on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: RMSE=234.3696, MAE=151.5054, R²=-0.0619, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,304] Trial 1 finished with values: [231.98585833336193, 153.16924731182797, -0.04045168721941628] and parameters: {'max_depth': 41, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,338] Trial 2 finished with values: [234.36955011584882, 151.50537634408602, -0.0619431518260356] and parameters: {'max_depth': 87, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,371] Trial 3 finished with values: [231.98585833336193, 153.16924731182797, -0.04045168721941628] and parameters: {'max_depth': 87, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,405] Trial 4 finished with values: [252.000609668148, 155.0995698924731, -0.22772776874061784] and parameters: {'max_depth': 30, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,438] Trial 5 finished with values: [252.000609668148, 155.0995698924731, -0.22772776874061784] and parameters: {'max_depth': 37, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=231.9859, MAE=153.1692, R²=-0.0405, Time=0.03s\n  Trial 2: RMSE=234.3696, MAE=151.5054, R²=-0.0619, Time=0.03s\n  Trial 3: RMSE=231.9859, MAE=153.1692, R²=-0.0405, Time=0.03s\n  Trial 4: RMSE=252.0006, MAE=155.0996, R²=-0.2277, Time=0.03s\n  Trial 5: RMSE=252.0006, MAE=155.0996, R²=-0.2277, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,473] Trial 6 finished with values: [234.36955011584882, 151.50537634408602, -0.0619431518260356] and parameters: {'max_depth': 20, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=234.3696, MAE=151.5054, R²=-0.0619, Time=0.03s\n  Trial 7: RMSE=252.0006, MAE=155.0996, R²=-0.2277, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,506] Trial 7 finished with values: [252.000609668148, 155.0995698924731, -0.22772776874061784] and parameters: {'max_depth': 52, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,541] Trial 8 finished with values: [241.69818111166697, 182.48387096774192, -0.12939447850686703] and parameters: {'max_depth': 19, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,575] Trial 9 finished with values: [251.39648361968807, 155.52688172043014, -0.2218483125150319] and parameters: {'max_depth': 25, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,610] Trial 10 finished with values: [234.36955011584882, 151.50537634408602, -0.0619431518260356] and parameters: {'max_depth': 61, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,645] Trial 11 finished with values: [241.69818111166697, 182.48387096774192, -0.12939447850686703] and parameters: {'max_depth': 36, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=241.6982, MAE=182.4839, R²=-0.1294, Time=0.03s\n  Trial 9: RMSE=251.3965, MAE=155.5269, R²=-0.2218, Time=0.03s\n  Trial 10: RMSE=234.3696, MAE=151.5054, R²=-0.0619, Time=0.03s\n  Trial 11: RMSE=241.6982, MAE=182.4839, R²=-0.1294, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,681] Trial 12 finished with values: [251.39648361968807, 155.52688172043014, -0.2218483125150319] and parameters: {'max_depth': 69, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,714] Trial 13 finished with values: [252.000609668148, 155.0995698924731, -0.22772776874061784] and parameters: {'max_depth': 29, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=251.3965, MAE=155.5269, R²=-0.2218, Time=0.03s\n  Trial 13: RMSE=252.0006, MAE=155.0996, R²=-0.2277, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,749] Trial 14 finished with values: [252.000609668148, 155.0995698924731, -0.22772776874061784] and parameters: {'max_depth': 61, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,783] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_afschrijvingen_mva_trajectory\n[I 2025-01-19 13:44:53,820] Trial 0 finished with values: [528.9570943469802, 398.51088888888887, -0.11286305236056338] and parameters: {'max_depth': 97, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,857] Trial 1 finished with values: [518.5866870232766, 386.1331111111111, -0.06965458824968396] and parameters: {'max_depth': 20, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=252.0006, MAE=155.0996, R²=-0.2277, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_week_data_cleaned_verkoopkosten_trajectory: [{'max_depth': 26, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 41, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 87, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 87, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 20, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 61, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_week_data_cleaned_verkoopkosten_trajectory: 0.51 seconds\n  Added results for TrainerDecisionTree on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: RMSE=528.9571, MAE=398.5109, R²=-0.1129, Time=0.04s\n  Trial 1: RMSE=518.5867, MAE=386.1331, R²=-0.0697, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,896] Trial 2 finished with values: [521.2422994858853, 389.096, -0.0806377517616339] and parameters: {'max_depth': 8, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:53,933] Trial 3 finished with values: [555.8568569381733, 420.8850977431334, -0.22892892480352245] and parameters: {'max_depth': 44, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=521.2423, MAE=389.0960, R²=-0.0806, Time=0.04s\n  Trial 3: RMSE=555.8569, MAE=420.8851, R²=-0.2289, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:53,970] Trial 4 finished with values: [528.9570943469802, 398.51088888888887, -0.11286305236056338] and parameters: {'max_depth': 63, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,008] Trial 5 finished with values: [574.1028150651629, 439.8586479558929, -0.31093205852405714] and parameters: {'max_depth': 77, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,046] Trial 6 finished with values: [528.9570943469802, 398.51088888888887, -0.11286305236056338] and parameters: {'max_depth': 76, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,084] Trial 7 finished with values: [558.099654252664, 425.6317872517812, -0.23886601187167966] and parameters: {'max_depth': 71, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=528.9571, MAE=398.5109, R²=-0.1129, Time=0.04s\n  Trial 5: RMSE=574.1028, MAE=439.8586, R²=-0.3109, Time=0.04s\n  Trial 6: RMSE=528.9571, MAE=398.5109, R²=-0.1129, Time=0.04s\n  Trial 7: RMSE=558.0997, MAE=425.6318, R²=-0.2389, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,123] Trial 8 finished with values: [520.3964838488268, 387.71088888888886, -0.07713351305085081] and parameters: {'max_depth': 22, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,161] Trial 9 finished with values: [574.1028150651629, 439.8586479558929, -0.31093205852405714] and parameters: {'max_depth': 6, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=520.3965, MAE=387.7109, R²=-0.0771, Time=0.04s\n  Trial 9: RMSE=574.1028, MAE=439.8586, R²=-0.3109, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,199] Trial 10 finished with values: [556.4701951721559, 422.07050516747637, -0.23164244694257508] and parameters: {'max_depth': 25, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,236] Trial 11 finished with values: [566.6198221293588, 435.8368828868992, -0.276980772712881] and parameters: {'max_depth': 95, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,274] Trial 12 finished with values: [555.8568569381733, 420.8850977431334, -0.22892892480352245] and parameters: {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,312] Trial 13 finished with values: [582.1838663012371, 449.402744788588, -0.3480970651829498] and parameters: {'max_depth': 32, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=556.4702, MAE=422.0705, R²=-0.2316, Time=0.04s\n  Trial 11: RMSE=566.6198, MAE=435.8369, R²=-0.2770, Time=0.04s\n  Trial 12: RMSE=555.8569, MAE=420.8851, R²=-0.2289, Time=0.04s\n  Trial 13: RMSE=582.1839, MAE=449.4027, R²=-0.3481, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,351] Trial 14 finished with values: [521.5273582852582, 390.7111111111111, -0.08182004081538086] and parameters: {'max_depth': 79, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,390] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_afschrijvingen_iva_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=521.5274, MAE=390.7111, R²=-0.0818, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_afschrijvingen_mva_trajectory: [{'max_depth': 20, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_afschrijvingen_mva_trajectory: 0.57 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,429] Trial 0 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 81, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,466] Trial 1 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 100, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,503] Trial 2 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 9, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,541] Trial 3 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 54, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 1: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 2: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 3: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,579] Trial 4 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 98, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,616] Trial 5 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 64, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 5: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,653] Trial 6 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 35, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,693] Trial 7 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 84, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,731] Trial 8 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 89, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,767] Trial 9 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 26, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 7: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 8: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 9: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,806] Trial 10 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 78, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,843] Trial 11 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 35, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 11: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:54,881] Trial 12 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 56, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,917] Trial 13 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 42, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,954] Trial 14 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'max_depth': 76, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:54,992] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_omzet_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\n  Trial 13: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 14: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_afschrijvingen_iva_trajectory: [{'max_depth': 81, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 100, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 9, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 54, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 98, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 64, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 35, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 84, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 89, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 26, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 78, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 35, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 56, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 42, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'max_depth': 76, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_afschrijvingen_iva_trajectory: 0.56 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,030] Trial 0 finished with values: [1060.1828353244862, 789.4346296296296, -0.5893030100060392] and parameters: {'max_depth': 84, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,067] Trial 1 finished with values: [1019.4194861592117, 765.7309259259259, -0.4694372009034429] and parameters: {'max_depth': 79, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1060.1828, MAE=789.4346, R²=-0.5893, Time=0.04s\n  Trial 1: RMSE=1019.4195, MAE=765.7309, R²=-0.4694, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,105] Trial 2 finished with values: [930.7783496480642, 701.6107726485915, -0.22500458555438296] and parameters: {'max_depth': 21, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,143] Trial 3 finished with values: [1037.59150776637, 786.3111111111111, -0.5222920729858629] and parameters: {'max_depth': 76, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,180] Trial 4 finished with values: [996.7438863972884, 755.5622222222222, -0.40479298497572946] and parameters: {'max_depth': 100, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,218] Trial 5 finished with values: [941.1903364979233, 710.1340915975054, -0.25256446790827125] and parameters: {'max_depth': 93, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=930.7783, MAE=701.6108, R²=-0.2250, Time=0.04s\n  Trial 3: RMSE=1037.5915, MAE=786.3111, R²=-0.5223, Time=0.04s\n  Trial 4: RMSE=996.7439, MAE=755.5622, R²=-0.4048, Time=0.04s\n  Trial 5: RMSE=941.1903, MAE=710.1341, R²=-0.2526, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,256] Trial 6 finished with values: [928.1888249812588, 697.4911251042814, -0.21819788034595056] and parameters: {'max_depth': 40, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,293] Trial 7 finished with values: [930.5804625542594, 701.4394500894346, -0.2244837594554634] and parameters: {'max_depth': 61, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=928.1888, MAE=697.4911, R²=-0.2182, Time=0.04s\n  Trial 7: RMSE=930.5805, MAE=701.4395, R²=-0.2245, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,331] Trial 8 finished with values: [940.3756362835617, 703.7729574926802, -0.2503969512206845] and parameters: {'max_depth': 21, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,368] Trial 9 finished with values: [996.7438863972884, 755.5622222222222, -0.40479298497572946] and parameters: {'max_depth': 11, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,405] Trial 10 finished with values: [1038.6699602019526, 790.7466666666667, -0.5254581990907803] and parameters: {'max_depth': 7, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,443] Trial 11 finished with values: [943.5309924415963, 714.290650009179, -0.25880224562985954] and parameters: {'max_depth': 98, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=940.3756, MAE=703.7730, R²=-0.2504, Time=0.04s\n  Trial 9: RMSE=996.7439, MAE=755.5622, R²=-0.4048, Time=0.04s\n  Trial 10: RMSE=1038.6700, MAE=790.7467, R²=-0.5255, Time=0.04s\n  Trial 11: RMSE=943.5310, MAE=714.2907, R²=-0.2588, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,480] Trial 12 finished with values: [943.1594174329211, 714.290650009179, -0.257810974843657] and parameters: {'max_depth': 82, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,518] Trial 13 finished with values: [943.9843928220326, 714.634805856618, -0.260012335287678] and parameters: {'max_depth': 74, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=943.1594, MAE=714.2907, R²=-0.2578, Time=0.04s\n  Trial 13: RMSE=943.9844, MAE=714.6348, R²=-0.2600, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,558] Trial 14 finished with values: [930.0056388403965, 701.1035989460778, -0.22297148847827697] and parameters: {'max_depth': 33, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,597] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:44:55,636] Trial 0 finished with values: [1163.6903661175818, 973.4710256410256, -0.08557296850749707] and parameters: {'max_depth': 40, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,674] Trial 1 finished with values: [1410.913570166883, 1173.9529353119592, -0.5958238953521378] and parameters: {'max_depth': 12, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=930.0056, MAE=701.1036, R²=-0.2230, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_omzet_trajectory: [{'max_depth': 40, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_omzet_trajectory: 0.57 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: RMSE=1163.6904, MAE=973.4710, R²=-0.0856, Time=0.04s\n  Trial 1: RMSE=1410.9136, MAE=1173.9529, R²=-0.5958, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,712] Trial 2 finished with values: [1346.6993947461535, 1114.4571565028552, -0.45386965660581646] and parameters: {'max_depth': 13, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,756] Trial 3 finished with values: [1171.3674040837911, 989.2980769230769, -0.09994358702438211] and parameters: {'max_depth': 96, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1346.6994, MAE=1114.4572, R²=-0.4539, Time=0.04s\n  Trial 3: RMSE=1171.3674, MAE=989.2981, R²=-0.0999, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,795] Trial 4 finished with values: [1175.705816965347, 989.0638461538463, -0.10810643413023868] and parameters: {'max_depth': 58, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,835] Trial 5 finished with values: [1364.5029150385033, 1130.9483470420284, -0.49256439834935994] and parameters: {'max_depth': 73, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,872] Trial 6 finished with values: [1164.8897613090107, 971.3838461538462, -0.08781188364596826] and parameters: {'max_depth': 87, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,909] Trial 7 finished with values: [1377.2933824449042, 1145.5591884377461, -0.5206773045568476] and parameters: {'max_depth': 66, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1175.7058, MAE=989.0638, R²=-0.1081, Time=0.04s\n  Trial 5: RMSE=1364.5029, MAE=1130.9483, R²=-0.4926, Time=0.04s\n  Trial 6: RMSE=1164.8898, MAE=971.3838, R²=-0.0878, Time=0.04s\n  Trial 7: RMSE=1377.2934, MAE=1145.5592, R²=-0.5207, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:55,946] Trial 8 finished with values: [1357.50101466939, 1125.0186627819253, -0.47728561342774234] and parameters: {'max_depth': 15, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:55,983] Trial 9 finished with values: [1171.3017533004104, 983.2564102564103, -0.0998202949909861] and parameters: {'max_depth': 90, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1357.5010, MAE=1125.0187, R²=-0.4773, Time=0.04s\n  Trial 9: RMSE=1171.3018, MAE=983.2564, R²=-0.0998, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,021] Trial 10 finished with values: [1386.220745359515, 1159.785563302679, -0.5404546965705801] and parameters: {'max_depth': 33, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,058] Trial 11 finished with values: [1369.5626859853608, 1143.5753281406749, -0.5036542038806402] and parameters: {'max_depth': 100, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,096] Trial 12 finished with values: [1169.4962001599072, 988.2596153846154, -0.09643217839980656] and parameters: {'max_depth': 63, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,134] Trial 13 finished with values: [1360.4419887520708, 1133.0005490757394, -0.4836935128301727] and parameters: {'max_depth': 73, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1386.2207, MAE=1159.7856, R²=-0.5405, Time=0.04s\n  Trial 11: RMSE=1369.5627, MAE=1143.5753, R²=-0.5037, Time=0.04s\n  Trial 12: RMSE=1169.4962, MAE=988.2596, R²=-0.0964, Time=0.04s\n  Trial 13: RMSE=1360.4420, MAE=1133.0005, R²=-0.4837, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,173] Trial 14 finished with values: [1172.758774834485, 983.8289743589742, -0.1025582035221011] and parameters: {'max_depth': 90, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,212] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_autokosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1172.7588, MAE=983.8290, R²=-0.1026, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_algemene_kosten_trajectory: [{'max_depth': 40, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 87, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_algemene_kosten_trajectory: 0.58 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,250] Trial 0 finished with values: [1433.5304725025828, 1239.4595652173912, -0.10749780823447996] and parameters: {'max_depth': 85, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,288] Trial 1 finished with values: [1504.524619719597, 1333.5264023190969, -0.21990950391232578] and parameters: {'max_depth': 43, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,325] Trial 2 finished with values: [1428.3153837978077, 1233.2117391304346, -0.09945445845501522] and parameters: {'max_depth': 99, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,363] Trial 3 finished with values: [1432.3826809383638, 1238.2058695652172, -0.10572502730435596] and parameters: {'max_depth': 90, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1433.5305, MAE=1239.4596, R²=-0.1075, Time=0.04s\n  Trial 1: RMSE=1504.5246, MAE=1333.5264, R²=-0.2199, Time=0.04s\n  Trial 2: RMSE=1428.3154, MAE=1233.2117, R²=-0.0995, Time=0.04s\n  Trial 3: RMSE=1432.3827, MAE=1238.2059, R²=-0.1057, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,401] Trial 4 finished with values: [1432.3826809383638, 1238.2058695652172, -0.10572502730435596] and parameters: {'max_depth': 53, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,438] Trial 5 finished with values: [1517.0221157517476, 1342.4938363313286, -0.24026029709183772] and parameters: {'max_depth': 36, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1432.3827, MAE=1238.2059, R²=-0.1057, Time=0.04s\n  Trial 5: RMSE=1517.0221, MAE=1342.4938, R²=-0.2403, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,476] Trial 6 finished with values: [1440.0867693015555, 1234.0193478260867, -0.11765132624282049] and parameters: {'max_depth': 62, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,513] Trial 7 finished with values: [1517.6764223948628, 1343.8527264559284, -0.2413304008819075] and parameters: {'max_depth': 12, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,551] Trial 8 finished with values: [1437.33487749444, 1239.459456521739, -0.11338392107489459] and parameters: {'max_depth': 47, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,589] Trial 9 finished with values: [1519.2368915927266, 1357.600598352324, -0.24388437571363863] and parameters: {'max_depth': 86, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1440.0868, MAE=1234.0193, R²=-0.1177, Time=0.04s\n  Trial 7: RMSE=1517.6764, MAE=1343.8527, R²=-0.2413, Time=0.04s\n  Trial 8: RMSE=1437.3349, MAE=1239.4595, R²=-0.1134, Time=0.04s\n  Trial 9: RMSE=1519.2369, MAE=1357.6006, R²=-0.2439, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,628] Trial 10 finished with values: [1502.4662760176093, 1355.4715818873656, -0.21657386504844367] and parameters: {'max_depth': 5, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,666] Trial 11 finished with values: [1504.524619719597, 1333.5264023190969, -0.21990950391232578] and parameters: {'max_depth': 55, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1502.4663, MAE=1355.4716, R²=-0.2166, Time=0.04s\n  Trial 11: RMSE=1504.5246, MAE=1333.5264, R²=-0.2199, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,705] Trial 12 finished with values: [1503.447384813095, 1332.167512194497, -0.21816322654735076] and parameters: {'max_depth': 21, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,745] Trial 13 finished with values: [1426.2159585176555, 1233.2121739130434, -0.09622474304712592] and parameters: {'max_depth': 87, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,783] Trial 14 finished with values: [1514.7968524532014, 1346.4284018947471, -0.23662438237494676] and parameters: {'max_depth': 96, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,825] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_overige_rentelasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1503.4474, MAE=1332.1675, R²=-0.2182, Time=0.04s\n  Trial 13: RMSE=1426.2160, MAE=1233.2122, R²=-0.0962, Time=0.04s\n  Trial 14: RMSE=1514.7969, MAE=1346.4284, R²=-0.2366, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_autokosten_trajectory: [{'max_depth': 99, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 87, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_autokosten_trajectory: 0.57 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,866] Trial 0 finished with values: [989.351820110404, 729.7794230769231, -0.4678282245806662] and parameters: {'max_depth': 65, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,904] Trial 1 finished with values: [1228.523880208815, 991.7209425033099, -1.2632937586130542] and parameters: {'max_depth': 85, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=989.3518, MAE=729.7794, R²=-0.4678, Time=0.04s\n  Trial 1: RMSE=1228.5239, MAE=991.7209, R²=-1.2633, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:56,941] Trial 2 finished with values: [898.2563933725245, 642.0088461538461, -0.2099693081817655] and parameters: {'max_depth': 9, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:56,979] Trial 3 finished with values: [1144.0152127348717, 910.5058526926746, -0.9626249676495695] and parameters: {'max_depth': 97, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,016] Trial 4 finished with values: [904.6629258458645, 643.4023076923077, -0.22729031148528023] and parameters: {'max_depth': 51, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,057] Trial 5 finished with values: [1145.025066873788, 905.4564836818262, -0.966091424550702] and parameters: {'max_depth': 76, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=898.2564, MAE=642.0088, R²=-0.2100, Time=0.04s\n  Trial 3: RMSE=1144.0152, MAE=910.5059, R²=-0.9626, Time=0.04s\n  Trial 4: RMSE=904.6629, MAE=643.4023, R²=-0.2273, Time=0.04s\n  Trial 5: RMSE=1145.0251, MAE=905.4565, R²=-0.9661, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,096] Trial 6 finished with values: [1137.250282562123, 902.450815699295, -0.9394823292209988] and parameters: {'max_depth': 72, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,132] Trial 7 finished with values: [982.9598026750637, 727.9348076923077, -0.44892276648387597] and parameters: {'max_depth': 84, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1137.2503, MAE=902.4508, R²=-0.9395, Time=0.04s\n  Trial 7: RMSE=982.9598, MAE=727.9348, R²=-0.4489, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,172] Trial 8 finished with values: [989.0337194628985, 736.5823076923077, -0.4668844914483683] and parameters: {'max_depth': 91, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,209] Trial 9 finished with values: [1220.1029516990004, 982.251301667475, -1.2323725611064975] and parameters: {'max_depth': 87, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,246] Trial 10 finished with values: [975.8121169490648, 727.988076923077, -0.4279274203629966] and parameters: {'max_depth': 17, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,283] Trial 11 finished with values: [905.0726740199885, 648.8815384615385, -0.22840231427519986] and parameters: {'max_depth': 48, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=989.0337, MAE=736.5823, R²=-0.4669, Time=0.04s\n  Trial 9: RMSE=1220.1030, MAE=982.2513, R²=-1.2324, Time=0.04s\n  Trial 10: RMSE=975.8121, MAE=727.9881, R²=-0.4279, Time=0.04s\n  Trial 11: RMSE=905.0727, MAE=648.8815, R²=-0.2284, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,321] Trial 12 finished with values: [974.7220777285894, 732.1034615384616, -0.42473904523191264] and parameters: {'max_depth': 5, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,357] Trial 13 finished with values: [981.0083719689027, 727.3026923076924, -0.4431755004494313] and parameters: {'max_depth': 8, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=974.7221, MAE=732.1035, R²=-0.4247, Time=0.04s\n  Trial 13: RMSE=981.0084, MAE=727.3027, R²=-0.4432, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,394] Trial 14 finished with values: [993.8107765043374, 738.7488461538462, -0.4810888884982649] and parameters: {'max_depth': 57, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,432] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_pensioenlasten_trajectory\n[I 2025-01-19 13:44:57,469] Trial 0 finished with values: [558.2640810823016, 373.24133333333333, -0.3735325492844759] and parameters: {'max_depth': 67, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,506] Trial 1 finished with values: [680614.5801733338, 318829.2060890324, -2041558.6805637358] and parameters: {'max_depth': 42, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=993.8108, MAE=738.7488, R²=-0.4811, Time=0.03s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_overige_rentelasten_trajectory: [{'max_depth': 9, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_overige_rentelasten_trajectory: 0.57 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: RMSE=558.2641, MAE=373.2413, R²=-0.3735, Time=0.04s\n  Trial 1: RMSE=680614.5802, MAE=318829.2061, R²=-2041558.6806, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,544] Trial 2 finished with values: [558.2640810823016, 373.24133333333333, -0.3735325492844759] and parameters: {'max_depth': 44, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,581] Trial 3 finished with values: [557.9885445060678, 329.9506666666667, -0.3721770436272005] and parameters: {'max_depth': 47, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=558.2641, MAE=373.2413, R²=-0.3735, Time=0.04s\n  Trial 3: RMSE=557.9885, MAE=329.9507, R²=-0.3722, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,618] Trial 4 finished with values: [962631.009664884, 434728.54506270663, -4083938.302701004] and parameters: {'max_depth': 66, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,654] Trial 5 finished with values: [681814.0358842091, 320664.2849239425, -2048760.754189896] and parameters: {'max_depth': 48, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,691] Trial 6 finished with values: [551.016659046409, 378.38933333333335, -0.3381014515330245] and parameters: {'max_depth': 46, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,727] Trial 7 finished with values: [684154.280540643, 322782.63868391525, -2062849.1476375568] and parameters: {'max_depth': 12, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=962631.0097, MAE=434728.5451, R²=-4083938.3027, Time=0.04s\n  Trial 5: RMSE=681814.0359, MAE=320664.2849, R²=-2048760.7542, Time=0.04s\n  Trial 6: RMSE=551.0167, MAE=378.3893, R²=-0.3381, Time=0.04s\n  Trial 7: RMSE=684154.2805, MAE=322782.6387, R²=-2062849.1476, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,763] Trial 8 finished with values: [558.2640810823016, 373.24133333333333, -0.3735325492844759] and parameters: {'max_depth': 11, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,800] Trial 9 finished with values: [557.9885445060678, 329.9506666666667, -0.3721770436272005] and parameters: {'max_depth': 24, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=558.2641, MAE=373.2413, R²=-0.3735, Time=0.03s\n  Trial 9: RMSE=557.9885, MAE=329.9507, R²=-0.3722, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,837] Trial 10 finished with values: [631.0456450632818, 404.90066666666667, -0.7550162067130923] and parameters: {'max_depth': 89, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,878] Trial 11 finished with values: [489.5853281706877, 299.91200000000003, -0.05637076180304179] and parameters: {'max_depth': 82, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,916] Trial 12 finished with values: [633552.6365436686, 303071.64652467397, -1768987.414282088] and parameters: {'max_depth': 83, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:57,952] Trial 13 finished with values: [688.4026922279334, 431.6, -1.08854916742137] and parameters: {'max_depth': 31, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=631.0456, MAE=404.9007, R²=-0.7550, Time=0.04s\n  Trial 11: RMSE=489.5853, MAE=299.9120, R²=-0.0564, Time=0.04s\n  Trial 12: RMSE=633552.6365, MAE=303071.6465, R²=-1768987.4143, Time=0.04s\n  Trial 13: RMSE=688.4027, MAE=431.6000, R²=-1.0885, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:57,990] Trial 14 finished with values: [962788.0802926931, 436519.5964430768, -4085271.148281963] and parameters: {'max_depth': 40, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,028] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=962788.0803, MAE=436519.5964, R²=-4085271.1483, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_pensioenlasten_trajectory: [{'max_depth': 82, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_pensioenlasten_trajectory: 0.56 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,067] Trial 0 finished with values: [1167.6943690655978, 1001.611694297339, -0.13519447944226926] and parameters: {'max_depth': 56, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,104] Trial 1 finished with values: [1134.773472240165, 968.155806451613, -0.07208753839210802] and parameters: {'max_depth': 33, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,142] Trial 2 finished with values: [1135.2573935370979, 969.1800000000001, -0.073002111435019] and parameters: {'max_depth': 19, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,180] Trial 3 finished with values: [1158.8430675171992, 991.3166189180648, -0.11804981140828663] and parameters: {'max_depth': 60, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1167.6944, MAE=1001.6117, R²=-0.1352, Time=0.04s\n  Trial 1: RMSE=1134.7735, MAE=968.1558, R²=-0.0721, Time=0.04s\n  Trial 2: RMSE=1135.2574, MAE=969.1800, R²=-0.0730, Time=0.04s\n  Trial 3: RMSE=1158.8431, MAE=991.3166, R²=-0.1180, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,218] Trial 4 finished with values: [1134.5489298253037, 969.1800000000001, -0.07166330339956106] and parameters: {'max_depth': 48, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,256] Trial 5 finished with values: [1163.7621951009573, 994.5123675479294, -0.12756188914798772] and parameters: {'max_depth': 51, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1134.5489, MAE=969.1800, R²=-0.0717, Time=0.04s\n  Trial 5: RMSE=1163.7622, MAE=994.5124, R²=-0.1276, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,294] Trial 6 finished with values: [1130.4145616585438, 966.1190322580646, -0.06386711630706543] and parameters: {'max_depth': 87, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,332] Trial 7 finished with values: [1135.2573935370979, 969.1800000000001, -0.073002111435019] and parameters: {'max_depth': 45, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,371] Trial 8 finished with values: [1163.0908339408054, 994.5123675479294, -0.12626130916949374] and parameters: {'max_depth': 45, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,408] Trial 9 finished with values: [1160.2342066400918, 994.5123675479294, -0.12073575991896002] and parameters: {'max_depth': 63, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1130.4146, MAE=966.1190, R²=-0.0639, Time=0.04s\n  Trial 7: RMSE=1135.2574, MAE=969.1800, R²=-0.0730, Time=0.04s\n  Trial 8: RMSE=1163.0908, MAE=994.5124, R²=-0.1263, Time=0.04s\n  Trial 9: RMSE=1160.2342, MAE=994.5124, R²=-0.1207, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,446] Trial 10 finished with values: [1162.3461575092415, 992.0244484077451, -0.12481957867584259] and parameters: {'max_depth': 70, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,483] Trial 11 finished with values: [1135.2573935370979, 969.1800000000001, -0.073002111435019] and parameters: {'max_depth': 12, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1162.3462, MAE=992.0244, R²=-0.1248, Time=0.04s\n  Trial 11: RMSE=1135.2574, MAE=969.1800, R²=-0.0730, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,522] Trial 12 finished with values: [1163.0908339408054, 994.5123675479294, -0.12626130916949374] and parameters: {'max_depth': 23, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,566] Trial 13 finished with values: [1158.8430675171992, 991.3166189180648, -0.11804981140828663] and parameters: {'max_depth': 96, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,603] Trial 14 finished with values: [1135.2573935370979, 969.1800000000001, -0.073002111435019] and parameters: {'max_depth': 64, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,642] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_overige_personeelskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1163.0908, MAE=994.5124, R²=-0.1263, Time=0.04s\n  Trial 13: RMSE=1158.8431, MAE=991.3166, R²=-0.1180, Time=0.04s\n  Trial 14: RMSE=1135.2574, MAE=969.1800, R²=-0.0730, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_lonen_en_salarissen_trajectory: [{'max_depth': 87, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_lonen_en_salarissen_trajectory: 0.58 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,681] Trial 0 finished with values: [974.5954249382695, 551.3128787878788, -0.22257229095017017] and parameters: {'max_depth': 55, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,718] Trial 1 finished with values: [956.166219581981, 531.1318181818182, -0.17677275433436646] and parameters: {'max_depth': 83, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=974.5954, MAE=551.3129, R²=-0.2226, Time=0.04s\n  Trial 1: RMSE=956.1662, MAE=531.1318, R²=-0.1768, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,756] Trial 2 finished with values: [1272.5290849547296, 873.0032373486541, -1.0843048857517994] and parameters: {'max_depth': 15, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,792] Trial 3 finished with values: [1265.6450696926274, 846.111387160029, -1.0618149065485798] and parameters: {'max_depth': 12, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,829] Trial 4 finished with values: [991.7561060502118, 565.8487878787878, -0.26600545752816385] and parameters: {'max_depth': 34, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,866] Trial 5 finished with values: [976.6163172395211, 559.2628787878788, -0.22764772725729476] and parameters: {'max_depth': 39, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1272.5291, MAE=873.0032, R²=-1.0843, Time=0.04s\n  Trial 3: RMSE=1265.6451, MAE=846.1114, R²=-1.0618, Time=0.04s\n  Trial 4: RMSE=991.7561, MAE=565.8488, R²=-0.2660, Time=0.04s\n  Trial 5: RMSE=976.6163, MAE=559.2629, R²=-0.2276, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,904] Trial 6 finished with values: [1287.9656591160167, 845.2730962510796, -1.1351794408402864] and parameters: {'max_depth': 70, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:58,945] Trial 7 finished with values: [975.8626275847778, 555.5795454545455, -0.22575361931496474] and parameters: {'max_depth': 71, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1287.9657, MAE=845.2731, R²=-1.1352, Time=0.04s\n  Trial 7: RMSE=975.8626, MAE=555.5795, R²=-0.2258, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:58,987] Trial 8 finished with values: [1285.7161892583556, 910.1115466016472, -1.1277276466878923] and parameters: {'max_depth': 73, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,027] Trial 9 finished with values: [988.6705942524002, 589.1484848484848, -0.2581402208457919] and parameters: {'max_depth': 51, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,069] Trial 10 finished with values: [1150.2878275431053, 770.4984850231239, -0.7030949451678368] and parameters: {'max_depth': 96, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1285.7162, MAE=910.1115, R²=-1.1277, Time=0.04s\n  Trial 9: RMSE=988.6706, MAE=589.1485, R²=-0.2581, Time=0.04s\n  Trial 10: RMSE=1150.2878, MAE=770.4985, R²=-0.7031, Time=0.04s\n  Trial 11: RMSE=995.6447, MAE=568.2265, R²=-0.2760, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,107] Trial 11 finished with values: [995.644694007127, 568.2265151515152, -0.2759527113285345] and parameters: {'max_depth': 21, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,147] Trial 12 finished with values: [947.9736940954479, 526.9606060606061, -0.15669373631177796] and parameters: {'max_depth': 70, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,186] Trial 13 finished with values: [1247.4169089465195, 854.2651152331299, -1.0028529534270838] and parameters: {'max_depth': 93, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=947.9737, MAE=526.9606, R²=-0.1567, Time=0.04s\n  Trial 13: RMSE=1247.4169, MAE=854.2651, R²=-1.0029, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,227] Trial 14 finished with values: [962.8195791370764, 543.969696969697, -0.19320657587145917] and parameters: {'max_depth': 57, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,267] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_sociale_lasten_trajectory\n[I 2025-01-19 13:44:59,311] Trial 0 finished with values: [1682.9038093389477, 1131.0182621600402, -4.428519427271513] and parameters: {'max_depth': 47, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,347] Trial 1 finished with values: [1744.5349017434055, 1155.9849371433972, -4.83340506597196] and parameters: {'max_depth': 7, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=962.8196, MAE=543.9697, R²=-0.1932, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_overige_personeelskosten_trajectory: [{'max_depth': 70, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_overige_personeelskosten_trajectory: 0.59 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: RMSE=1682.9038, MAE=1131.0183, R²=-4.4285, Time=0.04s\n  Trial 1: RMSE=1744.5349, MAE=1155.9849, R²=-4.8334, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,386] Trial 2 finished with values: [874.3228836381519, 667.7166666666667, -0.46523235489688197] and parameters: {'max_depth': 44, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,428] Trial 3 finished with values: [885.3736056151663, 675.3166666666667, -0.5025050871628092] and parameters: {'max_depth': 94, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=874.3229, MAE=667.7167, R²=-0.4652, Time=0.04s\n  Trial 3: RMSE=885.3736, MAE=675.3167, R²=-0.5025, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,469] Trial 4 finished with values: [1699.8967224161631, 1154.1545617739291, -4.538700509934141] and parameters: {'max_depth': 53, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,506] Trial 5 finished with values: [1716.9895439732402, 1168.4596751106044, -4.650646126185621] and parameters: {'max_depth': 100, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,546] Trial 6 finished with values: [1687.4253621220394, 1141.753775220289, -4.457728833846431] and parameters: {'max_depth': 19, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,584] Trial 7 finished with values: [933.9743537806593, 717.394, -0.6719862879442056] and parameters: {'max_depth': 67, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1699.8967, MAE=1154.1546, R²=-4.5387, Time=0.04s\n  Trial 5: RMSE=1716.9895, MAE=1168.4597, R²=-4.6506, Time=0.04s\n  Trial 6: RMSE=1687.4254, MAE=1141.7538, R²=-4.4577, Time=0.04s\n  Trial 7: RMSE=933.9744, MAE=717.3940, R²=-0.6720, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,621] Trial 8 finished with values: [865.3861400207425, 667.106, -0.43543218607867007] and parameters: {'max_depth': 69, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,659] Trial 9 finished with values: [880.0185063508608, 671.05, -0.4843845312655264] and parameters: {'max_depth': 48, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=865.3861, MAE=667.1060, R²=-0.4354, Time=0.04s\n  Trial 9: RMSE=880.0185, MAE=671.0500, R²=-0.4844, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,697] Trial 10 finished with values: [1690.247929661498, 1147.2036078245756, -4.4760024623622465] and parameters: {'max_depth': 8, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,735] Trial 11 finished with values: [854.6270729934392, 661.306, -0.39996153128482814] and parameters: {'max_depth': 5, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,774] Trial 12 finished with values: [864.7201688176355, 667.106, -0.4332237183895282] and parameters: {'max_depth': 54, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,812] Trial 13 finished with values: [858.4769403193076, 646.956, -0.4126028477904462] and parameters: {'max_depth': 65, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1690.2479, MAE=1147.2036, R²=-4.4760, Time=0.04s\n  Trial 11: RMSE=854.6271, MAE=661.3060, R²=-0.4000, Time=0.04s\n  Trial 12: RMSE=864.7202, MAE=667.1060, R²=-0.4332, Time=0.04s\n  Trial 13: RMSE=858.4769, MAE=646.9560, R²=-0.4126, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,851] Trial 14 finished with values: [1699.8967224161631, 1154.1545617739291, -4.538700509934141] and parameters: {'max_depth': 94, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,891] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1699.8967, MAE=1154.1546, R²=-4.5387, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_sociale_lasten_trajectory: [{'max_depth': 5, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 65, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_sociale_lasten_trajectory: 0.58 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:44:59,935] Trial 0 finished with values: [12959.68025186716, 8643.390384984366, -95.82918554381195] and parameters: {'max_depth': 36, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:44:59,974] Trial 1 finished with values: [1472.714968533709, 1148.1678378378379, -0.2504176861399183] and parameters: {'max_depth': 85, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,027] Trial 2 finished with values: [1662.8188907849678, 1254.287027027027, -0.5940707958162736] and parameters: {'max_depth': 9, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=12959.6803, MAE=8643.3904, R²=-95.8292, Time=0.04s\n  Trial 1: RMSE=1472.7150, MAE=1148.1678, R²=-0.2504, Time=0.04s\n  Trial 2: RMSE=1662.8189, MAE=1254.2870, R²=-0.5941, Time=0.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,083] Trial 3 finished with values: [1459.4237431139952, 1139.8035135135135, -0.2279495399306508] and parameters: {'max_depth': 57, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,121] Trial 4 finished with values: [1454.9743593338403, 1132.672972972973, -0.2204735888890017] and parameters: {'max_depth': 31, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1459.4237, MAE=1139.8035, R²=-0.2279, Time=0.05s\n  Trial 4: RMSE=1454.9744, MAE=1132.6730, R²=-0.2205, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,166] Trial 5 finished with values: [18017.62993128675, 10135.349971289326, -186.15999763612163] and parameters: {'max_depth': 90, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,209] Trial 6 finished with values: [1648.280191158307, 1235.8683783783786, -0.5663174436384191] and parameters: {'max_depth': 88, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,248] Trial 7 finished with values: [13401.344760269514, 9064.371132210534, -102.54150318980717] and parameters: {'max_depth': 64, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=18017.6299, MAE=10135.3500, R²=-186.1600, Time=0.04s\n  Trial 6: RMSE=1648.2802, MAE=1235.8684, R²=-0.5663, Time=0.04s\n  Trial 7: RMSE=13401.3448, MAE=9064.3711, R²=-102.5415, Time=0.04s\n  Trial 8: RMSE=12969.8174, MAE=8752.8927, R²=-95.9807, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,287] Trial 8 finished with values: [12969.817366268158, 8752.892679265313, -95.98072515058779] and parameters: {'max_depth': 36, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,324] Trial 9 finished with values: [12864.29005009225, 8587.396523923124, -94.40900196444042] and parameters: {'max_depth': 95, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,362] Trial 10 finished with values: [13369.317119226305, 8935.084786532994, -102.0471904915019] and parameters: {'max_depth': 82, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=12864.2901, MAE=8587.3965, R²=-94.4090, Time=0.04s\n  Trial 10: RMSE=13369.3171, MAE=8935.0848, R²=-102.0472, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,401] Trial 11 finished with values: [13711.591518333113, 9157.298340982225, -107.39105397018749] and parameters: {'max_depth': 18, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,438] Trial 12 finished with values: [1669.1962623823931, 1260.1967567567567, -0.6063216507395319] and parameters: {'max_depth': 67, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,476] Trial 13 finished with values: [1457.5947545500744, 1132.5994594594595, -0.22487367062003427] and parameters: {'max_depth': 32, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,513] Trial 14 finished with values: [1641.0612387374476, 1239.3637837837837, -0.5526275258402056] and parameters: {'max_depth': 18, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=13711.5915, MAE=9157.2983, R²=-107.3911, Time=0.04s\n  Trial 12: RMSE=1669.1963, MAE=1260.1968, R²=-0.6063, Time=0.04s\n  Trial 13: RMSE=1457.5948, MAE=1132.5995, R²=-0.2249, Time=0.04s\n  Trial 14: RMSE=1641.0612, MAE=1239.3638, R²=-0.5526, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'max_depth': 31, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 32, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.62 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,553] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[I 2025-01-19 13:45:00,593] Trial 0 finished with values: [1613.937407123593, 1310.2094897167929, -0.5974777305430317] and parameters: {'max_depth': 20, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: RMSE=1613.9374, MAE=1310.2095, R²=-0.5975, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,632] Trial 1 finished with values: [1613.0041692121472, 1314.3970194770784, -0.5956308240287604] and parameters: {'max_depth': 49, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,669] Trial 2 finished with values: [1514.7883532086805, 1216.2191666666668, -0.4072308651197676] and parameters: {'max_depth': 12, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,706] Trial 3 finished with values: [1761.489613147066, 1460.256666666667, -0.9029247326463943] and parameters: {'max_depth': 67, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,743] Trial 4 finished with values: [2091.3267531450083, 1643.8976001445953, -1.6822868706035168] and parameters: {'max_depth': 21, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1613.0042, MAE=1314.3970, R²=-0.5956, Time=0.04s\n  Trial 2: RMSE=1514.7884, MAE=1216.2192, R²=-0.4072, Time=0.04s\n  Trial 3: RMSE=1761.4896, MAE=1460.2567, R²=-0.9029, Time=0.04s\n  Trial 4: RMSE=2091.3268, MAE=1643.8976, R²=-1.6823, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,780] Trial 5 finished with values: [1499.4867825790152, 1216.9758333333332, -0.37894429177811206] and parameters: {'max_depth': 83, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,818] Trial 6 finished with values: [1687.5951713987665, 1369.6478385491985, -0.746618217649839] and parameters: {'max_depth': 9, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1499.4868, MAE=1216.9758, R²=-0.3789, Time=0.04s\n  Trial 6: RMSE=1687.5952, MAE=1369.6478, R²=-0.7466, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:00,855] Trial 7 finished with values: [1427.0860265896727, 1135.44875, -0.2489980056948733] and parameters: {'max_depth': 45, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,891] Trial 8 finished with values: [2069.8636465122227, 1639.0621527504784, -1.6275132299139519] and parameters: {'max_depth': 34, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,928] Trial 9 finished with values: [1473.146490023565, 1192.971875, -0.3309241579303399] and parameters: {'max_depth': 35, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:00,965] Trial 10 finished with values: [1633.7990740729776, 1327.8827978622778, -0.6370378793260594] and parameters: {'max_depth': 91, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1427.0860, MAE=1135.4488, R²=-0.2490, Time=0.04s\n  Trial 8: RMSE=2069.8636, MAE=1639.0622, R²=-1.6275, Time=0.03s\n  Trial 9: RMSE=1473.1465, MAE=1192.9719, R²=-0.3309, Time=0.04s\n  Trial 10: RMSE=1633.7991, MAE=1327.8828, R²=-0.6370, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,002] Trial 11 finished with values: [2309.4988759151465, 1845.2454707864533, -2.2711235512391683] and parameters: {'max_depth': 77, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,046] Trial 12 finished with values: [1459.0808736688484, 1192.971875, -0.30563013852399923] and parameters: {'max_depth': 14, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=2309.4989, MAE=1845.2455, R²=-2.2711, Time=0.04s\n  Trial 12: RMSE=1459.0809, MAE=1192.9719, R²=-0.3056, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,087] Trial 13 finished with values: [1660.350432656447, 1352.2312493926613, -0.6906782155559543] and parameters: {'max_depth': 85, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,125] Trial 14 finished with values: [2121.1213083619864, 1668.5393324584231, -1.7592588939893572] and parameters: {'max_depth': 14, 'min_samples_split': 4, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,166] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_kantoorkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1660.3504, MAE=1352.2312, R²=-0.6907, Time=0.04s\n  Trial 14: RMSE=2121.1213, MAE=1668.5393, R²=-1.7593, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_kostprijs_van_de_omzet_trajectory: [{'max_depth': 45, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_kostprijs_van_de_omzet_trajectory: 0.57 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,207] Trial 0 finished with values: [621.6885899606824, 453.50396825396825, -0.29605276488943] and parameters: {'max_depth': 100, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,245] Trial 1 finished with values: [614.0096593754442, 449.5501587301587, -0.26423350582022476] and parameters: {'max_depth': 36, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,283] Trial 2 finished with values: [630.9765853228353, 486.75390149503363, -0.3350679690039289] and parameters: {'max_depth': 76, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=621.6886, MAE=453.5040, R²=-0.2961, Time=0.04s\n  Trial 1: RMSE=614.0097, MAE=449.5502, R²=-0.2642, Time=0.04s\n  Trial 2: RMSE=630.9766, MAE=486.7539, R²=-0.3351, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,322] Trial 3 finished with values: [611.2398512651176, 447.90253968253955, -0.2528532739765681] and parameters: {'max_depth': 37, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,362] Trial 4 finished with values: [604.5218122195479, 447.31761904761896, -0.22546479856220847] and parameters: {'max_depth': 94, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,402] Trial 5 finished with values: [607.9543422353829, 447.41761904761904, -0.23942091034375923] and parameters: {'max_depth': 20, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=611.2399, MAE=447.9025, R²=-0.2529, Time=0.04s\n  Trial 4: RMSE=604.5218, MAE=447.3176, R²=-0.2255, Time=0.04s\n  Trial 5: RMSE=607.9543, MAE=447.4176, R²=-0.2394, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,440] Trial 6 finished with values: [635.490811173285, 486.0858834683701, -0.3542393848178864] and parameters: {'max_depth': 21, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,478] Trial 7 finished with values: [606.6187120476495, 445.867619047619, -0.23398106243227712] and parameters: {'max_depth': 80, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,517] Trial 8 finished with values: [633.7643891778712, 486.08588346837024, -0.34689132299767134] and parameters: {'max_depth': 12, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=635.4908, MAE=486.0859, R²=-0.3542, Time=0.04s\n  Trial 7: RMSE=606.6187, MAE=445.8676, R²=-0.2340, Time=0.04s\n  Trial 8: RMSE=633.7644, MAE=486.0859, R²=-0.3469, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,556] Trial 9 finished with values: [612.6872296448174, 448.0001587301587, -0.2587936579087424] and parameters: {'max_depth': 95, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,593] Trial 10 finished with values: [633.886769072514, 484.3983011394656, -0.34741154261110396] and parameters: {'max_depth': 51, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=612.6872, MAE=448.0002, R²=-0.2588, Time=0.04s\n  Trial 10: RMSE=633.8868, MAE=484.3983, R²=-0.3474, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,654] Trial 11 finished with values: [641.4844781936729, 487.4888454866555, -0.37990501869853577] and parameters: {'max_depth': 54, 'min_samples_split': 5, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,691] Trial 12 finished with values: [607.2257311676304, 446.16999999999996, -0.23645188918380056] and parameters: {'max_depth': 26, 'min_samples_split': 3, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,731] Trial 13 finished with values: [635.3995411799423, 498.02707687105027, -0.35385041760839164] and parameters: {'max_depth': 13, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=641.4845, MAE=487.4888, R²=-0.3799, Time=0.06s\n  Trial 12: RMSE=607.2257, MAE=446.1700, R²=-0.2365, Time=0.04s\n  Trial 13: RMSE=635.3995, MAE=498.0271, R²=-0.3539, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,769] Trial 14 finished with values: [608.1401584195371, 453.899365079365, -0.24017866349540284] and parameters: {'max_depth': 10, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,810] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:45:01,848] Trial 0 finished with values: [381.8383918163945, 278.1180493663949, -0.47015495062642176] and parameters: {'max_depth': 84, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=608.1402, MAE=453.8994, R²=-0.2402, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_kantoorkosten_trajectory: [{'max_depth': 94, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 80, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_kantoorkosten_trajectory: 0.60 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: RMSE=381.8384, MAE=278.1180, R²=-0.4702, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,886] Trial 1 finished with values: [370.3265337474968, 266.78128205128206, -0.3828452637809403] and parameters: {'max_depth': 23, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,923] Trial 2 finished with values: [368.36588145901476, 268.39153846153846, -0.3682413874497257] and parameters: {'max_depth': 36, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:01,960] Trial 3 finished with values: [370.94563409114556, 268.67435897435894, -0.38747272369682473] and parameters: {'max_depth': 10, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=370.3265, MAE=266.7813, R²=-0.3828, Time=0.04s\n  Trial 2: RMSE=368.3659, MAE=268.3915, R²=-0.3682, Time=0.04s\n  Trial 3: RMSE=370.9456, MAE=268.6744, R²=-0.3875, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:01,999] Trial 4 finished with values: [380.6995701300893, 279.66053141926506, -0.4613986407122237] and parameters: {'max_depth': 92, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,039] Trial 5 finished with values: [381.556874307768, 278.22116021023845, -0.46798795118608605] and parameters: {'max_depth': 66, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,076] Trial 6 finished with values: [374.9560240875102, 272.8739632167472, -0.41763555513544337] and parameters: {'max_depth': 38, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=380.6996, MAE=279.6605, R²=-0.4614, Time=0.04s\n  Trial 5: RMSE=381.5569, MAE=278.2212, R²=-0.4680, Time=0.04s\n  Trial 6: RMSE=374.9560, MAE=272.8740, R²=-0.4176, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,117] Trial 7 finished with values: [371.4434891657003, 267.7130769230769, -0.3911995441029419] and parameters: {'max_depth': 87, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,154] Trial 8 finished with values: [381.2104878639311, 278.5453655781083, -0.4653238119710126] and parameters: {'max_depth': 88, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,192] Trial 9 finished with values: [372.4928618658693, 266.84846153846155, -0.39907126102878165] and parameters: {'max_depth': 14, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=371.4435, MAE=267.7131, R²=-0.3912, Time=0.04s\n  Trial 8: RMSE=381.2105, MAE=278.5454, R²=-0.4653, Time=0.04s\n  Trial 9: RMSE=372.4929, MAE=266.8485, R²=-0.3991, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,233] Trial 10 finished with values: [369.93970999790406, 267.38384615384615, -0.37995787674306003] and parameters: {'max_depth': 95, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,271] Trial 11 finished with values: [371.05782983180285, 268.315641025641, -0.3883121570650616] and parameters: {'max_depth': 19, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,308] Trial 12 finished with values: [378.1625479079673, 279.2218054306187, -0.44198571149103594] and parameters: {'max_depth': 88, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=369.9397, MAE=267.3838, R²=-0.3800, Time=0.04s\n  Trial 11: RMSE=371.0578, MAE=268.3156, R²=-0.3883, Time=0.04s\n  Trial 12: RMSE=378.1625, MAE=279.2218, R²=-0.4420, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,352] Trial 13 finished with values: [383.25532829474224, 277.507711313116, -0.48108617842171486] and parameters: {'max_depth': 25, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,390] Trial 14 finished with values: [370.88153337344244, 268.76435897435897, -0.3869932447392139] and parameters: {'max_depth': 40, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,428] A new study created in memory with name: TrainerDecisionTree_month_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=383.2553, MAE=277.5077, R²=-0.4811, Time=0.04s\n  Trial 14: RMSE=370.8815, MAE=268.7644, R²=-0.3870, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_verkoopkosten_trajectory: [{'max_depth': 23, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 36, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 95, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_verkoopkosten_trajectory: 0.58 seconds\n  Added results for TrainerDecisionTree on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,466] Trial 0 finished with values: [1653.4084897192918, 1290.2507588956369, -0.8845077320387513] and parameters: {'max_depth': 78, 'min_samples_split': 2, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,503] Trial 1 finished with values: [1784.9554463776842, 1286.2232648333381, -1.1963035209017856] and parameters: {'max_depth': 70, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,541] Trial 2 finished with values: [1936.5368600555437, 1433.302057596084, -1.5851701502705025] and parameters: {'max_depth': 59, 'min_samples_split': 6, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1653.4085, MAE=1290.2508, R²=-0.8845, Time=0.04s\n  Trial 1: RMSE=1784.9554, MAE=1286.2233, R²=-1.1963, Time=0.04s\n  Trial 2: RMSE=1936.5369, MAE=1433.3021, R²=-1.5852, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,584] Trial 3 finished with values: [1385.7823692388836, 1167.4773333333333, -0.323816105846495] and parameters: {'max_depth': 95, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,624] Trial 4 finished with values: [1396.105325284116, 1161.8793333333333, -0.3436122801340715] and parameters: {'max_depth': 47, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,661] Trial 5 finished with values: [1807.113037383402, 1347.0933069386765, -1.2511697037995568] and parameters: {'max_depth': 16, 'min_samples_split': 8, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1385.7824, MAE=1167.4773, R²=-0.3238, Time=0.04s\n  Trial 4: RMSE=1396.1053, MAE=1161.8793, R²=-0.3436, Time=0.04s\n  Trial 5: RMSE=1807.1130, MAE=1347.0933, R²=-1.2512, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,699] Trial 6 finished with values: [1398.282847011529, 1161.8793333333333, -0.34780684416788477] and parameters: {'max_depth': 44, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,736] Trial 7 finished with values: [1394.4198909247768, 1180.826, -0.3403701130546699] and parameters: {'max_depth': 35, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,774] Trial 8 finished with values: [1610.7445231708266, 1267.8527806873726, -0.7885081513330814] and parameters: {'max_depth': 89, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1398.2828, MAE=1161.8793, R²=-0.3478, Time=0.04s\n  Trial 7: RMSE=1394.4199, MAE=1180.8260, R²=-0.3404, Time=0.04s\n  Trial 8: RMSE=1610.7445, MAE=1267.8528, R²=-0.7885, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,812] Trial 9 finished with values: [1407.4662991974858, 1193.3543333333332, -0.365568866254272] and parameters: {'max_depth': 85, 'min_samples_split': 7, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,850] Trial 10 finished with values: [1393.0163034006457, 1180.826, -0.33767310631681324] and parameters: {'max_depth': 26, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,887] Trial 11 finished with values: [1409.0786249531998, 1166.2160000000001, -0.3686993184155065] and parameters: {'max_depth': 43, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1407.4663, MAE=1193.3543, R²=-0.3656, Time=0.04s\n  Trial 10: RMSE=1393.0163, MAE=1180.8260, R²=-0.3377, Time=0.04s\n  Trial 11: RMSE=1409.0786, MAE=1166.2160, R²=-0.3687, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:02,925] Trial 12 finished with values: [1394.4268075820019, 1159.1543333333332, -0.3403834102023655] and parameters: {'max_depth': 49, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:02,963] Trial 13 finished with values: [1390.5405946477554, 1181.3343333333332, -0.33292262896042213] and parameters: {'max_depth': 15, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,000] Trial 14 finished with values: [1795.564508547532, 1302.3946098514618, -1.2224890099932773] and parameters: {'max_depth': 71, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1394.4268, MAE=1159.1543, R²=-0.3404, Time=0.04s\n  Trial 13: RMSE=1390.5406, MAE=1181.3343, R²=-0.3329, Time=0.04s\n  Trial 14: RMSE=1795.5645, MAE=1302.3946, R²=-1.2225, Time=0.04s\nBest hyperparameters for TrainerDecisionTree_month_data_cleaned_huisvestingskosten_trajectory: [{'max_depth': 95, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'max_depth': 49, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_month_data_cleaned_huisvestingskosten_trajectory: 0.57 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,040] A new study created in memory with name: TrainerDecisionTree_day_data_trajectory\n[I 2025-01-19 13:45:03,082] Trial 0 finished with values: [783.1943433498554, 618.2193675638291, -0.31890063998425555] and parameters: {'max_depth': 26, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,123] Trial 1 finished with values: [727.3874211268748, 575.8380197761317, -0.13763925080202477] and parameters: {'max_depth': 43, 'min_samples_split': 9, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerDecisionTree on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: RMSE=783.1943, MAE=618.2194, R²=-0.3189, Time=0.04s\n  Trial 1: RMSE=727.3874, MAE=575.8380, R²=-0.1376, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,167] Trial 2 finished with values: [763.5693550854608, 608.0560739856802, -0.25363172826548275] and parameters: {'max_depth': 78, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,208] Trial 3 finished with values: [737.0410564001623, 582.6360145229294, -0.1680363434402694] and parameters: {'max_depth': 32, 'min_samples_split': 7, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=763.5694, MAE=608.0561, R²=-0.2536, Time=0.04s\n  Trial 3: RMSE=737.0411, MAE=582.6360, R²=-0.1680, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,251] Trial 4 finished with values: [784.3219561974274, 614.9008233890214, -0.3227011779531539] and parameters: {'max_depth': 74, 'min_samples_split': 2, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,291] Trial 5 finished with values: [756.0732589129757, 603.8605966587113, -0.22913829819546971] and parameters: {'max_depth': 58, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,332] Trial 6 finished with values: [725.3607420541418, 575.1955369928401, -0.1313086006662969] and parameters: {'max_depth': 14, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=784.3220, MAE=614.9008, R²=-0.3227, Time=0.04s\n  Trial 5: RMSE=756.0733, MAE=603.8606, R²=-0.2291, Time=0.04s\n  Trial 6: RMSE=725.3607, MAE=575.1955, R²=-0.1313, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,396] Trial 7 finished with values: [727.3968258814965, 575.9011455847256, -0.13766866920234033] and parameters: {'max_depth': 100, 'min_samples_split': 9, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,437] Trial 8 finished with values: [687.7100572673608, 540.744737470167, -0.016912875356259738] and parameters: {'max_depth': 9, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=727.3968, MAE=575.9011, R²=-0.1377, Time=0.06s\n  Trial 8: RMSE=687.7101, MAE=540.7447, R²=-0.0169, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,482] Trial 9 finished with values: [785.7182048404335, 622.2867171696028, -0.32741471061130856] and parameters: {'max_depth': 23, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,524] Trial 10 finished with values: [725.8987116659594, 574.4303937947494, -0.13298731114388795] and parameters: {'max_depth': 36, 'min_samples_split': 10, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,566] Trial 11 finished with values: [742.6439924646027, 588.340155131265, -0.18586250946903982] and parameters: {'max_depth': 90, 'min_samples_split': 6, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=785.7182, MAE=622.2867, R²=-0.3274, Time=0.04s\n  Trial 10: RMSE=725.8987, MAE=574.4304, R²=-0.1330, Time=0.04s\n  Trial 11: RMSE=742.6440, MAE=588.3402, R²=-0.1859, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,610] Trial 12 finished with values: [780.1974222804017, 618.6470801219922, -0.30882631120768433] and parameters: {'max_depth': 85, 'min_samples_split': 3, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,652] Trial 13 finished with values: [725.4536861549869, 573.6015551231484, -0.13159853970261337] and parameters: {'max_depth': 83, 'min_samples_split': 10, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=780.1974, MAE=618.6471, R²=-0.3088, Time=0.04s\n  Trial 13: RMSE=725.4537, MAE=573.6016, R²=-0.1316, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:03,699] Trial 14 finished with values: [734.9751560870104, 578.964522673031, -0.16149759018068766] and parameters: {'max_depth': 82, 'min_samples_split': 8, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:03,741] A new study created in memory with name: TrainerDecisionTree_weather_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=734.9752, MAE=578.9645, R²=-0.1615, Time=0.05s\nBest hyperparameters for TrainerDecisionTree_day_data_trajectory: [{'max_depth': 9, 'min_samples_split': 4, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerDecisionTree_day_data_trajectory: 0.66 seconds\n  Added results for TrainerDecisionTree on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:03,744] Trial 0 failed with parameters: {'max_depth': 9, 'min_samples_split': 5, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_decision_tree.py\", line 45, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:03,971] Trial 0 failed with value None.\n[I 2025-01-19 13:45:03,972] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerDecisionTree on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerGradientBoosting\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:03,982] Trial 0 failed with parameters: {'learning_rate': 0.08286429286602824, 'n_estimators': 253, 'subsample': 0.6694761630422548, 'min_samples_split': 9, 'max_depth': 22, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,209] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,210] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:04,222] Trial 0 failed with parameters: {'learning_rate': 0.023854585510378005, 'n_estimators': 267, 'subsample': 0.893282531404318, 'min_samples_split': 9, 'max_depth': 6, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,232] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,232] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:04,244] Trial 0 failed with parameters: {'learning_rate': 0.14212273532028896, 'n_estimators': 214, 'subsample': 0.6057573991284253, 'min_samples_split': 9, 'max_depth': 28, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,247] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,248] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:04,259] Trial 0 failed with parameters: {'learning_rate': 0.027134162718521836, 'n_estimators': 118, 'subsample': 0.5839376420434175, 'min_samples_split': 7, 'max_depth': 16, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,263] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,263] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:04,274] Trial 0 failed with parameters: {'learning_rate': 0.14512829666711985, 'n_estimators': 186, 'subsample': 0.6022492265789037, 'min_samples_split': 5, 'max_depth': 9, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,278] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,279] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:04,290] Trial 0 failed with parameters: {'learning_rate': 0.05023115196828683, 'n_estimators': 195, 'subsample': 0.7687693303295885, 'min_samples_split': 5, 'max_depth': 29, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,294] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,295] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[W 2025-01-19 13:45:04,306] Trial 0 failed with parameters: {'learning_rate': 0.05039800030897293, 'n_estimators': 72, 'subsample': 0.6276211909838234, 'min_samples_split': 3, 'max_depth': 19, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,309] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,310] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:04,320] Trial 0 failed with parameters: {'learning_rate': 0.129224267760763, 'n_estimators': 79, 'subsample': 0.8053282734088978, 'min_samples_split': 5, 'max_depth': 14, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,324] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,325] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:04,336] Trial 0 failed with parameters: {'learning_rate': 0.17420745778537108, 'n_estimators': 54, 'subsample': 0.9184260305277299, 'min_samples_split': 8, 'max_depth': 5, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,339] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,340] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:04,350] Trial 0 failed with parameters: {'learning_rate': 0.1868267327904245, 'n_estimators': 109, 'subsample': 0.7219742502609034, 'min_samples_split': 6, 'max_depth': 23, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,354] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,354] A new study created in memory with name: TrainerGradientBoosting_week_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:04,365] Trial 0 failed with parameters: {'learning_rate': 0.028752567863281862, 'n_estimators': 158, 'subsample': 0.9750582061834049, 'min_samples_split': 10, 'max_depth': 8, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,368] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,369] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_afschrijvingen_mva_trajectory\n[W 2025-01-19 13:45:04,380] Trial 0 failed with parameters: {'learning_rate': 0.16746829798392418, 'n_estimators': 188, 'subsample': 0.5541821274881163, 'min_samples_split': 6, 'max_depth': 24, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,383] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,384] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_afschrijvingen_iva_trajectory\n[W 2025-01-19 13:45:04,395] Trial 0 failed with parameters: {'learning_rate': 0.10173680332761603, 'n_estimators': 172, 'subsample': 0.7503346007845226, 'min_samples_split': 8, 'max_depth': 26, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,398] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,400] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_omzet_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_algemene_kosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_autokosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_exploitatie-_en_machinekosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_huisvestingskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_kantoorkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_lonen_en_salarissen: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_overige_bedrijfsopbrengsten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_overige_personeelskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_overige_rentelasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_sociale_lasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Error with trainer TrainerGradientBoosting on dataset week_data_cleaned_verkoopkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_afschrijvingen_mva: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_afschrijvingen_iva: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:04,410] Trial 0 failed with parameters: {'learning_rate': 0.13087021064403914, 'n_estimators': 170, 'subsample': 0.9205246036828565, 'min_samples_split': 9, 'max_depth': 10, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,414] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,414] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_algemene_kosten_trajectory\n[W 2025-01-19 13:45:04,425] Trial 0 failed with parameters: {'learning_rate': 0.13815303905364354, 'n_estimators': 61, 'subsample': 0.8025560678691541, 'min_samples_split': 9, 'max_depth': 6, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,428] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,429] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:04,440] Trial 0 failed with parameters: {'learning_rate': 0.16788756563720472, 'n_estimators': 150, 'subsample': 0.651128059790121, 'min_samples_split': 2, 'max_depth': 6, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,443] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,444] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:04,458] Trial 0 failed with parameters: {'learning_rate': 0.12127359076273757, 'n_estimators': 72, 'subsample': 0.7761730271015157, 'min_samples_split': 8, 'max_depth': 3, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,462] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,462] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_pensioenlasten_trajectory\n[W 2025-01-19 13:45:04,474] Trial 0 failed with parameters: {'learning_rate': 0.08018446416895579, 'n_estimators': 80, 'subsample': 0.8138302863343099, 'min_samples_split': 3, 'max_depth': 26, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,478] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,479] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:04,490] Trial 0 failed with parameters: {'learning_rate': 0.08261176039629543, 'n_estimators': 201, 'subsample': 0.9062410543553618, 'min_samples_split': 4, 'max_depth': 29, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,494] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,495] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:04,505] Trial 0 failed with parameters: {'learning_rate': 0.15176109836693186, 'n_estimators': 76, 'subsample': 0.6356091992461242, 'min_samples_split': 9, 'max_depth': 21, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,509] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,510] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:04,520] Trial 0 failed with parameters: {'learning_rate': 0.16306830797841426, 'n_estimators': 131, 'subsample': 0.9117455723221658, 'min_samples_split': 8, 'max_depth': 3, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,524] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,525] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:04,535] Trial 0 failed with parameters: {'learning_rate': 0.10638719109569081, 'n_estimators': 50, 'subsample': 0.954147941252313, 'min_samples_split': 7, 'max_depth': 27, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,539] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,540] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[W 2025-01-19 13:45:04,552] Trial 0 failed with parameters: {'learning_rate': 0.14071383536248863, 'n_estimators': 106, 'subsample': 0.7918896734465357, 'min_samples_split': 7, 'max_depth': 5, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,556] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,556] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:04,567] Trial 0 failed with parameters: {'learning_rate': 0.011273598954195978, 'n_estimators': 102, 'subsample': 0.8402658090278301, 'min_samples_split': 2, 'max_depth': 9, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,571] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,573] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:04,584] Trial 0 failed with parameters: {'learning_rate': 0.17590888703921795, 'n_estimators': 133, 'subsample': 0.7648128912822626, 'min_samples_split': 6, 'max_depth': 23, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,588] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,589] A new study created in memory with name: TrainerGradientBoosting_month_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:04,599] Trial 0 failed with parameters: {'learning_rate': 0.04096659274752609, 'n_estimators': 86, 'subsample': 0.7084244078584472, 'min_samples_split': 8, 'max_depth': 13, 'prediction_mode': 'AverageTrend'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,604] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,604] A new study created in memory with name: TrainerGradientBoosting_day_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_omzet: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_algemene_kosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_autokosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_overige_rentelasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_pensioenlasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_lonen_en_salarissen: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_overige_personeelskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_sociale_lasten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_exploitatie-_en_machinekosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_kostprijs_van_de_omzet: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_kantoorkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_verkoopkosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Error with trainer TrainerGradientBoosting on dataset month_data_cleaned_huisvestingskosten: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:04,616] Trial 0 failed with parameters: {'learning_rate': 0.010159383605127633, 'n_estimators': 130, 'subsample': 0.7981202085818655, 'min_samples_split': 3, 'max_depth': 24, 'prediction_mode': 'Zero'} because of the following error: AttributeError(\"'TrainerGradientBoosting' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 62, in fit\n    self._trend_finder.find_trend(df)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerGradientBoosting' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:04,619] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,620] A new study created in memory with name: TrainerGradientBoosting_weather_data_trajectory\n[W 2025-01-19 13:45:04,623] Trial 0 failed with parameters: {'learning_rate': 0.0073167997168862445, 'n_estimators': 276, 'subsample': 0.9103454815590701, 'min_samples_split': 7, 'max_depth': 29, 'prediction_mode': 'Zero'} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_gradient_boosting.py\", line 47, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:04,625] Trial 0 failed with value None.\n[I 2025-01-19 13:45:04,627] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:45:04,660] Trial 0 finished with values: [228.1073776276325, 112.3495145631068, 0.3271450037421231] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:04,692] Trial 1 finished with values: [280.67840050267114, 184.09999999999997, -0.018734007135367436] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:04,725] Trial 2 finished with values: [281.96896346800884, 166.71844660194174, -0.028123849570935278] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:04,758] Trial 3 finished with values: [297.3160370945238, 122.1868932038835, -0.1430875351054406] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 35, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:04,791] Trial 4 finished with values: [265.3315850593312, 161.5830097087379, 0.08962416581682464] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerGradientBoosting on dataset day_data: 'TrainerGradientBoosting' object has no attribute '_trend_finder'\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerGradientBoosting on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerKNeighborsRegressor\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: RMSE=228.1074, MAE=112.3495, R²=0.3271, Time=0.03s\n  Trial 1: RMSE=280.6784, MAE=184.1000, R²=-0.0187, Time=0.03s\n  Trial 2: RMSE=281.9690, MAE=166.7184, R²=-0.0281, Time=0.03s\n  Trial 3: RMSE=297.3160, MAE=122.1869, R²=-0.1431, Time=0.03s\n  Trial 4: RMSE=265.3316, MAE=161.5830, R²=0.0896, Time=0.03s\n  Trial 5: RMSE=280.4407, MAE=177.5216, R²=-0.0170, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:04,822] Trial 5 finished with values: [280.4407108272984, 177.5215533980583, -0.01700932844956826] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:04,857] Trial 6 finished with values: [286.9103535442278, 218.21844660194174, -0.06447449286461304] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:04,889] Trial 7 finished with values: [245.9486111215539, 114.49203883495146, 0.21777522528456272] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:04,920] Trial 8 finished with values: [297.3160370945238, 122.1868932038835, -0.1430875351054406] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:04,951] Trial 9 finished with values: [280.45881946816314, 177.55631067961164, -0.017140673511643056] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:04,983] Trial 10 finished with values: [322.9996843907202, 170.05825242718447, -0.3491089206065734] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 32, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,014] Trial 11 finished with values: [322.9996843907202, 170.05825242718447, -0.3491089206065734] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,044] Trial 12 finished with values: [273.562270621822, 172.00864077669902, 0.0322677426110185] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 39, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=286.9104, MAE=218.2184, R²=-0.0645, Time=0.03s\n  Trial 7: RMSE=245.9486, MAE=114.4920, R²=0.2178, Time=0.03s\n  Trial 8: RMSE=297.3160, MAE=122.1869, R²=-0.1431, Time=0.03s\n  Trial 9: RMSE=280.4588, MAE=177.5563, R²=-0.0171, Time=0.03s\n  Trial 10: RMSE=322.9997, MAE=170.0583, R²=-0.3491, Time=0.03s\n  Trial 11: RMSE=322.9997, MAE=170.0583, R²=-0.3491, Time=0.03s\n  Trial 12: RMSE=273.5623, MAE=172.0086, R²=0.0323, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:05,076] Trial 13 finished with values: [265.1281331550676, 170.24854368932037, 0.09101975304835386] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 29, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,114] Trial 14 finished with values: [280.7408781286174, 185.04077669902912, -0.01918758793101749] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,146] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:45:05,180] Trial 0 finished with values: [51.72980765477482, 36.16, 0.597045961049391] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,220] Trial 1 finished with values: [153.63783127862746, 95.08, -2.5544312809530187] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,251] Trial 2 finished with values: [164.79785597310826, 101.66666666666667, -3.089562976843797] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=265.1281, MAE=170.2485, R²=0.0910, Time=0.03s\n  Trial 14: RMSE=280.7409, MAE=185.0408, R²=-0.0192, Time=0.04s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_algemene_kosten_trajectory: [{'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_algemene_kosten_trajectory: 0.49 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: RMSE=51.7298, MAE=36.1600, R²=0.5970, Time=0.03s\n  Trial 1: RMSE=153.6378, MAE=95.0800, R²=-2.5544, Time=0.04s\n  Trial 2: RMSE=164.7979, MAE=101.6667, R²=-3.0896, Time=0.03s\n  Trial 3: RMSE=117.2037, MAE=104.5233, R²=-1.0685, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:05,281] Trial 3 finished with values: [117.20368978833388, 104.52333333333333, -1.0685039502743945] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,311] Trial 4 finished with values: [134.6112537395493, 111.77666666666669, -1.7285789502743945] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,342] Trial 5 finished with values: [97.36871503037649, 62.666666666666664, -0.42762013117387254] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,377] Trial 6 finished with values: [134.6112537395493, 111.77666666666669, -1.7285789502743945] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=134.6113, MAE=111.7767, R²=-1.7286, Time=0.03s\n  Trial 5: RMSE=97.3687, MAE=62.6667, R²=-0.4276, Time=0.03s\n  Trial 6: RMSE=134.6113, MAE=111.7767, R²=-1.7286, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:05,405] Trial 7 failed with parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0} because of the following error: ValueError('Expected n_neighbors <= n_samples_fit, but n_neighbors = 8, n_samples_fit = 7, n_samples = 3').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_knn.py\", line 119, in predict\n    df['predictions'] = self.model.predict(df).round(2)\n                        ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/neighbors/_regression.py\", line 245, in predict\n    neigh_dist, neigh_ind = self.kneighbors(X)\n                            ^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/neighbors/_base.py\", line 835, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 8, n_samples_fit = 7, n_samples = 3\n[W 2025-01-19 13:45:05,607] Trial 7 failed with value None.\n[I 2025-01-19 13:45:05,608] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[I 2025-01-19 13:45:05,639] Trial 0 finished with values: [250.89816828033756, 204.22892857142855, -0.06111203506847951] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,670] Trial 1 finished with values: [346.06790356600743, 281.3885714285715, -1.0187795793071612] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,700] Trial 2 finished with values: [252.64731657985206, 200.6325, -0.07595879196061439] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 45, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,732] Trial 3 finished with values: [247.5053448196336, 205.97857142857146, -0.03260785083825701] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 29, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,764] Trial 4 finished with values: [253.87010890695376, 206.3432142857143, -0.08639910100910608] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,794] Trial 5 finished with values: [254.74432090263142, 207.0889285714286, -0.09389410205306681] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerKNeighborsRegressor on dataset week_data_cleaned_autokosten: Expected n_neighbors <= n_samples_fit, but n_neighbors = 8, n_samples_fit = 7, n_samples = 3\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: RMSE=250.8982, MAE=204.2289, R²=-0.0611, Time=0.03s\n  Trial 1: RMSE=346.0679, MAE=281.3886, R²=-1.0188, Time=0.03s\n  Trial 2: RMSE=252.6473, MAE=200.6325, R²=-0.0760, Time=0.03s\n  Trial 3: RMSE=247.5053, MAE=205.9786, R²=-0.0326, Time=0.03s\n  Trial 4: RMSE=253.8701, MAE=206.3432, R²=-0.0864, Time=0.03s\n  Trial 5: RMSE=254.7443, MAE=207.0889, R²=-0.0939, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:05,825] Trial 6 finished with values: [235.7161484028134, 187.16464285714284, 0.06341988860075953] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,859] Trial 7 finished with values: [242.42350487171356, 202.3071428571429, 0.009360340729167693] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 35, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:05,890] Trial 8 finished with values: [285.93940395775167, 237.52999999999997, -0.37820643711485324] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 18, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,922] Trial 9 finished with values: [285.93940395775167, 237.52999999999997, -0.37820643711485324] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 18, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,953] Trial 10 finished with values: [584.3374147577017, 527.2857142857143, -4.755640349546986] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:05,983] Trial 11 finished with values: [273.0772732082572, 225.45714285714288, -0.2570060677434718] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,012] Trial 12 finished with values: [584.3374147577017, 527.2857142857143, -4.755640349546986] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=235.7161, MAE=187.1646, R²=0.0634, Time=0.03s\n  Trial 7: RMSE=242.4235, MAE=202.3071, R²=0.0094, Time=0.03s\n  Trial 8: RMSE=285.9394, MAE=237.5300, R²=-0.3782, Time=0.03s\n  Trial 9: RMSE=285.9394, MAE=237.5300, R²=-0.3782, Time=0.03s\n  Trial 10: RMSE=584.3374, MAE=527.2857, R²=-4.7556, Time=0.03s\n  Trial 11: RMSE=273.0773, MAE=225.4571, R²=-0.2570, Time=0.03s\n  Trial 12: RMSE=584.3374, MAE=527.2857, R²=-4.7556, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:06,042] Trial 13 finished with values: [245.67073225297779, 206.26857142857145, -0.017356348535684685] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 50, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,075] Trial 14 finished with values: [249.78202061283068, 203.88428571428568, -0.05169209103922223] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,107] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:45:06,137] Trial 0 finished with values: [140.7766097312899, 54.53628205128205, -0.09330761818525635] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,168] Trial 1 finished with values: [140.62143831159074, 54.297948717948714, -0.09089874362925454] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,199] Trial 2 finished with values: [140.73134890315862, 54.434358974358965, -0.09260471656630687] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,230] Trial 3 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=245.6707, MAE=206.2686, R²=-0.0174, Time=0.03s\n  Trial 14: RMSE=249.7820, MAE=203.8843, R²=-0.0517, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.47 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: RMSE=140.7766, MAE=54.5363, R²=-0.0933, Time=0.03s\n  Trial 1: RMSE=140.6214, MAE=54.2979, R²=-0.0909, Time=0.03s\n  Trial 2: RMSE=140.7313, MAE=54.4344, R²=-0.0926, Time=0.03s\n  Trial 3: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:06,263] Trial 4 finished with values: [140.85692188283716, 54.35807692307693, -0.09455542396257166] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,294] Trial 5 finished with values: [135.96184795743252, 58.17307692307692, -0.01980112734701489] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,324] Trial 6 finished with values: [139.66165100534383, 54.76410256410256, -0.0760580818445391] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,355] Trial 7 finished with values: [137.93157748662458, 56.05910256410256, -0.049563638655100384] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,387] Trial 8 finished with values: [135.96184795743252, 58.17307692307692, -0.01980112734701489] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,418] Trial 9 finished with values: [141.03536063242422, 54.06538461538462, -0.09733036479582724] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,449] Trial 10 finished with values: [140.68520541192262, 54.14807692307693, -0.09188833985038092] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=140.8569, MAE=54.3581, R²=-0.0946, Time=0.03s\n  Trial 5: RMSE=135.9618, MAE=58.1731, R²=-0.0198, Time=0.03s\n  Trial 6: RMSE=139.6617, MAE=54.7641, R²=-0.0761, Time=0.03s\n  Trial 7: RMSE=137.9316, MAE=56.0591, R²=-0.0496, Time=0.03s\n  Trial 8: RMSE=135.9618, MAE=58.1731, R²=-0.0198, Time=0.03s\n  Trial 9: RMSE=141.0354, MAE=54.0654, R²=-0.0973, Time=0.03s\n  Trial 10: RMSE=140.6852, MAE=54.1481, R²=-0.0919, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:06,482] Trial 11 finished with values: [137.92432935564753, 55.94358974358973, -0.049453335054121306] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 14, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,511] Trial 12 finished with values: [137.92432935564753, 55.94358974358973, -0.049453335054121306] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,543] Trial 13 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,574] Trial 14 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,607] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:45:06,638] Trial 0 finished with values: [224.90154651654115, 202.02936170212763, -0.021502385077897035] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,669] Trial 1 finished with values: [216.62879082636647, 190.63808510638293, 0.05226514618786493] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=137.9243, MAE=55.9436, R²=-0.0495, Time=0.03s\n  Trial 12: RMSE=137.9243, MAE=55.9436, R²=-0.0495, Time=0.03s\n  Trial 13: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.03s\n  Trial 14: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_huisvestingskosten_trajectory: [{'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}, {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 14, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_huisvestingskosten_trajectory: 0.47 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: RMSE=224.9015, MAE=202.0294, R²=-0.0215, Time=0.03s\n  Trial 1: RMSE=216.6288, MAE=190.6381, R²=0.0523, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:06,700] Trial 2 finished with values: [227.0960065324327, 201.69319148936165, -0.04153410582274786] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,731] Trial 3 finished with values: [224.87986473159873, 202.70212765957447, -0.021305437322060916] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,762] Trial 4 finished with values: [225.03836365611372, 201.8593617021277, -0.022745609477455853] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,792] Trial 5 finished with values: [216.62879082636647, 190.63808510638293, 0.05226514618786493] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,823] Trial 6 finished with values: [228.22762968841323, 209.61574468085107, -0.051939930933052825] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,854] Trial 7 finished with values: [204.44963370816848, 182.1327659574468, 0.15583532447139048] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,888] Trial 8 finished with values: [387.4458369833707, 317.5531914893617, -2.031632115060747] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=227.0960, MAE=201.6932, R²=-0.0415, Time=0.03s\n  Trial 3: RMSE=224.8799, MAE=202.7021, R²=-0.0213, Time=0.03s\n  Trial 4: RMSE=225.0384, MAE=201.8594, R²=-0.0227, Time=0.03s\n  Trial 5: RMSE=216.6288, MAE=190.6381, R²=0.0523, Time=0.03s\n  Trial 6: RMSE=228.2276, MAE=209.6157, R²=-0.0519, Time=0.03s\n  Trial 7: RMSE=204.4496, MAE=182.1328, R²=0.1558, Time=0.03s\n  Trial 8: RMSE=387.4458, MAE=317.5532, R²=-2.0316, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:06,920] Trial 9 finished with values: [171.87644003265217, 91.2127659574468, 0.4033945710596638] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:06,951] Trial 10 finished with values: [226.53659787459452, 205.0202127659574, -0.03640917572210789] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 32, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:06,993] Trial 11 finished with values: [223.92112071945184, 200.71170212765955, -0.012615613577808826] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 15, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,025] Trial 12 finished with values: [239.50485051277965, 218.91638297872336, -0.15846556186216532] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,056] Trial 13 finished with values: [233.44478893943793, 214.29085106382976, -0.10058317429022967] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,089] Trial 14 finished with values: [211.4388967416335, 189.4578723404255, 0.09713198203743756] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 24, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=171.8764, MAE=91.2128, R²=0.4034, Time=0.03s\n  Trial 10: RMSE=226.5366, MAE=205.0202, R²=-0.0364, Time=0.03s\n  Trial 11: RMSE=223.9211, MAE=200.7117, R²=-0.0126, Time=0.04s\n  Trial 12: RMSE=239.5049, MAE=218.9164, R²=-0.1585, Time=0.03s\n  Trial 13: RMSE=233.4448, MAE=214.2909, R²=-0.1006, Time=0.03s\n  Trial 14: RMSE=211.4389, MAE=189.4579, R²=0.0971, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_kantoorkosten_trajectory: [{'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 42, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_kantoorkosten_trajectory: 0.48 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:07,125] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_lonen_en_salarissen_trajectory\n[I 2025-01-19 13:45:07,154] Trial 0 finished with values: [522.6721501319248, 380.0335294117647, -0.008584403119832107] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,184] Trial 1 finished with values: [520.5931397256516, 380.60705882352937, -0.0005767555743170227] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,216] Trial 2 finished with values: [522.9791498487015, 379.0882352941176, -0.009769566938329755] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 40, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,250] Trial 3 finished with values: [585.8972837000175, 434.74000000000007, -0.2673497898639976] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,291] Trial 4 finished with values: [518.62883021426, 401.83529411764704, 0.0069597802358513094] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: RMSE=522.6722, MAE=380.0335, R²=-0.0086, Time=0.03s\n  Trial 1: RMSE=520.5931, MAE=380.6071, R²=-0.0006, Time=0.03s\n  Trial 2: RMSE=522.9791, MAE=379.0882, R²=-0.0098, Time=0.03s\n  Trial 3: RMSE=585.8973, MAE=434.7400, R²=-0.2673, Time=0.03s\n  Trial 4: RMSE=518.6288, MAE=401.8353, R²=0.0070, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:07,334] Trial 5 finished with values: [578.8056668692869, 432.0, -0.236855820069253] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,369] Trial 6 finished with values: [522.7801562573608, 380.83647058823533, -0.009001278396759016] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 35, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,400] Trial 7 finished with values: [526.531197679123, 403.21294117647057, -0.023532755439312547] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,429] Trial 8 finished with values: [522.9791498487015, 379.0882352941176, -0.009769566938329755] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 40, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,460] Trial 9 finished with values: [536.4116129099982, 396.9770588235294, -0.06230657843139897] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,491] Trial 10 finished with values: [486.2329128889473, 372.55176470588236, 0.1271447399340213] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,522] Trial 11 finished with values: [522.9791498487015, 379.0882352941176, -0.009769566938329755] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=578.8057, MAE=432.0000, R²=-0.2369, Time=0.03s\n  Trial 6: RMSE=522.7802, MAE=380.8365, R²=-0.0090, Time=0.03s\n  Trial 7: RMSE=526.5312, MAE=403.2129, R²=-0.0235, Time=0.03s\n  Trial 8: RMSE=522.9791, MAE=379.0882, R²=-0.0098, Time=0.03s\n  Trial 9: RMSE=536.4116, MAE=396.9771, R²=-0.0623, Time=0.03s\n  Trial 10: RMSE=486.2329, MAE=372.5518, R²=0.1271, Time=0.03s\n  Trial 11: RMSE=522.9791, MAE=379.0882, R²=-0.0098, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:07,553] Trial 12 finished with values: [578.653812995402, 431.7647058823529, -0.23620690897416097] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,584] Trial 13 finished with values: [515.5329554765174, 379.2476470588236, 0.018779995726302956] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,616] Trial 14 finished with values: [515.5329554765174, 379.2476470588236, 0.018779995726302956] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,646] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[I 2025-01-19 13:45:07,676] Trial 0 finished with values: [56.08280079335898, 10.850344827586206, -0.031564469422153074] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,706] Trial 1 finished with values: [56.082622700490006, 10.865862068965518, -0.03155791789542506] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,738] Trial 2 finished with values: [56.12294757786324, 10.974827586206896, -0.03304188563325927] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=578.6538, MAE=431.7647, R²=-0.2362, Time=0.03s\n  Trial 13: RMSE=515.5330, MAE=379.2476, R²=0.0188, Time=0.03s\n  Trial 14: RMSE=515.5330, MAE=379.2476, R²=0.0188, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_lonen_en_salarissen_trajectory: [{'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 1, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_lonen_en_salarissen_trajectory: 0.49 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: RMSE=56.0828, MAE=10.8503, R²=-0.0316, Time=0.03s\n  Trial 1: RMSE=56.0826, MAE=10.8659, R²=-0.0316, Time=0.03s\n  Trial 2: RMSE=56.1229, MAE=10.9748, R²=-0.0330, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:07,770] Trial 3 finished with values: [56.15729675928449, 10.95862068965517, -0.0343067871909124] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 22, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,799] Trial 4 finished with values: [56.12545602303025, 10.888965517241378, -0.03313423241644142] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 27, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:07,830] Trial 5 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,881] Trial 6 finished with values: [56.130104775146876, 10.971034482758622, -0.03330538412521156] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,911] Trial 7 finished with values: [56.14459328530588, 10.965172413793104, -0.033838894183934265] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:07,941] Trial 8 finished with values: [56.17552541073749, 10.931034482758621, -0.03497836787635511] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 15, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=56.1573, MAE=10.9586, R²=-0.0343, Time=0.03s\n  Trial 4: RMSE=56.1255, MAE=10.8890, R²=-0.0331, Time=0.03s\n  Trial 5: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.03s\n  Trial 6: RMSE=56.1301, MAE=10.9710, R²=-0.0333, Time=0.05s\n  Trial 7: RMSE=56.1446, MAE=10.9652, R²=-0.0338, Time=0.03s\n  Trial 8: RMSE=56.1755, MAE=10.9310, R²=-0.0350, Time=0.03s\n  Trial 9: RMSE=56.1229, MAE=10.9748, R²=-0.0330, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:07,971] Trial 9 finished with values: [56.12294757786324, 10.974827586206896, -0.03304188563325927] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,003] Trial 10 finished with values: [56.12122347328086, 10.979310344827585, -0.03297841623372544] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,033] Trial 11 finished with values: [56.08460357906339, 10.931034482758621, -0.03163078991764445] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,062] Trial 12 finished with values: [56.15357021842745, 10.95448275862069, -0.0341695206614665] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,095] Trial 13 finished with values: [56.144597216043195, 10.965862068965516, -0.03383903894406215] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,129] Trial 14 finished with values: [56.15366466378142, 10.960689655172414, -0.03417299942829133] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 27, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,159] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_overige_personeelskosten_trajectory\n[I 2025-01-19 13:45:08,191] Trial 0 finished with values: [211.9703034007583, 144.2952380952381, -0.2212944801457124] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=56.1212, MAE=10.9793, R²=-0.0330, Time=0.03s\n  Trial 11: RMSE=56.0846, MAE=10.9310, R²=-0.0316, Time=0.03s\n  Trial 12: RMSE=56.1536, MAE=10.9545, R²=-0.0342, Time=0.03s\n  Trial 13: RMSE=56.1446, MAE=10.9659, R²=-0.0338, Time=0.03s\n  Trial 14: RMSE=56.1537, MAE=10.9607, R²=-0.0342, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: [{'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 37, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: 0.48 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: RMSE=211.9703, MAE=144.2952, R²=-0.2213, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:08,224] Trial 1 finished with values: [262.3039411591428, 224.7122857142857, -0.8701652514121827] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,256] Trial 2 finished with values: [239.57521568293288, 169.81561904761904, -0.5601060713599446] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 35, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,290] Trial 3 finished with values: [235.30494676766432, 175.90704761904763, -0.5049860211796753] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,322] Trial 4 finished with values: [225.93394926288482, 171.64085714285713, -0.3875011087274014] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,355] Trial 5 finished with values: [282.7229882664049, 197.2595238095238, -1.1726641400652675] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,388] Trial 6 finished with values: [253.3984357921429, 149.2404761904762, -0.7453326404400862] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,423] Trial 7 finished with values: [348.5782606313278, 194.05542857142856, -2.3027138550781903] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=262.3039, MAE=224.7123, R²=-0.8702, Time=0.03s\n  Trial 2: RMSE=239.5752, MAE=169.8156, R²=-0.5601, Time=0.03s\n  Trial 3: RMSE=235.3049, MAE=175.9070, R²=-0.5050, Time=0.03s\n  Trial 4: RMSE=225.9339, MAE=171.6409, R²=-0.3875, Time=0.03s\n  Trial 5: RMSE=282.7230, MAE=197.2595, R²=-1.1727, Time=0.03s\n  Trial 6: RMSE=253.3984, MAE=149.2405, R²=-0.7453, Time=0.03s\n  Trial 7: RMSE=348.5783, MAE=194.0554, R²=-2.3027, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:08,463] Trial 8 finished with values: [251.86862168126274, 166.63057142857144, -0.7243224495723253] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 23, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,495] Trial 9 finished with values: [223.26253812389533, 165.90990476190478, -0.3548838517390194] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 29, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,526] Trial 10 finished with values: [231.33495220855264, 179.81819047619047, -0.4546310754402225] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,558] Trial 11 finished with values: [602.9102609778515, 586.2994285714286, -8.880426727270423] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,588] Trial 12 finished with values: [336.3157191744233, 312.23161904761906, -2.0744305304593116] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 42, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,630] Trial 13 finished with values: [236.753821213191, 178.26571428571432, -0.5235767823899244] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,661] Trial 14 finished with values: [262.3039411591428, 224.7122857142857, -0.8701652514121827] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 50, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=251.8686, MAE=166.6306, R²=-0.7243, Time=0.04s\n  Trial 9: RMSE=223.2625, MAE=165.9099, R²=-0.3549, Time=0.03s\n  Trial 10: RMSE=231.3350, MAE=179.8182, R²=-0.4546, Time=0.03s\n  Trial 11: RMSE=602.9103, MAE=586.2994, R²=-8.8804, Time=0.03s\n  Trial 12: RMSE=336.3157, MAE=312.2316, R²=-2.0744, Time=0.03s\n  Trial 13: RMSE=236.7538, MAE=178.2657, R²=-0.5236, Time=0.04s\n  Trial 14: RMSE=262.3039, MAE=224.7123, R²=-0.8702, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_overige_personeelskosten_trajectory: [{'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 13, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_overige_personeelskosten_trajectory: 0.50 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:08,693] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:45:08,725] Trial 0 finished with values: [164.74518501141222, 66.11444444444443, 0.29334387297225617] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 39, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,755] Trial 1 finished with values: [197.6709221014675, 124.90466666666667, -0.0173449753449737] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,785] Trial 2 finished with values: [170.3026419022585, 93.58188888888888, 0.24486354199197558] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 12, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,813] Trial 3 finished with values: [194.1414149531212, 125.77000000000001, 0.01866102161403982] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,843] Trial 4 finished with values: [85.47007273504178, 31.4, 0.8097998674876956] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 48, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,885] Trial 5 finished with values: [170.3026419022585, 93.58188888888888, 0.24486354199197558] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 27, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: RMSE=164.7452, MAE=66.1144, R²=0.2933, Time=0.03s\n  Trial 1: RMSE=197.6709, MAE=124.9047, R²=-0.0173, Time=0.03s\n  Trial 2: RMSE=170.3026, MAE=93.5819, R²=0.2449, Time=0.03s\n  Trial 3: RMSE=194.1414, MAE=125.7700, R²=0.0187, Time=0.03s\n  Trial 4: RMSE=85.4701, MAE=31.4000, R²=0.8098, Time=0.03s\n  Trial 5: RMSE=170.3026, MAE=93.5819, R²=0.2449, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:08,919] Trial 6 finished with values: [211.47891935919603, 84.4, -0.16443924268669008] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:08,954] Trial 7 finished with values: [211.47891935919603, 84.4, -0.16443924268669008] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:08,987] Trial 8 finished with values: [187.0115047471085, 97.71566666666666, 0.08941746249865912] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,017] Trial 9 finished with values: [196.76438779243904, 137.05988888888888, -0.00803512500845538] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 45, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,048] Trial 10 finished with values: [182.5555207753399, 101.57344444444443, 0.13229397985949776] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:09,078] Trial 11 finished with values: [199.69404260851982, 113.28333333333336, -0.038276168888270456] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 26, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,114] Trial 12 finished with values: [187.0113079587554, 97.63133333333332, 0.08941937887213447] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=211.4789, MAE=84.4000, R²=-0.1644, Time=0.03s\n  Trial 7: RMSE=211.4789, MAE=84.4000, R²=-0.1644, Time=0.03s\n  Trial 8: RMSE=187.0115, MAE=97.7157, R²=0.0894, Time=0.03s\n  Trial 9: RMSE=196.7644, MAE=137.0599, R²=-0.0080, Time=0.03s\n  Trial 10: RMSE=182.5555, MAE=101.5734, R²=0.1323, Time=0.03s\n  Trial 11: RMSE=199.6940, MAE=113.2833, R²=-0.0383, Time=0.03s\n  Trial 12: RMSE=187.0113, MAE=97.6313, R²=0.0894, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,146] Trial 13 finished with values: [197.53586903536166, 132.65333333333334, -0.015955305878840864] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,177] Trial 14 finished with values: [181.39975150050356, 105.73266666666667, 0.14324619151199947] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:09,208] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:09,239] Trial 0 failed with parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 32, 'p': 1, 'outlier_removal': 0} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:45:09,240] Trial 0 failed with value None.\n[I 2025-01-19 13:45:09,241] A new study created in memory with name: TrainerKNeighborsRegressor_week_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:45:09,271] Trial 0 finished with values: [254.978654877248, 158.13591397849464, -0.25691684689162564] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,304] Trial 1 finished with values: [260.44007937764985, 162.19892473118279, -0.31133766048690403] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 16, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,335] Trial 2 finished with values: [250.1312557567559, 152.55516129032256, -0.20958062790926313] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=197.5359, MAE=132.6533, R²=-0.0160, Time=0.03s\n  Trial 14: RMSE=181.3998, MAE=105.7327, R²=0.1432, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_overige_rentelasten_trajectory: [{'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 48, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_overige_rentelasten_trajectory: 0.49 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerKNeighborsRegressor on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: RMSE=254.9787, MAE=158.1359, R²=-0.2569, Time=0.03s\n  Trial 1: RMSE=260.4401, MAE=162.1989, R²=-0.3113, Time=0.03s\n  Trial 2: RMSE=250.1313, MAE=152.5552, R²=-0.2096, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,367] Trial 3 finished with values: [239.70403554141242, 153.42806451612904, -0.1108350824510087] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 15, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:09,398] Trial 4 finished with values: [269.1538114044614, 165.94623655913978, -0.4005543414130528] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 29, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=239.7040, MAE=153.4281, R²=-0.1108, Time=0.03s\n  Trial 4: RMSE=269.1538, MAE=165.9462, R²=-0.4006, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,433] Trial 5 finished with values: [260.44007937764985, 162.19892473118279, -0.31133766048690403] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 37, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,464] Trial 6 finished with values: [260.44398864536186, 161.94172043010752, -0.31137702776449006] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,495] Trial 7 finished with values: [264.1344965317187, 169.247311827957, -0.3488049318838322] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,526] Trial 8 finished with values: [254.41117849248585, 154.15913978494623, -0.2513283249288236] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,558] Trial 9 finished with values: [236.20757109359445, 153.42634408602152, -0.07866484183942446] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=260.4401, MAE=162.1989, R²=-0.3113, Time=0.03s\n  Trial 6: RMSE=260.4440, MAE=161.9417, R²=-0.3114, Time=0.03s\n  Trial 7: RMSE=264.1345, MAE=169.2473, R²=-0.3488, Time=0.03s\n  Trial 8: RMSE=254.4112, MAE=154.1591, R²=-0.2513, Time=0.03s\n  Trial 9: RMSE=236.2076, MAE=153.4263, R²=-0.0787, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,589] Trial 10 finished with values: [235.10698867006352, 151.35989247311832, -0.0686364262170216] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,621] Trial 11 finished with values: [255.21160288746103, 157.1089247311828, -0.25921452963441793] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 27, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=235.1070, MAE=151.3599, R²=-0.0686, Time=0.03s\n  Trial 11: RMSE=255.2116, MAE=157.1089, R²=-0.2592, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,654] Trial 12 finished with values: [254.03101681123613, 157.33430107526883, -0.24759144777827236] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 27, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:09,686] Trial 13 finished with values: [234.3628232518559, 154.3840860215054, -0.06188219301436271] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,717] Trial 14 finished with values: [251.64776714621854, 156.75268817204298, -0.22429213189253727] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,749] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_mva_trajectory\n[I 2025-01-19 13:45:09,779] Trial 0 finished with values: [516.2017468759456, 414.24644444444453, -0.05983869375809969] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 16, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=254.0310, MAE=157.3343, R²=-0.2476, Time=0.03s\n  Trial 13: RMSE=234.3628, MAE=154.3841, R²=-0.0619, Time=0.03s\n  Trial 14: RMSE=251.6478, MAE=156.7527, R²=-0.2243, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_week_data_cleaned_verkoopkosten_trajectory: [{'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_week_data_cleaned_verkoopkosten_trajectory: 0.48 seconds\n  Added results for TrainerKNeighborsRegressor on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: RMSE=516.2017, MAE=414.2464, R²=-0.0598, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,809] Trial 1 finished with values: [527.5651249951148, 418.94444444444446, -0.10701368173953218] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 17, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,840] Trial 2 finished with values: [527.5651249951148, 418.94444444444446, -0.10701368173953218] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=527.5651, MAE=418.9444, R²=-0.1070, Time=0.03s\n  Trial 2: RMSE=527.5651, MAE=418.9444, R²=-0.1070, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:09,876] Trial 3 finished with values: [508.2128788433271, 404.4933333333333, -0.027287880105231643] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,907] Trial 4 finished with values: [517.3777096860667, 419.60311111111116, -0.06467304596126722] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 40, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:09,938] Trial 5 finished with values: [517.4611949530344, 419.53222222222234, -0.06501666990608235] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:09,968] Trial 6 finished with values: [517.3777096860667, 419.60311111111116, -0.06467304596126722] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:09,999] Trial 7 finished with values: [569.8630829711058, 465.8888888888889, -0.2916411658758655] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 18, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=508.2129, MAE=404.4933, R²=-0.0273, Time=0.03s\n  Trial 4: RMSE=517.3777, MAE=419.6031, R²=-0.0647, Time=0.03s\n  Trial 5: RMSE=517.4612, MAE=419.5322, R²=-0.0650, Time=0.03s\n  Trial 6: RMSE=517.3777, MAE=419.6031, R²=-0.0647, Time=0.03s\n  Trial 7: RMSE=569.8631, MAE=465.8889, R²=-0.2916, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,030] Trial 8 finished with values: [569.8630829711058, 465.8888888888889, -0.2916411658758655] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,061] Trial 9 finished with values: [518.7678792742151, 418.11577777777774, -0.07040218546424026] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=569.8631, MAE=465.8889, R²=-0.2916, Time=0.03s\n  Trial 9: RMSE=518.7679, MAE=418.1158, R²=-0.0704, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,093] Trial 10 finished with values: [521.3869154284561, 421.8886666666667, -0.08123746949897726] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:10,125] Trial 11 finished with values: [517.8999561219435, 415.79955555555546, -0.06682351483634652] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,154] Trial 12 finished with values: [516.4259867589934, 416.70577777777777, -0.06075968918650099] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,184] Trial 13 finished with values: [517.3432589640611, 416.5822222222222, -0.06453126353315208] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 17, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:10,217] Trial 14 finished with values: [569.8630829711058, 465.8888888888889, -0.2916411658758655] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 12, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=521.3869, MAE=421.8887, R²=-0.0812, Time=0.03s\n  Trial 11: RMSE=517.9000, MAE=415.7996, R²=-0.0668, Time=0.03s\n  Trial 12: RMSE=516.4260, MAE=416.7058, R²=-0.0608, Time=0.03s\n  Trial 13: RMSE=517.3433, MAE=416.5822, R²=-0.0645, Time=0.03s\n  Trial 14: RMSE=569.8631, MAE=465.8889, R²=-0.2916, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_mva_trajectory: [{'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_mva_trajectory: 0.47 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,250] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_iva_trajectory\n[I 2025-01-19 13:45:10,283] Trial 0 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,316] Trial 1 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,349] Trial 2 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 36, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,382] Trial 3 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 31, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,413] Trial 4 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,444] Trial 5 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 2: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 3: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 4: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 5: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,477] Trial 6 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,509] Trial 7 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 45, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 7: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,540] Trial 8 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,575] Trial 9 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:10,606] Trial 10 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,638] Trial 11 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,669] Trial 12 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 9: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 10: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 11: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 12: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,700] Trial 13 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:10,731] Trial 14 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\n  Trial 14: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_iva_trajectory: [{'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 36, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 31, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 21, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 45, 'p': 2, 'outlier_removal': 1}, {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 10, 'p': 2, 'outlier_removal': 1}, {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}, {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_afschrijvingen_iva_trajectory: 0.48 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,763] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_omzet_trajectory\n[I 2025-01-19 13:45:10,794] Trial 0 finished with values: [1041.1424053164621, 790.9851851851853, -0.5327292298894111] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:10,824] Trial 1 finished with values: [1113.762809905133, 848.8224074074072, -0.754004054460033] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,854] Trial 2 finished with values: [1158.937679575088, 899.0046296296297, -0.899176529948529] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 36, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,887] Trial 3 finished with values: [1128.4494375477582, 858.9390740740741, -0.8005673782163609] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: RMSE=1041.1424, MAE=790.9852, R²=-0.5327, Time=0.03s\n  Trial 1: RMSE=1113.7628, MAE=848.8224, R²=-0.7540, Time=0.03s\n  Trial 2: RMSE=1158.9377, MAE=899.0046, R²=-0.8992, Time=0.03s\n  Trial 3: RMSE=1128.4494, MAE=858.9391, R²=-0.8006, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,917] Trial 4 finished with values: [1719.9426616196422, 1401.5740740740741, -3.1828578572651463] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:10,948] Trial 5 finished with values: [978.6441703817698, 739.4259259259256, -0.35423737516851284] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 34, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1719.9427, MAE=1401.5741, R²=-3.1829, Time=0.03s\n  Trial 5: RMSE=978.6442, MAE=739.4259, R²=-0.3542, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:10,978] Trial 6 finished with values: [1139.0781534977862, 855.5427777777778, -0.8346457274888457] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,008] Trial 7 finished with values: [1203.5860749505266, 980.3981481481482, -1.048327886602916] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 28, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,037] Trial 8 finished with values: [1168.314503841768, 894.9987037037039, -0.9300328685797026] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,067] Trial 9 finished with values: [1521.224871449539, 1260.2564814814816, -2.2721409534010997] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,099] Trial 10 finished with values: [1108.556352618793, 849.4194444444445, -0.7376436547623686] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1139.0782, MAE=855.5428, R²=-0.8346, Time=0.03s\n  Trial 7: RMSE=1203.5861, MAE=980.3981, R²=-1.0483, Time=0.03s\n  Trial 8: RMSE=1168.3145, MAE=894.9987, R²=-0.9300, Time=0.03s\n  Trial 9: RMSE=1521.2249, MAE=1260.2565, R²=-2.2721, Time=0.03s\n  Trial 10: RMSE=1108.5564, MAE=849.4194, R²=-0.7376, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,131] Trial 11 finished with values: [944.9244250369876, 721.4657407407407, -0.26252305885904903] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,165] Trial 12 finished with values: [987.7350611251612, 756.992777777778, -0.37951398854785223] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=944.9244, MAE=721.4657, R²=-0.2625, Time=0.03s\n  Trial 12: RMSE=987.7351, MAE=756.9928, R²=-0.3795, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,196] Trial 13 finished with values: [1191.6623104512453, 905.4931481481481, -1.0079439069220757] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,227] Trial 14 finished with values: [1146.5675412193464, 875.1792592592591, -0.858850465874798] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,259] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:45:11,290] Trial 0 finished with values: [1131.435070610635, 935.1948717948719, -0.026226949136819222] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1191.6623, MAE=905.4931, R²=-1.0079, Time=0.03s\n  Trial 14: RMSE=1146.5675, MAE=875.1793, R²=-0.8589, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_omzet_trajectory: [{'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 24, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_omzet_trajectory: 0.47 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: RMSE=1131.4351, MAE=935.1949, R²=-0.0262, Time=0.03s\n  Trial 1: RMSE=1136.3488, MAE=921.1532, R²=-0.0352, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,334] Trial 1 finished with values: [1136.3487907751537, 921.1532051282053, -0.035159926282722465] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 28, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,367] Trial 2 finished with values: [1171.3789314143987, 938.8589743589744, -0.0999652360402612] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1171.3789, MAE=938.8590, R²=-0.1000, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,400] Trial 3 finished with values: [1126.6171637370537, 929.7565384615384, -0.017505743478418045] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,431] Trial 4 finished with values: [1130.2879548978567, 928.9571794871796, -0.0241471049976254] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 36, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,462] Trial 5 finished with values: [1128.1933707930045, 929.3152564102563, -0.02035484198584947] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,492] Trial 6 finished with values: [1144.640888042274, 955.1662820512821, -0.050322462479108765] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 24, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,522] Trial 7 finished with values: [1127.2209744822976, 936.4251282051282, -0.018596700655066245] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,553] Trial 8 finished with values: [1417.040875539135, 1140.5320512820513, -0.6097146575738392] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 23, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1126.6172, MAE=929.7565, R²=-0.0175, Time=0.03s\n  Trial 4: RMSE=1130.2880, MAE=928.9572, R²=-0.0241, Time=0.03s\n  Trial 5: RMSE=1128.1934, MAE=929.3153, R²=-0.0204, Time=0.03s\n  Trial 6: RMSE=1144.6409, MAE=955.1663, R²=-0.0503, Time=0.03s\n  Trial 7: RMSE=1127.2210, MAE=936.4251, R²=-0.0186, Time=0.03s\n  Trial 8: RMSE=1417.0409, MAE=1140.5321, R²=-0.6097, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,584] Trial 9 finished with values: [1370.3764631082313, 1085.7628205128206, -0.505441640030893] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1370.3765, MAE=1085.7628, R²=-0.5054, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,615] Trial 10 finished with values: [1142.4207418505043, 924.9346153846153, -0.04625200161781695] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 45, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,646] Trial 11 finished with values: [1231.9129404543871, 994.2946153846153, -0.2165898173536831] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 49, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,677] Trial 12 finished with values: [1370.3764631082313, 1085.7628205128206, -0.505441640030893] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 20, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,707] Trial 13 finished with values: [1119.5020834321722, 907.6896153846153, -0.004694338546328725] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,738] Trial 14 finished with values: [1754.9829278152756, 1381.8461538461538, -1.4690502846885973] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 22, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,775] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_autokosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1142.4207, MAE=924.9346, R²=-0.0463, Time=0.03s\n  Trial 11: RMSE=1231.9129, MAE=994.2946, R²=-0.2166, Time=0.03s\n  Trial 12: RMSE=1370.3765, MAE=1085.7628, R²=-0.5054, Time=0.03s\n  Trial 13: RMSE=1119.5021, MAE=907.6896, R²=-0.0047, Time=0.03s\n  Trial 14: RMSE=1754.9829, MAE=1381.8462, R²=-1.4691, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_algemene_kosten_trajectory: [{'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_algemene_kosten_trajectory: 0.48 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,806] Trial 0 finished with values: [1456.8099956202698, 1250.3847826086956, -0.14375983717501484] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 19, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1456.8100, MAE=1250.3848, R²=-0.1438, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:11,837] Trial 1 finished with values: [1374.7316392663697, 1180.3086956521738, -0.01850900503265951] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,867] Trial 2 finished with values: [1467.7925991537206, 1223.8695652173913, -0.16107000124066273] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 17, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,897] Trial 3 finished with values: [1426.0113622958056, 1244.6225, -0.09591025020721489] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 34, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:11,931] Trial 4 finished with values: [1442.8430107814468, 1242.2700000000002, -0.12193365835698478] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:11,962] Trial 5 finished with values: [1529.0890432900835, 1290.1222826086957, -0.2600697038413333] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,002] Trial 6 finished with values: [1395.5367490631945, 1228.8666304347826, -0.0495703942402681] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 11, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,041] Trial 7 finished with values: [1426.5232234302634, 1254.2901086956524, -0.09669713670034419] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1374.7316, MAE=1180.3087, R²=-0.0185, Time=0.03s\n  Trial 2: RMSE=1467.7926, MAE=1223.8696, R²=-0.1611, Time=0.03s\n  Trial 3: RMSE=1426.0114, MAE=1244.6225, R²=-0.0959, Time=0.03s\n  Trial 4: RMSE=1442.8430, MAE=1242.2700, R²=-0.1219, Time=0.03s\n  Trial 5: RMSE=1529.0890, MAE=1290.1223, R²=-0.2601, Time=0.03s\n  Trial 6: RMSE=1395.5367, MAE=1228.8666, R²=-0.0496, Time=0.04s\n  Trial 7: RMSE=1426.5232, MAE=1254.2901, R²=-0.0967, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:12,074] Trial 8 finished with values: [1450.9737659158718, 1220.5710869565216, -0.13461399925478723] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,105] Trial 9 finished with values: [1415.4132154373797, 1198.2695652173913, -0.07968112603921429] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,136] Trial 10 finished with values: [1767.1345258004799, 1353.6741304347825, -0.6829384826890794] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,166] Trial 11 finished with values: [1529.0890432900835, 1290.1222826086957, -0.2600697038413333] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 23, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,195] Trial 12 finished with values: [1423.8596949179919, 1233.897934782609, -0.09260557057882535] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,225] Trial 13 finished with values: [1622.6705309994118, 1108.1521739130435, -0.41902391677670625] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,255] Trial 14 finished with values: [1446.7778183229464, 1242.3471739130434, -0.12806130017484207] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 25, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1450.9738, MAE=1220.5711, R²=-0.1346, Time=0.03s\n  Trial 9: RMSE=1415.4132, MAE=1198.2696, R²=-0.0797, Time=0.03s\n  Trial 10: RMSE=1767.1345, MAE=1353.6741, R²=-0.6829, Time=0.03s\n  Trial 11: RMSE=1529.0890, MAE=1290.1223, R²=-0.2601, Time=0.03s\n  Trial 12: RMSE=1423.8597, MAE=1233.8979, R²=-0.0926, Time=0.03s\n  Trial 13: RMSE=1622.6705, MAE=1108.1522, R²=-0.4190, Time=0.03s\n  Trial 14: RMSE=1446.7778, MAE=1242.3472, R²=-0.1281, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_autokosten_trajectory: [{'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 26, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_autokosten_trajectory: 0.48 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:12,290] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:45:12,320] Trial 0 finished with values: [833.8952353597957, 656.6313461538462, -0.042789633313374376] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,370] Trial 1 finished with values: [909.0288906511506, 708.0288461538462, -0.23916486924084124] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,418] Trial 2 finished with values: [1305.1310942111995, 1123.1346153846155, -1.554359346307681] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,466] Trial 3 finished with values: [1076.4049473023258, 816.7596153846154, -0.7375011095277058] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 25, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: RMSE=833.8952, MAE=656.6313, R²=-0.0428, Time=0.03s\n  Trial 1: RMSE=909.0289, MAE=708.0288, R²=-0.2392, Time=0.05s\n  Trial 2: RMSE=1305.1311, MAE=1123.1346, R²=-1.5544, Time=0.05s\n  Trial 3: RMSE=1076.4049, MAE=816.7596, R²=-0.7375, Time=0.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:12,496] Trial 4 finished with values: [1172.0242761334569, 924.1730769230769, -1.0599037815621326] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,525] Trial 5 finished with values: [1076.4049473023258, 816.7596153846154, -0.7375011095277058] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 16, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,556] Trial 6 finished with values: [893.192335370935, 708.6965384615388, -0.19636499019109066] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 33, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,585] Trial 7 finished with values: [924.6807158180435, 682.4994230769231, -0.2822045725163804] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 19, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,617] Trial 8 finished with values: [836.5778250155165, 636.9730769230771, -0.04950960498111745] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,656] Trial 9 finished with values: [838.1885284533362, 626.3346153846154, -0.05355483790316251] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 14, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,686] Trial 10 finished with values: [893.7401498392111, 707.0826923076922, -0.1978329540468713] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 35, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1172.0243, MAE=924.1731, R²=-1.0599, Time=0.03s\n  Trial 5: RMSE=1076.4049, MAE=816.7596, R²=-0.7375, Time=0.03s\n  Trial 6: RMSE=893.1923, MAE=708.6965, R²=-0.1964, Time=0.03s\n  Trial 7: RMSE=924.6807, MAE=682.4994, R²=-0.2822, Time=0.03s\n  Trial 8: RMSE=836.5778, MAE=636.9731, R²=-0.0495, Time=0.03s\n  Trial 9: RMSE=838.1885, MAE=626.3346, R²=-0.0536, Time=0.04s\n  Trial 10: RMSE=893.7401, MAE=707.0827, R²=-0.1978, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:12,734] Trial 11 finished with values: [889.4574429295042, 692.940576923077, -0.18638068496613203] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 31, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,768] Trial 12 finished with values: [858.6515851422554, 645.8263461538462, -0.10562454684301903] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 25, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,799] Trial 13 finished with values: [1121.8603282734648, 836.8653846153846, -0.8873450281810886] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,831] Trial 14 finished with values: [893.7401498392111, 707.0826923076922, -0.1978329540468713] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,866] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_pensioenlasten_trajectory\n[I 2025-01-19 13:45:12,899] Trial 0 finished with values: [625.638927284207, 492.54, -0.7250715342091416] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:12,933] Trial 1 finished with values: [817.3235181574878, 614.9333333333333, -1.9440662245709364] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=889.4574, MAE=692.9406, R²=-0.1864, Time=0.05s\n  Trial 12: RMSE=858.6516, MAE=645.8263, R²=-0.1056, Time=0.03s\n  Trial 13: RMSE=1121.8603, MAE=836.8654, R²=-0.8873, Time=0.03s\n  Trial 14: RMSE=893.7401, MAE=707.0827, R²=-0.1978, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_overige_rentelasten_trajectory: [{'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 14, 'p': 1, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_overige_rentelasten_trajectory: 0.54 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: RMSE=625.6389, MAE=492.5400, R²=-0.7251, Time=0.03s\n  Trial 1: RMSE=817.3235, MAE=614.9333, R²=-1.9441, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:12,963] Trial 2 finished with values: [520.2456350097199, 472.5106666666667, -0.19282428798385132] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 24, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:12,994] Trial 3 finished with values: [613.1439755391876, 489.9033333333333, -0.6568550442268102] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,023] Trial 4 finished with values: [551.3565065726531, 493.96733333333333, -0.33975254754863937] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 35, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,056] Trial 5 finished with values: [597.5994146862373, 486.59666666666664, -0.5739100564340773] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 22, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,088] Trial 6 finished with values: [513.5528860464779, 461.9166666666667, -0.16233129699656823] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,120] Trial 7 finished with values: [586.8922110916109, 481.4986666666667, -0.5180157413455566] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,150] Trial 8 finished with values: [549.8406496492113, 490.58866666666665, -0.3323958504282478] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=520.2456, MAE=472.5107, R²=-0.1928, Time=0.03s\n  Trial 3: RMSE=613.1440, MAE=489.9033, R²=-0.6569, Time=0.03s\n  Trial 4: RMSE=551.3565, MAE=493.9673, R²=-0.3398, Time=0.03s\n  Trial 5: RMSE=597.5994, MAE=486.5967, R²=-0.5739, Time=0.03s\n  Trial 6: RMSE=513.5529, MAE=461.9167, R²=-0.1623, Time=0.03s\n  Trial 7: RMSE=586.8922, MAE=481.4987, R²=-0.5180, Time=0.03s\n  Trial 8: RMSE=549.8406, MAE=490.5887, R²=-0.3324, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:13,182] Trial 9 finished with values: [513.5528860464779, 461.9166666666667, -0.16233129699656823] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,219] Trial 10 finished with values: [517.5405821446919, 450.9166666666667, -0.18045219318884587] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,251] Trial 11 finished with values: [603.7043102987864, 487.4046666666666, -0.6062314925690455] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 40, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,282] Trial 12 finished with values: [606.5516875309693, 469.96199999999993, -0.6214188367462834] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,312] Trial 13 finished with values: [561.9608509792594, 469.62999999999994, -0.3917835733045978] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 19, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,340] Trial 14 finished with values: [559.5632523078452, 434.6, -0.37993285474233596] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,371] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=513.5529, MAE=461.9167, R²=-0.1623, Time=0.03s\n  Trial 10: RMSE=517.5406, MAE=450.9167, R²=-0.1805, Time=0.04s\n  Trial 11: RMSE=603.7043, MAE=487.4047, R²=-0.6062, Time=0.03s\n  Trial 12: RMSE=606.5517, MAE=469.9620, R²=-0.6214, Time=0.03s\n  Trial 13: RMSE=561.9609, MAE=469.6300, R²=-0.3918, Time=0.03s\n  Trial 14: RMSE=559.5633, MAE=434.6000, R²=-0.3799, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_pensioenlasten_trajectory: [{'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_pensioenlasten_trajectory: 0.48 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:13,401] Trial 0 finished with values: [1056.8763802814283, 875.311935483871, 0.0700485351793666] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 32, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,432] Trial 1 finished with values: [1045.935667003319, 856.5045161290324, 0.08920246940595944] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,472] Trial 2 finished with values: [1042.0384804640096, 825.741935483871, 0.0959771404092068] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,507] Trial 3 finished with values: [1909.6182104487323, 1380.5483870967741, -2.0360225547743345] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,538] Trial 4 finished with values: [1056.8763802814283, 875.311935483871, 0.0700485351793666] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,571] Trial 5 finished with values: [1074.7128404909513, 859.3709677419355, 0.038394864238265325] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 44, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1056.8764, MAE=875.3119, R²=0.0700, Time=0.03s\n  Trial 1: RMSE=1045.9357, MAE=856.5045, R²=0.0892, Time=0.03s\n  Trial 2: RMSE=1042.0385, MAE=825.7419, R²=0.0960, Time=0.04s\n  Trial 3: RMSE=1909.6182, MAE=1380.5484, R²=-2.0360, Time=0.03s\n  Trial 4: RMSE=1056.8764, MAE=875.3119, R²=0.0700, Time=0.03s\n  Trial 5: RMSE=1074.7128, MAE=859.3710, R²=0.0384, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:13,607] Trial 6 finished with values: [1046.1645586956995, 824.5677419354838, 0.0888037894375665] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 20, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,638] Trial 7 finished with values: [1909.6182104487323, 1380.5483870967741, -2.0360225547743345] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 31, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,670] Trial 8 finished with values: [1071.9616345596244, 841.516129032258, 0.04331187535360004] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,701] Trial 9 finished with values: [1057.215945988147, 889.0806451612904, 0.06945086763572617] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,735] Trial 10 finished with values: [1035.0449471695856, 827.8603225806451, 0.10807093216073338] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,766] Trial 11 finished with values: [1058.8779205076992, 878.8370967741936, 0.06652286685548958] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 25, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,797] Trial 12 finished with values: [1020.4960746411839, 860.1287096774196, 0.1329690997384011] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1046.1646, MAE=824.5677, R²=0.0888, Time=0.03s\n  Trial 7: RMSE=1909.6182, MAE=1380.5484, R²=-2.0360, Time=0.03s\n  Trial 8: RMSE=1071.9616, MAE=841.5161, R²=0.0433, Time=0.03s\n  Trial 9: RMSE=1057.2159, MAE=889.0806, R²=0.0695, Time=0.03s\n  Trial 10: RMSE=1035.0449, MAE=827.8603, R²=0.1081, Time=0.03s\n  Trial 11: RMSE=1058.8779, MAE=878.8371, R²=0.0665, Time=0.03s\n  Trial 12: RMSE=1020.4961, MAE=860.1287, R²=0.1330, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:13,828] Trial 13 finished with values: [1032.5277681464786, 855.770322580645, 0.11240391326237076] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,859] Trial 14 finished with values: [1044.083800112838, 822.6451612903226, 0.09242481411373948] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,891] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_overige_personeelskosten_trajectory\n[I 2025-01-19 13:45:13,922] Trial 0 finished with values: [936.4965560380946, 584.3883333333334, -0.12885505218624327] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:13,954] Trial 1 finished with values: [938.0310180953991, 545.2939393939395, -0.13255737087364383] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 48, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:13,986] Trial 2 finished with values: [928.7594533145879, 571.7454545454547, -0.11027946193805227] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 21, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,018] Trial 3 finished with values: [1042.4922370904924, 750.0378787878788, -0.39885104360282986] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1032.5278, MAE=855.7703, R²=0.1124, Time=0.03s\n  Trial 14: RMSE=1044.0838, MAE=822.6452, R²=0.0924, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_lonen_en_salarissen_trajectory: [{'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}, {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 24, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_lonen_en_salarissen_trajectory: 0.49 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: RMSE=936.4966, MAE=584.3883, R²=-0.1289, Time=0.03s\n  Trial 1: RMSE=938.0310, MAE=545.2939, R²=-0.1326, Time=0.03s\n  Trial 2: RMSE=928.7595, MAE=571.7455, R²=-0.1103, Time=0.03s\n  Trial 3: RMSE=1042.4922, MAE=750.0379, R²=-0.3989, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:14,049] Trial 4 finished with values: [916.9600190228381, 539.2507575757576, -0.08224755181809362] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,081] Trial 5 finished with values: [966.99246250862, 583.7884848484849, -0.20357176117330344] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 13, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,111] Trial 6 finished with values: [964.8772404756362, 592.4624242424242, -0.19831207775028603] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 14, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,144] Trial 7 finished with values: [921.7832193552064, 529.0893939393939, -0.09366271702672369] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,177] Trial 8 finished with values: [936.5010414173374, 531.810606060606, -0.12886586558456714] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,215] Trial 9 finished with values: [909.6283296939571, 565.6666666666667, -0.06501019987591605] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,245] Trial 10 finished with values: [1000.4534047878068, 587.1969696969697, -0.288307529269586] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 15, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=916.9600, MAE=539.2508, R²=-0.0822, Time=0.03s\n  Trial 5: RMSE=966.9925, MAE=583.7885, R²=-0.2036, Time=0.03s\n  Trial 6: RMSE=964.8772, MAE=592.4624, R²=-0.1983, Time=0.03s\n  Trial 7: RMSE=921.7832, MAE=529.0894, R²=-0.0937, Time=0.03s\n  Trial 8: RMSE=936.5010, MAE=531.8106, R²=-0.1289, Time=0.03s\n  Trial 9: RMSE=909.6283, MAE=565.6667, R²=-0.0650, Time=0.04s\n  Trial 10: RMSE=1000.4534, MAE=587.1970, R²=-0.2883, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:14,276] Trial 11 finished with values: [1143.9021864308208, 918.8484848484849, -0.6842385051740012] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 49, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,306] Trial 12 finished with values: [1042.4922370904924, 750.0378787878788, -0.39885104360282986] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 37, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,336] Trial 13 finished with values: [1054.3290161246746, 707.939393939394, -0.43079735805292496] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,367] Trial 14 finished with values: [934.0341273605812, 531.2504545454545, -0.12292642271300713] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,398] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_sociale_lasten_trajectory\n[I 2025-01-19 13:45:14,430] Trial 0 finished with values: [687.2861073914803, 531.4773333333334, 0.0946053164044911] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,463] Trial 1 finished with values: [687.0168029240624, 509.93333333333334, 0.09531471256483537] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1143.9022, MAE=918.8485, R²=-0.6842, Time=0.03s\n  Trial 12: RMSE=1042.4922, MAE=750.0379, R²=-0.3989, Time=0.03s\n  Trial 13: RMSE=1054.3290, MAE=707.9394, R²=-0.4308, Time=0.03s\n  Trial 14: RMSE=934.0341, MAE=531.2505, R²=-0.1229, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_overige_personeelskosten_trajectory: [{'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}, {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 46, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 44, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_overige_personeelskosten_trajectory: 0.48 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: RMSE=687.2861, MAE=531.4773, R²=0.0946, Time=0.03s\n  Trial 1: RMSE=687.0168, MAE=509.9333, R²=0.0953, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:14,498] Trial 2 finished with values: [739.6769888043474, 610.6833333333335, -0.048689755939823165] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 20, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,530] Trial 3 finished with values: [720.6311981890135, 559.7170000000001, 0.004619955895384442] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,562] Trial 4 finished with values: [717.4654729021228, 608.3593333333333, 0.013346134860370062] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 15, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,594] Trial 5 finished with values: [834.9986650927453, 666.6446666666668, -0.33639355283281636] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,625] Trial 6 finished with values: [996.0113285834989, 799.2333333333333, -0.9014782654202906] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 29, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,656] Trial 7 finished with values: [781.570608789336, 656.5263333333332, -0.17084457471955883] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 29, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,688] Trial 8 finished with values: [725.0165558339569, 612.4946666666667, -0.007531555906033605] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=739.6770, MAE=610.6833, R²=-0.0487, Time=0.03s\n  Trial 3: RMSE=720.6312, MAE=559.7170, R²=0.0046, Time=0.03s\n  Trial 4: RMSE=717.4655, MAE=608.3593, R²=0.0133, Time=0.03s\n  Trial 5: RMSE=834.9987, MAE=666.6447, R²=-0.3364, Time=0.03s\n  Trial 6: RMSE=996.0113, MAE=799.2333, R²=-0.9015, Time=0.03s\n  Trial 7: RMSE=781.5706, MAE=656.5263, R²=-0.1708, Time=0.03s\n  Trial 8: RMSE=725.0166, MAE=612.4947, R²=-0.0075, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:14,721] Trial 9 finished with values: [735.7348380995244, 572.1193333333333, -0.03754143936236365] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 21, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,750] Trial 10 finished with values: [725.3028744761276, 619.3303333333333, -0.008327488153434093] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,780] Trial 11 finished with values: [725.0165558339569, 612.4946666666667, -0.007531555906033605] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,810] Trial 12 finished with values: [724.2005454522479, 577.1666666666666, -0.005264866870889673] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 38, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,842] Trial 13 finished with values: [779.8190801140993, 636.2003333333334, -0.16560264289538673] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 16, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,873] Trial 14 finished with values: [680.982202716537, 524.075, 0.11113801374518983] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:14,908] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=735.7348, MAE=572.1193, R²=-0.0375, Time=0.03s\n  Trial 10: RMSE=725.3029, MAE=619.3303, R²=-0.0083, Time=0.03s\n  Trial 11: RMSE=725.0166, MAE=612.4947, R²=-0.0075, Time=0.03s\n  Trial 12: RMSE=724.2005, MAE=577.1667, R²=-0.0053, Time=0.03s\n  Trial 13: RMSE=779.8191, MAE=636.2003, R²=-0.1656, Time=0.03s\n  Trial 14: RMSE=680.9822, MAE=524.0750, R²=0.1111, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_sociale_lasten_trajectory: [{'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 15, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_sociale_lasten_trajectory: 0.48 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:14,940] Trial 0 finished with values: [1501.7266411017004, 1368.5432432432433, -0.3001680110027103] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:14,972] Trial 1 finished with values: [1475.4094891423706, 1350.8445945945948, -0.254997470494569] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 45, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,002] Trial 2 finished with values: [1547.381914304357, 1393.67, -0.38042475534285103] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 50, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,033] Trial 3 finished with values: [1476.824009624269, 1336.3143243243242, -0.2574050334371403] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,064] Trial 4 finished with values: [1524.7947124803745, 1313.348918918919, -0.3404186458716518] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,101] Trial 5 finished with values: [1511.3428744868459, 1366.2354054054053, -0.31687244837037065] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,133] Trial 6 finished with values: [1540.605766696457, 1345.527027027027, -0.36836117772485544] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1501.7266, MAE=1368.5432, R²=-0.3002, Time=0.03s\n  Trial 1: RMSE=1475.4095, MAE=1350.8446, R²=-0.2550, Time=0.03s\n  Trial 2: RMSE=1547.3819, MAE=1393.6700, R²=-0.3804, Time=0.03s\n  Trial 3: RMSE=1476.8240, MAE=1336.3143, R²=-0.2574, Time=0.03s\n  Trial 4: RMSE=1524.7947, MAE=1313.3489, R²=-0.3404, Time=0.03s\n  Trial 5: RMSE=1511.3429, MAE=1366.2354, R²=-0.3169, Time=0.04s\n  Trial 6: RMSE=1540.6058, MAE=1345.5270, R²=-0.3684, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:15,163] Trial 7 finished with values: [1469.5453825763095, 1322.4354054054052, -0.24504116522763386] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,194] Trial 8 finished with values: [1485.1570697768327, 1339.9599999999998, -0.2716350204154876] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 19, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,225] Trial 9 finished with values: [1556.7266126785466, 1362.662162162162, -0.39714797486011255] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 24, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,257] Trial 10 finished with values: [1466.4710120714783, 1326.8267567567566, -0.2398372239517388] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 29, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,287] Trial 11 finished with values: [1497.3760136959227, 1334.7510810810809, -0.29264553296651563] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 34, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,319] Trial 12 finished with values: [1569.1073960281592, 1348.7297297297298, -0.41945962759236366] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 39, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,350] Trial 13 finished with values: [1474.7279479023662, 1343.3421621621621, -0.25383828725071456] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 40, 'p': 2, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1469.5454, MAE=1322.4354, R²=-0.2450, Time=0.03s\n  Trial 8: RMSE=1485.1571, MAE=1339.9600, R²=-0.2716, Time=0.03s\n  Trial 9: RMSE=1556.7266, MAE=1362.6622, R²=-0.3971, Time=0.03s\n  Trial 10: RMSE=1466.4710, MAE=1326.8268, R²=-0.2398, Time=0.03s\n  Trial 11: RMSE=1497.3760, MAE=1334.7511, R²=-0.2926, Time=0.03s\n  Trial 12: RMSE=1569.1074, MAE=1348.7297, R²=-0.4195, Time=0.03s\n  Trial 13: RMSE=1474.7279, MAE=1343.3422, R²=-0.2538, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:15,381] Trial 14 finished with values: [1535.4796480253328, 1409.0472972972973, -0.3592703222730562] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 26, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,413] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[I 2025-01-19 13:45:15,445] Trial 0 finished with values: [1412.3978552860615, 1212.30125, -0.2234198884255214] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 34, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,476] Trial 1 finished with values: [1358.7327377008328, 1137.0208333333333, -0.1322165961920132] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 27, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,507] Trial 2 finished with values: [2153.881791285987, 1859.3541666666667, -1.8451499943360559] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,541] Trial 3 finished with values: [1324.2106456237743, 1122.83125, -0.07541375590154731] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 11, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,573] Trial 4 finished with values: [1321.4355079585798, 1112.545625, -0.07091100701385944] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1535.4796, MAE=1409.0473, R²=-0.3593, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 22, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 29, 'p': 1, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.47 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: RMSE=1412.3979, MAE=1212.3012, R²=-0.2234, Time=0.03s\n  Trial 1: RMSE=1358.7327, MAE=1137.0208, R²=-0.1322, Time=0.03s\n  Trial 2: RMSE=2153.8818, MAE=1859.3542, R²=-1.8451, Time=0.03s\n  Trial 3: RMSE=1324.2106, MAE=1122.8312, R²=-0.0754, Time=0.03s\n  Trial 4: RMSE=1321.4355, MAE=1112.5456, R²=-0.0709, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:15,605] Trial 5 finished with values: [1380.509107053747, 1201.885, -0.168799425347403] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 43, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,636] Trial 6 finished with values: [1345.7670919165087, 1135.3377083333332, -0.11071144260538368] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 23, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,668] Trial 7 finished with values: [1466.0043144917183, 1243.8620833333334, -0.31805014838443557] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,702] Trial 8 finished with values: [1395.1842884738082, 1169.1804166666668, -0.19378080435457035] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,734] Trial 9 finished with values: [1338.5222348716636, 1178.9691666666668, -0.09878473472027838] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 12, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,767] Trial 10 finished with values: [1420.7588487223709, 1233.3739583333333, -0.23794735605102635] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 45, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,799] Trial 11 finished with values: [2002.0139807620392, 1703.8958333333333, -1.4580779409787366] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1380.5091, MAE=1201.8850, R²=-0.1688, Time=0.03s\n  Trial 6: RMSE=1345.7671, MAE=1135.3377, R²=-0.1107, Time=0.03s\n  Trial 7: RMSE=1466.0043, MAE=1243.8621, R²=-0.3181, Time=0.03s\n  Trial 8: RMSE=1395.1843, MAE=1169.1804, R²=-0.1938, Time=0.03s\n  Trial 9: RMSE=1338.5222, MAE=1178.9692, R²=-0.0988, Time=0.03s\n  Trial 10: RMSE=1420.7588, MAE=1233.3740, R²=-0.2379, Time=0.03s\n  Trial 11: RMSE=2002.0140, MAE=1703.8958, R²=-1.4581, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:15,838] Trial 12 finished with values: [1409.3930492850163, 1199.7947916666667, -0.21821989607612946] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 48, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,869] Trial 13 finished with values: [2002.0139807620392, 1703.8958333333333, -1.4580779409787366] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:15,900] Trial 14 finished with values: [1549.3533530153798, 1191.6458333333333, -0.47218500591024104] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,934] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:45:15,965] Trial 0 finished with values: [549.8527461129357, 410.3734920634921, -0.013840617181984483] and parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:15,995] Trial 1 finished with values: [571.665990281427, 408.5873015873016, -0.09587646742521772] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 43, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,026] Trial 2 finished with values: [555.7998458949277, 395.3220634920635, -0.03589022163753919] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 47, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1409.3930, MAE=1199.7948, R²=-0.2182, Time=0.04s\n  Trial 13: RMSE=2002.0140, MAE=1703.8958, R²=-1.4581, Time=0.03s\n  Trial 14: RMSE=1549.3534, MAE=1191.6458, R²=-0.4722, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_kostprijs_van_de_omzet_trajectory: [{'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 32, 'p': 1, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_kostprijs_van_de_omzet_trajectory: 0.49 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: RMSE=549.8527, MAE=410.3735, R²=-0.0138, Time=0.03s\n  Trial 1: RMSE=571.6660, MAE=408.5873, R²=-0.0959, Time=0.03s\n  Trial 2: RMSE=555.7998, MAE=395.3221, R²=-0.0359, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:16,057] Trial 3 finished with values: [573.6196993861086, 398.8968253968254, -0.10337973828248326] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,095] Trial 4 finished with values: [560.176265602573, 410.4388888888888, -0.052267840224926365] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 45, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,125] Trial 5 finished with values: [554.4353258374757, 387.90476190476204, -0.030810127094304418] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,155] Trial 6 finished with values: [547.210618584895, 405.4390476190477, -0.004120704177216661] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,185] Trial 7 finished with values: [548.2698912495504, 399.4000000000001, -0.008011955755611533] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,217] Trial 8 finished with values: [599.8990129973862, 401.345238095238, -0.206794116774351] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 48, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,248] Trial 9 finished with values: [578.4025349760032, 411.9244444444444, -0.12185638703937474] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 23, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=573.6197, MAE=398.8968, R²=-0.1034, Time=0.03s\n  Trial 4: RMSE=560.1763, MAE=410.4389, R²=-0.0523, Time=0.04s\n  Trial 5: RMSE=554.4353, MAE=387.9048, R²=-0.0308, Time=0.03s\n  Trial 6: RMSE=547.2106, MAE=405.4390, R²=-0.0041, Time=0.03s\n  Trial 7: RMSE=548.2699, MAE=399.4000, R²=-0.0080, Time=0.03s\n  Trial 8: RMSE=599.8990, MAE=401.3452, R²=-0.2068, Time=0.03s\n  Trial 9: RMSE=578.4025, MAE=411.9244, R²=-0.1219, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:16,279] Trial 10 finished with values: [544.617234354143, 404.57523809523815, 0.005374360434773462] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,313] Trial 11 finished with values: [571.665990281427, 408.5873015873016, -0.09587646742521772] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 15, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,345] Trial 12 finished with values: [916.2450112469484, 698.7619047619048, -1.8151408935678095] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 11, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,375] Trial 13 finished with values: [538.141556922806, 408.38238095238097, 0.02888659011304273] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,405] Trial 14 finished with values: [551.202008226581, 400.3323809523809, -0.018822369503501468] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 10, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,437] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:45:16,466] Trial 0 finished with values: [316.07914580094723, 217.93076923076927, -0.007385306875668629] and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 39, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=544.6172, MAE=404.5752, R²=0.0054, Time=0.03s\n  Trial 11: RMSE=571.6660, MAE=408.5873, R²=-0.0959, Time=0.03s\n  Trial 12: RMSE=916.2450, MAE=698.7619, R²=-1.8151, Time=0.03s\n  Trial 13: RMSE=538.1416, MAE=408.3824, R²=0.0289, Time=0.03s\n  Trial 14: RMSE=551.2020, MAE=400.3324, R²=-0.0188, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_kantoorkosten_trajectory: [{'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 28, 'p': 1, 'outlier_removal': 1}, {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 30, 'p': 2, 'outlier_removal': 0}, {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 25, 'p': 2, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_kantoorkosten_trajectory: 0.47 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: RMSE=316.0791, MAE=217.9308, R²=-0.0074, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:16,496] Trial 1 finished with values: [359.6136003317863, 277.23128205128205, -0.30399564919811617] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,526] Trial 2 finished with values: [310.5029218409947, 215.29384615384612, 0.02784545993648868] and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 23, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,557] Trial 3 finished with values: [537.4909420822949, 440.35897435897436, -1.9130385090876314] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 41, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,589] Trial 4 finished with values: [537.4909420822949, 440.35897435897436, -1.9130385090876314] and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,620] Trial 5 finished with values: [342.45234244886973, 246.29205128205126, -0.18250832976361853] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 47, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,650] Trial 6 finished with values: [450.3784163886164, 369.64102564102564, -1.0453096398664563] and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 22, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,679] Trial 7 finished with values: [306.1305049844776, 209.05487179487181, 0.05503191296776] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=359.6136, MAE=277.2313, R²=-0.3040, Time=0.03s\n  Trial 2: RMSE=310.5029, MAE=215.2938, R²=0.0278, Time=0.03s\n  Trial 3: RMSE=537.4909, MAE=440.3590, R²=-1.9130, Time=0.03s\n  Trial 4: RMSE=537.4909, MAE=440.3590, R²=-1.9130, Time=0.03s\n  Trial 5: RMSE=342.4523, MAE=246.2921, R²=-0.1825, Time=0.03s\n  Trial 6: RMSE=450.3784, MAE=369.6410, R²=-1.0453, Time=0.03s\n  Trial 7: RMSE=306.1305, MAE=209.0549, R²=0.0550, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:16,711] Trial 8 finished with values: [359.6136003317863, 277.23128205128205, -0.30399564919811617] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 46, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,741] Trial 9 finished with values: [328.77680813772554, 239.06358974358977, -0.08994924774124802] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 43, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,770] Trial 10 finished with values: [347.4705324528641, 260.12871794871796, -0.21741846825896705] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,800] Trial 11 finished with values: [359.6136003317863, 277.23128205128205, -0.30399564919811617] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 28, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,829] Trial 12 finished with values: [314.5048275280708, 218.44461538461533, 0.0026248155997170564] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 17, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,859] Trial 13 finished with values: [309.7615270552328, 222.44230769230768, 0.0324823878395083] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:16,889] Trial 14 finished with values: [316.0108987166302, 220.9697435897436, -0.006950329189856497] and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 14, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=359.6136, MAE=277.2313, R²=-0.3040, Time=0.03s\n  Trial 9: RMSE=328.7768, MAE=239.0636, R²=-0.0899, Time=0.03s\n  Trial 10: RMSE=347.4705, MAE=260.1287, R²=-0.2174, Time=0.03s\n  Trial 11: RMSE=359.6136, MAE=277.2313, R²=-0.3040, Time=0.03s\n  Trial 12: RMSE=314.5048, MAE=218.4446, R²=0.0026, Time=0.03s\n  Trial 13: RMSE=309.7615, MAE=222.4423, R²=0.0325, Time=0.03s\n  Trial 14: RMSE=316.0109, MAE=220.9697, R²=-0.0070, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_verkoopkosten_trajectory: [{'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 40, 'p': 1, 'outlier_removal': 0}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_verkoopkosten_trajectory: 0.45 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:16,921] A new study created in memory with name: TrainerKNeighborsRegressor_month_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:45:16,957] Trial 0 finished with values: [1237.7204831315241, 1023.5376666666666, -0.05604579960705425] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 30, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:16,987] Trial 1 finished with values: [1208.0147936456187, 973.4833333333333, -0.0059632209266489156] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,016] Trial 2 finished with values: [1280.700850038759, 1057.2943333333333, -0.130662511163967] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 20, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,048] Trial 3 finished with values: [1258.0807584041124, 1019.2933333333333, -0.09107508187828373] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 42, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,079] Trial 4 finished with values: [1275.5751713272984, 1047.2140000000002, -0.12163024507004638] and parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 20, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,110] Trial 5 finished with values: [1267.8709439778693, 1047.029, -0.10812230178276971] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 43, 'p': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: RMSE=1237.7205, MAE=1023.5377, R²=-0.0560, Time=0.03s\n  Trial 1: RMSE=1208.0148, MAE=973.4833, R²=-0.0060, Time=0.03s\n  Trial 2: RMSE=1280.7009, MAE=1057.2943, R²=-0.1307, Time=0.03s\n  Trial 3: RMSE=1258.0808, MAE=1019.2933, R²=-0.0911, Time=0.03s\n  Trial 4: RMSE=1275.5752, MAE=1047.2140, R²=-0.1216, Time=0.03s\n  Trial 5: RMSE=1267.8709, MAE=1047.0290, R²=-0.1081, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:17,140] Trial 6 finished with values: [1300.3699242933399, 1079.2666666666667, -0.1656587547193813] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 13, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,170] Trial 7 finished with values: [1319.3826256258392, 1106.0970000000002, -0.19999412180652176] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan', 'leaf_size': 47, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,200] Trial 8 finished with values: [1337.651355922013, 1128.3333333333333, -0.23345544188077993] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 18, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,230] Trial 9 finished with values: [1266.8612026053472, 1046.7066666666665, -0.10635797177337336] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 16, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,259] Trial 10 finished with values: [1299.096053116679, 1090.301, -0.16337606309184416] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 19, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,289] Trial 11 finished with values: [1284.3786148990491, 1072.0156666666667, -0.137165640328482] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 38, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,319] Trial 12 finished with values: [1282.7277958254951, 1057.1969999999997, -0.13424430812310328] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'minkowski', 'leaf_size': 36, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1300.3699, MAE=1079.2667, R²=-0.1657, Time=0.03s\n  Trial 7: RMSE=1319.3826, MAE=1106.0970, R²=-0.2000, Time=0.03s\n  Trial 8: RMSE=1337.6514, MAE=1128.3333, R²=-0.2335, Time=0.03s\n  Trial 9: RMSE=1266.8612, MAE=1046.7067, R²=-0.1064, Time=0.03s\n  Trial 10: RMSE=1299.0961, MAE=1090.3010, R²=-0.1634, Time=0.03s\n  Trial 11: RMSE=1284.3786, MAE=1072.0157, R²=-0.1372, Time=0.03s\n  Trial 12: RMSE=1282.7278, MAE=1057.1970, R²=-0.1342, Time=0.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:17,350] Trial 13 finished with values: [1317.7190756113384, 1075.1496666666667, -0.1969699926281283] and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 10, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,381] Trial 14 finished with values: [1392.3532896981762, 1204.4, -0.33640006373238496] and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 46, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,412] A new study created in memory with name: TrainerKNeighborsRegressor_day_data_trajectory\n[I 2025-01-19 13:45:17,448] Trial 0 finished with values: [660.5173302911938, 542.679200477327, 0.06191664827026411] and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,480] Trial 1 finished with values: [698.5743049816808, 572.4464797136038, -0.04929646431584178] and parameters: {'n_neighbors': 3, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 29, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,513] Trial 2 finished with values: [672.9070010297226, 552.8492720763722, 0.026394343563912792] and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 32, 'p': 2, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1317.7191, MAE=1075.1497, R²=-0.1970, Time=0.03s\n  Trial 14: RMSE=1392.3533, MAE=1204.4000, R²=-0.3364, Time=0.03s\nBest hyperparameters for TrainerKNeighborsRegressor_month_data_cleaned_huisvestingskosten_trajectory: [{'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'ball_tree', 'metric': 'minkowski', 'leaf_size': 16, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_month_data_cleaned_huisvestingskosten_trajectory: 0.46 seconds\n  Added results for TrainerKNeighborsRegressor on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: RMSE=660.5173, MAE=542.6792, R²=0.0619, Time=0.03s\n  Trial 1: RMSE=698.5743, MAE=572.4465, R²=-0.0493, Time=0.03s\n  Trial 2: RMSE=672.9070, MAE=552.8493, R²=0.0264, Time=0.03s\n  Trial 3: RMSE=734.2962, MAE=591.0334, R²=-0.1594, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:17,551] Trial 3 finished with values: [734.2961582452228, 591.0334128878281, -0.15935251070123346] and parameters: {'n_neighbors': 2, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 33, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,585] Trial 4 finished with values: [681.6231087106504, 557.4332577565633, 0.0010089298775075584] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'minkowski', 'leaf_size': 49, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,618] Trial 5 finished with values: [657.1101343984029, 536.4840811455847, 0.07156965784700942] and parameters: {'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 48, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,659] Trial 6 finished with values: [655.4937312829794, 537.5625417661098, 0.07613166910374003] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 30, 'p': 2, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,697] Trial 7 finished with values: [681.6231087106504, 557.4332577565633, 0.0010089298775075584] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 37, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,738] Trial 8 finished with values: [681.066947927849, 558.5380668257757, 0.002638490206709365] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 39, 'p': 1, 'outlier_removal': 1}.\n[I 2025-01-19 13:45:17,781] Trial 9 finished with values: [680.6700108126256, 562.5636515513127, 0.003800709093310206] and parameters: {'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 13, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=681.6231, MAE=557.4333, R²=0.0010, Time=0.03s\n  Trial 5: RMSE=657.1101, MAE=536.4841, R²=0.0716, Time=0.03s\n  Trial 6: RMSE=655.4937, MAE=537.5625, R²=0.0761, Time=0.04s\n  Trial 7: RMSE=681.6231, MAE=557.4333, R²=0.0010, Time=0.04s\n  Trial 8: RMSE=681.0669, MAE=558.5381, R²=0.0026, Time=0.04s\n  Trial 9: RMSE=680.6700, MAE=562.5637, R²=0.0038, Time=0.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:17,824] Trial 10 finished with values: [681.6231087106504, 557.4332577565633, 0.0010089298775075584] and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan', 'leaf_size': 49, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,865] Trial 11 finished with values: [670.7294073936903, 553.1515274463007, 0.03268551611301329] and parameters: {'n_neighbors': 5, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 32, 'p': 2, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,911] Trial 12 finished with values: [705.8347280560248, 578.851491646778, -0.07122090572820405] and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'manhattan', 'leaf_size': 41, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,949] Trial 13 finished with values: [657.509128261612, 539.7671241050119, 0.07044183937775506] and parameters: {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 29, 'p': 1, 'outlier_removal': 0}.\n[I 2025-01-19 13:45:17,990] Trial 14 finished with values: [662.0865079366414, 545.9763484486873, 0.05745418262134527] and parameters: {'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean', 'leaf_size': 21, 'p': 1, 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=681.6231, MAE=557.4333, R²=0.0010, Time=0.04s\n  Trial 11: RMSE=670.7294, MAE=553.1515, R²=0.0327, Time=0.04s\n  Trial 12: RMSE=705.8347, MAE=578.8515, R²=-0.0712, Time=0.04s\n  Trial 13: RMSE=657.5091, MAE=539.7671, R²=0.0704, Time=0.04s\n  Trial 14: RMSE=662.0865, MAE=545.9763, R²=0.0575, Time=0.04s\nBest hyperparameters for TrainerKNeighborsRegressor_day_data_trajectory: [{'n_neighbors': 10, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean', 'leaf_size': 48, 'p': 2, 'outlier_removal': 1}, {'n_neighbors': 8, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'minkowski', 'leaf_size': 30, 'p': 2, 'outlier_removal': 1}]\nTotal optimization time for TrainerKNeighborsRegressor_day_data_trajectory: 0.58 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:18,031] A new study created in memory with name: TrainerKNeighborsRegressor_weather_data_trajectory\n[W 2025-01-19 13:45:18,035] Trial 0 failed with parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan', 'leaf_size': 18, 'p': 1, 'outlier_removal': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_knn.py\", line 49, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:18,038] Trial 0 failed with value None.\n[I 2025-01-19 13:45:18,039] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:45:18,042] Trial 0 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,046] Trial 1 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,049] Trial 2 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,052] Trial 3 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,055] Trial 4 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,058] Trial 5 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,061] Trial 6 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,064] Trial 7 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,067] Trial 8 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,071] Trial 9 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,074] Trial 10 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,080] Trial 11 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,083] Trial 12 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,087] Trial 13 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,090] Trial 14 finished with values: [296.8660742143121, 122.2621359223301, -0.1396302190846479] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,094] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:45:18,098] Trial 0 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,101] Trial 1 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,104] Trial 2 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,107] Trial 3 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,110] Trial 4 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,113] Trial 5 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,116] Trial 6 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,119] Trial 7 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,121] Trial 8 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,124] Trial 9 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,127] Trial 10 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,129] Trial 11 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,132] Trial 12 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,134] Trial 13 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,137] Trial 14 finished with values: [97.3926759737781, 62.666666666666664, -0.4283228483469417] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,141] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[I 2025-01-19 13:45:18,143] Trial 0 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,146] Trial 1 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,148] Trial 2 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,151] Trial 3 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,154] Trial 4 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,156] Trial 5 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,158] Trial 6 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,161] Trial 7 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,164] Trial 8 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,166] Trial 9 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,169] Trial 10 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,172] Trial 11 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,175] Trial 12 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,177] Trial 13 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,180] Trial 14 finished with values: [251.60875240284128, 198.53571428571428, -0.06713102761532475] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,183] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:45:18,186] Trial 0 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,189] Trial 1 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,191] Trial 2 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,194] Trial 3 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,196] Trial 4 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,199] Trial 5 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,201] Trial 6 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,203] Trial 7 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,207] Trial 8 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,209] Trial 9 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,212] Trial 10 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,214] Trial 11 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,217] Trial 12 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,219] Trial 13 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,222] Trial 14 finished with values: [146.74454517446821, 58.5, -0.18796953429180308] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,225] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:45:18,228] Trial 0 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerKNeighborsRegressor on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerKNeighborsRegressor on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerMajoritySelector\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 1: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 2: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 3: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 4: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 5: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 6: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 7: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 8: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 9: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 10: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 11: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.01s\n  Trial 12: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 13: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\n  Trial 14: RMSE=296.8661, MAE=122.2621, R²=-0.1396, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_algemene_kosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_algemene_kosten_trajectory: 0.05 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 1: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 2: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 3: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 4: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 5: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 6: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 7: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 8: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 9: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 10: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 11: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 12: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 13: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\n  Trial 14: RMSE=97.3927, MAE=62.6667, R²=-0.4283, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_autokosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_autokosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 1: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 2: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 3: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 4: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 5: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 6: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 7: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 8: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 9: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 10: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 11: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 12: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 13: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\n  Trial 14: RMSE=251.6088, MAE=198.5357, R²=-0.0671, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 1: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 2: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 3: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 4: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 5: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 6: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 7: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 8: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 9: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 10: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 11: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 12: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 13: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\n  Trial 14: RMSE=146.7445, MAE=58.5000, R²=-0.1880, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_huisvestingskosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_huisvestingskosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 1: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:18,231] Trial 1 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,233] Trial 2 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,236] Trial 3 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,239] Trial 4 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,241] Trial 5 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,243] Trial 6 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,246] Trial 7 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,249] Trial 8 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,251] Trial 9 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,253] Trial 10 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,256] Trial 11 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,259] Trial 12 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,261] Trial 13 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,264] Trial 14 finished with values: [408.4655510357988, 342.531914893617, -2.3694993080597393] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,267] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_lonen_en_salarissen_trajectory\n[I 2025-01-19 13:45:18,270] Trial 0 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,272] Trial 1 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,274] Trial 2 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,277] Trial 3 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,279] Trial 4 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,282] Trial 5 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,285] Trial 6 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,287] Trial 7 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,291] Trial 8 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,293] Trial 9 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,296] Trial 10 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,298] Trial 11 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,301] Trial 12 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,303] Trial 13 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,306] Trial 14 finished with values: [695.8812018288924, 500.4117647058824, -0.7878197793150403] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,310] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[I 2025-01-19 13:45:18,313] Trial 0 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,315] Trial 1 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,317] Trial 2 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,320] Trial 3 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,322] Trial 4 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,325] Trial 5 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,327] Trial 6 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,332] Trial 7 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,334] Trial 8 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,336] Trial 9 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,339] Trial 10 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,342] Trial 11 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,344] Trial 12 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,347] Trial 13 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,349] Trial 14 finished with values: [56.08583323491925, 11.0, -0.0316760274576271] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,352] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_overige_personeelskosten_trajectory\n[I 2025-01-19 13:45:18,355] Trial 0 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,358] Trial 1 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,360] Trial 2 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,363] Trial 3 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,366] Trial 4 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,368] Trial 5 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,371] Trial 6 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,373] Trial 7 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,375] Trial 8 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,377] Trial 9 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,382] Trial 10 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,385] Trial 11 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,388] Trial 12 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,391] Trial 13 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,393] Trial 14 finished with values: [198.5698629605975, 54.10476190476191, -0.07175871469715145] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,397] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:45:18,399] Trial 0 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,402] Trial 1 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,405] Trial 2 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,407] Trial 3 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,410] Trial 4 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,412] Trial 5 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,415] Trial 6 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,418] Trial 7 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,420] Trial 8 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,423] Trial 9 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,425] Trial 10 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,428] Trial 11 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,431] Trial 12 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,434] Trial 13 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 3: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 4: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 5: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 6: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 7: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 8: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 9: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 10: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 11: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 12: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 13: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\n  Trial 14: RMSE=408.4656, MAE=342.5319, R²=-2.3695, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_kantoorkosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_kantoorkosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 1: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 2: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 3: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 4: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 5: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 6: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 7: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 8: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 9: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 10: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 11: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 12: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 13: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\n  Trial 14: RMSE=695.8812, MAE=500.4118, R²=-0.7878, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_lonen_en_salarissen_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_lonen_en_salarissen_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 1: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 2: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 3: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 4: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 5: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 6: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 7: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 8: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 9: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 10: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 11: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 12: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 13: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\n  Trial 14: RMSE=56.0858, MAE=11.0000, R²=-0.0317, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 1: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 2: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 3: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 4: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 5: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 6: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 7: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 8: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 9: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 10: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 11: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 12: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 13: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\n  Trial 14: RMSE=198.5699, MAE=54.1048, R²=-0.0718, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_overige_personeelskosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_overige_personeelskosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 1: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 2: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 3: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 4: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 5: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 6: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 7: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 8: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 9: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 10: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 11: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 12: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 13: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s\n  Trial 14: RMSE=213.9821, MAE=86.9333, R²=-0.1922, Time=0.00s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:18,436] Trial 14 finished with values: [213.98208647766134, 86.93333333333334, -0.19216811933857914] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,440] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:18,442] Trial 0 failed with parameters: {'': ''} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:45:18,444] Trial 0 failed with value None.\n[I 2025-01-19 13:45:18,445] A new study created in memory with name: TrainerMajoritySelector_week_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:45:18,447] Trial 0 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,450] Trial 1 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,453] Trial 2 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,455] Trial 3 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,458] Trial 4 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,461] Trial 5 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,463] Trial 6 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,466] Trial 7 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,468] Trial 8 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,471] Trial 9 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,474] Trial 10 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,476] Trial 11 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,479] Trial 12 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,481] Trial 13 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,484] Trial 14 finished with values: [293.247079205174, 187.8279569892473, -0.6625177324080191] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,488] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_afschrijvingen_mva_trajectory\n[I 2025-01-19 13:45:18,490] Trial 0 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,493] Trial 1 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,495] Trial 2 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,498] Trial 3 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,501] Trial 4 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,503] Trial 5 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,505] Trial 6 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,508] Trial 7 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,510] Trial 8 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,513] Trial 9 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,515] Trial 10 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,518] Trial 11 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,521] Trial 12 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,523] Trial 13 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,526] Trial 14 finished with values: [736.9149355402035, 600.7333333333333, -1.1599094712220364] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,530] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_afschrijvingen_iva_trajectory\n[I 2025-01-19 13:45:18,533] Trial 0 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,536] Trial 1 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,538] Trial 2 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,543] Trial 3 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,546] Trial 4 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,548] Trial 5 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,552] Trial 6 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,556] Trial 7 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,559] Trial 8 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,562] Trial 9 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,566] Trial 10 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,568] Trial 11 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,571] Trial 12 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,573] Trial 13 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,576] Trial 14 finished with values: [161.3743060919757, 41.666666666666664, -0.0714285714285714] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,580] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_omzet_trajectory\n[I 2025-01-19 13:45:18,585] Trial 0 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,588] Trial 1 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,591] Trial 2 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,593] Trial 3 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,596] Trial 4 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,599] Trial 5 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,601] Trial 6 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,604] Trial 7 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,607] Trial 8 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,609] Trial 9 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,612] Trial 10 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,614] Trial 11 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,617] Trial 12 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,620] Trial 13 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,624] Trial 14 finished with values: [1042.3283409609328, 778.4814814814815, -0.5362229949560862] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,628] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:45:18,631] Trial 0 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,634] Trial 1 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,637] Trial 2 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_overige_rentelasten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_overige_rentelasten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerMajoritySelector on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 1: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 2: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 3: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 4: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 5: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 6: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 7: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 8: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 9: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 10: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 11: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 12: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 13: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\n  Trial 14: RMSE=293.2471, MAE=187.8280, R²=-0.6625, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_week_data_cleaned_verkoopkosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_week_data_cleaned_verkoopkosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Trial 0: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 1: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 2: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 3: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 4: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 5: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 6: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 7: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 8: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 9: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 10: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 11: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 12: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 13: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\n  Trial 14: RMSE=736.9149, MAE=600.7333, R²=-1.1599, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_mva_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_mva_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Trial 0: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 1: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 2: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 3: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 4: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 5: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 6: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 7: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 8: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 9: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 10: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 11: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 12: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 13: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\n  Trial 14: RMSE=161.3743, MAE=41.6667, R²=-0.0714, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_iva_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_afschrijvingen_iva_trajectory: 0.05 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Trial 0: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 1: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 2: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 3: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 4: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 5: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 6: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 7: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 8: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 9: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 10: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 11: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 12: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 13: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\n  Trial 14: RMSE=1042.3283, MAE=778.4815, R²=-0.5362, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_omzet_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_omzet_trajectory: 0.05 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Trial 0: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 1: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 2: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:18,640] Trial 3 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,642] Trial 4 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,646] Trial 5 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,648] Trial 6 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,651] Trial 7 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,653] Trial 8 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,656] Trial 9 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,659] Trial 10 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,662] Trial 11 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,665] Trial 12 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,669] Trial 13 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,672] Trial 14 finished with values: [1429.4480735136183, 966.2564102564103, -0.6380264494358172] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,676] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:45:18,678] Trial 0 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,681] Trial 1 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,684] Trial 2 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,686] Trial 3 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,688] Trial 4 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,691] Trial 5 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,695] Trial 6 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,698] Trial 7 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,700] Trial 8 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,703] Trial 9 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,706] Trial 10 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,709] Trial 11 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,711] Trial 12 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,714] Trial 13 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,716] Trial 14 finished with values: [1710.5826302118846, 1092.695652173913, -0.5769471283112477] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,720] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:45:18,723] Trial 0 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,725] Trial 1 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,728] Trial 2 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,730] Trial 3 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,733] Trial 4 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,735] Trial 5 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,738] Trial 6 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,740] Trial 7 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,743] Trial 8 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,745] Trial 9 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,747] Trial 10 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,750] Trial 11 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,752] Trial 12 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,755] Trial 13 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,757] Trial 14 finished with values: [821.3638517265517, 687.3461538461538, -0.011684023022646928] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,761] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_pensioenlasten_trajectory\n[I 2025-01-19 13:45:18,766] Trial 0 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,769] Trial 1 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,772] Trial 2 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,774] Trial 3 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,777] Trial 4 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,779] Trial 5 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,781] Trial 6 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,784] Trial 7 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,787] Trial 8 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,789] Trial 9 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,792] Trial 10 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,794] Trial 11 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,796] Trial 12 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,799] Trial 13 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,801] Trial 14 finished with values: [519.4563825128471, 378.6666666666667, -0.1892078215828057] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,805] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_lonen_en_salarissen_trajectory\n[I 2025-01-19 13:45:18,808] Trial 0 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,811] Trial 1 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,813] Trial 2 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,815] Trial 3 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,818] Trial 4 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,821] Trial 5 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,824] Trial 6 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,826] Trial 7 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,829] Trial 8 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,831] Trial 9 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,834] Trial 10 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,836] Trial 11 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,838] Trial 12 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,841] Trial 13 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 4: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 5: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 6: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 7: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 8: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 9: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 10: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 11: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 12: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 13: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\n  Trial 14: RMSE=1429.4481, MAE=966.2564, R²=-0.6380, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_algemene_kosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_algemene_kosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Trial 0: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 1: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 2: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 3: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 4: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 5: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 6: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 7: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 8: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 9: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 10: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 11: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 12: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 13: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\n  Trial 14: RMSE=1710.5826, MAE=1092.6957, R²=-0.5769, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_autokosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_autokosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Trial 0: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 1: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 2: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 3: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 4: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 5: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 6: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 7: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 8: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 9: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 10: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 11: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 12: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 13: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\n  Trial 14: RMSE=821.3639, MAE=687.3462, R²=-0.0117, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_overige_rentelasten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_overige_rentelasten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Trial 0: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 1: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 2: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 3: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 4: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 5: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 6: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 7: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 8: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 9: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 10: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 11: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 12: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 13: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\n  Trial 14: RMSE=519.4564, MAE=378.6667, R²=-0.1892, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_pensioenlasten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_pensioenlasten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Trial 0: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 1: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 2: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 3: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 4: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 5: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 6: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 7: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 8: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 9: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 10: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 11: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 12: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n  Trial 13: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:18,843] Trial 14 finished with values: [1145.7227891935377, 835.4193548387096, -0.0928762842868831] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,847] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_overige_personeelskosten_trajectory\n[I 2025-01-19 13:45:18,850] Trial 0 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,853] Trial 1 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,857] Trial 2 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,859] Trial 3 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,862] Trial 4 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,864] Trial 5 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,866] Trial 6 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,869] Trial 7 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,872] Trial 8 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,874] Trial 9 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,877] Trial 10 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,879] Trial 11 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,882] Trial 12 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,884] Trial 13 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,886] Trial 14 finished with values: [956.383639899108, 443.06060606060606, -0.177307982183329] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,890] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_sociale_lasten_trajectory\n[I 2025-01-19 13:45:18,893] Trial 0 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,896] Trial 1 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,898] Trial 2 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,900] Trial 3 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,903] Trial 4 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,905] Trial 5 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,908] Trial 6 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,910] Trial 7 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,913] Trial 8 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,916] Trial 9 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,918] Trial 10 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,921] Trial 11 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,923] Trial 12 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,926] Trial 13 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,928] Trial 14 finished with values: [780.7639634785065, 564.8333333333334, -0.1684290056157256] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,931] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[I 2025-01-19 13:45:18,934] Trial 0 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,936] Trial 1 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,939] Trial 2 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,943] Trial 3 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,945] Trial 4 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,948] Trial 5 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,950] Trial 6 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,953] Trial 7 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,956] Trial 8 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,958] Trial 9 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,961] Trial 10 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,963] Trial 11 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,966] Trial 12 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,968] Trial 13 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,971] Trial 14 finished with values: [2608.301461394659, 2275.972972972973, -2.9222319698037853] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,975] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[I 2025-01-19 13:45:18,978] Trial 0 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,980] Trial 1 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,983] Trial 2 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,986] Trial 3 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,988] Trial 4 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,991] Trial 5 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,993] Trial 6 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,995] Trial 7 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:18,998] Trial 8 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,000] Trial 9 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,003] Trial 10 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,005] Trial 11 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,007] Trial 12 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,010] Trial 13 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,013] Trial 14 finished with values: [1279.9722734627235, 1052.8958333333333, -0.004760519330603952] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,017] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:45:19,020] Trial 0 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,022] Trial 1 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,025] Trial 2 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,028] Trial 3 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,030] Trial 4 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,033] Trial 5 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,035] Trial 6 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,038] Trial 7 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,040] Trial 8 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,043] Trial 9 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1145.7228, MAE=835.4194, R²=-0.0929, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_lonen_en_salarissen_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_lonen_en_salarissen_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Trial 0: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 1: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 2: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 3: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 4: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 5: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 6: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 7: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 8: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 9: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 10: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 11: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 12: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 13: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\n  Trial 14: RMSE=956.3836, MAE=443.0606, R²=-0.1773, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_overige_personeelskosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_overige_personeelskosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Trial 0: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 1: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 2: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 3: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 4: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 5: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 6: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 7: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 8: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 9: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 10: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 11: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 12: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 13: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\n  Trial 14: RMSE=780.7640, MAE=564.8333, R²=-0.1684, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_sociale_lasten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_sociale_lasten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Trial 0: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 1: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 2: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 3: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 4: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 5: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 6: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 7: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 8: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 9: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 10: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 11: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 12: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 13: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\n  Trial 14: RMSE=2608.3015, MAE=2275.9730, R²=-2.9222, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Trial 0: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 1: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 2: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 3: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 4: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 5: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 6: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 7: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 8: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 9: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 10: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 11: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 12: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 13: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\n  Trial 14: RMSE=1279.9723, MAE=1052.8958, R²=-0.0048, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_kostprijs_van_de_omzet_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_kostprijs_van_de_omzet_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Trial 0: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 1: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 2: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 3: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 4: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 5: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 6: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 7: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 8: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 9: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:19,047] Trial 10 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,050] Trial 11 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,052] Trial 12 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,055] Trial 13 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,058] Trial 14 finished with values: [571.2559679796623, 370.3333333333333, -0.09430501605695563] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,062] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:45:19,065] Trial 0 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,067] Trial 1 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,070] Trial 2 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,073] Trial 3 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,076] Trial 4 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,078] Trial 5 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,081] Trial 6 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,084] Trial 7 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,087] Trial 8 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,090] Trial 9 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,092] Trial 10 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,095] Trial 11 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,097] Trial 12 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,100] Trial 13 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,103] Trial 14 finished with values: [359.3702469027929, 207.17948717948718, -0.30223139755784834] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,107] A new study created in memory with name: TrainerMajoritySelector_month_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:45:19,109] Trial 0 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,112] Trial 1 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,114] Trial 2 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,117] Trial 3 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,119] Trial 4 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,122] Trial 5 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,125] Trial 6 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,128] Trial 7 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,130] Trial 8 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,133] Trial 9 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,135] Trial 10 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,138] Trial 11 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,141] Trial 12 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,143] Trial 13 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,145] Trial 14 finished with values: [1213.6103987688964, 940.9333333333333, -0.015304182430873059] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,149] A new study created in memory with name: TrainerMajoritySelector_day_data_trajectory\n[I 2025-01-19 13:45:19,153] Trial 0 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,156] Trial 1 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,159] Trial 2 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,162] Trial 3 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,165] Trial 4 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,168] Trial 5 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,171] Trial 6 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,174] Trial 7 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,177] Trial 8 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,180] Trial 9 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,182] Trial 10 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,185] Trial 11 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,188] Trial 12 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,191] Trial 13 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,194] Trial 14 finished with values: [857.1390368252582, 665.4685918854415, -0.5797033684016584] and parameters: {'': ''}.\n[I 2025-01-19 13:45:19,198] A new study created in memory with name: TrainerMajoritySelector_weather_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 11: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 12: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 13: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\n  Trial 14: RMSE=571.2560, MAE=370.3333, R²=-0.0943, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_kantoorkosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_kantoorkosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Trial 0: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 1: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 2: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 3: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 4: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 5: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 6: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 7: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 8: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 9: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 10: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 11: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 12: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 13: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\n  Trial 14: RMSE=359.3702, MAE=207.1795, R²=-0.3022, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_verkoopkosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_verkoopkosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Trial 0: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 1: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 2: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 3: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 4: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 5: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 6: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 7: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 8: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 9: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 10: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 11: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 12: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 13: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\n  Trial 14: RMSE=1213.6104, MAE=940.9333, R²=-0.0153, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_month_data_cleaned_huisvestingskosten_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_month_data_cleaned_huisvestingskosten_trajectory: 0.04 seconds\n  Added results for TrainerMajoritySelector on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Trial 0: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 1: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 2: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 3: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 4: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 5: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 6: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 7: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 8: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 9: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 10: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 11: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 12: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 13: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\n  Trial 14: RMSE=857.1390, MAE=665.4686, R²=-0.5797, Time=0.00s\nBest hyperparameters for TrainerMajoritySelector_day_data_trajectory: [{'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}, {'': ''}]\nTotal optimization time for TrainerMajoritySelector_day_data_trajectory: 0.05 seconds\n  Added results for TrainerMajoritySelector on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:19,199] Trial 0 failed with parameters: {'': ''} because of the following error: KeyError('value').\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'value'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_majority_selector.py\", line 55, in predict\n    pdf_test['predictions'] = self.model['value'].value_counts().idxmax()\n                              ~~~~~~~~~~^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'value'\n[W 2025-01-19 13:45:19,475] Trial 0 failed with value None.\n[I 2025-01-19 13:45:19,477] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerMajoritySelector on dataset weather_data: 'value'\n\nProcessing Trainer: TrainerMovingAverage\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:20,083] Trial 0 finished with values: [295.6591410220609, 120.94660194174757, -0.1303825371146523] and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}.\n[W 2025-01-19 13:45:20,115] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:20,170] Trial 1 failed with value None.\n[I 2025-01-19 13:45:20,171] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:20,205] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:20,208] Trial 0 failed with value None.\n[I 2025-01-19 13:45:20,208] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=295.6591, MAE=120.9466, R²=-0.1304, Time=0.60s\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_algemene_kosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_autokosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:20,394] Trial 0 finished with values: [243.60909589250255, 211.078125, -0.00035295387398637246] and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 1}.\n[W 2025-01-19 13:45:20,426] Trial 1 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:20,429] Trial 1 failed with value None.\n[I 2025-01-19 13:45:20,430] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=243.6091, MAE=211.0781, R²=-0.0004, Time=0.18s\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_exploitatie-_en_machinekosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:20,890] Trial 0 finished with values: [142.7262486415237, 54.217948717948715, -0.12380011561729032] and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=142.7262, MAE=54.2179, R²=-0.1238, Time=0.46s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:21,383] Trial 1 finished with values: [135.4467276780507, 61.87625726023516, -0.01208830046257825] and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=135.4467, MAE=61.8763, R²=-0.0121, Time=0.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:21,864] Trial 2 finished with values: [135.4467276780507, 61.87625726023516, -0.01208830046257825] and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=135.4467, MAE=61.8763, R²=-0.0121, Time=0.48s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:22,337] Trial 3 finished with values: [135.4467276780507, 61.87625726023516, -0.01208830046257825] and parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}.\n[W 2025-01-19 13:45:22,369] Trial 4 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:22,371] Trial 4 failed with value None.\n[I 2025-01-19 13:45:22,372] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:22,403] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:22,406] Trial 0 failed with value None.\n[I 2025-01-19 13:45:22,407] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:22,441] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:22,443] Trial 0 failed with value None.\n[I 2025-01-19 13:45:22,444] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[W 2025-01-19 13:45:22,476] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:22,479] Trial 0 failed with value None.\n[I 2025-01-19 13:45:22,480] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:22,511] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:22,514] Trial 0 failed with value None.\n[I 2025-01-19 13:45:22,515] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_overige_rentelasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=135.4467, MAE=61.8763, R²=-0.0121, Time=0.47s\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_huisvestingskosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_kantoorkosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_lonen_en_salarissen: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_overige_bedrijfsopbrengsten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_overige_personeelskosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:23,045] Trial 0 finished with values: [213.58256275059327, 86.82222222222222, -0.1877205058837419] and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 0, 'outlier_removal': 0}.\n[W 2025-01-19 13:45:23,075] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,078] Trial 1 failed with value None.\n[I 2025-01-19 13:45:23,078] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:23,173] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 0} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:45:23,174] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,175] A new study created in memory with name: TrainerMovingAverage_week_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:23,213] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,216] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,217] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_afschrijvingen_mva_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=213.5826, MAE=86.8222, R²=-0.1877, Time=0.53s\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_overige_rentelasten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Error with trainer TrainerMovingAverage on dataset week_data_cleaned_verkoopkosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:23,497] Trial 0 finished with values: [527.9278543934241, 385.1, -0.10853646795128968] and parameters: {'avg_or_med': 'med', 'time': 'year', 'pattern': 1, 'outlier_removal': 0}.\n[W 2025-01-19 13:45:23,521] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,523] Trial 1 failed with value None.\n[I 2025-01-19 13:45:23,524] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_afschrijvingen_iva_trajectory\n[W 2025-01-19 13:45:23,549] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,552] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,553] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_omzet_trajectory\n[W 2025-01-19 13:45:23,578] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,580] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,581] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_algemene_kosten_trajectory\n[W 2025-01-19 13:45:23,606] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,608] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,608] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:23,632] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,635] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,636] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:23,665] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,667] Trial 0 failed with value None.\n[I 2025-01-19 13:45:23,668] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_pensioenlasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=527.9279, MAE=385.1000, R²=-0.1085, Time=0.28s\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_afschrijvingen_mva: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_afschrijvingen_iva: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_omzet: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_algemene_kosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_autokosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_overige_rentelasten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:23,783] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 0} because of the following error: The value nan is not acceptable.\n[W 2025-01-19 13:45:23,783] Trial 0 failed with value (29.698484809834994, 21.0, nan).\n[W 2025-01-19 13:45:23,807] Trial 1 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:23,810] Trial 1 failed with value None.\n[I 2025-01-19 13:45:23,811] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=29.6985, MAE=21.0000, R²=nan, Time=0.11s\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_pensioenlasten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:24,034] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 0} because of the following error: The value nan is not acceptable.\n[W 2025-01-19 13:45:24,035] Trial 0 failed with value (1578.757452476472, 1031.0, nan).\n[W 2025-01-19 13:45:24,059] Trial 1 failed with parameters: {'avg_or_med': 'med', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,061] Trial 1 failed with value None.\n[I 2025-01-19 13:45:24,062] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:24,090] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,092] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,093] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:24,122] Trial 0 failed with parameters: {'avg_or_med': 'med', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,124] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,125] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:24,151] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,153] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,154] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[W 2025-01-19 13:45:24,180] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,182] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,183] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_kantoorkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1578.7575, MAE=1031.0000, R²=nan, Time=0.22s\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_lonen_en_salarissen: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_overige_personeelskosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_sociale_lasten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_exploitatie-_en_machinekosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_kostprijs_van_de_omzet: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:24,577] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 1, 'outlier_removal': 1} because of the following error: The value nan is not acceptable.\n[W 2025-01-19 13:45:24,578] Trial 0 failed with value (640.0891127196448, 398.8, nan).\n[W 2025-01-19 13:45:24,602] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 1, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,604] Trial 1 failed with value None.\n[I 2025-01-19 13:45:24,605] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:24,630] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,632] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,633] A new study created in memory with name: TrainerMovingAverage_month_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=640.0891, MAE=398.8000, R²=nan, Time=0.39s\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_kantoorkosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_verkoopkosten: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:24,839] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'year', 'pattern': 0, 'outlier_removal': 0} because of the following error: The value nan is not acceptable.\n[W 2025-01-19 13:45:24,839] Trial 0 failed with value (1753.659406730627, 1278.888888888889, nan).\n[W 2025-01-19 13:45:24,862] Trial 1 failed with parameters: {'avg_or_med': 'avg', 'time': 'month', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to month,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,865] Trial 1 failed with value None.\n[I 2025-01-19 13:45:24,866] A new study created in memory with name: TrainerMovingAverage_day_data_trajectory\n[W 2025-01-19 13:45:24,898] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 1, 'outlier_removal': 0} because of the following error: ValueError('Time hyperparameter is set to week,                                      which is not in the list of possibilities.').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 142, in predict\n    raise ValueError(f\"Time hyperparameter is set to {self.hyperparameters.get('time')}, \\\nValueError: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n[W 2025-01-19 13:45:24,901] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,902] A new study created in memory with name: TrainerMovingAverage_weather_data_trajectory\n[W 2025-01-19 13:45:24,904] Trial 0 failed with parameters: {'avg_or_med': 'avg', 'time': 'week', 'pattern': 0, 'outlier_removal': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_moving_average.py\", line 45, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:24,907] Trial 0 failed with value None.\n[I 2025-01-19 13:45:24,908] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1753.6594, MAE=1278.8889, R²=nan, Time=0.20s\n  Error with trainer TrainerMovingAverage on dataset month_data_cleaned_huisvestingskosten: Time hyperparameter is set to month,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Error with trainer TrainerMovingAverage on dataset day_data: Time hyperparameter is set to week,                                      which is not in the list of possibilities.\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerMovingAverage on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerRandomForest\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:24,928] Trial 0 failed with parameters: {'max_depth': 335, 'n_estimators': 33, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,168] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,169] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:25,190] Trial 0 failed with parameters: {'max_depth': 258, 'n_estimators': 68, 'min_samples_split': 2, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,193] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,194] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:25,215] Trial 0 failed with parameters: {'max_depth': 281, 'n_estimators': 74, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,218] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,218] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:25,240] Trial 0 failed with parameters: {'max_depth': 410, 'n_estimators': 25, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,243] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,243] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:25,268] Trial 0 failed with parameters: {'max_depth': 292, 'n_estimators': 31, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,271] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,275] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:25,298] Trial 0 failed with parameters: {'max_depth': 86, 'n_estimators': 71, 'min_samples_split': 3, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,301] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,302] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[W 2025-01-19 13:45:25,321] Trial 0 failed with parameters: {'max_depth': 303, 'n_estimators': 21, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,324] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,325] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:25,344] Trial 0 failed with parameters: {'max_depth': 305, 'n_estimators': 32, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,347] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,348] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:25,367] Trial 0 failed with parameters: {'max_depth': 449, 'n_estimators': 83, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,369] Trial 0 failed with value None.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset week_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_overige_bedrijfsopbrengsten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:25,370] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:25,392] Trial 0 failed with parameters: {'max_depth': 385, 'n_estimators': 34, 'min_samples_split': 3, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,394] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,395] A new study created in memory with name: TrainerRandomForest_week_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:25,415] Trial 0 failed with parameters: {'max_depth': 381, 'n_estimators': 67, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,418] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,418] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_afschrijvingen_mva_trajectory\n[W 2025-01-19 13:45:25,440] Trial 0 failed with parameters: {'max_depth': 300, 'n_estimators': 39, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,443] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,444] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_afschrijvingen_iva_trajectory\n[W 2025-01-19 13:45:25,464] Trial 0 failed with parameters: {'max_depth': 135, 'n_estimators': 6, 'min_samples_split': 5, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,467] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,468] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_omzet_trajectory\n[W 2025-01-19 13:45:25,491] Trial 0 failed with parameters: {'max_depth': 367, 'n_estimators': 71, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,493] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,494] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_algemene_kosten_trajectory\n[W 2025-01-19 13:45:25,516] Trial 0 failed with parameters: {'max_depth': 79, 'n_estimators': 41, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,519] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,520] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:25,544] Trial 0 failed with parameters: {'max_depth': 226, 'n_estimators': 17, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,546] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,547] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:25,568] Trial 0 failed with parameters: {'max_depth': 248, 'n_estimators': 14, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset week_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Error with trainer TrainerRandomForest on dataset week_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_afschrijvingen_mva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_afschrijvingen_iva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:25,571] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,572] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_pensioenlasten_trajectory\n[W 2025-01-19 13:45:25,593] Trial 0 failed with parameters: {'max_depth': 471, 'n_estimators': 62, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,595] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,596] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:25,618] Trial 0 failed with parameters: {'max_depth': 283, 'n_estimators': 40, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,621] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,622] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:25,651] Trial 0 failed with parameters: {'max_depth': 363, 'n_estimators': 11, 'min_samples_split': 2, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,654] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,655] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:25,680] Trial 0 failed with parameters: {'max_depth': 499, 'n_estimators': 28, 'min_samples_split': 2, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,683] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,684] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:25,705] Trial 0 failed with parameters: {'max_depth': 427, 'n_estimators': 69, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,708] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,709] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[W 2025-01-19 13:45:25,730] Trial 0 failed with parameters: {'max_depth': 120, 'n_estimators': 72, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,732] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,733] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:25,755] Trial 0 failed with parameters: {'max_depth': 273, 'n_estimators': 52, 'min_samples_split': 6, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,758] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,758] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_verkoopkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset month_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_pensioenlasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_kostprijs_van_de_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:25,780] Trial 0 failed with parameters: {'max_depth': 424, 'n_estimators': 52, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,783] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,783] A new study created in memory with name: TrainerRandomForest_month_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:25,805] Trial 0 failed with parameters: {'max_depth': 314, 'n_estimators': 28, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:25,807] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,808] A new study created in memory with name: TrainerRandomForest_day_data_trajectory\n[W 2025-01-19 13:45:25,831] Trial 0 failed with parameters: {'max_depth': 69, 'n_estimators': 36, 'min_samples_split': 4, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 93, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:25,834] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,835] A new study created in memory with name: TrainerRandomForest_weather_data_trajectory\n[W 2025-01-19 13:45:25,838] Trial 0 failed with parameters: {'max_depth': 91, 'n_estimators': 47, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest.py\", line 49, in fit\n    df = df_train[[\n         ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:25,841] Trial 0 failed with value None.\n[I 2025-01-19 13:45:25,841] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForest on dataset month_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Error with trainer TrainerRandomForest on dataset month_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Error with trainer TrainerRandomForest on dataset day_data: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerRandomForest on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerRandomForestPattern\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:25,901] Trial 0 failed with parameters: {'n_estimators': 300, 'max_depth': 79, 'min_samples_split': 8, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,092] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,093] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:26,136] Trial 0 failed with parameters: {'n_estimators': 197, 'max_depth': 46, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,139] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,140] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:26,184] Trial 0 failed with parameters: {'n_estimators': 212, 'max_depth': 84, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,187] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,188] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:26,236] Trial 0 failed with parameters: {'n_estimators': 55, 'max_depth': 66, 'min_samples_split': 3, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,239] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,240] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:26,288] Trial 0 failed with parameters: {'n_estimators': 66, 'max_depth': 11, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,292] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,293] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:26,337] Trial 0 failed with parameters: {'n_estimators': 115, 'max_depth': 36, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,339] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,340] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[W 2025-01-19 13:45:26,390] Trial 0 failed with parameters: {'n_estimators': 163, 'max_depth': 71, 'min_samples_split': 3, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,393] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,393] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:26,437] Trial 0 failed with parameters: {'n_estimators': 154, 'max_depth': 40, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,440] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,441] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:26,483] Trial 0 failed with parameters: {'n_estimators': 117, 'max_depth': 76, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,486] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,487] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:26,533] Trial 0 failed with parameters: {'n_estimators': 186, 'max_depth': 47, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,536] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,537] A new study created in memory with name: TrainerRandomForestPattern_week_data_cleaned_verkoopkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_overige_bedrijfsopbrengsten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:26,581] Trial 0 failed with parameters: {'n_estimators': 182, 'max_depth': 52, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,584] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,585] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_afschrijvingen_mva_trajectory\n[W 2025-01-19 13:45:26,627] Trial 0 failed with parameters: {'n_estimators': 157, 'max_depth': 51, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,630] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,631] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_afschrijvingen_iva_trajectory\n[W 2025-01-19 13:45:26,672] Trial 0 failed with parameters: {'n_estimators': 86, 'max_depth': 65, 'min_samples_split': 5, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,674] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,675] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_omzet_trajectory\n[W 2025-01-19 13:45:26,718] Trial 0 failed with parameters: {'n_estimators': 216, 'max_depth': 79, 'min_samples_split': 4, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,721] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,721] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_algemene_kosten_trajectory\n[W 2025-01-19 13:45:26,760] Trial 0 failed with parameters: {'n_estimators': 123, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,763] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,763] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_autokosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset week_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_afschrijvingen_mva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_afschrijvingen_iva: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_algemene_kosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:26,809] Trial 0 failed with parameters: {'n_estimators': 208, 'max_depth': 95, 'min_samples_split': 10, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,813] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,813] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:26,854] Trial 0 failed with parameters: {'n_estimators': 128, 'max_depth': 21, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,858] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,859] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_pensioenlasten_trajectory\n[W 2025-01-19 13:45:26,895] Trial 0 failed with parameters: {'n_estimators': 214, 'max_depth': 90, 'min_samples_split': 5, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,898] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,899] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:26,941] Trial 0 failed with parameters: {'n_estimators': 113, 'max_depth': 17, 'min_samples_split': 9, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:26,943] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,944] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:26,983] Trial 0 failed with parameters: {'n_estimators': 169, 'max_depth': 43, 'min_samples_split': 6, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:26,987] Trial 0 failed with value None.\n[I 2025-01-19 13:45:26,987] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_sociale_lasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_autokosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_overige_rentelasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_pensioenlasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_lonen_en_salarissen: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_overige_personeelskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:27,027] Trial 0 failed with parameters: {'n_estimators': 248, 'max_depth': 42, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:27,029] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,030] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:27,071] Trial 0 failed with parameters: {'n_estimators': 285, 'max_depth': 67, 'min_samples_split': 2, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:27,074] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,075] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[W 2025-01-19 13:45:27,113] Trial 0 failed with parameters: {'n_estimators': 74, 'max_depth': 43, 'min_samples_split': 7, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:27,116] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,117] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:27,164] Trial 0 failed with parameters: {'n_estimators': 241, 'max_depth': 28, 'min_samples_split': 3, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:27,167] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,168] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:27,210] Trial 0 failed with parameters: {'n_estimators': 158, 'max_depth': 39, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:27,213] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,214] A new study created in memory with name: TrainerRandomForestPattern_month_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_sociale_lasten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_exploitatie-_en_machinekosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_kostprijs_van_de_omzet: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_kantoorkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_verkoopkosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:27,255] Trial 0 failed with parameters: {'n_estimators': 85, 'max_depth': 15, 'min_samples_split': 10, 'bootstrap': 1, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n[W 2025-01-19 13:45:27,258] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,259] A new study created in memory with name: TrainerRandomForestPattern_day_data_trajectory\n[W 2025-01-19 13:45:27,306] Trial 0 failed with parameters: {'n_estimators': 292, 'max_depth': 93, 'min_samples_split': 5, 'bootstrap': 0, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: InvalidParameterError(\"The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 50, in fit\n    self.model = rf_reg.fit(X_train, y_train)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py\", line 29, in patch_function\n    original_result = original(self, *args, **kwargs)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n    estimator._validate_params()\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/databricks/python/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n[W 2025-01-19 13:45:27,309] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,310] A new study created in memory with name: TrainerRandomForestPattern_weather_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset month_data_cleaned_huisvestingskosten: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 1 instead.\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Error with trainer TrainerRandomForestPattern on dataset day_data: The 'bootstrap' parameter of RandomForestRegressor must be an instance of 'bool' or an instance of 'numpy.bool_'. Got 0 instead.\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:27,313] Trial 0 failed with parameters: {'n_estimators': 286, 'max_depth': 80, 'min_samples_split': 9, 'bootstrap': 1, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_random_forest_pattern.py\", line 38, in fit\n    pdf_train = self._preprocessing(pdf_train, True)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/abstract_classes/trainer.py\", line 132, in _preprocessing\n    df = df[relevant_columns]\n         ~~^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:27,510] Trial 0 failed with value None.\n[I 2025-01-19 13:45:27,510] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_algemene_kosten_trajectory\n[I 2025-01-19 13:45:27,527] Trial 0 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,546] Trial 1 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,561] Trial 2 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,575] Trial 3 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,589] Trial 4 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,603] Trial 5 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,617] Trial 6 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,632] Trial 7 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,646] Trial 8 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,660] Trial 9 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,673] Trial 10 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,687] Trial 11 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,701] Trial 12 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,715] Trial 13 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerRandomForestPattern on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerValueLastYears\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n  Trial 0: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.02s\n  Trial 1: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.02s\n  Trial 2: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 3: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 4: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 5: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 6: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 7: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 8: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 9: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 10: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 11: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 12: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n  Trial 13: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:27,729] Trial 14 finished with values: [296.1719357636381, 121.3883495145631, -0.13430703543116507] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,745] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:45:27,756] Trial 0 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,766] Trial 1 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,775] Trial 2 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,784] Trial 3 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,793] Trial 4 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,802] Trial 5 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,812] Trial 6 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,821] Trial 7 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,830] Trial 8 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,840] Trial 9 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,849] Trial 10 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,858] Trial 11 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,867] Trial 12 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,877] Trial 13 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,887] Trial 14 finished with values: [90.92671041375392, 63.0, -0.24496386025967087] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,897] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[I 2025-01-19 13:45:27,908] Trial 0 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,919] Trial 1 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,929] Trial 2 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=296.1719, MAE=121.3883, R²=-0.1343, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_algemene_kosten_trajectory: [{'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_algemene_kosten_trajectory: 0.22 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 1: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 2: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 3: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 4: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 5: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 6: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 7: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 8: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 9: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 10: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 11: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 12: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 13: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\n  Trial 14: RMSE=90.9267, MAE=63.0000, R²=-0.2450, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_autokosten_trajectory: [{'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_autokosten_trajectory: 0.14 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Trial 0: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 1: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 2: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:27,941] Trial 3 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,952] Trial 4 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:27,963] Trial 5 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,973] Trial 6 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,984] Trial 7 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:27,996] Trial 8 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,007] Trial 9 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,018] Trial 10 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,030] Trial 11 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,041] Trial 12 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,052] Trial 13 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,063] Trial 14 finished with values: [402.0645381740882, 319.89285714285717, -1.7249453675611401] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,075] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_huisvestingskosten_trajectory\n[I 2025-01-19 13:45:28,086] Trial 0 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,098] Trial 1 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,110] Trial 2 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,124] Trial 3 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,136] Trial 4 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 4: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 5: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 6: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 7: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 8: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 9: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 10: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 11: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 12: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 13: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\n  Trial 14: RMSE=402.0645, MAE=319.8929, R²=-1.7249, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: 0.17 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Trial 0: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 1: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 2: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 3: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 4: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:28,149] Trial 5 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,165] Trial 6 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,177] Trial 7 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,189] Trial 8 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,200] Trial 9 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,212] Trial 10 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,223] Trial 11 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,238] Trial 12 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,251] Trial 13 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,263] Trial 14 finished with values: [147.55151208289504, 60.37179487179487, -0.20107104993776326] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,276] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_kantoorkosten_trajectory\n[I 2025-01-19 13:45:28,288] Trial 0 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,299] Trial 1 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,311] Trial 2 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,323] Trial 3 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,334] Trial 4 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,346] Trial 5 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 6: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.02s\n  Trial 7: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 8: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 9: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 10: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 11: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 12: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 13: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\n  Trial 14: RMSE=147.5515, MAE=60.3718, R²=-0.2011, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_huisvestingskosten_trajectory: [{'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_huisvestingskosten_trajectory: 0.19 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Trial 0: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 1: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 2: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 3: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 4: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 5: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:28,358] Trial 6 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,370] Trial 7 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,381] Trial 8 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,393] Trial 9 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,404] Trial 10 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,415] Trial 11 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,426] Trial 12 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,438] Trial 13 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,449] Trial 14 finished with values: [367.5471600946156, 305.29787234042556, -1.7282278896585441] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,461] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_lonen_en_salarissen_trajectory\n[I 2025-01-19 13:45:28,471] Trial 0 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,481] Trial 1 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,490] Trial 2 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,500] Trial 3 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,509] Trial 4 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,519] Trial 5 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,528] Trial 6 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,537] Trial 7 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,546] Trial 8 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,555] Trial 9 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 7: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 8: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 9: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 10: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 11: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 12: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 13: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\n  Trial 14: RMSE=367.5472, MAE=305.2979, R²=-1.7282, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_kantoorkosten_trajectory: [{'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_kantoorkosten_trajectory: 0.17 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Trial 0: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 1: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 2: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 3: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 4: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 5: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 6: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 7: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 8: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 9: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:28,564] Trial 10 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,573] Trial 11 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,582] Trial 12 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,591] Trial 13 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,599] Trial 14 finished with values: [527.6743648256163, 396.0, -0.027982023440616732] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,610] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[I 2025-01-19 13:45:28,631] Trial 0 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,640] Trial 1 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,649] Trial 2 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,659] Trial 3 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,668] Trial 4 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,677] Trial 5 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,687] Trial 6 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,697] Trial 7 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,707] Trial 8 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,717] Trial 9 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,726] Trial 10 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,737] Trial 11 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,746] Trial 12 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,757] Trial 13 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 11: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 12: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 13: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\n  Trial 14: RMSE=527.6744, MAE=396.0000, R²=-0.0280, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_lonen_en_salarissen_trajectory: [{'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_lonen_en_salarissen_trajectory: 0.14 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Trial 0: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 1: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 2: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 3: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 4: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 5: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 6: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 7: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 8: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 9: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 10: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 11: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 12: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 13: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n  Trial 14: RMSE=55.9193, MAE=11.9310, R²=-0.0256, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:28,767] Trial 14 finished with values: [55.919276794692, 11.931034482758621, -0.02555765017498368] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,778] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_overige_personeelskosten_trajectory\n[I 2025-01-19 13:45:28,792] Trial 0 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,806] Trial 1 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,820] Trial 2 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,834] Trial 3 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,848] Trial 4 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,867] Trial 5 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,885] Trial 6 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,899] Trial 7 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,915] Trial 8 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:28,930] Trial 9 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,944] Trial 10 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,958] Trial 11 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:28,974] Trial 12 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for TrainerValueLastYears_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: [{'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: 0.16 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Trial 0: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 1: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 2: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 3: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 4: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 5: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.02s\n  Trial 6: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 7: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 8: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 9: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 10: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 11: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 12: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:28,989] Trial 13 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,010] Trial 14 finished with values: [202.96901006710124, 67.02857142857142, -0.11977255371803053] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,025] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_overige_rentelasten_trajectory\n[I 2025-01-19 13:45:29,040] Trial 0 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,053] Trial 1 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,068] Trial 2 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,083] Trial 3 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,097] Trial 4 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,116] Trial 5 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,131] Trial 6 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,146] Trial 7 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,160] Trial 8 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,174] Trial 9 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,188] Trial 10 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\n  Trial 14: RMSE=202.9690, MAE=67.0286, R²=-0.1198, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_overige_personeelskosten_trajectory: [{'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_overige_personeelskosten_trajectory: 0.23 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Trial 0: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 1: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 2: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 3: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 4: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 5: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.02s\n  Trial 6: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 7: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 8: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 9: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 10: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 11: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:29,202] Trial 11 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,219] Trial 12 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,233] Trial 13 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,249] Trial 14 finished with values: [215.61916014636134, 89.91111111111111, -0.2104793032358978] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,264] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:29,274] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:45:29,275] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,276] A new study created in memory with name: TrainerValueLastYears_week_data_cleaned_verkoopkosten_trajectory\n[I 2025-01-19 13:45:29,289] Trial 0 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,302] Trial 1 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,316] Trial 2 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,329] Trial 3 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,342] Trial 4 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,355] Trial 5 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,369] Trial 6 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,382] Trial 7 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,395] Trial 8 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,408] Trial 9 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 13: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\n  Trial 14: RMSE=215.6192, MAE=89.9111, R²=-0.2105, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_overige_rentelasten_trajectory: [{'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_overige_rentelasten_trajectory: 0.22 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerValueLastYears on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Trial 0: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 1: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 2: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 3: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 4: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 5: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 6: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 7: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 8: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 9: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 10: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:29,421] Trial 10 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,435] Trial 11 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:29,451] Trial 12 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,465] Trial 13 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:45:29,478] Trial 14 finished with values: [344.771453050727, 259.1182795698925, -1.2980606922391251] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n[I 2025-01-19 13:45:29,491] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_afschrijvingen_mva_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 13: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\n  Trial 14: RMSE=344.7715, MAE=259.1183, R²=-1.2981, Time=0.01s\nBest hyperparameters for TrainerValueLastYears_week_data_cleaned_verkoopkosten_trajectory: [{'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerValueLastYears_week_data_cleaned_verkoopkosten_trajectory: 0.20 seconds\n  Added results for TrainerValueLastYears on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:29,505] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,709] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,711] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_afschrijvingen_iva_trajectory\n[W 2025-01-19 13:45:29,724] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,727] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,728] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_omzet_trajectory\n[W 2025-01-19 13:45:29,742] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: TypeError(\"don't know how to coerce float64 and int64\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 149, in predict\n    predictions.append(mean(values_all_years) * trend)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 484, in mean\n    T, total, n = _sum(data)\n                  ^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 204, in _sum\n    T = reduce(_coerce, types, int)  # or raise TypeError\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 284, in _coerce\n    raise TypeError(msg % (T.__name__, S.__name__))\nTypeError: don't know how to coerce float64 and int64\n[W 2025-01-19 13:45:29,745] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,745] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_algemene_kosten_trajectory\n[W 2025-01-19 13:45:29,759] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: TypeError(\"don't know how to coerce float64 and int64\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 149, in predict\n    predictions.append(mean(values_all_years) * trend)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 484, in mean\n    T, total, n = _sum(data)\n                  ^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 204, in _sum\n    T = reduce(_coerce, types, int)  # or raise TypeError\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 284, in _coerce\n    raise TypeError(msg % (T.__name__, S.__name__))\nTypeError: don't know how to coerce float64 and int64\n[W 2025-01-19 13:45:29,762] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,763] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:29,780] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,782] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,783] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:29,798] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,801] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,801] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_pensioenlasten_trajectory\n[W 2025-01-19 13:45:29,814] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,816] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,817] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:29,833] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,835] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,836] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:29,855] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,859] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,859] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:29,873] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,876] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,876] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:29,889] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: TypeError(\"don't know how to coerce float64 and int64\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 149, in predict\n    predictions.append(mean(values_all_years) * trend)\n                       ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 484, in mean\n    T, total, n = _sum(data)\n                  ^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 204, in _sum\n    T = reduce(_coerce, types, int)  # or raise TypeError\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/statistics.py\", line 284, in _coerce\n    raise TypeError(msg % (T.__name__, S.__name__))\nTypeError: don't know how to coerce float64 and int64\n[W 2025-01-19 13:45:29,891] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,892] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[W 2025-01-19 13:45:29,905] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,908] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,909] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_kantoorkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_afschrijvingen_mva: list index out of range\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_afschrijvingen_iva: list index out of range\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_omzet: don't know how to coerce float64 and int64\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_algemene_kosten: don't know how to coerce float64 and int64\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_autokosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_overige_rentelasten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_pensioenlasten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_lonen_en_salarissen: list index out of range\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_overige_personeelskosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_sociale_lasten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_exploitatie-_en_machinekosten: don't know how to coerce float64 and int64\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_kostprijs_van_de_omzet: list index out of range\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:29,928] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,931] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,931] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:29,945] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,948] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,948] A new study created in memory with name: TrainerValueLastYears_month_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:29,963] Trial 0 failed with parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: IndexError('list index out of range').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 36, in objective\n    predictions = trainer.predict(test_data)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 115, in predict\n    value = predictions[index]\n            ~~~~~~~~~~~^^^^^^^\nIndexError: list index out of range\n[W 2025-01-19 13:45:29,965] Trial 0 failed with value None.\n[I 2025-01-19 13:45:29,966] A new study created in memory with name: TrainerValueLastYears_day_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_kantoorkosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_verkoopkosten: list index out of range\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Error with trainer TrainerValueLastYears on dataset month_data_cleaned_huisvestingskosten: list index out of range\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:30,780] Trial 0 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.81s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:31,583] Trial 1 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:32,383] Trial 2 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:33,184] Trial 3 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:33,982] Trial 4 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:34,782] Trial 5 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:35,580] Trial 6 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:36,382] Trial 7 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:37,187] Trial 8 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:37,985] Trial 9 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:38,784] Trial 10 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:39,598] Trial 11 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.81s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:40,392] Trial 12 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.79s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:41,188] Trial 13 finished with values: [874.1008753655184, 691.3783283886, -0.6428431645571635] and parameters: {'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=874.1009, MAE=691.3783, R²=-0.6428, Time=0.79s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:41,987] Trial 14 finished with values: [872.6672416170404, 690.1918281622912, -0.6374586510953111] and parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=872.6672, MAE=690.1918, R²=-0.6375, Time=0.80s\nBest hyperparameters for TrainerValueLastYears_day_data_trajectory: [{'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 1}, {'prediction_mode': 'Zero', 'outlier_removal': 0}, {'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerValueLastYears_day_data_trajectory: 12.02 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:42,791] A new study created in memory with name: TrainerValueLastYears_weather_data_trajectory\n[W 2025-01-19 13:45:42,794] Trial 0 failed with parameters: {'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_value_last_years.py\", line 51, in fit\n    df = pdf_train[['category', 'value', 'date', 'year']]\n         ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:42,798] Trial 0 failed with value None.\n[I 2025-01-19 13:45:42,799] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerValueLastYears on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerValueLastYears on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerXGBoost\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:42,807] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 487, 'max_depth': 14, 'learning_rate': 0.07629810104133279, 'subsample': 0.5884548682466944, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,019] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,020] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:43,028] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 343, 'max_depth': 7, 'learning_rate': 0.11475502005754348, 'subsample': 0.7075217295416658, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,031] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,032] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:43,039] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 274, 'max_depth': 15, 'learning_rate': 0.10887928481748706, 'subsample': 0.6296999046396015, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,043] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,044] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:43,052] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 317, 'max_depth': 25, 'learning_rate': 0.12487215109760365, 'subsample': 0.9701411926379384, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,055] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,056] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:43,065] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 390, 'max_depth': 29, 'learning_rate': 0.11062794591341005, 'subsample': 0.6318857610417898, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,068] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,069] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_lonen_en_salarissen_trajectory\n[W 2025-01-19 13:45:43,077] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 18, 'learning_rate': 0.0703209276624598, 'subsample': 0.6994257896763918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,080] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,081] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n[W 2025-01-19 13:45:43,088] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 291, 'max_depth': 11, 'learning_rate': 0.03114544113168065, 'subsample': 0.8107075219884127, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,091] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,092] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:43,099] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 148, 'max_depth': 23, 'learning_rate': 0.14727223311732796, 'subsample': 0.9118116342001823, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,103] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,104] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:43,112] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 318, 'max_depth': 5, 'learning_rate': 0.08772815330833827, 'subsample': 0.6195937125581074, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,115] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,116] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:43,123] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 190, 'max_depth': 13, 'learning_rate': 0.028117480183051876, 'subsample': 0.774986170605491, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,127] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,127] A new study created in memory with name: TrainerXGBoost_week_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:43,135] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 93, 'max_depth': 20, 'learning_rate': 0.013130563392685562, 'subsample': 0.6672173966007728, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,138] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,139] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_afschrijvingen_mva_trajectory\n[W 2025-01-19 13:45:43,146] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 470, 'max_depth': 7, 'learning_rate': 0.15068880267256374, 'subsample': 0.9359904645320567, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,149] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,152] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_afschrijvingen_iva_trajectory\n[W 2025-01-19 13:45:43,159] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 337, 'max_depth': 27, 'learning_rate': 0.14104909472742505, 'subsample': 0.6338397296176616, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,162] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,163] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_omzet_trajectory\n[W 2025-01-19 13:45:43,171] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 483, 'max_depth': 26, 'learning_rate': 0.13237555313951166, 'subsample': 0.7280809565005006, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,174] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,174] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_algemene_kosten_trajectory\n[W 2025-01-19 13:45:43,182] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 13, 'learning_rate': 0.16794843653003305, 'subsample': 0.9470706086271, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,185] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,186] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_autokosten_trajectory\n[W 2025-01-19 13:45:43,193] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 310, 'max_depth': 28, 'learning_rate': 0.13242948281454045, 'subsample': 0.820193358526548, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,196] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,196] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_overige_rentelasten_trajectory\n[W 2025-01-19 13:45:43,203] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 79, 'max_depth': 27, 'learning_rate': 0.1677666878750491, 'subsample': 0.7979112392421108, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,207] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,207] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_pensioenlasten_trajectory\n[W 2025-01-19 13:45:43,214] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 292, 'max_depth': 4, 'learning_rate': 0.1307572985977616, 'subsample': 0.9872132841548443, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,218] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,219] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerXGBoost on dataset week_data_cleaned_algemene_kosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_autokosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_exploitatie-_en_machinekosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_huisvestingskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_kantoorkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_lonen_en_salarissen: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_overige_bedrijfsopbrengsten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_overige_personeelskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_overige_rentelasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_sociale_lasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n  Error with trainer TrainerXGBoost on dataset week_data_cleaned_verkoopkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_afschrijvingen_mva: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_afschrijvingen_iva: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_omzet: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_algemene_kosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_autokosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_overige_rentelasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_pensioenlasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:45:43,226] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 474, 'max_depth': 8, 'learning_rate': 0.0807391013233653, 'subsample': 0.5432401185469751, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,229] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,230] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_overige_personeelskosten_trajectory\n[W 2025-01-19 13:45:43,238] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 466, 'max_depth': 29, 'learning_rate': 0.1525809710749794, 'subsample': 0.689817250715412, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,241] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,242] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_sociale_lasten_trajectory\n[W 2025-01-19 13:45:43,249] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 173, 'max_depth': 24, 'learning_rate': 0.011039157763306558, 'subsample': 0.915721443185194, 'prediction_mode': 'Zero', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,252] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,253] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n[W 2025-01-19 13:45:43,260] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 25, 'learning_rate': 0.04176733319863321, 'subsample': 0.6011442357192991, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,264] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,264] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n[W 2025-01-19 13:45:43,271] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 72, 'max_depth': 27, 'learning_rate': 0.1907749981235807, 'subsample': 0.9394080982124468, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,275] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,275] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_kantoorkosten_trajectory\n[W 2025-01-19 13:45:43,283] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 388, 'max_depth': 14, 'learning_rate': 0.18118019906074206, 'subsample': 0.6736218775150074, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,287] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,288] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_verkoopkosten_trajectory\n[W 2025-01-19 13:45:43,295] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.13690684362972189, 'subsample': 0.8694834507407567, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,299] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,299] A new study created in memory with name: TrainerXGBoost_month_data_cleaned_huisvestingskosten_trajectory\n[W 2025-01-19 13:45:43,306] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 269, 'max_depth': 28, 'learning_rate': 0.1872658917462266, 'subsample': 0.8980385484557627, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,310] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,311] A new study created in memory with name: TrainerXGBoost_day_data_trajectory\n[W 2025-01-19 13:45:43,318] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 224, 'max_depth': 3, 'learning_rate': 0.041504174085407956, 'subsample': 0.5011631395259482, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: AttributeError(\"'TrainerXGBoost' object has no attribute '_trend_finder'\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 96, in fit\n    self._trend_finder.find_trend(trainset)\n    ^^^^^^^^^^^^^^^^^^\nAttributeError: 'TrainerXGBoost' object has no attribute '_trend_finder'. Did you mean: '_pattern_finder'?\n[W 2025-01-19 13:45:43,322] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,322] A new study created in memory with name: TrainerXGBoost_weather_data_trajectory\n[W 2025-01-19 13:45:43,326] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.047015386737012575, 'subsample': 0.9862271849236841, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost.py\", line 52, in fit\n    trainset = df_train[[\n               ^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:45:43,328] Trial 0 failed with value None.\n[I 2025-01-19 13:45:43,329] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerXGBoost on dataset month_data_cleaned_lonen_en_salarissen: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_overige_personeelskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_sociale_lasten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_exploitatie-_en_machinekosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_kostprijs_van_de_omzet: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_kantoorkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_verkoopkosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n  Error with trainer TrainerXGBoost on dataset month_data_cleaned_huisvestingskosten: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n  Error with trainer TrainerXGBoost on dataset day_data: 'TrainerXGBoost' object has no attribute '_trend_finder'\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n  Error with trainer TrainerXGBoost on dataset weather_data: \"['category', 'value'] not in index\"\n\nProcessing Trainer: TrainerXGBoostPattern\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:46,137] Trial 0 finished with values: [294.8831368064569, 126.89902912621358, -0.1244565883344444] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 223, 'max_depth': 25, 'learning_rate': 0.12381697867428676, 'subsample': 0.7415691235291347, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=294.8831, MAE=126.8990, R²=-0.1245, Time=2.81s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:48,633] Trial 1 finished with values: [289.8981677487418, 125.48757281553398, -0.08676028489032417] and parameters: {'objective': 'reg:linear', 'n_estimators': 206, 'max_depth': 21, 'learning_rate': 0.01865700944183845, 'subsample': 0.5622187040590123, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=289.8982, MAE=125.4876, R²=-0.0868, Time=2.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:51,163] Trial 2 finished with values: [293.3793511638479, 125.70291262135922, -0.11301727627602043] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 187, 'max_depth': 30, 'learning_rate': 0.05890492887780314, 'subsample': 0.6737682760604655, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=293.3794, MAE=125.7029, R²=-0.1130, Time=2.53s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:53,341] Trial 3 finished with values: [284.82920083882806, 140.39436893203882, -0.049087809924547976] and parameters: {'objective': 'reg:linear', 'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.050448870564336216, 'subsample': 0.6335220351607231, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=284.8292, MAE=140.3944, R²=-0.0491, Time=2.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:55,881] Trial 4 finished with values: [293.95683076994607, 121.55543689320388, -0.11740325201726631] and parameters: {'objective': 'reg:linear', 'n_estimators': 109, 'max_depth': 30, 'learning_rate': 0.12515902280516125, 'subsample': 0.8344719412593258, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=293.9568, MAE=121.5554, R²=-0.1174, Time=2.54s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:45:58,245] Trial 5 finished with values: [291.814629987527, 127.09174757281552, -0.1011765149036905] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 73, 'max_depth': 18, 'learning_rate': 0.19738111113563853, 'subsample': 0.7176588515844287, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=291.8146, MAE=127.0917, R²=-0.1012, Time=2.36s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:00,724] Trial 6 finished with values: [293.89752958821924, 121.42825242718442, -0.11695246031875683] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 126, 'max_depth': 25, 'learning_rate': 0.059057316854854436, 'subsample': 0.9617216598910923, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=293.8975, MAE=121.4283, R²=-0.1170, Time=2.48s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:03,085] Trial 7 finished with values: [286.0542270218837, 131.69407766990292, -0.05813129081574697] and parameters: {'objective': 'reg:linear', 'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.014544759080053307, 'subsample': 0.5924435441857216, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=286.0542, MAE=131.6941, R²=-0.0581, Time=2.36s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:05,770] Trial 8 finished with values: [294.36707339646534, 122.82650485436892, -0.12052429749224247] and parameters: {'objective': 'reg:linear', 'n_estimators': 190, 'max_depth': 15, 'learning_rate': 0.056305138374286794, 'subsample': 0.9635969445686994, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=294.3671, MAE=122.8265, R²=-0.1205, Time=2.68s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:08,619] Trial 9 finished with values: [293.93637815010237, 123.01786407766993, -0.1172477664052054] and parameters: {'objective': 'reg:linear', 'n_estimators': 287, 'max_depth': 16, 'learning_rate': 0.1677334494234896, 'subsample': 0.7990254107915471, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=293.9364, MAE=123.0179, R²=-0.1172, Time=2.85s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:11,316] Trial 10 finished with values: [294.1785124550929, 122.58388349514563, -0.11908922228174679] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 26, 'learning_rate': 0.1045360885150723, 'subsample': 0.7763976841631136, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=294.1785, MAE=122.5839, R²=-0.1191, Time=2.70s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:14,001] Trial 11 finished with values: [291.5135518473877, 120.00563106796116, -0.09890542147215875] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 167, 'max_depth': 24, 'learning_rate': 0.033372085936644896, 'subsample': 0.8041646730898344, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=291.5136, MAE=120.0056, R²=-0.0989, Time=2.68s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:16,910] Trial 12 finished with values: [294.04177465247466, 122.76524271844659, -0.11804913110240745] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 226, 'max_depth': 25, 'learning_rate': 0.18318820652206538, 'subsample': 0.9394297713320552, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=294.0418, MAE=122.7652, R²=-0.1180, Time=2.91s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:19,323] Trial 13 finished with values: [295.231369894703, 127.16456310679612, -0.12711394068481985] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 85, 'max_depth': 21, 'learning_rate': 0.1751342833032457, 'subsample': 0.5594736408333971, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=295.2314, MAE=127.1646, R²=-0.1271, Time=2.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:22,225] Trial 14 finished with values: [295.4099557238664, 129.863786407767, -0.128477938399449] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 249, 'max_depth': 26, 'learning_rate': 0.16772908361174552, 'subsample': 0.6435425905930858, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=295.4100, MAE=129.8638, R²=-0.1285, Time=2.90s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_algemene_kosten_trajectory: [{'objective': 'reg:linear', 'n_estimators': 206, 'max_depth': 21, 'learning_rate': 0.01865700944183845, 'subsample': 0.5622187040590123, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 154, 'max_depth': 5, 'learning_rate': 0.050448870564336216, 'subsample': 0.6335220351607231, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 182, 'max_depth': 9, 'learning_rate': 0.014544759080053307, 'subsample': 0.5924435441857216, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 167, 'max_depth': 24, 'learning_rate': 0.033372085936644896, 'subsample': 0.8041646730898344, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_algemene_kosten_trajectory: 38.90 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:24,769] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_autokosten_trajectory\n[I 2025-01-19 13:46:24,946] Trial 0 finished with values: [845.5070816577075, 841.5666666666666, -106.64857492638203] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 112, 'max_depth': 28, 'learning_rate': 0.14206512900764492, 'subsample': 0.6274122457553342, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_algemene_kosten\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\n  Trial 0: RMSE=845.5071, MAE=841.5667, R²=-106.6486, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:25,131] Trial 1 finished with values: [837.3415611326122, 833.3666666666668, -104.57937374514793] and parameters: {'objective': 'reg:linear', 'n_estimators': 99, 'max_depth': 16, 'learning_rate': 0.0730568615905246, 'subsample': 0.8331987519717923, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=837.3416, MAE=833.3667, R²=-104.5794, Time=0.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:25,440] Trial 2 finished with values: [837.9133976531625, 833.91, -104.72362732063984] and parameters: {'objective': 'reg:linear', 'n_estimators': 279, 'max_depth': 5, 'learning_rate': 0.10951151276236658, 'subsample': 0.566079652482002, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=837.9134, MAE=833.9100, R²=-104.7236, Time=0.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:25,714] Trial 3 finished with values: [855.6262257746273, 851.7366666666667, -109.24069977412665] and parameters: {'objective': 'reg:linear', 'n_estimators': 206, 'max_depth': 15, 'learning_rate': 0.06413839007595327, 'subsample': 0.9459370693854533, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=855.6262, MAE=851.7367, R²=-109.2407, Time=0.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:25,947] Trial 4 finished with values: [856.4425017283219, 852.5566666666667, -109.45114156237453] and parameters: {'objective': 'reg:linear', 'n_estimators': 245, 'max_depth': 20, 'learning_rate': 0.14052352837829898, 'subsample': 0.8313979311774298, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=856.4425, MAE=852.5567, R²=-109.4511, Time=0.23s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:26,221] Trial 5 finished with values: [851.5150910387124, 847.6066666666667, -108.18387017132916] and parameters: {'objective': 'reg:linear', 'n_estimators': 267, 'max_depth': 30, 'learning_rate': 0.03726667995796237, 'subsample': 0.9612360650963223, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=851.5151, MAE=847.6067, R²=-108.1839, Time=0.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:26,479] Trial 6 finished with values: [855.5764530810012, 851.6866666666666, -109.227874508098] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 193, 'max_depth': 10, 'learning_rate': 0.06790637813026791, 'subsample': 0.8107568439490309, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=855.5765, MAE=851.6867, R²=-109.2279, Time=0.26s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:26,686] Trial 7 finished with values: [573.6939928510088, 567.8766666666667, -48.56035297985546] and parameters: {'objective': 'reg:linear', 'n_estimators': 146, 'max_depth': 15, 'learning_rate': 0.013550924300304978, 'subsample': 0.6803805964922374, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=573.6940, MAE=567.8767, R²=-48.5604, Time=0.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:26,930] Trial 8 finished with values: [795.2032795665102, 791.0166666666668, -94.22042401452283] and parameters: {'objective': 'reg:linear', 'n_estimators': 209, 'max_depth': 11, 'learning_rate': 0.02399777820521583, 'subsample': 0.5324199143610795, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=795.2033, MAE=791.0167, R²=-94.2204, Time=0.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:27,252] Trial 9 finished with values: [856.5420480630243, 852.6566666666668, -109.47681904865483] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 297, 'max_depth': 19, 'learning_rate': 0.08526459718203405, 'subsample': 0.8717354300624158, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=856.5420, MAE=852.6567, R²=-109.4768, Time=0.32s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:27,551] Trial 10 finished with values: [853.6338118889153, 849.7333333333332, -108.72788387096774] and parameters: {'objective': 'reg:linear', 'n_estimators': 276, 'max_depth': 18, 'learning_rate': 0.12264888578059288, 'subsample': 0.7450604714659463, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n[I 2025-01-19 13:46:27,726] Trial 11 finished with values: [854.4814605361546, 850.5866666666666, -108.9459091420158] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 57, 'max_depth': 25, 'learning_rate': 0.19710727563884795, 'subsample': 0.9532082119540379, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=853.6338, MAE=849.7333, R²=-108.7279, Time=0.30s\n  Trial 11: RMSE=854.4815, MAE=850.5867, R²=-108.9459, Time=0.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:27,952] Trial 12 finished with values: [680.6128874036987, 675.7166666666666, -68.7548039502744] and parameters: {'objective': 'reg:linear', 'n_estimators': 162, 'max_depth': 25, 'learning_rate': 0.018047280041400854, 'subsample': 0.7909849192760325, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=680.6129, MAE=675.7167, R²=-68.7548, Time=0.22s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:28,255] Trial 13 finished with values: [847.746463985548, 843.8133333333334, -107.21955904162765] and parameters: {'objective': 'reg:linear', 'n_estimators': 281, 'max_depth': 18, 'learning_rate': 0.15786495731988043, 'subsample': 0.7137480896797925, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=847.7465, MAE=843.8133, R²=-107.2196, Time=0.30s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:28,526] Trial 14 finished with values: [856.5420480630243, 852.6566666666668, -109.47681904865483] and parameters: {'objective': 'reg:linear', 'n_estimators': 231, 'max_depth': 14, 'learning_rate': 0.09784479533209121, 'subsample': 0.9611135488820988, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=856.5420, MAE=852.6567, R²=-109.4768, Time=0.27s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_autokosten_trajectory: [{'objective': 'reg:linear', 'n_estimators': 146, 'max_depth': 15, 'learning_rate': 0.013550924300304978, 'subsample': 0.6803805964922374, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_autokosten_trajectory: 3.76 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:28,752] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_autokosten\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:29,681] Trial 0 finished with values: [300.60959714030616, 251.80714285714288, -0.5232526490919627] and parameters: {'objective': 'reg:linear', 'n_estimators': 222, 'max_depth': 27, 'learning_rate': 0.15870864057808087, 'subsample': 0.8781284534730123, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=300.6096, MAE=251.8071, R²=-0.5233, Time=0.93s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:30,751] Trial 1 finished with values: [237.45710695377628, 211.55428571428575, 0.049533961533009485] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 14, 'learning_rate': 0.15879823417873098, 'subsample': 0.6043600007925246, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=237.4571, MAE=211.5543, R²=0.0495, Time=1.07s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:31,649] Trial 2 finished with values: [277.554805147946, 240.69178571428571, -0.2985651989488536] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 29, 'learning_rate': 0.1372434676693899, 'subsample': 0.799578013615166, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=277.5548, MAE=240.6918, R²=-0.2986, Time=0.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:32,425] Trial 3 finished with values: [249.07425042545046, 225.20964285714282, -0.045740487952676157] and parameters: {'objective': 'reg:linear', 'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.06821721618608538, 'subsample': 0.6874348647878479, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=249.0743, MAE=225.2096, R²=-0.0457, Time=0.78s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:33,128] Trial 4 finished with values: [286.43969099720005, 245.65571428571425, -0.3830333479300776] and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 7, 'learning_rate': 0.06158592486152537, 'subsample': 0.7254531596593843, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=286.4397, MAE=245.6557, R²=-0.3830, Time=0.70s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:34,001] Trial 5 finished with values: [383.84032034353623, 306.955, -1.4835187608544338] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 167, 'max_depth': 13, 'learning_rate': 0.037637504965657195, 'subsample': 0.979992288374339, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=383.8403, MAE=306.9550, R²=-1.4835, Time=0.87s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:34,783] Trial 6 finished with values: [269.0701992377772, 237.30750000000003, -0.2203866819380993] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 105, 'max_depth': 8, 'learning_rate': 0.18583687766118206, 'subsample': 0.820508587852803, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=269.0702, MAE=237.3075, R²=-0.2204, Time=0.78s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:35,552] Trial 7 finished with values: [263.13703830622444, 234.4121428571428, -0.1671595379877746] and parameters: {'objective': 'reg:linear', 'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.04011013894277042, 'subsample': 0.5645114510871775, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=263.1370, MAE=234.4121, R²=-0.1672, Time=0.77s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:36,315] Trial 8 finished with values: [291.00127781997304, 246.8664285714286, -0.42743404595074086] and parameters: {'objective': 'reg:linear', 'n_estimators': 85, 'max_depth': 24, 'learning_rate': 0.1265746247564452, 'subsample': 0.8182843833884275, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=291.0013, MAE=246.8664, R²=-0.4274, Time=0.76s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:37,148] Trial 9 finished with values: [247.3110977739229, 223.46607142857147, -0.030987665103767936] and parameters: {'objective': 'reg:linear', 'n_estimators': 99, 'max_depth': 9, 'learning_rate': 0.06511038103670809, 'subsample': 0.5578125434273031, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=247.3111, MAE=223.4661, R²=-0.0310, Time=0.83s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:38,174] Trial 10 finished with values: [299.02523015266985, 250.3546428571428, -0.5072383146975972] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 283, 'max_depth': 8, 'learning_rate': 0.15571022184593494, 'subsample': 0.8713511458499866, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=299.0252, MAE=250.3546, R²=-0.5072, Time=1.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:39,224] Trial 11 finished with values: [297.6856818741156, 249.5585714285714, -0.4937645608374097] and parameters: {'objective': 'reg:linear', 'n_estimators': 237, 'max_depth': 11, 'learning_rate': 0.1511531920191384, 'subsample': 0.8606393740355077, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=297.6857, MAE=249.5586, R²=-0.4938, Time=1.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:40,211] Trial 12 finished with values: [251.4628923632954, 226.7371428571429, -0.06589413377932418] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 258, 'max_depth': 20, 'learning_rate': 0.09845042610052371, 'subsample': 0.7080558172614717, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=251.4629, MAE=226.7371, R²=-0.0659, Time=0.99s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:41,151] Trial 13 finished with values: [326.9160694221509, 265.8132142857143, -0.8015187901640259] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 241, 'max_depth': 13, 'learning_rate': 0.014715072326244992, 'subsample': 0.8173521943625868, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=326.9161, MAE=265.8132, R²=-0.8015, Time=0.94s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:42,198] Trial 14 finished with values: [239.21703804883367, 215.07500000000005, 0.035392850906306506] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 17, 'learning_rate': 0.17067255904832684, 'subsample': 0.6389299492869849, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=239.2170, MAE=215.0750, R²=0.0354, Time=1.05s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 293, 'max_depth': 14, 'learning_rate': 0.15879823417873098, 'subsample': 0.6043600007925246, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_exploitatie-_en_machinekosten_trajectory: 13.45 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:43,223] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:45,559] Trial 0 finished with values: [143.32286105601594, 55.165, -0.1332149840773469] and parameters: {'objective': 'reg:linear', 'n_estimators': 246, 'max_depth': 25, 'learning_rate': 0.05100083927302798, 'subsample': 0.7729884634213389, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=143.3229, MAE=55.1650, R²=-0.1332, Time=2.33s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:47,504] Trial 1 finished with values: [143.81219153679353, 55.01602564102564, -0.14096620031083207] and parameters: {'objective': 'reg:linear', 'n_estimators': 171, 'max_depth': 12, 'learning_rate': 0.08599993361479033, 'subsample': 0.5034809904813935, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=143.8122, MAE=55.0160, R²=-0.1410, Time=1.94s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:49,390] Trial 2 finished with values: [143.17257745327973, 54.98423076923078, -0.13083972667799126] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 154, 'max_depth': 15, 'learning_rate': 0.07262969482362498, 'subsample': 0.5029953256607539, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=143.1726, MAE=54.9842, R²=-0.1308, Time=1.89s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:51,647] Trial 3 finished with values: [142.9721938314383, 54.7924358974359, -0.12767650661395447] and parameters: {'objective': 'reg:linear', 'n_estimators': 270, 'max_depth': 14, 'learning_rate': 0.024486787332878367, 'subsample': 0.9275644620387891, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=142.9722, MAE=54.7924, R²=-0.1277, Time=2.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:53,697] Trial 4 finished with values: [141.8835827902038, 54.88525641025641, -0.1105692986068465] and parameters: {'objective': 'reg:linear', 'n_estimators': 136, 'max_depth': 26, 'learning_rate': 0.18879434625032782, 'subsample': 0.8391310517589081, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=141.8836, MAE=54.8853, R²=-0.1106, Time=2.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:55,774] Trial 5 finished with values: [141.29135429118054, 54.63846153846154, -0.10131751459404659] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 17, 'learning_rate': 0.1543513106284366, 'subsample': 0.8758889574834929, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=141.2914, MAE=54.6385, R²=-0.1013, Time=2.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:57,970] Trial 6 finished with values: [142.41198951075103, 54.92282051282051, -0.11885672718558604] and parameters: {'objective': 'reg:linear', 'n_estimators': 213, 'max_depth': 13, 'learning_rate': 0.04205895216569036, 'subsample': 0.6967397021069106, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=142.4120, MAE=54.9228, R²=-0.1189, Time=2.19s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:46:59,877] Trial 7 finished with values: [143.56671534114776, 55.25717948717948, -0.13707444396072854] and parameters: {'objective': 'reg:linear', 'n_estimators': 170, 'max_depth': 10, 'learning_rate': 0.1180402823973284, 'subsample': 0.937516465720775, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=143.5667, MAE=55.2572, R²=-0.1371, Time=1.91s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:01,841] Trial 8 finished with values: [141.683663173481, 54.69128205128205, -0.10744183081365577] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 144, 'max_depth': 27, 'learning_rate': 0.06586578498593211, 'subsample': 0.5206636895842216, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=141.6837, MAE=54.6913, R²=-0.1074, Time=1.96s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:03,940] Trial 9 finished with values: [141.8048729678776, 54.69358974358973, -0.10933746523495014] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 216, 'max_depth': 25, 'learning_rate': 0.021080693525003615, 'subsample': 0.5503196832809389, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=141.8049, MAE=54.6936, R²=-0.1093, Time=2.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:06,183] Trial 10 finished with values: [140.1908271259443, 54.98641025641025, -0.0842278694360108] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 246, 'max_depth': 21, 'learning_rate': 0.15995674416635805, 'subsample': 0.8801202677717357, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=140.1908, MAE=54.9864, R²=-0.0842, Time=2.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:08,526] Trial 11 finished with values: [142.43221046590946, 54.83346153846153, -0.11917448073980497] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 282, 'max_depth': 26, 'learning_rate': 0.021632301596275556, 'subsample': 0.8424509046601584, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=142.4322, MAE=54.8335, R²=-0.1192, Time=2.34s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:10,761] Trial 12 finished with values: [143.68472652714166, 55.45192307692308, -0.1389445522812336] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 262, 'max_depth': 26, 'learning_rate': 0.13546152742397424, 'subsample': 0.8013018762616557, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=143.6847, MAE=55.4519, R²=-0.1389, Time=2.23s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:12,811] Trial 13 finished with values: [142.4129606920554, 54.749871794871794, -0.11887198736760562] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 162, 'max_depth': 17, 'learning_rate': 0.1978349490115287, 'subsample': 0.8942891225758511, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=142.4130, MAE=54.7499, R²=-0.1189, Time=2.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:15,145] Trial 14 finished with values: [142.89663338698128, 54.999743589743595, -0.12648487319597135] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 214, 'max_depth': 15, 'learning_rate': 0.0302296462385528, 'subsample': 0.7900365442512574, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=142.8966, MAE=54.9997, R²=-0.1265, Time=2.33s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_huisvestingskosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 17, 'learning_rate': 0.1543513106284366, 'subsample': 0.8758889574834929, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 246, 'max_depth': 21, 'learning_rate': 0.15995674416635805, 'subsample': 0.8801202677717357, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_huisvestingskosten_trajectory: 31.92 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:17,171] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_kantoorkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:18,458] Trial 0 finished with values: [227.3082374128678, 173.56382978723406, -0.04348173133994315] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 262, 'max_depth': 7, 'learning_rate': 0.17867141371949768, 'subsample': 0.5494338131832205, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=227.3082, MAE=173.5638, R²=-0.0435, Time=1.28s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:19,811] Trial 1 finished with values: [200.4398733902036, 162.53893617021274, 0.18862291003002996] and parameters: {'objective': 'reg:linear', 'n_estimators': 158, 'max_depth': 17, 'learning_rate': 0.13875618978391532, 'subsample': 0.9379526149570834, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=200.4399, MAE=162.5389, R²=0.1886, Time=1.35s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:20,961] Trial 2 finished with values: [185.8688474635995, 161.2057446808511, 0.3023016221169651] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 83, 'max_depth': 28, 'learning_rate': 0.022351332308757632, 'subsample': 0.8831342957377564, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=185.8688, MAE=161.2057, R²=0.3023, Time=1.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:22,409] Trial 3 finished with values: [185.97626089072125, 157.0223404255319, 0.30149499067341146] and parameters: {'objective': 'reg:linear', 'n_estimators': 188, 'max_depth': 14, 'learning_rate': 0.18791842738702783, 'subsample': 0.8841867068206047, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=185.9763, MAE=157.0223, R²=0.3015, Time=1.45s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:23,745] Trial 4 finished with values: [185.1743674245003, 155.801914893617, 0.3075056397953828] and parameters: {'objective': 'reg:linear', 'n_estimators': 286, 'max_depth': 8, 'learning_rate': 0.15171070373134127, 'subsample': 0.9020261094647164, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=185.1744, MAE=155.8019, R²=0.3075, Time=1.33s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:25,041] Trial 5 finished with values: [188.30546542954693, 158.20170212765962, 0.2838889884251199] and parameters: {'objective': 'reg:linear', 'n_estimators': 114, 'max_depth': 29, 'learning_rate': 0.0966743665918357, 'subsample': 0.8895518674585449, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=188.3055, MAE=158.2017, R²=0.2839, Time=1.29s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:26,464] Trial 6 finished with values: [204.00244795152034, 167.56042553191492, 0.15952411146084733] and parameters: {'objective': 'reg:linear', 'n_estimators': 246, 'max_depth': 17, 'learning_rate': 0.14793529408775338, 'subsample': 0.7582243614576132, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=204.0024, MAE=167.5604, R²=0.1595, Time=1.42s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:27,875] Trial 7 finished with values: [186.5179413536631, 159.31829787234042, 0.2974200884652274] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 228, 'max_depth': 19, 'learning_rate': 0.016628644723839184, 'subsample': 0.779677938621806, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=186.5179, MAE=159.3183, R²=0.2974, Time=1.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:29,089] Trial 8 finished with values: [235.26500190934533, 180.19829787234042, -0.11781299393687172] and parameters: {'objective': 'reg:linear', 'n_estimators': 126, 'max_depth': 22, 'learning_rate': 0.09766419246524444, 'subsample': 0.5643632707354008, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=235.2650, MAE=180.1983, R²=-0.1178, Time=1.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:30,403] Trial 9 finished with values: [184.9284185265299, 157.68085106382978, 0.3093439624383908] and parameters: {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 11, 'learning_rate': 0.09148244447808503, 'subsample': 0.8615106226761835, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=184.9284, MAE=157.6809, R²=0.3093, Time=1.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:31,649] Trial 10 finished with values: [281.27240111640396, 219.90468085106377, -0.5977496921370955] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 137, 'max_depth': 22, 'learning_rate': 0.14899940876359202, 'subsample': 0.5025371805661802, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=281.2724, MAE=219.9047, R²=-0.5977, Time=1.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:32,883] Trial 11 finished with values: [224.66126411943978, 177.32468085106385, -0.01932082672073343] and parameters: {'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 30, 'learning_rate': 0.1637772580491971, 'subsample': 0.7417358035546842, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=224.6613, MAE=177.3247, R²=-0.0193, Time=1.23s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:34,120] Trial 12 finished with values: [185.15144936545235, 158.16489361702128, 0.3076770419688716] and parameters: {'objective': 'reg:linear', 'n_estimators': 59, 'max_depth': 8, 'learning_rate': 0.14402544923860586, 'subsample': 0.8120392995313707, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=185.1514, MAE=158.1649, R²=0.3077, Time=1.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:35,313] Trial 13 finished with values: [187.27313676336897, 164.6940425531915, 0.2917191969854315] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 85, 'max_depth': 11, 'learning_rate': 0.015396875676577083, 'subsample': 0.7104125765305495, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=187.2731, MAE=164.6940, R²=0.2917, Time=1.19s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:36,658] Trial 14 finished with values: [208.3071823411128, 170.8895744680851, 0.12367946181520117] and parameters: {'objective': 'reg:linear', 'n_estimators': 176, 'max_depth': 21, 'learning_rate': 0.11024401588905396, 'subsample': 0.6481050845753373, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=208.3072, MAE=170.8896, R²=0.1237, Time=1.34s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_kantoorkosten_trajectory: [{'objective': 'reg:linear', 'n_estimators': 286, 'max_depth': 8, 'learning_rate': 0.15171070373134127, 'subsample': 0.9020261094647164, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 11, 'learning_rate': 0.09148244447808503, 'subsample': 0.8615106226761835, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_kantoorkosten_trajectory: 19.49 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:38,033] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_kantoorkosten\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:38,625] Trial 0 finished with values: [536.1464522376874, 386.83294117647057, -0.06125659256676674] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 11, 'learning_rate': 0.06250575802508532, 'subsample': 0.6840661919711362, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=536.1465, MAE=386.8329, R²=-0.0613, Time=0.59s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:39,461] Trial 1 finished with values: [569.5416459337642, 420.0041176470589, -0.19757990481027665] and parameters: {'objective': 'reg:linear', 'n_estimators': 253, 'max_depth': 13, 'learning_rate': 0.14067028029957937, 'subsample': 0.8677025552016702, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=569.5416, MAE=420.0041, R²=-0.1976, Time=0.83s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:40,112] Trial 2 finished with values: [564.2559889697542, 412.73, -0.17545466182120162] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 280, 'max_depth': 28, 'learning_rate': 0.1401801870744176, 'subsample': 0.9865316440420722, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=564.2560, MAE=412.7300, R²=-0.1755, Time=0.65s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:40,689] Trial 3 finished with values: [539.9636531068278, 394.89352941176475, -0.07642204082948201] and parameters: {'objective': 'reg:linear', 'n_estimators': 147, 'max_depth': 25, 'learning_rate': 0.020811931001684065, 'subsample': 0.8184554496273377, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=539.9637, MAE=394.8935, R²=-0.0764, Time=0.57s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:41,226] Trial 4 finished with values: [554.9067967739109, 412.8411764705882, -0.1368250026380058] and parameters: {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 15, 'learning_rate': 0.11116841800436675, 'subsample': 0.7189819607178243, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=554.9068, MAE=412.8412, R²=-0.1368, Time=0.54s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:42,200] Trial 5 finished with values: [523.9945455935249, 384.09411764705885, -0.013694431163430387] and parameters: {'objective': 'reg:linear', 'n_estimators': 272, 'max_depth': 30, 'learning_rate': 0.06328433949346132, 'subsample': 0.5215165455840205, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=523.9945, MAE=384.0941, R²=-0.0137, Time=0.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:42,864] Trial 6 finished with values: [571.9465083636859, 425.6758823529412, -0.20771470462102481] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 211, 'max_depth': 10, 'learning_rate': 0.10701058322935778, 'subsample': 0.8643837549441508, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=571.9465, MAE=425.6759, R²=-0.2077, Time=0.66s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:43,452] Trial 7 finished with values: [539.4742561431235, 399.785294117647, -0.07447169123303699] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 173, 'max_depth': 9, 'learning_rate': 0.12482319250807221, 'subsample': 0.8204427625010761, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=539.4743, MAE=399.7853, R²=-0.0745, Time=0.59s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:44,116] Trial 8 finished with values: [585.1396972568879, 434.4541176470588, -0.2640744502894192] and parameters: {'objective': 'reg:linear', 'n_estimators': 300, 'max_depth': 24, 'learning_rate': 0.19871165367128057, 'subsample': 0.8667202277710044, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=585.1397, MAE=434.4541, R²=-0.2641, Time=0.66s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:44,814] Trial 9 finished with values: [530.6161564800369, 385.2811764705882, -0.039476001028017516] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 144, 'max_depth': 20, 'learning_rate': 0.015007372259085834, 'subsample': 0.7563979211665842, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=530.6162, MAE=385.2812, R²=-0.0395, Time=0.70s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:45,425] Trial 10 finished with values: [521.5922617163267, 381.2188235294118, -0.004421053447555501] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 159, 'max_depth': 17, 'learning_rate': 0.16429449210642144, 'subsample': 0.5536375139659869, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=521.5923, MAE=381.2188, R²=-0.0044, Time=0.61s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:46,044] Trial 11 finished with values: [556.9564531609694, 416.8964705882353, -0.14523868212998803] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 185, 'max_depth': 20, 'learning_rate': 0.10236414631633585, 'subsample': 0.7705171248390612, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=556.9565, MAE=416.8965, R²=-0.1452, Time=0.62s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:46,524] Trial 12 finished with values: [522.1139184744129, 381.4335294117647, -0.006431148622971117] and parameters: {'objective': 'reg:linear', 'n_estimators': 59, 'max_depth': 10, 'learning_rate': 0.029005498278108617, 'subsample': 0.5170093722088658, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=522.1139, MAE=381.4335, R²=-0.0064, Time=0.48s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:47,150] Trial 13 finished with values: [554.0942146740878, 403.4594117647059, -0.13349800324680383] and parameters: {'objective': 'reg:linear', 'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.14889894070033843, 'subsample': 0.9033054065703459, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=554.0942, MAE=403.4594, R²=-0.1335, Time=0.62s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:47,777] Trial 14 finished with values: [549.7946936972446, 400.0182352941177, -0.11597538619127024] and parameters: {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 25, 'learning_rate': 0.11444499302260533, 'subsample': 0.9181306072800421, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=549.7947, MAE=400.0182, R²=-0.1160, Time=0.63s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_lonen_en_salarissen_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 159, 'max_depth': 17, 'learning_rate': 0.16429449210642144, 'subsample': 0.5536375139659869, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_lonen_en_salarissen_trajectory: 9.75 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:48,322] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:49,088] Trial 0 finished with values: [55.96331252057782, 12.9651724137931, -0.027173513615329936] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.08103363215993879, 'subsample': 0.683893695442012, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=55.9633, MAE=12.9652, R²=-0.0272, Time=0.76s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:49,905] Trial 1 finished with values: [55.70378443158057, 13.051034482758622, -0.017668634863636346] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 121, 'max_depth': 19, 'learning_rate': 0.17185521503424134, 'subsample': 0.5848279628491186, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=55.7038, MAE=13.0510, R²=-0.0177, Time=0.82s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:50,799] Trial 2 finished with values: [55.92345892933207, 11.969310344827583, -0.025711056327757165] and parameters: {'objective': 'reg:linear', 'n_estimators': 239, 'max_depth': 7, 'learning_rate': 0.1163110405479896, 'subsample': 0.8511749440594203, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=55.9235, MAE=11.9693, R²=-0.0257, Time=0.89s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:51,659] Trial 3 finished with values: [56.09859301204473, 11.049655172413793, -0.032145502647566326] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 130, 'max_depth': 19, 'learning_rate': 0.07729962060102419, 'subsample': 0.9672272575463587, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=56.0986, MAE=11.0497, R²=-0.0321, Time=0.86s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:52,545] Trial 4 finished with values: [56.17135424690271, 11.018275862068965, -0.03482467446520299] and parameters: {'objective': 'reg:linear', 'n_estimators': 233, 'max_depth': 26, 'learning_rate': 0.19630425410050278, 'subsample': 0.8691701941603232, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=56.1714, MAE=11.0183, R²=-0.0348, Time=0.88s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:53,354] Trial 5 finished with values: [55.94352571089454, 12.422758620689654, -0.026447291636281012] and parameters: {'objective': 'reg:linear', 'n_estimators': 154, 'max_depth': 22, 'learning_rate': 0.10241154460102672, 'subsample': 0.6840876648406329, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=55.9435, MAE=12.4228, R²=-0.0264, Time=0.81s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:54,184] Trial 6 finished with values: [56.10051975910188, 11.084827586206893, -0.03221640344398091] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 195, 'max_depth': 7, 'learning_rate': 0.13041546816308974, 'subsample': 0.9407259201129916, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=56.1005, MAE=11.0848, R²=-0.0322, Time=0.83s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:54,949] Trial 7 finished with values: [57.26247073932816, 15.176896551724136, -0.07541763098022747] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 101, 'max_depth': 15, 'learning_rate': 0.025203230842677008, 'subsample': 0.8710751331626547, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=57.2625, MAE=15.1769, R²=-0.0754, Time=0.76s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:55,937] Trial 8 finished with values: [56.11059583997698, 11.010344827586206, -0.03258722460672603] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 292, 'max_depth': 17, 'learning_rate': 0.13704996440961956, 'subsample': 0.9978857688245817, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=56.1106, MAE=11.0103, R²=-0.0326, Time=0.99s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:56,924] Trial 9 finished with values: [56.03565822851953, 11.353103448275863, -0.029830955580635754] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 192, 'max_depth': 19, 'learning_rate': 0.1960698436638006, 'subsample': 0.8074242747664319, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=56.0357, MAE=11.3531, R²=-0.0298, Time=0.98s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:57,727] Trial 10 finished with values: [57.013616794586895, 14.160344827586208, -0.06609074046053398] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 211, 'max_depth': 5, 'learning_rate': 0.013687872266172501, 'subsample': 0.768944464660249, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=57.0136, MAE=14.1603, R²=-0.0661, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:58,807] Trial 11 finished with values: [56.04997772923977, 11.70241379310345, -0.030357354298073513] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 288, 'max_depth': 10, 'learning_rate': 0.04194946769857236, 'subsample': 0.7525543975609172, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=56.0500, MAE=11.7024, R²=-0.0304, Time=1.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:47:59,641] Trial 12 finished with values: [55.92320007739678, 12.622413793103451, -0.0257015609681146] and parameters: {'objective': 'reg:linear', 'n_estimators': 131, 'max_depth': 20, 'learning_rate': 0.09564541561133737, 'subsample': 0.680872434157778, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=55.9232, MAE=12.6224, R²=-0.0257, Time=0.83s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:00,518] Trial 13 finished with values: [56.27737614279153, 11.852758620689654, -0.03873476766233486] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.10676870712214896, 'subsample': 0.9616260229833249, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=56.2774, MAE=11.8528, R²=-0.0387, Time=0.88s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:01,374] Trial 14 finished with values: [55.97043603854473, 12.4848275862069, -0.0274350261792764] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 159, 'max_depth': 15, 'learning_rate': 0.05495051977914455, 'subsample': 0.625972686403821, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=55.9704, MAE=12.4848, R²=-0.0274, Time=0.85s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 121, 'max_depth': 19, 'learning_rate': 0.17185521503424134, 'subsample': 0.5848279628491186, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 239, 'max_depth': 7, 'learning_rate': 0.1163110405479896, 'subsample': 0.8511749440594203, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 130, 'max_depth': 19, 'learning_rate': 0.07729962060102419, 'subsample': 0.9672272575463587, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 292, 'max_depth': 17, 'learning_rate': 0.13704996440961956, 'subsample': 0.9978857688245817, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 192, 'max_depth': 19, 'learning_rate': 0.1960698436638006, 'subsample': 0.8074242747664319, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 131, 'max_depth': 20, 'learning_rate': 0.09564541561133737, 'subsample': 0.680872434157778, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_overige_bedrijfsopbrengsten_trajectory: 13.05 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:02,167] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_overige_personeelskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_overige_bedrijfsopbrengsten\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:04,560] Trial 0 finished with values: [219.36770705826325, 61.30238095238095, -0.30802409142194387] and parameters: {'objective': 'reg:linear', 'n_estimators': 79, 'max_depth': 12, 'learning_rate': 0.16137450665125547, 'subsample': 0.6481029784728753, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=219.3677, MAE=61.3024, R²=-0.3080, Time=2.39s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:07,057] Trial 1 finished with values: [200.43165354043353, 53.52647619047619, -0.09195054679423031] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 103, 'max_depth': 29, 'learning_rate': 0.15243836242825307, 'subsample': 0.797439465073725, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=200.4317, MAE=53.5265, R²=-0.0920, Time=2.50s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:09,745] Trial 2 finished with values: [192.7875871695755, 53.780095238095235, -0.01024913506119507] and parameters: {'objective': 'reg:linear', 'n_estimators': 180, 'max_depth': 15, 'learning_rate': 0.047566456998023796, 'subsample': 0.8243133538548276, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=192.7876, MAE=53.7801, R²=-0.0102, Time=2.69s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:12,436] Trial 3 finished with values: [202.92835369492684, 55.654666666666664, -0.11932399923108328] and parameters: {'objective': 'reg:linear', 'n_estimators': 181, 'max_depth': 24, 'learning_rate': 0.11529199669267982, 'subsample': 0.7571846333082453, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=202.9284, MAE=55.6547, R²=-0.1193, Time=2.69s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:15,238] Trial 4 finished with values: [198.5251879713192, 110.89504761904762, -0.07127651239139743] and parameters: {'objective': 'reg:linear', 'n_estimators': 229, 'max_depth': 14, 'learning_rate': 0.02348796293000801, 'subsample': 0.7018079181800368, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=198.5252, MAE=110.8950, R²=-0.0713, Time=2.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:17,636] Trial 5 finished with values: [230.10573805059605, 146.22400000000002, -0.4392135812483935] and parameters: {'objective': 'reg:linear', 'n_estimators': 75, 'max_depth': 18, 'learning_rate': 0.15556408062460056, 'subsample': 0.5192349516950976, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=230.1057, MAE=146.2240, R²=-0.4392, Time=2.40s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:19,896] Trial 6 finished with values: [208.2186086213009, 140.44295238095242, -0.17844530773826306] and parameters: {'objective': 'reg:linear', 'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.06375072631534826, 'subsample': 0.6932212567261578, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=208.2186, MAE=140.4430, R²=-0.1784, Time=2.26s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:22,393] Trial 7 finished with values: [196.8783909107829, 52.757333333333335, -0.05357741861250709] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 99, 'max_depth': 13, 'learning_rate': 0.1074460930973007, 'subsample': 0.8895724693306026, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=196.8784, MAE=52.7573, R²=-0.0536, Time=2.50s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:25,023] Trial 8 finished with values: [199.0014979029531, 56.92666666666668, -0.07642318184662389] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 126, 'max_depth': 19, 'learning_rate': 0.17919305311446138, 'subsample': 0.9041670036414491, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=199.0015, MAE=56.9267, R²=-0.0764, Time=2.63s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:27,447] Trial 9 finished with values: [206.72402296874193, 136.43066666666667, -0.1615883492556216] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 76, 'max_depth': 27, 'learning_rate': 0.036227768286349396, 'subsample': 0.6797315416049223, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=206.7240, MAE=136.4307, R²=-0.1616, Time=2.42s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:29,859] Trial 10 finished with values: [236.41851756497215, 157.24819047619044, -0.5192642936082237] and parameters: {'objective': 'reg:linear', 'n_estimators': 57, 'max_depth': 17, 'learning_rate': 0.17095269592317733, 'subsample': 0.567431763221579, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=236.4185, MAE=157.2482, R²=-0.5193, Time=2.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:32,610] Trial 11 finished with values: [203.59858588478878, 54.138, -0.12673002065754746] and parameters: {'objective': 'reg:linear', 'n_estimators': 205, 'max_depth': 20, 'learning_rate': 0.06671948036190102, 'subsample': 0.6659877119304479, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=203.5986, MAE=54.1380, R²=-0.1267, Time=2.75s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:35,603] Trial 12 finished with values: [198.5919720168059, 57.12885714285714, -0.07199739031953922] and parameters: {'objective': 'reg:linear', 'n_estimators': 299, 'max_depth': 20, 'learning_rate': 0.08913028986368615, 'subsample': 0.9461574157571045, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=198.5920, MAE=57.1289, R²=-0.0720, Time=2.99s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:38,800] Trial 13 finished with values: [196.7536941941564, 66.4775238095238, -0.05224323420632859] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 194, 'max_depth': 22, 'learning_rate': 0.050622189430442645, 'subsample': 0.7133725905682928, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=196.7537, MAE=66.4775, R²=-0.0522, Time=3.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:41,366] Trial 14 finished with values: [198.620830711134, 55.99828571428572, -0.07230897081780263] and parameters: {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 12, 'learning_rate': 0.15439046518509758, 'subsample': 0.9389457382865687, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=198.6208, MAE=55.9983, R²=-0.0723, Time=2.56s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_overige_personeelskosten_trajectory: [{'objective': 'reg:linear', 'n_estimators': 180, 'max_depth': 15, 'learning_rate': 0.047566456998023796, 'subsample': 0.8243133538548276, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 99, 'max_depth': 13, 'learning_rate': 0.1074460930973007, 'subsample': 0.8895724693306026, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_overige_personeelskosten_trajectory: 39.20 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:44,303] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_overige_rentelasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:46,470] Trial 0 finished with values: [215.04934495495579, 88.57522222222222, -0.2040899072527016] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 251, 'max_depth': 5, 'learning_rate': 0.14159219505668472, 'subsample': 0.5223840725310976, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=215.0493, MAE=88.5752, R²=-0.2041, Time=2.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:48,855] Trial 1 finished with values: [214.55929137808658, 87.831, -0.19860840957025272] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 239, 'max_depth': 5, 'learning_rate': 0.10349433012376763, 'subsample': 0.682848422243131, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=214.5593, MAE=87.8310, R²=-0.1986, Time=2.38s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:50,829] Trial 2 finished with values: [214.43679797449772, 87.58055555555553, -0.1972402123510255] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 138, 'max_depth': 5, 'learning_rate': 0.10024046230329942, 'subsample': 0.6282558996432648, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=214.4368, MAE=87.5806, R²=-0.1972, Time=1.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:53,065] Trial 3 finished with values: [214.64856049158846, 87.85655555555554, -0.19960599833284065] and parameters: {'objective': 'reg:linear', 'n_estimators': 165, 'max_depth': 23, 'learning_rate': 0.12082993356993044, 'subsample': 0.6622755950895522, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=214.6486, MAE=87.8566, R²=-0.1996, Time=2.23s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:55,187] Trial 4 finished with values: [214.6717989267441, 87.90944444444445, -0.19986575758916847] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 110, 'max_depth': 15, 'learning_rate': 0.1565489924406586, 'subsample': 0.5956573277983578, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=214.6718, MAE=87.9094, R²=-0.1999, Time=2.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:57,274] Trial 5 finished with values: [214.26925148824628, 87.348, -0.19537005734421053] and parameters: {'objective': 'reg:linear', 'n_estimators': 113, 'max_depth': 25, 'learning_rate': 0.14751750953738055, 'subsample': 0.620357872880946, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=214.2693, MAE=87.3480, R²=-0.1954, Time=2.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:48:59,835] Trial 6 finished with values: [214.6600263439842, 87.91255555555554, -0.19973416013033618] and parameters: {'objective': 'reg:linear', 'n_estimators': 287, 'max_depth': 20, 'learning_rate': 0.1405277087834479, 'subsample': 0.7402551357292991, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=214.6600, MAE=87.9126, R²=-0.1997, Time=2.56s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:02,014] Trial 7 finished with values: [214.69062316893735, 87.96144444444444, -0.2000761956068664] and parameters: {'objective': 'reg:linear', 'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.19558657526713433, 'subsample': 0.9290328056777539, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=214.6906, MAE=87.9614, R²=-0.2001, Time=2.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:04,111] Trial 8 finished with values: [212.86660512578712, 87.11933333333334, -0.1797710526638241] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 140, 'max_depth': 23, 'learning_rate': 0.025874395539855245, 'subsample': 0.7666415723683015, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=212.8666, MAE=87.1193, R²=-0.1798, Time=2.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:06,552] Trial 9 finished with values: [214.41235988419865, 87.53200000000002, -0.19696734316532605] and parameters: {'objective': 'reg:linear', 'n_estimators': 233, 'max_depth': 23, 'learning_rate': 0.04399767778861744, 'subsample': 0.8111067238569818, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=214.4124, MAE=87.5320, R²=-0.1970, Time=2.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:08,758] Trial 10 finished with values: [214.52241927904257, 87.69733333333335, -0.19819648231017584] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.1567192964062191, 'subsample': 0.9154122850769759, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=214.5224, MAE=87.6973, R²=-0.1982, Time=2.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:11,228] Trial 11 finished with values: [214.73950227607816, 87.98288888888888, -0.20062270601846577] and parameters: {'objective': 'reg:linear', 'n_estimators': 259, 'max_depth': 12, 'learning_rate': 0.12113706697275207, 'subsample': 0.7624989338731134, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=214.7395, MAE=87.9829, R²=-0.2006, Time=2.47s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:13,311] Trial 12 finished with values: [214.6654820645369, 87.86855555555556, -0.1997951449126878] and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.1278438090345253, 'subsample': 0.5248780703376486, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=214.6655, MAE=87.8686, R²=-0.1998, Time=2.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:15,701] Trial 13 finished with values: [214.25417287262653, 87.34355555555555, -0.1952018214328104] and parameters: {'objective': 'reg:linear', 'n_estimators': 182, 'max_depth': 15, 'learning_rate': 0.12245984343777394, 'subsample': 0.8750732878950469, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=214.2542, MAE=87.3436, R²=-0.1952, Time=2.39s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:18,102] Trial 14 finished with values: [214.69653258080862, 87.98444444444443, -0.20014226129723567] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 210, 'max_depth': 17, 'learning_rate': 0.1372212321972971, 'subsample': 0.9998364864265903, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=214.6965, MAE=87.9844, R²=-0.2001, Time=2.40s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_overige_rentelasten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 140, 'max_depth': 23, 'learning_rate': 0.025874395539855245, 'subsample': 0.7666415723683015, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_overige_rentelasten_trajectory: 33.80 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:20,110] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_sociale_lasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:49:20,561] Trial 0 failed with parameters: {'objective': 'reg:linear', 'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.15908448193214023, 'subsample': 0.6444945899799599, 'prediction_mode': 'Zero', 'outlier_removal': 1} because of the following error: ZeroDivisionError('float division by zero').\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 41, in objective\n    r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nZeroDivisionError: float division by zero\n[W 2025-01-19 13:49:20,562] Trial 0 failed with value None.\n[I 2025-01-19 13:49:20,563] A new study created in memory with name: TrainerXGBoostPattern_week_data_cleaned_verkoopkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerXGBoostPattern on dataset week_data_cleaned_sociale_lasten: float division by zero\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:23,124] Trial 0 finished with values: [283.4771809955103, 178.55795698924732, -0.5535853115159126] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 207, 'max_depth': 29, 'learning_rate': 0.16059310628283083, 'subsample': 0.8655356861684593, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=283.4772, MAE=178.5580, R²=-0.5536, Time=2.56s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:25,560] Trial 1 finished with values: [265.9470045255803, 164.43924731182798, -0.367379617627728] and parameters: {'objective': 'reg:linear', 'n_estimators': 263, 'max_depth': 30, 'learning_rate': 0.01431335938942186, 'subsample': 0.5405302522193471, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=265.9470, MAE=164.4392, R²=-0.3674, Time=2.43s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:27,942] Trial 2 finished with values: [284.777861601046, 179.37505376344083, -0.5678746741765166] and parameters: {'objective': 'reg:linear', 'n_estimators': 186, 'max_depth': 18, 'learning_rate': 0.09718693269289251, 'subsample': 0.5150594525360159, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=284.7779, MAE=179.3751, R²=-0.5679, Time=2.38s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:30,321] Trial 3 finished with values: [273.9327084840716, 170.30849462365595, -0.45073029055997704] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 97, 'max_depth': 16, 'learning_rate': 0.05725397940879286, 'subsample': 0.9766915598318693, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=273.9327, MAE=170.3085, R²=-0.4507, Time=2.38s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:32,370] Trial 4 finished with values: [278.4979358584536, 173.77053763440858, -0.4994875257063416] and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 18, 'learning_rate': 0.11692685807924703, 'subsample': 0.775316676905226, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=278.4979, MAE=173.7705, R²=-0.4995, Time=2.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:34,514] Trial 5 finished with values: [262.5460909069827, 162.2315053763441, -0.3326312974224197] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 94, 'max_depth': 28, 'learning_rate': 0.03918579181412167, 'subsample': 0.6435604323811296, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=262.5461, MAE=162.2315, R²=-0.3326, Time=2.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:37,170] Trial 6 finished with values: [277.8773113757569, 173.12505376344086, -0.49281184433097214] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 30, 'learning_rate': 0.14734379946005474, 'subsample': 0.7793416705891625, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=277.8773, MAE=173.1251, R²=-0.4928, Time=2.65s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:39,353] Trial 7 finished with values: [261.43570426907394, 161.7223655913979, -0.3213829344715238] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 173, 'max_depth': 10, 'learning_rate': 0.018650112902811204, 'subsample': 0.7887374908890371, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=261.4357, MAE=161.7224, R²=-0.3214, Time=2.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:41,404] Trial 8 finished with values: [245.51629573623623, 152.91623655913978, -0.16535848293055966] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.011565719990864722, 'subsample': 0.576826623510809, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=245.5163, MAE=152.9162, R²=-0.1654, Time=2.05s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:43,529] Trial 9 finished with values: [279.39982379094056, 174.01516129032257, -0.5092151343345779] and parameters: {'objective': 'reg:linear', 'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.1617761500784326, 'subsample': 0.8175489998854254, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=279.3998, MAE=174.0152, R²=-0.5092, Time=2.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:45,969] Trial 10 finished with values: [276.5782246616484, 171.6425806451613, -0.4788865699496785] and parameters: {'objective': 'reg:linear', 'n_estimators': 207, 'max_depth': 15, 'learning_rate': 0.19032660742797408, 'subsample': 0.998390636598067, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=276.5782, MAE=171.6426, R²=-0.4789, Time=2.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:48,317] Trial 11 finished with values: [271.0867369347595, 167.62129032258062, -0.4207427086279345] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 154, 'max_depth': 25, 'learning_rate': 0.04231869825867602, 'subsample': 0.6673369278846575, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=271.0867, MAE=167.6213, R²=-0.4207, Time=2.35s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:51,187] Trial 12 finished with values: [276.42620627403215, 172.27817204301078, -0.4772613070233289] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 22, 'learning_rate': 0.06352299993278782, 'subsample': 0.8952627513676703, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=276.4262, MAE=172.2782, R²=-0.4773, Time=2.87s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:53,574] Trial 13 finished with values: [263.89874350118714, 161.4240860215054, -0.3463982569064934] and parameters: {'objective': 'reg:linear', 'n_estimators': 214, 'max_depth': 24, 'learning_rate': 0.13626959910491698, 'subsample': 0.5531865207565758, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=263.8987, MAE=161.4241, R²=-0.3464, Time=2.39s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:55,770] Trial 14 finished with values: [273.5915313429505, 169.5605376344086, -0.447118835853348] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 23, 'learning_rate': 0.15879263737875912, 'subsample': 0.7683137420970743, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=273.5915, MAE=169.5605, R²=-0.4471, Time=2.19s\nBest hyperparameters for TrainerXGBoostPattern_week_data_cleaned_verkoopkosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.011565719990864722, 'subsample': 0.576826623510809, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_week_data_cleaned_verkoopkosten_trajectory: 35.21 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:57,969] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_mva_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on week_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:49:58,938] Trial 0 finished with values: [568.0410964221202, 435.83622222222215, -0.28339500714475196] and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 18, 'learning_rate': 0.010574386938625035, 'subsample': 0.9574340954830918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=568.0411, MAE=435.8362, R²=-0.2834, Time=0.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:00,104] Trial 1 finished with values: [581.6771830338733, 436.5111111111111, -0.3457515484918474] and parameters: {'objective': 'reg:linear', 'n_estimators': 163, 'max_depth': 30, 'learning_rate': 0.18064469787083953, 'subsample': 0.7964894199136918, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=581.6772, MAE=436.5111, R²=-0.3458, Time=1.16s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:01,181] Trial 2 finished with values: [500.44441699797636, 382.39533333333327, 0.0038780076799411756] and parameters: {'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 5, 'learning_rate': 0.10873766660695386, 'subsample': 0.6769990180802256, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=500.4444, MAE=382.3953, R²=0.0039, Time=1.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:02,295] Trial 3 finished with values: [573.5605358983479, 439.2175555555556, -0.30845669911707696] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 105, 'max_depth': 20, 'learning_rate': 0.05059659702743242, 'subsample': 0.969059266704859, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=573.5605, MAE=439.2176, R²=-0.3085, Time=1.11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:03,414] Trial 4 finished with values: [599.1162005116834, 456.4968888888889, -0.4276539724624733] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 27, 'learning_rate': 0.1502216687845948, 'subsample': 0.824765847596158, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=599.1162, MAE=456.4969, R²=-0.4277, Time=1.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:04,560] Trial 5 finished with values: [586.8943071627122, 449.10822222222225, -0.3700001830091797] and parameters: {'objective': 'reg:linear', 'n_estimators': 119, 'max_depth': 7, 'learning_rate': 0.08368817592454485, 'subsample': 0.7357443610611119, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=586.8943, MAE=449.1082, R²=-0.3700, Time=1.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:05,590] Trial 6 finished with values: [503.09946241496044, 376.62377777777783, -0.006719632072520687] and parameters: {'objective': 'reg:linear', 'n_estimators': 88, 'max_depth': 23, 'learning_rate': 0.1366633805529815, 'subsample': 0.7728419141013627, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=503.0995, MAE=376.6238, R²=-0.0067, Time=1.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:06,835] Trial 7 finished with values: [577.1151912977743, 440.89955555555554, -0.324725340596004] and parameters: {'objective': 'reg:linear', 'n_estimators': 190, 'max_depth': 14, 'learning_rate': 0.14703709851809094, 'subsample': 0.6847687755185196, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=577.1152, MAE=440.8996, R²=-0.3247, Time=1.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:08,060] Trial 8 finished with values: [689.8877336510791, 511.4037777777778, -0.8930307896031227] and parameters: {'objective': 'reg:linear', 'n_estimators': 179, 'max_depth': 24, 'learning_rate': 0.17295372629368436, 'subsample': 0.7165123285256046, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=689.8877, MAE=511.4038, R²=-0.8930, Time=1.22s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:09,064] Trial 9 finished with values: [503.0150947260153, 370.89133333333336, -0.006382014986724194] and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 17, 'learning_rate': 0.04923876469578331, 'subsample': 0.819852456175058, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=503.0151, MAE=370.8913, R²=-0.0064, Time=1.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:10,345] Trial 10 finished with values: [691.8472746495428, 532.0484444444445, -0.903799902925164] and parameters: {'objective': 'reg:linear', 'n_estimators': 290, 'max_depth': 26, 'learning_rate': 0.18283740641842464, 'subsample': 0.5558046300396415, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=691.8473, MAE=532.0484, R²=-0.9038, Time=1.28s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:11,431] Trial 11 finished with values: [562.0321563338999, 428.1193333333333, -0.2563862063819904] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 29, 'learning_rate': 0.17656477728083825, 'subsample': 0.9533429850067696, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=562.0322, MAE=428.1193, R²=-0.2564, Time=1.08s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:12,717] Trial 12 finished with values: [568.039881935141, 432.58511111111113, -0.283389519285268] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 276, 'max_depth': 14, 'learning_rate': 0.061062548060845906, 'subsample': 0.6609857474055474, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=568.0399, MAE=432.5851, R²=-0.2834, Time=1.28s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:13,858] Trial 13 finished with values: [506.75430819853693, 389.84022222222217, -0.021399710620815915] and parameters: {'objective': 'reg:linear', 'n_estimators': 155, 'max_depth': 23, 'learning_rate': 0.13195981223125228, 'subsample': 0.864600069764367, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=506.7543, MAE=389.8402, R²=-0.0214, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:14,933] Trial 14 finished with values: [539.8547065008428, 416.8375555555555, -0.15918997144126146] and parameters: {'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 11, 'learning_rate': 0.18306009219624828, 'subsample': 0.5882861375022719, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=539.8547, MAE=416.8376, R²=-0.1592, Time=1.07s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_mva_trajectory: [{'objective': 'reg:linear', 'n_estimators': 92, 'max_depth': 5, 'learning_rate': 0.10873766660695386, 'subsample': 0.6769990180802256, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 17, 'learning_rate': 0.04923876469578331, 'subsample': 0.819852456175058, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_mva_trajectory: 16.96 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:15,980] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_iva_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_afschrijvingen_mva\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:16,424] Trial 0 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 194, 'max_depth': 27, 'learning_rate': 0.17896984015893158, 'subsample': 0.7542233619950398, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:16,843] Trial 1 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 68, 'max_depth': 6, 'learning_rate': 0.11871614515041372, 'subsample': 0.5610793513910501, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.42s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:17,286] Trial 2 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 289, 'max_depth': 24, 'learning_rate': 0.1932093306504256, 'subsample': 0.7079240835563878, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:17,697] Trial 3 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 227, 'max_depth': 29, 'learning_rate': 0.032518290788083576, 'subsample': 0.5937928001566377, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:18,204] Trial 4 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 230, 'max_depth': 29, 'learning_rate': 0.06999547305341221, 'subsample': 0.9555749872005224, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.50s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:18,581] Trial 5 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 62, 'max_depth': 12, 'learning_rate': 0.13660123207864716, 'subsample': 0.5248576519062896, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.38s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:18,965] Trial 6 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 11, 'learning_rate': 0.0904851968271697, 'subsample': 0.9745594846586961, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.38s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:19,356] Trial 7 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 116, 'max_depth': 13, 'learning_rate': 0.05222973972020406, 'subsample': 0.7203554777079373, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.39s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:19,772] Trial 8 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 201, 'max_depth': 8, 'learning_rate': 0.07967086078509576, 'subsample': 0.9599138597449726, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:20,178] Trial 9 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 59, 'max_depth': 16, 'learning_rate': 0.13689564645574864, 'subsample': 0.7875623309431303, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.40s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:20,600] Trial 10 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 24, 'learning_rate': 0.11640842183045878, 'subsample': 0.7058134085313813, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.42s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:20,981] Trial 11 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 99, 'max_depth': 14, 'learning_rate': 0.05684656781375169, 'subsample': 0.5314253127615611, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.38s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:21,434] Trial 12 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 181, 'max_depth': 23, 'learning_rate': 0.0860068909973031, 'subsample': 0.5062863304184197, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.45s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:21,847] Trial 13 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 232, 'max_depth': 15, 'learning_rate': 0.028602592631102833, 'subsample': 0.5446936875312303, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:22,244] Trial 14 finished with values: [0.0, 0.0, 1.0] and parameters: {'objective': 'reg:linear', 'n_estimators': 101, 'max_depth': 17, 'learning_rate': 0.10686586963038415, 'subsample': 0.7814639652047292, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=0.0000, MAE=0.0000, R²=1.0000, Time=0.40s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_iva_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 194, 'max_depth': 27, 'learning_rate': 0.17896984015893158, 'subsample': 0.7542233619950398, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 68, 'max_depth': 6, 'learning_rate': 0.11871614515041372, 'subsample': 0.5610793513910501, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 289, 'max_depth': 24, 'learning_rate': 0.1932093306504256, 'subsample': 0.7079240835563878, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 227, 'max_depth': 29, 'learning_rate': 0.032518290788083576, 'subsample': 0.5937928001566377, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 230, 'max_depth': 29, 'learning_rate': 0.06999547305341221, 'subsample': 0.9555749872005224, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 62, 'max_depth': 12, 'learning_rate': 0.13660123207864716, 'subsample': 0.5248576519062896, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 160, 'max_depth': 11, 'learning_rate': 0.0904851968271697, 'subsample': 0.9745594846586961, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 116, 'max_depth': 13, 'learning_rate': 0.05222973972020406, 'subsample': 0.7203554777079373, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 201, 'max_depth': 8, 'learning_rate': 0.07967086078509576, 'subsample': 0.9599138597449726, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 59, 'max_depth': 16, 'learning_rate': 0.13689564645574864, 'subsample': 0.7875623309431303, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 24, 'learning_rate': 0.11640842183045878, 'subsample': 0.7058134085313813, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 99, 'max_depth': 14, 'learning_rate': 0.05684656781375169, 'subsample': 0.5314253127615611, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 181, 'max_depth': 23, 'learning_rate': 0.0860068909973031, 'subsample': 0.5062863304184197, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 232, 'max_depth': 15, 'learning_rate': 0.028602592631102833, 'subsample': 0.5446936875312303, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 101, 'max_depth': 17, 'learning_rate': 0.10686586963038415, 'subsample': 0.7814639652047292, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_afschrijvingen_iva_trajectory: 6.27 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:22,670] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_omzet_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_afschrijvingen_iva\n  Optimizing on Dataset: month_data_cleaned_omzet (Train: 126, Test: 54)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:24,022] Trial 0 finished with values: [974.4729447985944, 752.0722222222222, -0.34271778225583605] and parameters: {'objective': 'reg:linear', 'n_estimators': 175, 'max_depth': 15, 'learning_rate': 0.03126185999912506, 'subsample': 0.5466867204808623, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=974.4729, MAE=752.0722, R²=-0.3427, Time=1.35s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:25,542] Trial 1 finished with values: [1055.1139607846123, 855.3801851851853, -0.5741420039078855] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 213, 'max_depth': 20, 'learning_rate': 0.1848209631479308, 'subsample': 0.8770426775815756, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1055.1140, MAE=855.3802, R²=-0.5741, Time=1.52s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:27,033] Trial 2 finished with values: [938.194815878206, 749.0762962962964, -0.24460409755431733] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.030363252147144464, 'subsample': 0.8778822627012464, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=938.1948, MAE=749.0763, R²=-0.2446, Time=1.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:28,464] Trial 3 finished with values: [942.8889818049945, 735.6972222222222, -0.2570897645640835] and parameters: {'objective': 'reg:linear', 'n_estimators': 204, 'max_depth': 21, 'learning_rate': 0.17281685839555624, 'subsample': 0.8799139040016521, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=942.8890, MAE=735.6972, R²=-0.2571, Time=1.43s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:29,944] Trial 4 finished with values: [1011.1556498163651, 795.98, -0.4457100309757436] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 300, 'max_depth': 30, 'learning_rate': 0.057794217847322735, 'subsample': 0.9048514898882271, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1011.1556, MAE=795.9800, R²=-0.4457, Time=1.48s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:31,351] Trial 5 finished with values: [1010.8525792140532, 783.2833333333334, -0.4448435243267974] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 30, 'learning_rate': 0.03364502049778641, 'subsample': 0.5548311511564314, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1010.8526, MAE=783.2833, R²=-0.4448, Time=1.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:32,762] Trial 6 finished with values: [1334.5144855450726, 1084.7255555555557, -1.51820889221178] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 13, 'learning_rate': 0.1975614834957551, 'subsample': 0.6868614467418585, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1334.5145, MAE=1084.7256, R²=-1.5182, Time=1.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:34,047] Trial 7 finished with values: [1019.3065994550377, 803.0033333333334, -0.4691117789542034] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 99, 'max_depth': 24, 'learning_rate': 0.12117690957344016, 'subsample': 0.7512784378135366, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1019.3066, MAE=803.0033, R²=-0.4691, Time=1.28s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:35,386] Trial 8 finished with values: [968.5130831522293, 727.6922222222221, -0.3263439240804782] and parameters: {'objective': 'reg:linear', 'n_estimators': 76, 'max_depth': 21, 'learning_rate': 0.19322363465511216, 'subsample': 0.8820424772197588, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=968.5131, MAE=727.6922, R²=-0.3263, Time=1.34s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:36,673] Trial 9 finished with values: [1001.882578725523, 784.2783333333334, -0.41931508481930013] and parameters: {'objective': 'reg:linear', 'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.10159158883790487, 'subsample': 0.9618784690305764, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1001.8826, MAE=784.2783, R²=-0.4193, Time=1.29s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:38,027] Trial 10 finished with values: [980.5078637605596, 741.3307407407408, -0.35940020452020427] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 160, 'max_depth': 25, 'learning_rate': 0.194893520597166, 'subsample': 0.628997798476182, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=980.5079, MAE=741.3307, R²=-0.3594, Time=1.35s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:39,237] Trial 11 finished with values: [1013.2920387072066, 790.101111111111, -0.45182553193806596] and parameters: {'objective': 'reg:linear', 'n_estimators': 73, 'max_depth': 19, 'learning_rate': 0.1263060099389832, 'subsample': 0.9108107771360987, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1013.2920, MAE=790.1011, R²=-0.4518, Time=1.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:40,728] Trial 12 finished with values: [896.4838779829414, 718.3520370370371, -0.13639715111487494] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 254, 'max_depth': 22, 'learning_rate': 0.1712736182114297, 'subsample': 0.7562683777268613, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=896.4839, MAE=718.3520, R²=-0.1364, Time=1.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:41,943] Trial 13 finished with values: [888.7188504131269, 693.6046296296298, -0.11679626466869797] and parameters: {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 29, 'learning_rate': 0.07494981514557447, 'subsample': 0.7922736978509761, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=888.7189, MAE=693.6046, R²=-0.1168, Time=1.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:43,173] Trial 14 finished with values: [962.2589067214783, 743.0824074074076, -0.3092694912245699] and parameters: {'objective': 'reg:linear', 'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.03956654427171306, 'subsample': 0.5636035945813348, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=962.2589, MAE=743.0824, R²=-0.3093, Time=1.23s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_omzet_trajectory: [{'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 29, 'learning_rate': 0.07494981514557447, 'subsample': 0.7922736978509761, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_omzet_trajectory: 20.50 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:44,439] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_algemene_kosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_omzet\n  Optimizing on Dataset: month_data_cleaned_algemene_kosten (Train: 181, Test: 78)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:46,147] Trial 0 finished with values: [1133.3992239792062, 988.869358974359, -0.029793069287362695] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 64, 'max_depth': 24, 'learning_rate': 0.13431886057606213, 'subsample': 0.7808051988977747, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1133.3992, MAE=988.8694, R²=-0.0298, Time=1.71s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:48,116] Trial 1 finished with values: [1115.4556681653949, 938.5201282051283, 0.00255542615222637] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 260, 'max_depth': 17, 'learning_rate': 0.15917398803548014, 'subsample': 0.9885286005856251, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1115.4557, MAE=938.5201, R²=0.0026, Time=1.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:49,905] Trial 2 finished with values: [1384.221797816839, 1215.9033333333336, -0.5360151901575683] and parameters: {'objective': 'reg:linear', 'n_estimators': 107, 'max_depth': 18, 'learning_rate': 0.11504520252712121, 'subsample': 0.6078268567348359, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1384.2218, MAE=1215.9033, R²=-0.5360, Time=1.79s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:51,873] Trial 3 finished with values: [1111.827678545902, 933.5457692307693, 0.009033198009158139] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 280, 'max_depth': 26, 'learning_rate': 0.057448546699083634, 'subsample': 0.9098714501021701, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1111.8277, MAE=933.5458, R²=0.0090, Time=1.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:53,563] Trial 4 finished with values: [1149.9827042294692, 894.9555128205128, -0.060148638441321456] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 91, 'max_depth': 15, 'learning_rate': 0.1807622899972238, 'subsample': 0.5618601320434808, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1149.9827, MAE=894.9555, R²=-0.0601, Time=1.69s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:55,441] Trial 5 finished with values: [1660.4212027795065, 1349.953717948718, -1.2101445749263364] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 222, 'max_depth': 13, 'learning_rate': 0.1702724371249959, 'subsample': 0.8667635038532999, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1660.4212, MAE=1349.9537, R²=-1.2101, Time=1.88s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:57,182] Trial 6 finished with values: [1375.5273650145411, 1214.8793589743589, -0.5167800653657204] and parameters: {'objective': 'reg:linear', 'n_estimators': 53, 'max_depth': 24, 'learning_rate': 0.022304431087355952, 'subsample': 0.9702812995778554, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1375.5274, MAE=1214.8794, R²=-0.5168, Time=1.74s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:50:59,071] Trial 7 finished with values: [1141.954698885385, 945.1249999999998, -0.04539855260210213] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 186, 'max_depth': 22, 'learning_rate': 0.1275282408772351, 'subsample': 0.8745305177920266, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1141.9547, MAE=945.1250, R²=-0.0454, Time=1.89s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:01,045] Trial 8 finished with values: [1492.2349165227786, 1300.5423076923075, -0.7850835102568967] and parameters: {'objective': 'reg:linear', 'n_estimators': 298, 'max_depth': 7, 'learning_rate': 0.14088463933096923, 'subsample': 0.749830542391749, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1492.2349, MAE=1300.5423, R²=-0.7851, Time=1.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:02,727] Trial 9 finished with values: [1415.6625310129891, 1218.331923076923, -0.6065846669729369] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 94, 'max_depth': 13, 'learning_rate': 0.042783819597899043, 'subsample': 0.9828505337685898, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1415.6625, MAE=1218.3319, R²=-0.6066, Time=1.68s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:04,582] Trial 10 finished with values: [1443.1585140200164, 1255.3732051282052, -0.669599148007795] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 214, 'max_depth': 5, 'learning_rate': 0.05271256834612122, 'subsample': 0.9224107923210838, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1443.1585, MAE=1255.3732, R²=-0.6696, Time=1.85s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:06,312] Trial 11 finished with values: [1108.1040709421031, 904.9266666666666, 0.015659750976493858] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 19, 'learning_rate': 0.11606122312546475, 'subsample': 0.5597525386091904, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1108.1041, MAE=904.9267, R²=0.0157, Time=1.73s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:08,205] Trial 12 finished with values: [1632.2885450122487, 1341.0455128205128, -1.1358857016999826] and parameters: {'objective': 'reg:linear', 'n_estimators': 229, 'max_depth': 25, 'learning_rate': 0.14019505784595465, 'subsample': 0.7600294596776739, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1632.2885, MAE=1341.0455, R²=-1.1359, Time=1.89s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:10,136] Trial 13 finished with values: [1407.4208490642625, 1187.9470512820515, -0.5879327403260952] and parameters: {'objective': 'reg:linear', 'n_estimators': 202, 'max_depth': 26, 'learning_rate': 0.09612596417624386, 'subsample': 0.8809436002169899, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1407.4208, MAE=1187.9471, R²=-0.5879, Time=1.93s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:12,139] Trial 14 finished with values: [1142.9122549805015, 938.4679487179487, -0.047152470598330165] and parameters: {'objective': 'reg:linear', 'n_estimators': 268, 'max_depth': 26, 'learning_rate': 0.14155265342316095, 'subsample': 0.8732097822964267, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1142.9123, MAE=938.4679, R²=-0.0472, Time=2.00s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_algemene_kosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 91, 'max_depth': 15, 'learning_rate': 0.1807622899972238, 'subsample': 0.5618601320434808, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 19, 'learning_rate': 0.11606122312546475, 'subsample': 0.5597525386091904, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_algemene_kosten_trajectory: 27.70 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:13,947] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_autokosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_algemene_kosten\n  Optimizing on Dataset: month_data_cleaned_autokosten (Train: 212, Test: 92)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:16,116] Trial 0 finished with values: [1644.0247091314602, 1377.1628260869566, -0.45661808652117086] and parameters: {'objective': 'reg:linear', 'n_estimators': 181, 'max_depth': 23, 'learning_rate': 0.16726772943441093, 'subsample': 0.6505698256304147, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1644.0247, MAE=1377.1628, R²=-0.4566, Time=2.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:18,361] Trial 1 finished with values: [1368.330723148846, 1184.8523913043477, -0.00904648451427037] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 184, 'max_depth': 30, 'learning_rate': 0.029222818698385056, 'subsample': 0.6734214955344371, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1368.3307, MAE=1184.8524, R²=-0.0090, Time=2.24s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:20,399] Trial 2 finished with values: [1403.9762915450717, 1265.3911956521738, -0.06230338475524322] and parameters: {'objective': 'reg:linear', 'n_estimators': 85, 'max_depth': 24, 'learning_rate': 0.038944733303506125, 'subsample': 0.5294505065565926, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1403.9763, MAE=1265.3912, R²=-0.0623, Time=2.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:22,565] Trial 3 finished with values: [1471.8885617722854, 1258.1189130434782, -0.16755911265379608] and parameters: {'objective': 'reg:linear', 'n_estimators': 192, 'max_depth': 12, 'learning_rate': 0.09939853134725624, 'subsample': 0.6467371663558471, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1471.8886, MAE=1258.1189, R²=-0.1676, Time=2.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:24,672] Trial 4 finished with values: [1546.0041030810619, 1390.422391304348, -0.28810213922152283] and parameters: {'objective': 'reg:linear', 'n_estimators': 239, 'max_depth': 6, 'learning_rate': 0.07505163216169825, 'subsample': 0.6538015397289973, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1546.0041, MAE=1390.4224, R²=-0.2881, Time=2.11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:26,905] Trial 5 finished with values: [1607.3326414915948, 1373.0906521739132, -0.39232475844418135] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 237, 'max_depth': 25, 'learning_rate': 0.11074582163460195, 'subsample': 0.6328370697699269, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1607.3326, MAE=1373.0907, R²=-0.3923, Time=2.23s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:29,174] Trial 6 finished with values: [1531.6203845132518, 1382.5978260869565, -0.2642451396372354] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 279, 'max_depth': 20, 'learning_rate': 0.04614582138329565, 'subsample': 0.9815466824476996, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1531.6204, MAE=1382.5978, R²=-0.2642, Time=2.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:31,361] Trial 7 finished with values: [1520.5444680875078, 1311.3129347826089, -0.24602646944181839] and parameters: {'objective': 'reg:linear', 'n_estimators': 161, 'max_depth': 11, 'learning_rate': 0.11429495599407427, 'subsample': 0.7781088998802141, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1520.5445, MAE=1311.3129, R²=-0.2460, Time=2.19s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:33,347] Trial 8 finished with values: [1607.5522209622468, 1378.7435869565215, -0.3927051984456089] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 59, 'max_depth': 27, 'learning_rate': 0.11351357843929719, 'subsample': 0.5202691220918657, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1607.5522, MAE=1378.7436, R²=-0.3927, Time=1.98s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:35,385] Trial 9 finished with values: [1508.2782774253765, 1353.9598913043478, -0.22600423297891936] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 53, 'max_depth': 20, 'learning_rate': 0.09859328879699146, 'subsample': 0.9499545394393999, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1508.2783, MAE=1353.9599, R²=-0.2260, Time=2.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:37,494] Trial 10 finished with values: [1383.3033207660535, 1228.984891304348, -0.031249749616895528] and parameters: {'objective': 'reg:linear', 'n_estimators': 112, 'max_depth': 6, 'learning_rate': 0.13569562438096014, 'subsample': 0.9196822556658057, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1383.3033, MAE=1228.9849, R²=-0.0312, Time=2.11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:39,769] Trial 11 finished with values: [1432.5873710493952, 1082.3929347826086, -0.10604107015125352] and parameters: {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 15, 'learning_rate': 0.1871670463948298, 'subsample': 0.7150761077060812, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1432.5874, MAE=1082.3929, R²=-0.1060, Time=2.27s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:41,894] Trial 12 finished with values: [1575.3946495512744, 1424.9260869565219, -0.33754298945937045] and parameters: {'objective': 'reg:linear', 'n_estimators': 225, 'max_depth': 12, 'learning_rate': 0.041431809685168366, 'subsample': 0.5932605182062227, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1575.3946, MAE=1424.9261, R²=-0.3375, Time=2.12s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:43,969] Trial 13 finished with values: [1548.7698390833766, 1397.1460869565217, -0.29271498220182735] and parameters: {'objective': 'reg:linear', 'n_estimators': 90, 'max_depth': 16, 'learning_rate': 0.16054501948483108, 'subsample': 0.7453790639425981, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1548.7698, MAE=1397.1461, R²=-0.2927, Time=2.07s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:46,029] Trial 14 finished with values: [1411.2482946263815, 1224.6325, -0.07333644826168872] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 90, 'max_depth': 20, 'learning_rate': 0.19416769974173512, 'subsample': 0.8891760931530325, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1411.2483, MAE=1224.6325, R²=-0.0733, Time=2.06s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_autokosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 184, 'max_depth': 30, 'learning_rate': 0.029222818698385056, 'subsample': 0.6734214955344371, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 110, 'max_depth': 15, 'learning_rate': 0.1871670463948298, 'subsample': 0.7150761077060812, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_autokosten_trajectory: 32.08 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:48,267] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_overige_rentelasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_autokosten\n  Optimizing on Dataset: month_data_cleaned_overige_rentelasten (Train: 120, Test: 52)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:49,480] Trial 0 finished with values: [1170.452780048421, 1007.6515384615385, -1.0543834855097827] and parameters: {'objective': 'reg:linear', 'n_estimators': 205, 'max_depth': 5, 'learning_rate': 0.07348102440297141, 'subsample': 0.8709254176276733, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1170.4528, MAE=1007.6515, R²=-1.0544, Time=1.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:51,120] Trial 1 finished with values: [1256.4029149344444, 1070.6032692307692, -1.36718167887713] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 287, 'max_depth': 24, 'learning_rate': 0.07889492823558421, 'subsample': 0.7767069617287832, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1256.4029, MAE=1070.6033, R²=-1.3672, Time=1.64s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:52,416] Trial 2 finished with values: [842.9627247553257, 634.3888461538462, -0.06559079915660604] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 75, 'max_depth': 22, 'learning_rate': 0.16200452078855163, 'subsample': 0.7561373602972317, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=842.9627, MAE=634.3888, R²=-0.0656, Time=1.29s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:53,854] Trial 3 finished with values: [1502.8336600696903, 1275.585, -2.386846763977442] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 241, 'max_depth': 9, 'learning_rate': 0.0738590104036925, 'subsample': 0.7118847624723221, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1502.8337, MAE=1275.5850, R²=-2.3868, Time=1.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:55,023] Trial 4 finished with values: [1195.9167248447784, 1061.4628846153846, -1.1447446802262347] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 74, 'max_depth': 18, 'learning_rate': 0.18894162450545046, 'subsample': 0.8692387321729325, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1195.9167, MAE=1061.4629, R²=-1.1447, Time=1.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:56,412] Trial 5 finished with values: [1098.6353418498506, 954.1215384615384, -0.8100094886558735] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 206, 'max_depth': 19, 'learning_rate': 0.012157579106099946, 'subsample': 0.7528096811869571, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1098.6353, MAE=954.1215, R²=-0.8100, Time=1.39s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:57,723] Trial 6 finished with values: [1132.0656821305433, 983.2588461538461, -0.9218388601556036] and parameters: {'objective': 'reg:linear', 'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.054912493183251594, 'subsample': 0.8727987849808551, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1132.0657, MAE=983.2588, R²=-0.9218, Time=1.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:51:59,154] Trial 7 finished with values: [954.8335298415192, 703.1401923076924, -0.3671905337947803] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 264, 'max_depth': 30, 'learning_rate': 0.09172691487879431, 'subsample': 0.5594782949027043, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=954.8335, MAE=703.1402, R²=-0.3672, Time=1.43s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:00,465] Trial 8 finished with values: [1428.600482070181, 1227.6913461538463, -2.0605205851596713] and parameters: {'objective': 'reg:linear', 'n_estimators': 239, 'max_depth': 12, 'learning_rate': 0.05976677220713821, 'subsample': 0.5592072487697779, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1428.6005, MAE=1227.6913, R²=-2.0605, Time=1.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:01,712] Trial 9 finished with values: [890.9287313215524, 647.0721153846154, -0.1903088139685274] and parameters: {'objective': 'reg:linear', 'n_estimators': 76, 'max_depth': 28, 'learning_rate': 0.1723595867063213, 'subsample': 0.8220543434043716, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=890.9287, MAE=647.0721, R²=-0.1903, Time=1.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:03,128] Trial 10 finished with values: [1962.1481240114208, 1651.849230769231, -4.773475128131941] and parameters: {'objective': 'reg:linear', 'n_estimators': 259, 'max_depth': 8, 'learning_rate': 0.17018840379489175, 'subsample': 0.660424981205191, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1962.1481, MAE=1651.8492, R²=-4.7735, Time=1.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:04,525] Trial 11 finished with values: [836.6885878086485, 617.3792307692308, -0.04978753324387708] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 25, 'learning_rate': 0.06489585170562374, 'subsample': 0.5696002733672494, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=836.6886, MAE=617.3792, R²=-0.0498, Time=1.40s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:05,841] Trial 12 finished with values: [1653.5560432129762, 1424.2184615384615, -3.1002615243716] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 205, 'max_depth': 11, 'learning_rate': 0.1006679457914463, 'subsample': 0.5454983236063625, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1653.5560, MAE=1424.2185, R²=-3.1003, Time=1.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:07,073] Trial 13 finished with values: [1321.473445747354, 1098.006153846154, -1.61872926478298] and parameters: {'objective': 'reg:linear', 'n_estimators': 59, 'max_depth': 6, 'learning_rate': 0.1559554827996828, 'subsample': 0.5154918369497048, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1321.4734, MAE=1098.0062, R²=-1.6187, Time=1.23s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:08,327] Trial 14 finished with values: [1077.7249941650591, 954.6675000000001, -0.7417652840088236] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 11, 'learning_rate': 0.021646778511139504, 'subsample': 0.9446944190707369, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1077.7250, MAE=954.6675, R²=-0.7418, Time=1.25s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_overige_rentelasten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 25, 'learning_rate': 0.06489585170562374, 'subsample': 0.5696002733672494, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_overige_rentelasten_trajectory: 20.06 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:09,533] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_pensioenlasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_overige_rentelasten\n  Optimizing on Dataset: month_data_cleaned_pensioenlasten (Train: 32, Test: 15)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:10,107] Trial 0 finished with values: [1011723.6725707682, 819116.5319999999, -4511108.8954317905] and parameters: {'objective': 'reg:linear', 'n_estimators': 179, 'max_depth': 28, 'learning_rate': 0.02436073376604147, 'subsample': 0.97598742193635, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1011723.6726, MAE=819116.5320, R²=-4511108.8954, Time=0.57s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:10,760] Trial 1 finished with values: [936772.9488330827, 751811.66, -3867480.684686726] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 248, 'max_depth': 8, 'learning_rate': 0.13843139365297183, 'subsample': 0.8297931289289262, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=936772.9488, MAE=751811.6600, R²=-3867480.6847, Time=0.65s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:11,283] Trial 2 finished with values: [826441.417057016, 643207.7726666667, -3010118.455814715] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 184, 'max_depth': 18, 'learning_rate': 0.03091463656858312, 'subsample': 0.5711972760752144, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=826441.4171, MAE=643207.7727, R²=-3010118.4558, Time=0.52s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:11,917] Trial 3 finished with values: [520.2157303785933, 315.54666666666674, -0.19268716066277247] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 266, 'max_depth': 21, 'learning_rate': 0.13136093203176838, 'subsample': 0.9866960058595574, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=520.2157, MAE=315.5467, R²=-0.1927, Time=0.63s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:12,558] Trial 4 finished with values: [1031982.0669014041, 849707.27, -4693575.322653163] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 263, 'max_depth': 19, 'learning_rate': 0.08670166045618867, 'subsample': 0.9231130773070753, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1031982.0669, MAE=849707.2700, R²=-4693575.3227, Time=0.64s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:13,259] Trial 5 finished with values: [550.5752492378615, 364.2566666666667, -0.33595845089698195] and parameters: {'objective': 'reg:linear', 'n_estimators': 268, 'max_depth': 11, 'learning_rate': 0.1284607104144554, 'subsample': 0.7315552836747818, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=550.5752, MAE=364.2567, R²=-0.3360, Time=0.70s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:13,890] Trial 6 finished with values: [517.6421381482255, 337.3693333333334, -0.18091551441755005] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 215, 'max_depth': 27, 'learning_rate': 0.14354956037242392, 'subsample': 0.8668403033009929, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=517.6421, MAE=337.3693, R²=-0.1809, Time=0.63s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:14,297] Trial 7 finished with values: [811910.422843517, 646627.2606666667, -2905197.5366878146] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 58, 'max_depth': 8, 'learning_rate': 0.13070009366008406, 'subsample': 0.5256995478110588, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=811910.4228, MAE=646627.2607, R²=-2905197.5367, Time=0.41s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:15,003] Trial 8 finished with values: [1033743.4655620137, 841966.772, -4709611.094279788] and parameters: {'objective': 'reg:linear', 'n_estimators': 129, 'max_depth': 9, 'learning_rate': 0.10572281034954605, 'subsample': 0.9947106342019493, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1033743.4656, MAE=841966.7720, R²=-4709611.0943, Time=0.70s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:15,539] Trial 9 finished with values: [853219.3933181351, 672944.9433333332, -3208343.6833610074] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 181, 'max_depth': 16, 'learning_rate': 0.164333875345653, 'subsample': 0.5408155010780036, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=853219.3933, MAE=672944.9433, R²=-3208343.6834, Time=0.53s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:16,144] Trial 10 finished with values: [839004.1519043191, 609446.6993333333, -3102327.648638457] and parameters: {'objective': 'reg:linear', 'n_estimators': 189, 'max_depth': 13, 'learning_rate': 0.12572146905217332, 'subsample': 0.5974895435759814, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=839004.1519, MAE=609446.6993, R²=-3102327.6486, Time=0.60s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:16,631] Trial 11 finished with values: [503.92481191145964, 335.68466666666666, -0.11915713589213905] and parameters: {'objective': 'reg:linear', 'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.0179542392520085, 'subsample': 0.7224803704507037, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=503.9248, MAE=335.6847, R²=-0.1192, Time=0.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:17,387] Trial 12 finished with values: [867099.2453840632, 639240.1633333333, -3313577.0138575984] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 280, 'max_depth': 19, 'learning_rate': 0.1213415046443607, 'subsample': 0.6098566768813873, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=867099.2454, MAE=639240.1633, R²=-3313577.0139, Time=0.75s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:17,863] Trial 13 finished with values: [919699.8131960735, 750619.516, -3727791.9267817205] and parameters: {'objective': 'reg:linear', 'n_estimators': 109, 'max_depth': 30, 'learning_rate': 0.11826692371220755, 'subsample': 0.8285657216503782, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=919699.8132, MAE=750619.5160, R²=-3727791.9268, Time=0.47s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:18,404] Trial 14 finished with values: [892555.5080129369, 649163.5866666667, -3510992.716220082] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 273, 'max_depth': 6, 'learning_rate': 0.19320919779728526, 'subsample': 0.7532589973973329, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=892555.5080, MAE=649163.5867, R²=-3510992.7162, Time=0.54s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_pensioenlasten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 266, 'max_depth': 21, 'learning_rate': 0.13136093203176838, 'subsample': 0.9866960058595574, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:linear', 'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.0179542392520085, 'subsample': 0.7224803704507037, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_pensioenlasten_trajectory: 8.87 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:19,005] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_lonen_en_salarissen_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_pensioenlasten\n  Optimizing on Dataset: month_data_cleaned_lonen_en_salarissen (Train: 72, Test: 31)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:19,816] Trial 0 finished with values: [1102.389579864373, 864.4264516129033, -0.011770697915228112] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 154, 'max_depth': 10, 'learning_rate': 0.1284470751226718, 'subsample': 0.6077915487496797, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1102.3896, MAE=864.4265, R²=-0.0118, Time=0.81s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:20,910] Trial 1 finished with values: [966.7726562007323, 824.6867741935484, 0.22185484883710882] and parameters: {'objective': 'reg:linear', 'n_estimators': 223, 'max_depth': 28, 'learning_rate': 0.06156612575460328, 'subsample': 0.9456600680206759, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=966.7727, MAE=824.6868, R²=0.2219, Time=1.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:21,909] Trial 2 finished with values: [1030.0636427816708, 826.4464516129033, 0.11663535049112306] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 28, 'learning_rate': 0.09928398647805528, 'subsample': 0.738047150875847, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1030.0636, MAE=826.4465, R²=0.1166, Time=1.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:22,775] Trial 3 finished with values: [1037.4309302994272, 825.2464516129032, 0.10395404701067013] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 122, 'max_depth': 16, 'learning_rate': 0.1665683355353822, 'subsample': 0.5326590486900887, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1037.4309, MAE=825.2465, R²=0.1040, Time=0.86s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:23,561] Trial 4 finished with values: [998.7342169676252, 817.396129032258, 0.16955331273650887] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 51, 'max_depth': 15, 'learning_rate': 0.08401131479930614, 'subsample': 0.5328051379974854, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=998.7342, MAE=817.3961, R²=0.1696, Time=0.78s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:24,519] Trial 5 finished with values: [968.6074430218979, 813.1529032258065, 0.21889844483393606] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 272, 'max_depth': 23, 'learning_rate': 0.09886759942186246, 'subsample': 0.9309351130913603, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=968.6074, MAE=813.1529, R²=0.2189, Time=0.96s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:25,390] Trial 6 finished with values: [1080.8631219270717, 853.6116129032258, 0.027357376857486182] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 197, 'max_depth': 29, 'learning_rate': 0.10777476105283393, 'subsample': 0.5224999830916041, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1080.8631, MAE=853.6116, R²=0.0274, Time=0.87s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:26,345] Trial 7 finished with values: [1208.5213117196754, 981.8016129032258, -0.21596346250581377] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 243, 'max_depth': 15, 'learning_rate': 0.17067470616315172, 'subsample': 0.7709667963827076, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1208.5213, MAE=981.8016, R²=-0.2160, Time=0.95s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:27,300] Trial 8 finished with values: [962.3588520518636, 820.8296774193549, 0.22894387846595177] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 109, 'max_depth': 21, 'learning_rate': 0.06356159506827294, 'subsample': 0.9274574653844925, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=962.3589, MAE=820.8297, R²=0.2289, Time=0.95s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:28,074] Trial 9 finished with values: [1057.487231694442, 830.5125806451614, 0.06897324134052218] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 61, 'max_depth': 8, 'learning_rate': 0.19127168390778557, 'subsample': 0.8238230611422401, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1057.4872, MAE=830.5126, R²=0.0690, Time=0.77s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:28,945] Trial 10 finished with values: [977.5119368927122, 816.5677419354838, 0.2044709603681668] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 146, 'max_depth': 29, 'learning_rate': 0.023442625679772462, 'subsample': 0.8410786585619798, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=977.5119, MAE=816.5677, R²=0.2045, Time=0.87s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:29,902] Trial 11 finished with values: [965.290901583893, 815.6151612903226, 0.22423831832508812] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 240, 'max_depth': 11, 'learning_rate': 0.16623895923140583, 'subsample': 0.9216878032164366, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=965.2909, MAE=815.6152, R²=0.2242, Time=0.96s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:30,892] Trial 12 finished with values: [1050.8327523399348, 833.7112903225805, 0.08065377017604958] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 223, 'max_depth': 21, 'learning_rate': 0.08848240586929511, 'subsample': 0.5333470973648985, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1050.8328, MAE=833.7113, R²=0.0807, Time=0.99s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:31,873] Trial 13 finished with values: [974.2367200217357, 815.0696774193549, 0.20979297237701877] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 235, 'max_depth': 16, 'learning_rate': 0.013117274826158555, 'subsample': 0.9399010880266998, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=974.2367, MAE=815.0697, R²=0.2098, Time=0.98s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:32,849] Trial 14 finished with values: [1284.1906328011403, 1085.445806451613, -0.37300112809859454] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 291, 'max_depth': 14, 'learning_rate': 0.12999874898244004, 'subsample': 0.6225352088694671, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1284.1906, MAE=1085.4458, R²=-0.3730, Time=0.97s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_lonen_en_salarissen_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 272, 'max_depth': 23, 'learning_rate': 0.09886759942186246, 'subsample': 0.9309351130913603, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 109, 'max_depth': 21, 'learning_rate': 0.06356159506827294, 'subsample': 0.9274574653844925, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 240, 'max_depth': 11, 'learning_rate': 0.16623895923140583, 'subsample': 0.9216878032164366, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_lonen_en_salarissen_trajectory: 13.84 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:33,871] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_overige_personeelskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_lonen_en_salarissen\n  Optimizing on Dataset: month_data_cleaned_overige_personeelskosten (Train: 151, Test: 66)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:35,580] Trial 0 finished with values: [938.4135518078726, 505.50409090909085, -0.1334812842758739] and parameters: {'objective': 'reg:linear', 'n_estimators': 208, 'max_depth': 20, 'learning_rate': 0.06584658583453906, 'subsample': 0.5010806411290487, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=938.4136, MAE=505.5041, R²=-0.1335, Time=1.71s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:37,074] Trial 1 finished with values: [890.3108939484754, 462.28409090909093, -0.020256068829043627] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 14, 'learning_rate': 0.15176827798887194, 'subsample': 0.8691030130583628, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=890.3109, MAE=462.2841, R²=-0.0203, Time=1.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:38,710] Trial 2 finished with values: [1001.0291082249488, 780.625303030303, -0.28979064975703195] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 93, 'max_depth': 27, 'learning_rate': 0.08285551838497998, 'subsample': 0.9524326489772946, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1001.0291, MAE=780.6253, R²=-0.2898, Time=1.63s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:40,477] Trial 3 finished with values: [1073.114572358931, 880.2190909090909, -0.4822381829002478] and parameters: {'objective': 'reg:linear', 'n_estimators': 142, 'max_depth': 14, 'learning_rate': 0.12247423088319442, 'subsample': 0.8356204825908697, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1073.1146, MAE=880.2191, R²=-0.4822, Time=1.77s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:42,000] Trial 4 finished with values: [1075.6953502192587, 886.015303030303, -0.48937614827577325] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 155, 'max_depth': 17, 'learning_rate': 0.04874429737765539, 'subsample': 0.7351532913027247, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1075.6954, MAE=886.0153, R²=-0.4894, Time=1.52s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:43,710] Trial 5 finished with values: [1208.336581583304, 1067.835, -0.8793239963420378] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 216, 'max_depth': 29, 'learning_rate': 0.1281102798380517, 'subsample': 0.9084853795819038, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1208.3366, MAE=1067.8350, R²=-0.8793, Time=1.71s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:45,272] Trial 6 finished with values: [902.8084276435629, 453.72060606060614, -0.04910032330512015] and parameters: {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 16, 'learning_rate': 0.11807283965673598, 'subsample': 0.5691139311972578, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=902.8084, MAE=453.7206, R²=-0.0491, Time=1.56s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:46,913] Trial 7 finished with values: [1036.127095063997, 651.4971212121212, -0.38182127007428646] and parameters: {'objective': 'reg:linear', 'n_estimators': 237, 'max_depth': 27, 'learning_rate': 0.19506900558094376, 'subsample': 0.5768607016782052, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1036.1271, MAE=651.4971, R²=-0.3818, Time=1.64s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:48,568] Trial 8 finished with values: [1959.735549538702, 1695.645909090909, -3.9433430888578638] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 30, 'learning_rate': 0.1421910052091092, 'subsample': 0.7330312777878185, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1959.7355, MAE=1695.6459, R²=-3.9433, Time=1.65s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:50,085] Trial 9 finished with values: [959.4073221778563, 622.1972727272727, -0.1847640540694191] and parameters: {'objective': 'reg:linear', 'n_estimators': 137, 'max_depth': 11, 'learning_rate': 0.11991698675636477, 'subsample': 0.7518752541952052, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=959.4073, MAE=622.1973, R²=-0.1848, Time=1.51s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:51,760] Trial 10 finished with values: [967.6662767679461, 783.4712121212123, -0.2052496778041959] and parameters: {'objective': 'reg:linear', 'n_estimators': 241, 'max_depth': 16, 'learning_rate': 0.04565761086839526, 'subsample': 0.6917611093717397, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=967.6663, MAE=783.4712, R²=-0.2052, Time=1.67s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:53,410] Trial 11 finished with values: [1063.273634580459, 809.820909090909, -0.455177268366163] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 297, 'max_depth': 19, 'learning_rate': 0.04340897787513604, 'subsample': 0.5552163984292942, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1063.2736, MAE=809.8209, R²=-0.4552, Time=1.65s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:55,138] Trial 12 finished with values: [988.7824117937815, 585.6075757575758, -0.25842482545024326] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 183, 'max_depth': 20, 'learning_rate': 0.12964105124608802, 'subsample': 0.665469382200366, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=988.7824, MAE=585.6076, R²=-0.2584, Time=1.73s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:56,591] Trial 13 finished with values: [1025.4076000731995, 824.278787878788, -0.35337726249129653] and parameters: {'objective': 'reg:linear', 'n_estimators': 51, 'max_depth': 17, 'learning_rate': 0.11036132555485845, 'subsample': 0.8774716942131819, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1025.4076, MAE=824.2788, R²=-0.3534, Time=1.45s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:58,089] Trial 14 finished with values: [896.0815643180068, 471.0783333333333, -0.03352478657358948] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 66, 'max_depth': 30, 'learning_rate': 0.024720732060930742, 'subsample': 0.7264961970400377, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=896.0816, MAE=471.0783, R²=-0.0335, Time=1.50s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_overige_personeelskosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 60, 'max_depth': 14, 'learning_rate': 0.15176827798887194, 'subsample': 0.8691030130583628, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 16, 'learning_rate': 0.11807283965673598, 'subsample': 0.5691139311972578, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_overige_personeelskosten_trajectory: 24.22 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:52:59,567] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_sociale_lasten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_overige_personeelskosten\n  Optimizing on Dataset: month_data_cleaned_sociale_lasten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:00,500] Trial 0 finished with values: [1844.5426035668931, 1297.1873333333335, -5.5213902626770714] and parameters: {'objective': 'reg:linear', 'n_estimators': 235, 'max_depth': 19, 'learning_rate': 0.14758626882335035, 'subsample': 0.6982025752573696, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1844.5426, MAE=1297.1873, R²=-5.5214, Time=0.93s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:01,399] Trial 1 finished with values: [1920.953045698931, 1575.3600000000001, -6.072880301163705] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 242, 'max_depth': 28, 'learning_rate': 0.015083679266340952, 'subsample': 0.8524124776991191, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1920.9530, MAE=1575.3600, R²=-6.0729, Time=0.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:02,170] Trial 2 finished with values: [665.8720697201027, 499.3126666666666, 0.15014583596676312] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 101, 'max_depth': 17, 'learning_rate': 0.03463159724616318, 'subsample': 0.6174512931937106, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=665.8721, MAE=499.3127, R²=0.1501, Time=0.77s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:03,076] Trial 3 finished with values: [669.3839260768068, 503.99300000000005, 0.1411578147246777] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 241, 'max_depth': 11, 'learning_rate': 0.05556009832941705, 'subsample': 0.6048404564130254, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=669.3839, MAE=503.9930, R²=0.1412, Time=0.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:03,851] Trial 4 finished with values: [711.6450126479259, 535.908, 0.029289718451404823] and parameters: {'objective': 'reg:linear', 'n_estimators': 112, 'max_depth': 28, 'learning_rate': 0.181382913931868, 'subsample': 0.5945237839070294, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=711.6450, MAE=535.9080, R²=0.0293, Time=0.77s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:04,633] Trial 5 finished with values: [2006.6960799981646, 1612.712, -6.718377469171229] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 76, 'max_depth': 24, 'learning_rate': 0.07563173355447256, 'subsample': 0.7888901097742851, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=2006.6961, MAE=1612.7120, R²=-6.7184, Time=0.78s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:05,512] Trial 6 finished with values: [1971.8308982922445, 1586.2766666666669, -6.452502746603917] and parameters: {'objective': 'reg:linear', 'n_estimators': 210, 'max_depth': 26, 'learning_rate': 0.11592366234757116, 'subsample': 0.8719366793514812, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1971.8309, MAE=1586.2767, R²=-6.4525, Time=0.88s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:06,469] Trial 7 finished with values: [613.9732423078386, 465.62899999999996, 0.2774603266691461] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.16375286088725352, 'subsample': 0.911252005561594, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=613.9732, MAE=465.6290, R²=0.2775, Time=0.96s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:07,342] Trial 8 finished with values: [1569.0520052959791, 1152.5849999999998, -3.7188642718288705] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 211, 'max_depth': 10, 'learning_rate': 0.13721988910375463, 'subsample': 0.6738754566104621, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1569.0520, MAE=1152.5850, R²=-3.7189, Time=0.87s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:08,161] Trial 9 finished with values: [2031.3898696139054, 1544.033, -6.909506259776417] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 143, 'max_depth': 5, 'learning_rate': 0.12795043677358212, 'subsample': 0.7123200906127629, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=2031.3899, MAE=1544.0330, R²=-6.9095, Time=0.82s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:08,886] Trial 10 finished with values: [656.1121786884719, 493.6776666666667, 0.17487640212411137] and parameters: {'objective': 'reg:linear', 'n_estimators': 66, 'max_depth': 15, 'learning_rate': 0.17603774898196733, 'subsample': 0.6131606590436789, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=656.1122, MAE=493.6777, R²=0.1749, Time=0.72s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:09,646] Trial 11 finished with values: [1835.7209859244224, 1462.643, -5.45916167211781] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 125, 'max_depth': 26, 'learning_rate': 0.025748616240406592, 'subsample': 0.6466263040105397, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1835.7210, MAE=1462.6430, R²=-5.4592, Time=0.76s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:10,408] Trial 12 finished with values: [647.8196646341222, 476.6373333333333, 0.19560184964900307] and parameters: {'objective': 'reg:linear', 'n_estimators': 112, 'max_depth': 17, 'learning_rate': 0.09399040524829425, 'subsample': 0.5281024969445173, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=647.8197, MAE=476.6373, R²=0.1956, Time=0.76s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:11,309] Trial 13 finished with values: [1990.3147222805408, 1475.0120000000002, -6.5928762266722805] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 206, 'max_depth': 16, 'learning_rate': 0.14815322787032736, 'subsample': 0.695418661950411, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1990.3147, MAE=1475.0120, R²=-6.5929, Time=0.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:12,224] Trial 14 finished with values: [742.447917816462, 565.8363333333333, -0.056561537150898955] and parameters: {'objective': 'reg:linear', 'n_estimators': 261, 'max_depth': 16, 'learning_rate': 0.1638361768816986, 'subsample': 0.8879909168561839, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=742.4479, MAE=565.8363, R²=-0.0566, Time=0.91s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_sociale_lasten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 288, 'max_depth': 6, 'learning_rate': 0.16375286088725352, 'subsample': 0.911252005561594, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_sociale_lasten_trajectory: 12.66 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:13,098] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_exploitatie-_en_machinekosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_sociale_lasten\n  Optimizing on Dataset: month_data_cleaned_exploitatie-_en_machinekosten (Train: 85, Test: 37)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:14,206] Trial 0 finished with values: [1261.2550031979622, 968.6221621621621, 0.08288560555723978] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 240, 'max_depth': 18, 'learning_rate': 0.11046657323727396, 'subsample': 0.8810456630430727, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1261.2550, MAE=968.6222, R²=0.0829, Time=1.11s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:15,667] Trial 1 finished with values: [1553.029706338636, 1202.1164864864866, -0.3905199746606274] and parameters: {'objective': 'reg:linear', 'n_estimators': 276, 'max_depth': 25, 'learning_rate': 0.19264803074815315, 'subsample': 0.7809615671036767, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1553.0297, MAE=1202.1165, R²=-0.3905, Time=1.46s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:16,574] Trial 2 finished with values: [23559.882727386685, 20231.555405405405, -319.0102982512269] and parameters: {'objective': 'reg:linear', 'n_estimators': 138, 'max_depth': 7, 'learning_rate': 0.08521761370259814, 'subsample': 0.5297711480363473, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=23559.8827, MAE=20231.5554, R²=-319.0103, Time=0.91s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:17,504] Trial 3 finished with values: [22489.84146711373, 16550.092972972976, -290.60199708183734] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 66, 'max_depth': 30, 'learning_rate': 0.07812638874154465, 'subsample': 0.9352560001282515, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=22489.8415, MAE=16550.0930, R²=-290.6020, Time=0.93s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:18,499] Trial 4 finished with values: [22191.168122298175, 16497.8827027027, -282.9082634006822] and parameters: {'objective': 'reg:linear', 'n_estimators': 167, 'max_depth': 19, 'learning_rate': 0.05224971610826749, 'subsample': 0.9509585894519617, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=22191.1681, MAE=16497.8827, R²=-282.9083, Time=0.99s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:19,650] Trial 5 finished with values: [21904.33650427461, 15767.481081081083, -275.61639124760063] and parameters: {'objective': 'reg:linear', 'n_estimators': 294, 'max_depth': 28, 'learning_rate': 0.07440444387697666, 'subsample': 0.7416225654925285, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=21904.3365, MAE=15767.4811, R²=-275.6164, Time=1.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:20,654] Trial 6 finished with values: [1440.1163559174936, 1098.8332432432433, -0.195674236701864] and parameters: {'objective': 'reg:linear', 'n_estimators': 217, 'max_depth': 8, 'learning_rate': 0.09428492477603302, 'subsample': 0.8041428956231729, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1440.1164, MAE=1098.8332, R²=-0.1957, Time=1.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:21,563] Trial 7 finished with values: [32418.74046201038, 27107.649729729732, -604.9125961007251] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 107, 'max_depth': 22, 'learning_rate': 0.19028236170884028, 'subsample': 0.5182901289462141, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=32418.7405, MAE=27107.6497, R²=-604.9126, Time=0.91s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:22,566] Trial 8 finished with values: [25513.956103931498, 19578.601891891893, -374.2954627059215] and parameters: {'objective': 'reg:linear', 'n_estimators': 181, 'max_depth': 20, 'learning_rate': 0.11715303171675533, 'subsample': 0.7315846079014108, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=25513.9561, MAE=19578.6019, R²=-374.2955, Time=1.00s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:23,627] Trial 9 finished with values: [1835.0271291344604, 1394.9556756756758, -0.9413448340328248] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 214, 'max_depth': 22, 'learning_rate': 0.17509682052381953, 'subsample': 0.6790324996535302, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1835.0271, MAE=1394.9557, R²=-0.9413, Time=1.06s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:24,468] Trial 10 finished with values: [1203.3174700935879, 923.9632432432433, 0.16520824739707662] and parameters: {'objective': 'reg:linear', 'n_estimators': 54, 'max_depth': 17, 'learning_rate': 0.03375275428986708, 'subsample': 0.6063193044609718, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1203.3175, MAE=923.9632, R²=0.1652, Time=0.84s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:25,556] Trial 11 finished with values: [1299.7757187486804, 954.5167567567566, 0.0260098943998206] and parameters: {'objective': 'reg:linear', 'n_estimators': 274, 'max_depth': 15, 'learning_rate': 0.04277233447987447, 'subsample': 0.9343997274931053, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1299.7757, MAE=954.5168, R²=0.0260, Time=1.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:26,450] Trial 12 finished with values: [1441.5246918425964, 1142.8597297297297, -0.1980139564760266] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 100, 'max_depth': 11, 'learning_rate': 0.182954484835008, 'subsample': 0.6244843630230872, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1441.5247, MAE=1142.8597, R²=-0.1980, Time=0.89s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:27,580] Trial 13 finished with values: [1379.4331371568853, 1054.922702702703, -0.09703129008267597] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 285, 'max_depth': 12, 'learning_rate': 0.11314141497250767, 'subsample': 0.8006071634661016, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1379.4331, MAE=1054.9227, R²=-0.0970, Time=1.13s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:28,653] Trial 14 finished with values: [1354.0783384639522, 1069.269189189189, -0.05707374721229286] and parameters: {'objective': 'reg:linear', 'n_estimators': 224, 'max_depth': 23, 'learning_rate': 0.18008493524656244, 'subsample': 0.865611932754565, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1354.0783, MAE=1069.2692, R²=-0.0571, Time=1.07s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: [{'objective': 'reg:linear', 'n_estimators': 54, 'max_depth': 17, 'learning_rate': 0.03375275428986708, 'subsample': 0.6063193044609718, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_exploitatie-_en_machinekosten_trajectory: 15.56 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:29,600] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_kostprijs_van_de_omzet_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_exploitatie-_en_machinekosten\n  Optimizing on Dataset: month_data_cleaned_kostprijs_van_de_omzet (Train: 110, Test: 48)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:30,701] Trial 0 finished with values: [1492.3601707788516, 1317.8052083333334, -0.36586802074459746] and parameters: {'objective': 'reg:linear', 'n_estimators': 68, 'max_depth': 29, 'learning_rate': 0.02610297457741003, 'subsample': 0.8891532285645822, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1492.3602, MAE=1317.8052, R²=-0.3659, Time=1.10s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:32,039] Trial 1 finished with values: [1364.66993322714, 1055.0108333333335, -0.14213301015148017] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 13, 'learning_rate': 0.11850856507212568, 'subsample': 0.9149629329636624, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1364.6699, MAE=1055.0108, R²=-0.1421, Time=1.34s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:33,182] Trial 2 finished with values: [2079.356595685009, 1751.943125, -1.651669455740187] and parameters: {'objective': 'reg:linear', 'n_estimators': 140, 'max_depth': 5, 'learning_rate': 0.14438123110869563, 'subsample': 0.5868949064772071, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=2079.3566, MAE=1751.9431, R²=-1.6517, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:34,357] Trial 3 finished with values: [1406.3700933327732, 1070.5083333333332, -0.2129996692224967] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 137, 'max_depth': 21, 'learning_rate': 0.08853745636072136, 'subsample': 0.7691198851014884, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1406.3701, MAE=1070.5083, R²=-0.2130, Time=1.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:35,509] Trial 4 finished with values: [1324.0757754955591, 1041.81625, -0.07519470645433235] and parameters: {'objective': 'reg:linear', 'n_estimators': 143, 'max_depth': 27, 'learning_rate': 0.1522065451728443, 'subsample': 0.7897763589616564, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1324.0758, MAE=1041.8163, R²=-0.0752, Time=1.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:36,711] Trial 5 finished with values: [1293.311041669469, 1024.2795833333332, -0.02581113330572049] and parameters: {'objective': 'reg:linear', 'n_estimators': 87, 'max_depth': 17, 'learning_rate': 0.01733928338293426, 'subsample': 0.7407800303966047, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1293.3110, MAE=1024.2796, R²=-0.0258, Time=1.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:37,884] Trial 6 finished with values: [1439.7047298491452, 1164.4583333333333, -0.2711836558621128] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.16354700853402906, 'subsample': 0.7614580757749227, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1439.7047, MAE=1164.4583, R²=-0.2712, Time=1.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:39,025] Trial 7 finished with values: [1507.9697380812222, 1334.5335416666667, -0.39459045958279737] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 84, 'max_depth': 8, 'learning_rate': 0.04515159135310777, 'subsample': 0.9590787346626715, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1507.9697, MAE=1334.5335, R²=-0.3946, Time=1.14s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:40,251] Trial 8 finished with values: [1343.217327903884, 1112.1543749999998, -0.10650660032425985] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 105, 'max_depth': 25, 'learning_rate': 0.09305386045408254, 'subsample': 0.8610283708452151, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1343.2173, MAE=1112.1544, R²=-0.1065, Time=1.22s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:41,441] Trial 9 finished with values: [2233.6228321360754, 1856.7122916666667, -2.0597160040653817] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 218, 'max_depth': 5, 'learning_rate': 0.12352035655180968, 'subsample': 0.5725968747214294, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=2233.6228, MAE=1856.7123, R²=-2.0597, Time=1.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:42,836] Trial 10 finished with values: [1448.1898616275537, 1284.6854166666667, -0.28621166208948634] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 25, 'learning_rate': 0.07902361471744496, 'subsample': 0.9511679865439202, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1448.1899, MAE=1284.6854, R²=-0.2862, Time=1.39s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:44,040] Trial 11 finished with values: [1518.7461240526675, 1310.9329166666666, -0.41459397052371516] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 127, 'max_depth': 5, 'learning_rate': 0.03898535467311575, 'subsample': 0.5543523688173821, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1518.7461, MAE=1310.9329, R²=-0.4146, Time=1.20s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:45,908] Trial 12 finished with values: [1824.287768868077, 1549.4366666666665, -1.0410240876996912] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 277, 'max_depth': 19, 'learning_rate': 0.1119457747056912, 'subsample': 0.8178853389196314, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1824.2878, MAE=1549.4367, R²=-1.0410, Time=1.86s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:46,995] Trial 13 finished with values: [1345.7072719631797, 1054.0956250000002, -0.11061270155226466] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 66, 'max_depth': 22, 'learning_rate': 0.042204803970809626, 'subsample': 0.5591916765548663, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1345.7073, MAE=1054.0956, R²=-0.1106, Time=1.09s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:48,239] Trial 14 finished with values: [1350.2697048452642, 1069.1031249999999, -0.11815622257748837] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 178, 'max_depth': 8, 'learning_rate': 0.06747865675128949, 'subsample': 0.7252997444443732, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1350.2697, MAE=1069.1031, R²=-0.1182, Time=1.24s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_kostprijs_van_de_omzet_trajectory: [{'objective': 'reg:linear', 'n_estimators': 87, 'max_depth': 17, 'learning_rate': 0.01733928338293426, 'subsample': 0.7407800303966047, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_kostprijs_van_de_omzet_trajectory: 18.64 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:49,357] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_kantoorkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_kostprijs_van_de_omzet\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:51,086] Trial 0 finished with values: [760.6066209512776, 522.8679365079365, -0.9399792850208049] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 255, 'max_depth': 30, 'learning_rate': 0.11845368456918466, 'subsample': 0.631256707847951, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=760.6066, MAE=522.8679, R²=-0.9400, Time=1.73s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:52,675] Trial 1 finished with values: [665.7272704427176, 570.4741269841269, -0.48617374411730574] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 187, 'max_depth': 11, 'learning_rate': 0.18705929700855517, 'subsample': 0.7769417723458061, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=665.7273, MAE=570.4741, R²=-0.4862, Time=1.59s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:54,144] Trial 2 finished with values: [579.6082774530255, 442.8253968253969, -0.12653852347637207] and parameters: {'objective': 'reg:linear', 'n_estimators': 99, 'max_depth': 6, 'learning_rate': 0.18339286060324178, 'subsample': 0.9205709653766743, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=579.6083, MAE=442.8254, R²=-0.1265, Time=1.47s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:55,733] Trial 3 finished with values: [697.9672888591989, 507.0739682539681, -0.6336049027235402] and parameters: {'objective': 'reg:linear', 'n_estimators': 221, 'max_depth': 8, 'learning_rate': 0.11617865629552517, 'subsample': 0.6788114203647658, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=697.9673, MAE=507.0740, R²=-0.6336, Time=1.59s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:57,415] Trial 4 finished with values: [577.389692707139, 391.24158730158734, -0.11793085544983262] and parameters: {'objective': 'reg:linear', 'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.031248356819949974, 'subsample': 0.9982038119537703, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=577.3897, MAE=391.2416, R²=-0.1179, Time=1.68s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:53:59,038] Trial 5 finished with values: [564.8908854182118, 398.7819047619048, -0.07005481181192708] and parameters: {'objective': 'reg:linear', 'n_estimators': 106, 'max_depth': 9, 'learning_rate': 0.06024254232383885, 'subsample': 0.7397760537625383, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=564.8909, MAE=398.7819, R²=-0.0701, Time=1.62s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:00,703] Trial 6 finished with values: [670.9588887022599, 441.9509523809524, -0.5096237193038127] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 284, 'max_depth': 9, 'learning_rate': 0.10308682267632253, 'subsample': 0.6130600537571684, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=670.9589, MAE=441.9510, R²=-0.5096, Time=1.66s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:02,367] Trial 7 finished with values: [742.4559544297923, 580.9039682539682, -0.8484949936097561] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 14, 'learning_rate': 0.10389336297465979, 'subsample': 0.5575783687768904, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=742.4560, MAE=580.9040, R²=-0.8485, Time=1.66s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:03,806] Trial 8 finished with values: [579.8507649948211, 453.44365079365076, -0.127481328162119] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 96, 'max_depth': 30, 'learning_rate': 0.06162789278290404, 'subsample': 0.5598818801513228, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=579.8508, MAE=453.4437, R²=-0.1275, Time=1.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:05,308] Trial 9 finished with values: [568.2081282766752, 391.53634920634926, -0.08265920721920073] and parameters: {'objective': 'reg:linear', 'n_estimators': 106, 'max_depth': 23, 'learning_rate': 0.07294079378926678, 'subsample': 0.5917264177784702, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=568.2081, MAE=391.5363, R²=-0.0827, Time=1.50s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:06,871] Trial 10 finished with values: [595.8331500499219, 438.7866666666665, -0.19049126665277027] and parameters: {'objective': 'reg:linear', 'n_estimators': 121, 'max_depth': 19, 'learning_rate': 0.1368899255953055, 'subsample': 0.7090017991284683, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=595.8332, MAE=438.7867, R²=-0.1905, Time=1.56s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:08,609] Trial 11 finished with values: [567.7520497359434, 403.3823809523809, -0.08092188795628918] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 278, 'max_depth': 11, 'learning_rate': 0.16595687076815646, 'subsample': 0.9891453072604047, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=567.7520, MAE=403.3824, R²=-0.0809, Time=1.74s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:10,055] Trial 12 finished with values: [552.933688579984, 379.6973015873016, -0.025233979097736947] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 97, 'max_depth': 10, 'learning_rate': 0.14741259099609622, 'subsample': 0.925672660502312, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=552.9337, MAE=379.6973, R²=-0.0252, Time=1.44s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:11,556] Trial 13 finished with values: [554.187107680292, 399.5426984126985, -0.029887355751061495] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 90, 'max_depth': 12, 'learning_rate': 0.09111753725022968, 'subsample': 0.7726968630626803, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=554.1871, MAE=399.5427, R²=-0.0299, Time=1.50s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:13,204] Trial 14 finished with values: [559.4879746583491, 385.64571428571435, -0.04968357696651138] and parameters: {'objective': 'reg:linear', 'n_estimators': 203, 'max_depth': 25, 'learning_rate': 0.01727041076126736, 'subsample': 0.6851784393506548, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=559.4880, MAE=385.6457, R²=-0.0497, Time=1.65s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_kantoorkosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 97, 'max_depth': 10, 'learning_rate': 0.14741259099609622, 'subsample': 0.925672660502312, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_kantoorkosten_trajectory: 23.85 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:14,764] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_verkoopkosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_kantoorkosten\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:15,949] Trial 0 finished with values: [340.0566137669825, 222.644358974359, -0.166021015605466] and parameters: {'objective': 'reg:linear', 'n_estimators': 246, 'max_depth': 28, 'learning_rate': 0.07746595489790098, 'subsample': 0.5390868831523424, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=340.0566, MAE=222.6444, R²=-0.1660, Time=1.18s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:16,967] Trial 1 finished with values: [329.19898226312444, 225.80153846153843, -0.09275019836512999] and parameters: {'objective': 'reg:linear', 'n_estimators': 80, 'max_depth': 20, 'learning_rate': 0.11871636768119369, 'subsample': 0.7609639123223664, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=329.1990, MAE=225.8015, R²=-0.0928, Time=1.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:17,955] Trial 2 finished with values: [335.63842957135915, 246.18410256410257, -0.135918798955025] and parameters: {'objective': 'reg:linear', 'n_estimators': 120, 'max_depth': 14, 'learning_rate': 0.03904164686692196, 'subsample': 0.6780211695532088, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=335.6384, MAE=246.1841, R²=-0.1359, Time=0.99s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:18,845] Trial 3 finished with values: [337.69452993982895, 259.5110256410256, -0.14987856406225797] and parameters: {'objective': 'reg:linear', 'n_estimators': 97, 'max_depth': 6, 'learning_rate': 0.11244906798759959, 'subsample': 0.7180036576458059, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=337.6945, MAE=259.5110, R²=-0.1499, Time=0.89s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:19,784] Trial 4 finished with values: [332.6393939388418, 247.81487179487178, -0.11570990236977718] and parameters: {'objective': 'reg:linear', 'n_estimators': 80, 'max_depth': 28, 'learning_rate': 0.07410007242069057, 'subsample': 0.5696236592246529, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=332.6394, MAE=247.8149, R²=-0.1157, Time=0.94s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:20,858] Trial 5 finished with values: [347.60197926245974, 260.5679487179487, -0.21833973223518366] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 204, 'max_depth': 9, 'learning_rate': 0.08063046707875259, 'subsample': 0.8728418599229575, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=347.6020, MAE=260.5679, R²=-0.2183, Time=1.07s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:21,923] Trial 6 finished with values: [367.7697130103189, 250.07717948717945, -0.36381620957940886] and parameters: {'objective': 'reg:linear', 'n_estimators': 238, 'max_depth': 16, 'learning_rate': 0.09604654888339571, 'subsample': 0.5348616391154837, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=367.7697, MAE=250.0772, R²=-0.3638, Time=1.06s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:23,089] Trial 7 finished with values: [321.57226022889154, 224.27333333333328, -0.04270410316434603] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 281, 'max_depth': 11, 'learning_rate': 0.010934443987811243, 'subsample': 0.6442325877941922, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=321.5723, MAE=224.2733, R²=-0.0427, Time=1.16s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:24,256] Trial 8 finished with values: [332.05273952051186, 238.4961538461539, -0.11177796301233478] and parameters: {'objective': 'reg:linear', 'n_estimators': 230, 'max_depth': 18, 'learning_rate': 0.09240909761466082, 'subsample': 0.6497746044507975, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=332.0527, MAE=238.4962, R²=-0.1118, Time=1.17s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:25,157] Trial 9 finished with values: [354.3010288672759, 277.69179487179485, -0.2657523815602658] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 71, 'max_depth': 18, 'learning_rate': 0.15923279254714195, 'subsample': 0.8621994782694757, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=354.3010, MAE=277.6918, R²=-0.2658, Time=0.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:26,117] Trial 10 finished with values: [337.3619954239219, 249.11256410256405, -0.14761506251292578] and parameters: {'objective': 'reg:linear', 'n_estimators': 105, 'max_depth': 21, 'learning_rate': 0.049745161773537334, 'subsample': 0.7356288943238118, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=337.3620, MAE=249.1126, R²=-0.1476, Time=0.96s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:27,373] Trial 11 finished with values: [342.43046594930246, 246.26666666666665, -0.18235725287803128] and parameters: {'objective': 'reg:linear', 'n_estimators': 286, 'max_depth': 27, 'learning_rate': 0.1443150244695865, 'subsample': 0.7772958784925608, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=342.4305, MAE=246.2667, R²=-0.1824, Time=1.25s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:28,582] Trial 12 finished with values: [353.7742109283105, 232.36512820512826, -0.26199103032951254] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 280, 'max_depth': 15, 'learning_rate': 0.12518542649871867, 'subsample': 0.6542316753832214, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=353.7742, MAE=232.3651, R²=-0.2620, Time=1.21s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:29,464] Trial 13 finished with values: [312.39219163966936, 204.30282051282052, 0.015979228014650793] and parameters: {'objective': 'reg:linear', 'n_estimators': 53, 'max_depth': 24, 'learning_rate': 0.028040949185427787, 'subsample': 0.8039218847745134, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=312.3922, MAE=204.3028, R²=0.0160, Time=0.88s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:30,596] Trial 14 finished with values: [330.4868398365179, 242.47820512820513, -0.10131680672726273] and parameters: {'objective': 'reg:linear', 'n_estimators': 196, 'max_depth': 25, 'learning_rate': 0.023911196224729786, 'subsample': 0.9172861519179587, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=330.4868, MAE=242.4782, R²=-0.1013, Time=1.13s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_verkoopkosten_trajectory: [{'objective': 'reg:linear', 'n_estimators': 53, 'max_depth': 24, 'learning_rate': 0.028040949185427787, 'subsample': 0.8039218847745134, 'prediction_mode': 'Zero', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_verkoopkosten_trajectory: 15.83 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:31,491] A new study created in memory with name: TrainerXGBoostPattern_month_data_cleaned_huisvestingskosten_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_verkoopkosten\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:32,273] Trial 0 finished with values: [1573.3507190176426, 1248.2846666666667, -0.7064308070023637] and parameters: {'objective': 'reg:linear', 'n_estimators': 142, 'max_depth': 11, 'learning_rate': 0.1648349264907361, 'subsample': 0.9146384472186194, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=1573.3507, MAE=1248.2847, R²=-0.7064, Time=0.78s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:33,074] Trial 1 finished with values: [1403.522759769146, 1076.3429999999998, -0.3579272902022075] and parameters: {'objective': 'reg:linear', 'n_estimators': 124, 'max_depth': 30, 'learning_rate': 0.18365737095922627, 'subsample': 0.9342004859363303, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=1403.5228, MAE=1076.3430, R²=-0.3579, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:34,041] Trial 2 finished with values: [1256.602320550672, 1010.0160000000001, -0.08851222750016574] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 183, 'max_depth': 30, 'learning_rate': 0.14215570359686241, 'subsample': 0.9966419249618463, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=1256.6023, MAE=1010.0160, R²=-0.0885, Time=0.97s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:34,908] Trial 3 finished with values: [1314.92837128745, 1035.0856666666666, -0.19190540457104754] and parameters: {'objective': 'reg:linear', 'n_estimators': 203, 'max_depth': 17, 'learning_rate': 0.15522510165407233, 'subsample': 0.7904035487497401, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=1314.9284, MAE=1035.0857, R²=-0.1919, Time=0.87s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:35,759] Trial 4 finished with values: [1550.126811470597, 1186.5, -0.6564260550655527] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.0694714797287985, 'subsample': 0.8534160823909931, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=1550.1268, MAE=1186.5000, R²=-0.6564, Time=0.85s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:36,567] Trial 5 finished with values: [1460.034083230023, 1054.5126666666667, -0.4694796813684061] and parameters: {'objective': 'reg:linear', 'n_estimators': 104, 'max_depth': 8, 'learning_rate': 0.18851771847571785, 'subsample': 0.8190238636208864, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=1460.0341, MAE=1054.5127, R²=-0.4695, Time=0.81s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:37,473] Trial 6 finished with values: [1246.053992360149, 948.3236666666666, -0.07031427851521] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 205, 'max_depth': 17, 'learning_rate': 0.1276337481950338, 'subsample': 0.6648517900420634, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=1246.0540, MAE=948.3237, R²=-0.0703, Time=0.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:38,518] Trial 7 finished with values: [1348.1031366640066, 1024.4256666666668, -0.2528060313157263] and parameters: {'objective': 'reg:linear', 'n_estimators': 200, 'max_depth': 30, 'learning_rate': 0.1814217186874093, 'subsample': 0.928684671196624, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=1348.1031, MAE=1024.4257, R²=-0.2528, Time=1.04s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:39,324] Trial 8 finished with values: [1265.6611230499261, 986.8253333333333, -0.10426289029766811] and parameters: {'objective': 'reg:linear', 'n_estimators': 116, 'max_depth': 17, 'learning_rate': 0.08074631042481688, 'subsample': 0.8108979010171136, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=1265.6611, MAE=986.8253, R²=-0.1043, Time=0.80s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:40,043] Trial 9 finished with values: [1246.004427742267, 966.6966666666667, -0.07022913186270907] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 74, 'max_depth': 28, 'learning_rate': 0.1122127276176554, 'subsample': 0.5847391942415687, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=1246.0044, MAE=966.6967, R²=-0.0702, Time=0.72s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:40,752] Trial 10 finished with values: [1540.2162939470545, 1230.9686666666666, -0.6353135080073116] and parameters: {'objective': 'reg:linear', 'n_estimators': 70, 'max_depth': 27, 'learning_rate': 0.08775700737539063, 'subsample': 0.6695645611677331, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=1540.2163, MAE=1230.9687, R²=-0.6353, Time=0.71s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:41,602] Trial 11 finished with values: [1198.0445961065057, 933.3480000000002, 0.010573435493570704] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 22, 'learning_rate': 0.019008987240688772, 'subsample': 0.8011205090048772, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=1198.0446, MAE=933.3480, R²=0.0106, Time=0.85s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:42,546] Trial 12 finished with values: [1753.4764613827394, 1420.479, -1.1195197988757952] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 59, 'max_depth': 12, 'learning_rate': 0.09242951540298917, 'subsample': 0.6947492426489434, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=1753.4765, MAE=1420.4790, R²=-1.1195, Time=0.94s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:43,561] Trial 13 finished with values: [1225.488317720736, 930.4909999999999, -0.035275528273823964] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 30, 'learning_rate': 0.0814301599801918, 'subsample': 0.8035392013649212, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=1225.4883, MAE=930.4910, R²=-0.0353, Time=1.01s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:44,269] Trial 14 finished with values: [1960.0719409229175, 1616.4926666666665, -1.6483880552192307] and parameters: {'objective': 'reg:linear', 'n_estimators': 56, 'max_depth': 23, 'learning_rate': 0.09115424209866504, 'subsample': 0.5885864732085935, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=1960.0719, MAE=1616.4927, R²=-1.6484, Time=0.71s\nBest hyperparameters for TrainerXGBoostPattern_month_data_cleaned_huisvestingskosten_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 22, 'learning_rate': 0.019008987240688772, 'subsample': 0.8011205090048772, 'prediction_mode': 'Zero', 'outlier_removal': 1}, {'objective': 'reg:squarederror', 'n_estimators': 267, 'max_depth': 30, 'learning_rate': 0.0814301599801918, 'subsample': 0.8035392013649212, 'prediction_mode': 'Zero', 'outlier_removal': 0}]\nTotal optimization time for TrainerXGBoostPattern_month_data_cleaned_huisvestingskosten_trajectory: 12.78 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:45,118] A new study created in memory with name: TrainerXGBoostPattern_day_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on month_data_cleaned_huisvestingskosten\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:54:56,140] Trial 0 finished with values: [741.2770463317661, 597.5668854415275, -0.18150101638941263] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 238, 'max_depth': 29, 'learning_rate': 0.10986531140924362, 'subsample': 0.8616501939857444, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 0: RMSE=741.2770, MAE=597.5669, R²=-0.1815, Time=11.02s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:55:05,632] Trial 1 finished with values: [729.1933957485568, 590.4159904534606, -0.14329537873450104] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 220, 'max_depth': 10, 'learning_rate': 0.11356895880336576, 'subsample': 0.7547617067963477, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 1: RMSE=729.1934, MAE=590.4160, R²=-0.1433, Time=9.49s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:55:15,190] Trial 2 finished with values: [722.4015653311734, 582.5180071599045, -0.12209687146440662] and parameters: {'objective': 'reg:linear', 'n_estimators': 136, 'max_depth': 24, 'learning_rate': 0.046843764864833215, 'subsample': 0.8876045077033791, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 2: RMSE=722.4016, MAE=582.5180, R²=-0.1221, Time=9.56s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:55:24,090] Trial 3 finished with values: [696.7663986158242, 568.9195465393794, -0.04387234552752095] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 71, 'max_depth': 12, 'learning_rate': 0.05677080152390654, 'subsample': 0.7528150388482309, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 3: RMSE=696.7664, MAE=568.9195, R²=-0.0439, Time=8.90s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:55:34,117] Trial 4 finished with values: [748.2394609695474, 595.2336754176611, -0.2037996472923449] and parameters: {'objective': 'reg:linear', 'n_estimators': 217, 'max_depth': 21, 'learning_rate': 0.0828045019502708, 'subsample': 0.9535161267056977, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 4: RMSE=748.2395, MAE=595.2337, R²=-0.2038, Time=10.03s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:55:45,265] Trial 5 finished with values: [726.4962849087716, 584.5073269689738, -0.13485347116819546] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 222, 'max_depth': 20, 'learning_rate': 0.13207221174222006, 'subsample': 0.7107175733163413, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 5: RMSE=726.4963, MAE=584.5073, R²=-0.1349, Time=11.15s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:55:54,559] Trial 6 finished with values: [722.700023667854, 583.6938544152746, -0.12302424583148719] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 114, 'max_depth': 26, 'learning_rate': 0.12401414543334278, 'subsample': 0.5826281420603262, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 6: RMSE=722.7000, MAE=583.6939, R²=-0.1230, Time=9.29s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:04,018] Trial 7 finished with values: [740.2026938374988, 595.9548806682577, -0.17807873663601903] and parameters: {'objective': 'reg:linear', 'n_estimators': 286, 'max_depth': 11, 'learning_rate': 0.14225563884750925, 'subsample': 0.5726376821778187, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 7: RMSE=740.2027, MAE=595.9549, R²=-0.1781, Time=9.46s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:13,331] Trial 8 finished with values: [732.4058635191783, 592.5167422434367, -0.15339116361941163] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 132, 'max_depth': 15, 'learning_rate': 0.1058712291350316, 'subsample': 0.5144984825242469, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 8: RMSE=732.4059, MAE=592.5167, R²=-0.1534, Time=9.31s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:22,877] Trial 9 finished with values: [745.5999450984139, 602.863353221957, -0.1953214955750573] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 234, 'max_depth': 13, 'learning_rate': 0.14711521656826348, 'subsample': 0.5423572625618931, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 9: RMSE=745.5999, MAE=602.8634, R²=-0.1953, Time=9.55s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:32,646] Trial 10 finished with values: [723.1548813900462, 582.8011097852029, -0.12443832355155626] and parameters: {'objective': 'reg:linear', 'n_estimators': 177, 'max_depth': 25, 'learning_rate': 0.15888809768745857, 'subsample': 0.7891921910107529, 'prediction_mode': 'Zero', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 10: RMSE=723.1549, MAE=582.8011, R²=-0.1244, Time=9.77s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:42,295] Trial 11 finished with values: [793.1974387744649, 629.2468377088305, -0.3528062504942011] and parameters: {'objective': 'reg:linear', 'n_estimators': 117, 'max_depth': 26, 'learning_rate': 0.07807430815406469, 'subsample': 0.9908340030061716, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 11: RMSE=793.1974, MAE=629.2468, R²=-0.3528, Time=9.65s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:50,831] Trial 12 finished with values: [698.9455994803213, 564.3947971360382, -0.05041216965502482] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 6, 'learning_rate': 0.15068625570437363, 'subsample': 0.7916327454195324, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 12: RMSE=698.9456, MAE=564.3948, R²=-0.0504, Time=8.53s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:56:59,902] Trial 13 finished with values: [730.0407351090663, 591.4385441527446, -0.14595399314563617] and parameters: {'objective': 'reg:squarederror', 'n_estimators': 191, 'max_depth': 12, 'learning_rate': 0.08703769650987589, 'subsample': 0.7902551897342253, 'prediction_mode': 'Zero', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 13: RMSE=730.0407, MAE=591.4385, R²=-0.1460, Time=9.07s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:57:10,800] Trial 14 finished with values: [738.9599039302989, 590.4081622911694, -0.17412610238963033] and parameters: {'objective': 'reg:linear', 'n_estimators': 254, 'max_depth': 23, 'learning_rate': 0.09934435054585514, 'subsample': 0.9563963317044781, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Trial 14: RMSE=738.9599, MAE=590.4082, R²=-0.1741, Time=10.90s\nBest hyperparameters for TrainerXGBoostPattern_day_data_trajectory: [{'objective': 'reg:squarederror', 'n_estimators': 71, 'max_depth': 12, 'learning_rate': 0.05677080152390654, 'subsample': 0.7528150388482309, 'prediction_mode': 'Zero', 'outlier_removal': 0}, {'objective': 'reg:squarederror', 'n_estimators': 72, 'max_depth': 6, 'learning_rate': 0.15068625570437363, 'subsample': 0.7916327454195324, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1}]\nTotal optimization time for TrainerXGBoostPattern_day_data_trajectory: 145.68 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-19 13:57:19,813] A new study created in memory with name: TrainerXGBoostPattern_weather_data_trajectory\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Added results for TrainerXGBoostPattern on day_data\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-19 13:57:19,816] Trial 0 failed with parameters: {'objective': 'reg:squarederror', 'n_estimators': 192, 'max_depth': 25, 'learning_rate': 0.19554986467585356, 'subsample': 0.9121490320366128, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0} because of the following error: KeyError(\"['category', 'value'] not in index\").\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-a235616a-a90f-4730-b3b4-aa0a287651f8/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/root/.ipykernel/1794/command-4368468108118930-1706241585\", line 33, in objective\n    trainer.fit(train_data)\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/trainers/trainer_xgboost_pattern.py\", line 41, in fit\n    pdf_train = self._preprocessing(pdf_train, True)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Workspace/Users/n.gavrilov@student.fontys.nl/Claire/abstract_classes/trainer.py\", line 132, in _preprocessing\n    df = df[relevant_columns]\n         ~~^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/frame.py\", line 3813, in __getitem__\n    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6070, in _get_indexer_strict\n    self._raise_if_missing(keyarr, indexer, axis_name)\n  File \"/databricks/python/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 6133, in _raise_if_missing\n    raise KeyError(f\"{not_found} not in index\")\nKeyError: \"['category', 'value'] not in index\"\n[W 2025-01-19 13:57:21,451] Trial 0 failed with value None.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with trainer TrainerXGBoostPattern on dataset weather_data: \"['category', 'value'] not in index\"\n\nResults saved to 'trajectory_hpo_results_with_metrics.csv'\n                  Trainer  ...                                        Trial_Times\n0  TrainerAverageLastYear  ...  [0.027338743209838867, 0.023395776748657227, 0...\n1  TrainerAverageLastYear  ...  [0.009859085083007812, 0.010011911392211914, 0...\n2  TrainerAverageLastYear  ...  [0.014024972915649414, 0.013925552368164062, 0...\n3  TrainerAverageLastYear  ...  [0.013763189315795898, 0.012886524200439453, 0...\n4  TrainerAverageLastYear  ...  [0.015198945999145508, 0.014044523239135742, 0...\n\n[5 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def perform_trajectory_based_hpo(trainer, train_data, test_data, study_name=\"trajectory_hpo\", n_trials=15):\n",
    "    \"\"\"\n",
    "    Perform trajectory-based multi-objective hyperparameter optimization.\n",
    "    \"\"\"\n",
    "    trial_times = []\n",
    "\n",
    "    def objective(trial):\n",
    "        # Start timer for the trial\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Define the hyperparameter space\n",
    "        hyperparameters = {}\n",
    "        if hasattr(trainer, \"space_hyperparameters\"):\n",
    "            for param, values in trainer.space_hyperparameters.items():\n",
    "                if isinstance(values[0], int):\n",
    "                    hyperparameters[param] = trial.suggest_int(param, min(values), max(values))\n",
    "                elif isinstance(values[0], float):\n",
    "                    hyperparameters[param] = trial.suggest_float(param, min(values), max(values))\n",
    "                elif isinstance(values[0], bool):\n",
    "                    hyperparameters[param] = trial.suggest_categorical(param, [True, False])\n",
    "                else:\n",
    "                    hyperparameters[param] = trial.suggest_categorical(param, values)\n",
    "\n",
    "        # Set the hyperparameters\n",
    "        trainer.hyperparameters = hyperparameters\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(train_data)\n",
    "\n",
    "        # Predict\n",
    "        predictions = trainer.predict(test_data)\n",
    "\n",
    "        # Evaluate metrics\n",
    "        rmse = ((test_data['value'] - predictions) ** 2).mean() ** 0.5\n",
    "        mae = np.abs(test_data['value'] - predictions).mean()\n",
    "        r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n",
    "                  sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "\n",
    "        # End timer for the trial\n",
    "        trial_time = time.time() - start_time\n",
    "        trial_times.append(trial_time)\n",
    "\n",
    "        print(f\"  Trial {trial.number}: RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}, Time={trial_time:.2f}s\")\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    # Start timer for the entire optimization process\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create a multi-objective study and optimize\n",
    "    study = optuna.create_study(directions=[\"minimize\", \"minimize\", \"maximize\"], study_name=study_name)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # End timer for the optimization process\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Extract the best hyperparameters based on Pareto-optimal solutions\n",
    "    best_trials = study.best_trials\n",
    "    best_hyperparameters = [trial.params for trial in best_trials]\n",
    "\n",
    "    print(f\"Best hyperparameters for {study_name}: {best_hyperparameters}\")\n",
    "    print(f\"Total optimization time for {study_name}: {total_time:.2f} seconds\")\n",
    "\n",
    "    return best_hyperparameters, total_time, trial_times, best_trials\n",
    "\n",
    "\n",
    "def run_trainers_with_trajectory_hpo(trainers, data_splits, n_trials=15):\n",
    "    \"\"\"\n",
    "    Run trajectory-based multi-objective HPO for all trainers on all datasets.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    w1, w2, w3 = 0.5, 0.3, 0.2  # Weights for combined performance score\n",
    "\n",
    "    for trainer in trainers:\n",
    "        trainer_name = trainer.__class__.__name__\n",
    "        print(f\"\\nProcessing Trainer: {trainer_name}\")\n",
    "\n",
    "        for dataset_name, splits in data_splits.items():\n",
    "            train_data = splits['train']\n",
    "            test_data = splits['test']\n",
    "\n",
    "            print(f\"  Optimizing on Dataset: {dataset_name} (Train: {len(train_data)}, Test: {len(test_data)})\")\n",
    "\n",
    "            try:\n",
    "                # Perform trajectory-based optimization\n",
    "                best_hyperparams, total_time, trial_times, best_trials = perform_trajectory_based_hpo(\n",
    "                    trainer, train_data, test_data, \n",
    "                    study_name=f\"{trainer_name}_{dataset_name}_trajectory\", \n",
    "                    n_trials=n_trials\n",
    "                )\n",
    "\n",
    "                # Fit the model with the best hyperparameters (from the first Pareto-optimal solution)\n",
    "                trainer.hyperparameters = best_hyperparams[0]\n",
    "                trainer.fit(train_data)\n",
    "\n",
    "                # Predict on the test dataset\n",
    "                predictions = trainer.predict(test_data)\n",
    "\n",
    "                # Compute metrics\n",
    "                best_rmse = ((test_data['value'] - predictions) ** 2).mean() ** 0.5\n",
    "                mae = np.abs(test_data['value'] - predictions).mean()\n",
    "                r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n",
    "                          sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "\n",
    "                # Calculate combined performance score\n",
    "                combined_performance_score = (\n",
    "                    w1 * (1 / best_rmse) + w2 * (1 / mae) + w3 * r2\n",
    "                )\n",
    "\n",
    "                # Append results\n",
    "                results.append({\n",
    "                    \"Trainer\": trainer_name,\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Best_Hyperparameters\": best_hyperparams[0],\n",
    "                    \"Best_RMSE\": best_rmse,\n",
    "                    \"MAE\": mae,\n",
    "                    \"R2\": r2,\n",
    "                    \"Combined_Performance_Score\": combined_performance_score,\n",
    "                    \"Total_Time\": total_time,\n",
    "                    \"Average_Trial_Time\": np.mean(trial_times),\n",
    "                    \"Trial_Times\": trial_times\n",
    "                })\n",
    "\n",
    "                print(f\"  Added results for {trainer_name} on {dataset_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error with trainer {trainer_name} on dataset {dataset_name}: {e}\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_df.to_csv(\"trajectory_hpo_results_with_metrics.csv\", index=False)\n",
    "    print(\"\\nResults saved to 'trajectory_hpo_results_with_metrics.csv'\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Run the optimization\n",
    "trajectory_results_df = run_trainers_with_trajectory_hpo(trainers, data_splits, n_trials=15)\n",
    "\n",
    "# Display the results\n",
    "print(trajectory_results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a9a9e29-1ceb-4097-8afa-19f241edb566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize_trajectory_based_hpo_aggregated(results):\n",
    "    \"\"\"\n",
    "    Aggregated summary of Trajectory-Based Hyperparameter Optimization.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary of results with keys being trainer-dataset combinations\n",
    "                 and values containing 'best_rmse', 'mae', 'r2', 'combined_performance_score', \n",
    "                 'total_time', 'trial_times', and 'best_hyperparameters'.\n",
    "\n",
    "    Returns:\n",
    "        Summary DataFrame containing overall averages across all trainers and datasets.\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for key, value in results.items():\n",
    "        best_rmse = value.get('best_rmse', None)\n",
    "        mae = value.get('mae', None)\n",
    "        r2 = value.get('r2', None)\n",
    "        combined_performance_score = value.get('combined_performance_score', None)\n",
    "        total_time = value.get('total_time', None)\n",
    "        trial_times = value.get('trial_times', [])\n",
    "\n",
    "        summary_data.append({\n",
    "            \"Best_RMSE\": best_rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2,\n",
    "            \"Combined_Performance_Score\": combined_performance_score,\n",
    "            \"Total_Time\": total_time,\n",
    "            \"Avg_Trial_Time\": np.mean(trial_times) if trial_times else None\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for aggregated metrics\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Calculate overall averages\n",
    "    overall_metrics = {\n",
    "        \"Average_Best_RMSE\": summary_df[\"Best_RMSE\"].mean(),\n",
    "        \"Average_MAE\": summary_df[\"MAE\"].mean(),\n",
    "        \"Average_R2\": summary_df[\"R2\"].mean(),\n",
    "        \"Average_Combined_Performance_Score\": summary_df[\"Combined_Performance_Score\"].mean(),\n",
    "        \"Average_Total_Time\": summary_df[\"Total_Time\"].mean(),\n",
    "        \"Average_Trial_Time\": summary_df[\"Avg_Trial_Time\"].mean()\n",
    "    }\n",
    "\n",
    "    aggregated_summary_df = pd.DataFrame([overall_metrics])\n",
    "\n",
    "    # Save aggregated summary to CSV\n",
    "    aggregated_summary_df.to_csv(\"trajectory_hpo_aggregated_summary.csv\", index=False)\n",
    "    print(\"\\nAggregated summary saved to 'trajectory_hpo_aggregated_summary.csv'\")\n",
    "\n",
    "    # Return the aggregated summary\n",
    "    return aggregated_summary_df\n",
    "\n",
    "# Example usage\n",
    "aggregated_summary_df = summarize_trajectory_based_hpo_aggregated(trajectory_results)\n",
    "aggregated_summary_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c508c006-abf2-4d40-9cea-5923e4f2a341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Adaptive Fidelity Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ffa9e8-3da4-4158-8ca9-20bfb830f0d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nRunning AFI for Trainer: TrainerAverageLastYear\n  Optimizing on Dataset: week_data_cleaned_algemene_kosten (Train: 240, Test: 103)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nBest RMSE: 296.1690\nTotal Optimization Time: 0.90 seconds\n  Optimizing on Dataset: week_data_cleaned_autokosten (Train: 7, Test: 3)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nBest RMSE: 97.3927\nTotal Optimization Time: 0.23 seconds\n  Optimizing on Dataset: week_data_cleaned_exploitatie-_en_machinekosten (Train: 64, Test: 28)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nBest RMSE: 400.4802\nTotal Optimization Time: 0.21 seconds\n  Optimizing on Dataset: week_data_cleaned_huisvestingskosten (Train: 181, Test: 78)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nBest RMSE: 146.7331\nTotal Optimization Time: 0.80 seconds\n  Optimizing on Dataset: week_data_cleaned_kantoorkosten (Train: 108, Test: 47)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nBest RMSE: 367.4619\nTotal Optimization Time: 0.38 seconds\n  Optimizing on Dataset: week_data_cleaned_lonen_en_salarissen (Train: 37, Test: 17)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nBest RMSE: 522.7696\nTotal Optimization Time: 0.20 seconds\n  Optimizing on Dataset: week_data_cleaned_overige_bedrijfsopbrengsten (Train: 67, Test: 29)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nBest RMSE: 55.9193\nTotal Optimization Time: 0.24 seconds\n  Optimizing on Dataset: week_data_cleaned_overige_personeelskosten (Train: 244, Test: 105)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nBest RMSE: 202.9545\nTotal Optimization Time: 0.79 seconds\n  Optimizing on Dataset: week_data_cleaned_overige_rentelasten (Train: 208, Test: 90)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nBest RMSE: 215.6186\nTotal Optimization Time: 0.75 seconds\n  Optimizing on Dataset: week_data_cleaned_sociale_lasten (Train: 28, Test: 12)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nError in trial 1: float division by zero\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nError in trial 2: float division by zero\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nError in trial 3: float division by zero\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nError in trial 4: float division by zero\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nError in trial 5: float division by zero\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nError in trial 6: float division by zero\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nError in trial 7: float division by zero\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nError in trial 8: float division by zero\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nError in trial 9: float division by zero\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nError in trial 10: float division by zero\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nError in trial 11: float division by zero\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nError in trial 12: float division by zero\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nError in trial 13: float division by zero\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nError in trial 14: float division by zero\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nError in trial 15: float division by zero\n\nBest Hyperparameters: None\nBest RMSE: inf\nTotal Optimization Time: 0.60 seconds\n  Optimizing on Dataset: week_data_cleaned_verkoopkosten (Train: 217, Test: 93)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nBest RMSE: 342.7424\nTotal Optimization Time: 0.81 seconds\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_mva (Train: 102, Test: 45)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\n\nBest Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nBest RMSE: 777.2139\nTotal Optimization Time: 1.87 seconds\n  Optimizing on Dataset: month_data_cleaned_afschrijvingen_iva (Train: 34, Test: 15)\nTrial 1/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'month', 'pattern': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_period': 'year', 'pattern': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'avg_or_med': 'avg', 'time_period': 'week', 'pattern': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'avg_or_med': 'med', 'time_peri\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n': 0.5202049403486615, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 156, 'max_depth': 20, 'learning_rate': 0.10150545393771997, 'subsample': 0.9286450832098654, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 277, 'max_depth': 8, 'learning_rate': 0.030749424483873772, 'subsample': 0.7239616301541414, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.18363791037566476, 'subsample': 0.9945148048201463, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.03212293719784867, 'subsample': 0.544808182881771, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 127, 'max_depth': 28, 'learning_rate': 0.03320331101044072, 'subsample': 0.7127521703786202, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 152, 'max_depth': 16, 'learning_rate': 0.16812009810032122, 'subsample': 0.7197842870639067, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.11039294330572767, 'subsample': 0.7150436644049087, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 6, 'learning_rate': 0.0663468429718716, 'subsample': 0.7045301900605232, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 156, 'max_depth': 19, 'learning_rate': 0.03968766983100705, 'subsample': 0.7284157704214669, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 6, 'learning_rate': 0.06808892751386357, 'subsample': 0.8647873339172447, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 86, 'max_depth': 28, 'learning_rate': 0.030968753190429896, 'subsample': 0.706350995524782, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 232, 'max_depth': 25, 'learning_rate': 0.05025790380242075, 'subsample': 0.8665096963824764, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\n\nBest Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 287, 'max_depth': 10, 'learning_rate': 0.0857125787476602, 'subsample': 0.8483500595382474, 'fidelity': None, 'prediction_mode': 'Zero', 'outlier_removal': 1}\nBest RMSE: 2147.5275\nTotal Optimization Time: 3.09 seconds\n  Optimizing on Dataset: month_data_cleaned_kantoorkosten (Train: 144, Test: 63)\nTrial 1/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 97, 'max_depth': 25, 'learning_rate': 0.12793056040212042, 'subsample': 0.9422037081851788, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 192, 'max_depth': 18, 'learning_rate': 0.09349210844391016, 'subsample': 0.9886121451526126, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 300, 'max_depth': 16, 'learning_rate': 0.07749239154166891, 'subsample': 0.822673767670647, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 296, 'max_depth': 17, 'learning_rate': 0.14396330630317256, 'subsample': 0.5593427940931459, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 85, 'max_depth': 5, 'learning_rate': 0.022093466929527412, 'subsample': 0.7679960821362362, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 183, 'max_depth': 7, 'learning_rate': 0.07256262121859611, 'subsample': 0.6846788765126406, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 290, 'max_depth': 6, 'learning_rate': 0.11035578316342816, 'subsample': 0.7054998490159845, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 188, 'max_depth': 17, 'learning_rate': 0.03056554134311714, 'subsample': 0.6714775532114645, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 64, 'max_depth': 9, 'learning_rate': 0.04414095830356332, 'subsample': 0.8509209040139929, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 50, 'max_depth': 19, 'learning_rate': 0.180963676861252, 'subsample': 0.8274877397028082, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 108, 'max_depth': 16, 'learning_rate': 0.18565589768658694, 'subsample': 0.7669524964877505, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 279, 'max_depth': 27, 'learning_rate': 0.08813712318070481, 'subsample': 0.9888853815896707, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 297, 'max_depth': 26, 'learning_rate': 0.15227022998312378, 'subsample': 0.6754946608758301, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 184, 'max_depth': 28, 'learning_rate': 0.09281726698548057, 'subsample': 0.9553924126151725, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 219, 'max_depth': 8, 'learning_rate': 0.013985538604798113, 'subsample': 0.6678011524588561, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\n\nBest Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 97, 'max_depth': 25, 'learning_rate': 0.12793056040212042, 'subsample': 0.9422037081851788, 'fidelity': None, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\nBest RMSE: 730.8307\nTotal Optimization Time: 1.91 seconds\n  Optimizing on Dataset: month_data_cleaned_verkoopkosten (Train: 88, Test: 39)\nTrial 1/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 187, 'max_depth': 21, 'learning_rate': 0.15774594060669814, 'subsample': 0.7326059801813258, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 254, 'max_depth': 26, 'learning_rate': 0.09377794623193299, 'subsample': 0.5646310531931388, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 257, 'max_depth': 17, 'learning_rate': 0.10580662700386524, 'subsample': 0.9991997358539219, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 111, 'max_depth': 21, 'learning_rate': 0.04314784815507796, 'subsample': 0.5794529475854783, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 79, 'max_depth': 19, 'learning_rate': 0.05489918086868043, 'subsample': 0.9659983478530793, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 287, 'max_depth': 9, 'learning_rate': 0.10560057000305624, 'subsample': 0.6028302795480363, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 101, 'max_depth': 6, 'learning_rate': 0.1877511939807464, 'subsample': 0.6015778329004207, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 268, 'max_depth': 18, 'learning_rate': 0.0751998144969683, 'subsample': 0.6118393325543078, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 242, 'max_depth': 21, 'learning_rate': 0.08863270396049103, 'subsample': 0.7873007464449788, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 252, 'max_depth': 14, 'learning_rate': 0.17607786563243083, 'subsample': 0.6904963253048448, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 206, 'max_depth': 10, 'learning_rate': 0.056713582443039125, 'subsample': 0.5152530626599099, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 190, 'max_depth': 9, 'learning_rate': 0.04781259857958582, 'subsample': 0.9334277148758513, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.14898283201516482, 'subsample': 0.5874824443150242, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 98, 'max_depth': 17, 'learning_rate': 0.13210613685449293, 'subsample': 0.6215272254697813, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 224, 'max_depth': 20, 'learning_rate': 0.1275415779217198, 'subsample': 0.6475473296530827, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\n\nBest Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 187, 'max_depth': 21, 'learning_rate': 0.15774594060669814, 'subsample': 0.7326059801813258, 'fidelity': None, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0}\nBest RMSE: 416.8604\nTotal Optimization Time: 2.00 seconds\n  Optimizing on Dataset: month_data_cleaned_huisvestingskosten (Train: 69, Test: 30)\nTrial 1/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 145, 'max_depth': 18, 'learning_rate': 0.021466392052405678, 'subsample': 0.8508624947798361, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 154, 'max_depth': 25, 'learning_rate': 0.05159370257364503, 'subsample': 0.9678100546614592, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 206, 'max_depth': 19, 'learning_rate': 0.045522620835275154, 'subsample': 0.8871938121257552, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.09079799797967418, 'subsample': 0.8181222652313016, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 142, 'max_depth': 27, 'learning_rate': 0.04805583383033594, 'subsample': 0.5103725906437477, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 127, 'max_depth': 17, 'learning_rate': 0.12560267136424902, 'subsample': 0.7568683804351768, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 292, 'max_depth': 22, 'learning_rate': 0.015323749908913643, 'subsample': 0.5266058010604815, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 213, 'max_depth': 20, 'learning_rate': 0.11256036615370997, 'subsample': 0.7708562931867665, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 204, 'max_depth': 8, 'learning_rate': 0.14070325899905062, 'subsample': 0.5965384738616475, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 58, 'max_depth': 16, 'learning_rate': 0.14506160725533043, 'subsample': 0.944547168010452, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.13809748967183683, 'subsample': 0.6040402731270904, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 134, 'max_depth': 25, 'learning_rate': 0.05860801032777221, 'subsample': 0.7334505376779307, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 190, 'max_depth': 17, 'learning_rate': 0.029150411363749934, 'subsample': 0.9889936403469863, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 147, 'max_depth': 16, 'learning_rate': 0.058253928054694024, 'subsample': 0.8714976365231903, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 119, 'max_depth': 29, 'learning_rate': 0.09899651706700072, 'subsample': 0.8140518501319873, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\n\nBest Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 145, 'max_depth': 18, 'learning_rate': 0.021466392052405678, 'subsample': 0.8508624947798361, 'fidelity': None, 'prediction_mode': 'Zero', 'outlier_removal': 1}\nBest RMSE: 2078.4875\nTotal Optimization Time: 2.86 seconds\n  Optimizing on Dataset: day_data (Train: 977, Test: 419)\nTrial 1/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 22, 'learning_rate': 0.12078439577174083, 'subsample': 0.7765023437157192, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 2/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 55, 'max_depth': 12, 'learning_rate': 0.07160764704215537, 'subsample': 0.9082454355845271, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 3/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 212, 'max_depth': 20, 'learning_rate': 0.034153827066390224, 'subsample': 0.8798099309373477, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 4/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 272, 'max_depth': 12, 'learning_rate': 0.08288422607316505, 'subsample': 0.6819747200190281, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 5/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 234, 'max_depth': 21, 'learning_rate': 0.04382924656337569, 'subsample': 0.9818408193299604, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 6/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 188, 'max_depth': 16, 'learning_rate': 0.13471295732181532, 'subsample': 0.7052196735275478, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 7/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 205, 'max_depth': 24, 'learning_rate': 0.15615663367063964, 'subsample': 0.9841638473719012, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 8/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 112, 'max_depth': 11, 'learning_rate': 0.19273994547538834, 'subsample': 0.7440990108076256, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 9/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 230, 'max_depth': 7, 'learning_rate': 0.15550232435618608, 'subsample': 0.6481060194167694, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 10/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 67, 'max_depth': 15, 'learning_rate': 0.1989908935299415, 'subsample': 0.8316092633687058, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nTrial 11/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 183, 'max_depth': 16, 'learning_rate': 0.01847243001711525, 'subsample': 0.6606389616010213, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 12/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 124, 'max_depth': 24, 'learning_rate': 0.08696008498431274, 'subsample': 0.7222976748696751, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nTrial 13/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 234, 'max_depth': 20, 'learning_rate': 0.15786546891683872, 'subsample': 0.5594334481316525, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nTrial 14/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 193, 'max_depth': 12, 'learning_rate': 0.03173094168125783, 'subsample': 0.5826021821653005, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nTrial 15/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 287, 'max_depth': 14, 'learning_rate': 0.0780029968776898, 'subsample': 0.7405573920428017, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\n\nBest Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 84, 'max_depth': 22, 'learning_rate': 0.12078439577174083, 'subsample': 0.7765023437157192, 'fidelity': None, 'prediction_mode': 'Zero', 'outlier_removal': 0}\nBest RMSE: 1494.2797\nTotal Optimization Time: 12.26 seconds\n  Optimizing on Dataset: weather_data (Train: 4766, Test: 2043)\nTrial 1/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 276, 'max_depth': 9, 'learning_rate': 0.056982122572951134, 'subsample': 0.624240707574297, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nError in trial 1: \"['category', 'value'] not in index\"\nTrial 2/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 138, 'max_depth': 10, 'learning_rate': 0.1589649723437185, 'subsample': 0.6712471736904162, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nError in trial 2: \"['category', 'value'] not in index\"\nTrial 3/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 241, 'max_depth': 21, 'learning_rate': 0.04693946077951494, 'subsample': 0.5286065400170411, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nError in trial 3: \"['category', 'value'] not in index\"\nTrial 4/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 53, 'max_depth': 5, 'learning_rate': 0.13771824834522334, 'subsample': 0.7304620337855539, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nError in trial 4: \"['category', 'value'] not in index\"\nTrial 5/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 265, 'max_depth': 20, 'learning_rate': 0.1289072699169672, 'subsample': 0.7041418829442516, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nError in trial 5: \"['category', 'value'] not in index\"\nTrial 6/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 117, 'max_depth': 9, 'learning_rate': 0.19990575961387377, 'subsample': 0.6810692420572126, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nError in trial 6: \"['category', 'value'] not in index\"\nTrial 7/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 249, 'max_depth': 8, 'learning_rate': 0.14944353373166452, 'subsample': 0.8241744731067736, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nError in trial 7: \"['category', 'value'] not in index\"\nTrial 8/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 164, 'max_depth': 20, 'learning_rate': 0.18652793290697606, 'subsample': 0.8972925655989585, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nError in trial 8: \"['category', 'value'] not in index\"\nTrial 9/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 155, 'max_depth': 9, 'learning_rate': 0.07226167600287295, 'subsample': 0.571993959125142, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nError in trial 9: \"['category', 'value'] not in index\"\nTrial 10/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 79, 'max_depth': 8, 'learning_rate': 0.07445798565445892, 'subsample': 0.5735251578162444, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nError in trial 10: \"['category', 'value'] not in index\"\nTrial 11/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 252, 'max_depth': 21, 'learning_rate': 0.15061107886863362, 'subsample': 0.8657861886473215, 'prediction_mode': 'Zero', 'outlier_removal': 0, 'fidelity': None}\nError in trial 11: \"['category', 'value'] not in index\"\nTrial 12/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.06821782560551419, 'subsample': 0.5463573958359332, 'prediction_mode': 'AverageTrend', 'outlier_removal': 0, 'fidelity': None}\nError in trial 12: \"['category', 'value'] not in index\"\nTrial 13/15: Testing Hyperparameters: {'objective': 'reg:squarederror', 'n_estimators': 180, 'max_depth': 22, 'learning_rate': 0.1629448078200246, 'subsample': 0.6393008181270468, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nError in trial 13: \"['category', 'value'] not in index\"\nTrial 14/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 144, 'max_depth': 29, 'learning_rate': 0.12116877147784673, 'subsample': 0.7116945140926559, 'prediction_mode': 'AverageTrend', 'outlier_removal': 1, 'fidelity': None}\nError in trial 14: \"['category', 'value'] not in index\"\nTrial 15/15: Testing Hyperparameters: {'objective': 'reg:linear', 'n_estimators': 130, 'max_depth': 13, 'learning_rate': 0.017849490183408784, 'subsample': 0.7815984766746976, 'prediction_mode': 'Zero', 'outlier_removal': 1, 'fidelity': None}\nError in trial 15: \"['category', 'value'] not in index\"\n\nBest Hyperparameters: None\nBest RMSE: inf\nTotal Optimization Time: 0.03 seconds\n\nResults saved to 'afi_hpo_results_with_metrics.csv'\n                  Trainer  ...                                        Trial_Times\n0  TrainerAverageLastYear  ...  [0.0560605525970459, 0.08781695365905762, 0.06...\n1  TrainerAverageLastYear  ...  [0.0560605525970459, 0.08781695365905762, 0.06...\n2  TrainerAverageLastYear  ...  [0.0560605525970459, 0.08781695365905762, 0.06...\n3  TrainerAverageLastYear  ...  [0.0560605525970459, 0.08781695365905762, 0.06...\n4  TrainerAverageLastYear  ...  [0.0560605525970459, 0.08781695365905762, 0.06...\n\n[5 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def perform_afi_hpo(trainer, train_data, test_data, n_trials=15, fidelity_key='fidelity'):\n",
    "    \"\"\"\n",
    "    Perform Adaptive Fidelity Identification (AFI) hyperparameter optimization for a given trainer instance.\n",
    "    \"\"\"\n",
    "    trial_times = []\n",
    "    best_hyperparameters = None\n",
    "    best_rmse = float(\"inf\")  # Start with a very high RMSE\n",
    "    w1, w2, w3 = 0.5, 0.3, 0.2  # Weights for combined performance score\n",
    "    results = []\n",
    "\n",
    "    def evaluate_metrics(predictions, test_data):\n",
    "        rmse = ((test_data['value'] - predictions) ** 2).mean() ** 0.5\n",
    "        mae = abs(test_data['value'] - predictions).mean()\n",
    "        r2 = 1 - (sum((test_data['value'] - predictions) ** 2) /\n",
    "                  sum((test_data['value'] - test_data['value'].mean()) ** 2))\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        trial_start_time = time.time()\n",
    "\n",
    "        # Sample hyperparameters\n",
    "        hyperparameters = {}\n",
    "        fidelity_level = None\n",
    "\n",
    "        for param, values in trainer.space_hyperparameters.items():\n",
    "            if param == fidelity_key:\n",
    "                fidelity_level = random.choice(values)  # Select a fidelity level randomly\n",
    "            elif isinstance(values[0], int):\n",
    "                hyperparameters[param] = random.randint(min(values), max(values))\n",
    "            elif isinstance(values[0], float):\n",
    "                hyperparameters[param] = random.uniform(min(values), max(values))\n",
    "            elif isinstance(values[0], bool):\n",
    "                hyperparameters[param] = random.choice([True, False])\n",
    "            else:\n",
    "                hyperparameters[param] = random.choice(values)\n",
    "\n",
    "        # Combine fidelity with other hyperparameters\n",
    "        hyperparameters[fidelity_key] = fidelity_level\n",
    "\n",
    "        print(f\"Trial {trial + 1}/{n_trials}: Testing Hyperparameters: {hyperparameters}\")\n",
    "\n",
    "        # Set the hyperparameters\n",
    "        trainer.hyperparameters = hyperparameters\n",
    "\n",
    "        try:\n",
    "            # Split training data based on fidelity level\n",
    "            fidelity_train_data = train_data.sample(frac=fidelity_level, random_state=42)\n",
    "            trainer.fit(fidelity_train_data)\n",
    "\n",
    "            # Predict on the test data\n",
    "            predictions = trainer.predict(test_data)\n",
    "\n",
    "            # Evaluate metrics\n",
    "            rmse, mae, r2 = evaluate_metrics(predictions, test_data)\n",
    "\n",
    "            # Calculate combined performance score\n",
    "            combined_score = w1 * (1 / rmse) + w2 * (1 / mae) + w3 * r2\n",
    "\n",
    "            # Update best parameters\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_hyperparameters = hyperparameters\n",
    "\n",
    "            # Record trial results\n",
    "            results.append({\n",
    "                \"Trial\": trial + 1,\n",
    "                \"Hyperparameters\": hyperparameters,\n",
    "                \"Fidelity_Level\": fidelity_level,\n",
    "                \"RMSE\": rmse,\n",
    "                \"MAE\": mae,\n",
    "                \"R2\": r2,\n",
    "                \"Combined_Score\": combined_score,\n",
    "                \"Trial_Time\": time.time() - trial_start_time\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in trial {trial + 1}: {e}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nBest Hyperparameters: {best_hyperparameters}\")\n",
    "    print(f\"Best RMSE: {best_rmse:.4f}\")\n",
    "    print(f\"Total Optimization Time: {total_time:.2f} seconds\")\n",
    "\n",
    "    return best_hyperparameters, best_rmse, results, total_time\n",
    "\n",
    "\n",
    "def run_trainers_with_afi(trainers, data_splits, n_trials=15, fidelity_key='fidelity'):\n",
    "    \"\"\"\n",
    "    Run Adaptive Fidelity Identification (AFI) for all trainers on all datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - trainers: List of trainer objects.\n",
    "    - data_splits: Dictionary of train-test splits for each dataset.\n",
    "    - n_trials: Number of trials for AFI.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: DataFrame summarizing the results for all trainers and datasets.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for trainer in trainers:\n",
    "        trainer_name = trainer.__class__.__name__\n",
    "        print(f\"\\nRunning AFI for Trainer: {trainer_name}\")\n",
    "\n",
    "        for dataset_name, splits in data_splits.items():\n",
    "            train_data = splits['train']\n",
    "            test_data = splits['test']\n",
    "\n",
    "            print(f\"  Optimizing on Dataset: {dataset_name} (Train: {len(train_data)}, Test: {len(test_data)})\")\n",
    "\n",
    "            try:\n",
    "                # Perform AFI optimization\n",
    "                best_hyperparams, best_rmse, trial_results, total_time = perform_afi_hpo(\n",
    "                    trainer, train_data, test_data, n_trials=n_trials, fidelity_key=fidelity_key\n",
    "                )\n",
    "\n",
    "                # Store results in a similar format to Optuna\n",
    "                for trial_result in trial_results:\n",
    "                    results.append({\n",
    "                        \"Trainer\": trainer_name,\n",
    "                        \"Dataset\": dataset_name,\n",
    "                        \"Best_Hyperparameters\": best_hyperparams,\n",
    "                        \"Best_RMSE\": best_rmse,\n",
    "                        \"MAE\": trial_result[\"MAE\"],\n",
    "                        \"R2\": trial_result[\"R2\"],\n",
    "                        \"Combined_Performance_Score\": trial_result[\"Combined_Score\"],\n",
    "                        \"Total_Time\": total_time,\n",
    "                        \"Average_Trial_Time\": np.mean([res[\"Trial_Time\"] for res in trial_results]),\n",
    "                        \"Trial_Times\": [res[\"Trial_Time\"] for res in trial_results]\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error with Trainer {trainer_name} on Dataset {dataset_name}: {e}\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_df.to_csv(\"afi_hpo_results_with_metrics.csv\", index=False)\n",
    "    print(\"\\nResults saved to 'afi_hpo_results_with_metrics.csv'\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "afi_results_df = run_trainers_with_afi(trainers, data_splits, n_trials=15)\n",
    "\n",
    "# Display results\n",
    "print(afi_results_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb76835-8392-4070-a907-e78f7d4854e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize_adaptive_fidelity_performance(results):\n",
    "    \"\"\"\n",
    "    Summarize the performance of Adaptive Fidelity Identification hyperparameter optimization.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary of results with keys being trainer-dataset combinations\n",
    "                 and values containing 'best_rmse', 'mae', 'r2', 'combined_performance_score', \n",
    "                 'total_time', 'trial_times', and 'best_hyperparameters'.\n",
    "\n",
    "    Returns:\n",
    "        Summary DataFrame containing generalized metrics for Adaptive Fidelity Identification optimization.\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "\n",
    "    for key, value in results.items():\n",
    "        trainer_name = value.get('trainer', 'Unknown')\n",
    "        dataset_name = value.get('dataset', 'Unknown')\n",
    "        best_rmse = value.get('best_rmse', None)\n",
    "        mae = value.get('mae', None)\n",
    "        r2 = value.get('r2', None)\n",
    "        combined_performance_score = value.get('combined_performance_score', None)\n",
    "        total_time = value.get('total_time', None)\n",
    "        trial_times = value.get('trial_times', [])\n",
    "        avg_trial_time = np.mean(trial_times) if trial_times else 0\n",
    "        best_hyperparameters = value.get('best_hyperparameters', {})\n",
    "\n",
    "        summary_data.append({\n",
    "            \"Trainer\": trainer_name,\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Best_RMSE\": best_rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2,\n",
    "            \"Combined_Performance_Score\": combined_performance_score,\n",
    "            \"Total_Time\": total_time,\n",
    "            \"Avg_Trial_Time\": avg_trial_time,\n",
    "            \"Best_Hyperparameters\": best_hyperparameters\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame for easier analysis\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Debug: Check the contents of the DataFrame\n",
    "    print(\"Adaptive Fidelity Identification Results DataFrame:\")\n",
    "    print(summary_df)\n",
    "\n",
    "    # Ensure the DataFrame is not empty\n",
    "    if summary_df.empty:\n",
    "        print(\"The results DataFrame is empty. Ensure the results dictionary is populated correctly.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Check for missing columns\n",
    "    required_columns = [\"Best_RMSE\", \"MAE\", \"R2\", \"Combined_Performance_Score\", \"Total_Time\", \"Avg_Trial_Time\"]\n",
    "    for col in required_columns:\n",
    "        if col not in summary_df.columns:\n",
    "            print(f\"Missing column: {col}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_avg_rmse = summary_df[\"Best_RMSE\"].mean()\n",
    "    overall_avg_mae = summary_df[\"MAE\"].mean()\n",
    "    overall_avg_r2 = summary_df[\"R2\"].mean()\n",
    "    overall_avg_score = summary_df[\"Combined_Performance_Score\"].mean()\n",
    "    overall_avg_time = summary_df[\"Total_Time\"].mean()\n",
    "    overall_avg_trial_time = summary_df[\"Avg_Trial_Time\"].mean()\n",
    "\n",
    "    # Print generalized metrics\n",
    "    print(\"\\n=== Generalized Adaptive Fidelity Identification Performance Summary ===\")\n",
    "    print(f\"Average RMSE Across All Trainers and Datasets: {overall_avg_rmse:.4f}\")\n",
    "    print(f\"Average MAE Across All Trainers and Datasets: {overall_avg_mae:.4f}\")\n",
    "    print(f\"Average R² Across All Trainers and Datasets: {overall_avg_r2:.4f}\")\n",
    "    print(f\"Average Combined Performance Score Across All Trainers and Datasets: {overall_avg_score:.4f}\")\n",
    "    print(f\"Average Total Optimization Time: {overall_avg_time:.2f} seconds\")\n",
    "    print(f\"Average Time Per Trial: {overall_avg_trial_time:.2f} seconds\")\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "# Summarize the performance\n",
    "adaptive_fidelity_summary_df = summarize_adaptive_fidelity_performance(afi_results)\n",
    "\n",
    "# Save summary to a CSV file\n",
    "adaptive_fidelity_summary_df.to_csv(\"adaptive_fidelity_summary_metrics.csv\", index=False)\n",
    "print(\"\\nAdaptive Fidelity Identification Summary saved to 'adaptive_fidelity_summary_metrics.csv'\")\n",
    "\n",
    "# Display the summary DataFrame\n",
    "adaptive_fidelity_summary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34538027-0e2f-4063-9349-ec576969453f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Apply the model(s) on the dataset\n",
    "# Look at the abstract class Trainer and the trainers itself for all functions\n",
    "# Each trainer has fit and predict as possible functions, some trainers have specific functions that are also useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd41d724-ff55-486a-9358-aae051018c02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:432)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:432)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:458)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:537)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:52)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:52)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:515)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:850)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:876)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:875)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:930)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:723)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1025)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:946)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:547)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:516)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$7(ActivityContextFactory.scala:638)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:638)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:616)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:238)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:516)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:406)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Review the results"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_claire",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}